{"pages":[],"posts":[{"title":"其它","text":"查看java的并发数：netstat -np|grep java|wc -l 两文件夹同步： rsync -ru –progress –delete /opt/rsync_test/f1/ /opt/rsync_test/f2/","link":"/2017/08/21/%E5%85%B6%E5%AE%83/"},{"title":"用Clonezilla再生龙备份系统及还原系统","text":"多台机器系统的克隆准备：2个U盘1、 下载Clonezilla系统 http://clonezilla.nchc.org.tw/clonezilla-live/download/2、 使用UltraISO制作启动盘 可参考：http://www.ultraiso.net/review/uplus.htm3、备份：在要备份的系统使用U盘启动 可参考：http://forum.ubuntu.org.cn/viewtopic.php?p=26435834、还原：在要还原的系统使用U盘启动 可参考：http://tiancong.blog.51cto.com/783138/776309 因图片还不会用，待完善。","link":"/2017/08/21/%E7%94%A8Clonezilla%E5%86%8D%E7%94%9F%E9%BE%99%E5%A4%87%E4%BB%BD%E7%B3%BB%E7%BB%9F%E5%8F%8A%E8%BF%98%E5%8E%9F%E7%B3%BB%E7%BB%9F/"},{"title":"CodePush部署","text":"简介CodePush是一个微软开发的云服务器。通过它，开发者可以直接在用户的设备上部署手机应用更新。CodePush相当于一个中心仓库，开发者可以推送当前的更新（包括JS/HTML/CSS/IMAGE等）到CoduPush，然后应用将会查询是否有更新。 安装nodejs采用源码包编译的方式1、下载nodejs源码包 https://github.com/nodejs/LTS/ 系统环境需求： gcc and g++ 4.9.4 or newer Python 2.6 or 2.7 GNU Make 3.81 or newer查看系统环境是否满足 123456789101112131415161718192021222324$ gcc --versiongcc (Ubuntu 5.5.0-12ubuntu1~14.04) 5.5.0 20171010Copyright (C) 2015 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.$ g++ --versiong++ (Ubuntu 5.5.0-12ubuntu1~14.04) 5.5.0 20171010Copyright (C) 2015 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.$ /usr/bin/pythonPython 2.7.6 (default, Oct 26 2016, 20:30:19)[GCC 4.8.4] on linux2Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; quit();$ make -vGNU Make 3.81Copyright (C) 2006 Free Software Foundation, Inc.This is free software; see the source for copying conditions.There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR APARTICULAR PURPOSE. 不满足的话进行安装或者更新。 1、安装nodejs 12345$ wget http://nodejs.org/dist/latest-v8.x/node-v8.11.1.tar.gz$ tar -zxvf node-v8.11.1.tar.gz$ cd node-v8.11.1$ ./configure$ make &amp;&amp; make install 2、安装npm 12$ wget http://npmjs.org/install.sh$ sh install.sh 3、设置淘宝镜像 12vi ~/.npmrcregistry = https://registry.npm.taobao.org 采用官方编译好的安装包1、下载编译好的安装包 123$ wget https://nodejs.org/dist/v8.11.1/node-v8.11.1-linux-x64.tar.xz$ tar -xvJf node-v8.11.1-linux-x64.tar.xz$ cd node-v8.11.1-linux-x64 2、添加到环境变量 vim /etc/profile 123#NODEJSexport NODEJS_HOME=/usr/local/nodejs/node-v8.11.1-linux-x64export PATH=$NODEJS_HOME/bin:$PATH source /etc/profile 3、验证版本 1234$ node --version v8.11.1$ npm --version 5.6.0 安装 code-push-server1、全局安装 1npm install code-push-server -g 2、修改配置文件vim /dbdata/nodejs/node-v8.11.1/lib/node_modules/code-push-server/config/config.js 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152db: { username: &quot;root&quot;, password: &quot;123456&quot;, database: &quot;codepush&quot;, host: &quot;127.0.0.1&quot;, port: 3306, dialect: &quot;mysql&quot;, logging: false }, qiniu: { accessKey: &quot;&quot;, secretKey: &quot;&quot;, bucketName: &quot;CodePush&quot;, downloadUrl: &quot;http://codepush.zyzsks.com/download&quot; }, s3: { accessKeyId: process.env.AWS_ACCESS_KEY_ID, secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY, sessionToken: process.env.AWS_SESSION_TOKEN, //(optional) bucketName: process.env.BUCKET_NAME, region: process.env.REGION, downloadUrl: process.env.DOWNLOAD_URL, // binary files download host address. }, oss: { accessKeyId: &quot;&quot;, secretAccessKey: &quot;&quot;, endpoint: &quot;&quot;, bucketName: &quot;&quot;, prefix: &quot;&quot;, // Key prefix in object key downloadUrl: &quot;&quot;, // binary files download host address. }, //文件存储在本地配置 当storageType为local时需要配置 local: { storageDir: &quot;/dbdata/nodejs/workspaces/storage&quot;, storage in storageDir. //文件下载地址 CodePush Server 地址 + '/download' download对应app.js里面的地址 downloadUrl: &quot;http://127.0.0.1:3000/download&quot;, public: '/download' }, jwt: { // 登录jwt签名密钥，必须更改，否则有安全隐患，可以使用随机生成的字符串 // Generate using: https://www.grc.com/passwords.htm tokenSecret: '6o1uI6A45I6buu9w4Wxlf1U1NyOS6vI5QkQssNcxTbw0TnPKy6h9bNfV5q7ZfU6' }, common: { tryLoginTimes: 0, diffNums: 3, dataDir: &quot;/dbdata/nodejs/workspaces/data&quot;, // 选择存储类型，目前支持local,oss,qiniu,s3配置 storageType: &quot;qiniu&quot;, // options value is (true | false), when it's true, it will cache updateCheck results in redis. updateCheckCache: true 3、 初始化数据库会在数据库中创建一个 database 名字是 codepush 1code-push-server-db init --dbhost localhost --dbuser root --dbpassword password 4、启动服务 12$ code-push-server$ nohup code-push-server &gt; /var/log/codepush.log 2&gt;&amp;1 &amp; //后台启动 启动完成后，打开 yourIp:3000 进行登录，默认密码为 admin,123456 安装 code-push-cli1、全局安装 1npm install code-push-cli@latest -g 2、相关命令 登录： code-push login http://127.0.0.1:3000 修改密码： 1$ curl -X PATCH -H \"Authorization: Bearer 登录获取的token\" -H \"Accept: application/json\" -H \"Content-Type:application/json\" -d '{\"oldPassword\":\"123456\",\"newPassword\":\"654321\"}'http://yourIp:3000/users/password 注销： code-push logout 列出登陆的token： code-push access-key ls 删除某个 key值： code-push access-key rm 在账号里面添加一个新的app：code-push app add code-push app 安装code-push-webcode-push-web 是 code-push-server web客户端，界面化操作，比较简单。可装可不装，如果不用，请把 code-push-server 配置文件中的 codePushWebUrl 这项注释。1、安装 1234$ cd /dbdata/nodejs/node-v8.11.1/lib/node_modules/$ git clone https://github.com/lisong/code-push-web.git$ cd code-push-web$ npm install 2、修改配置vim src/config.js 123456export const common = { api: { URL: 'http://localhost:3000', // production code-push-server address devURL: 'http://localhost:3000', // development code-push-server address },}; 3、启动 123456$ npm run build -- --release$ cd ./build$ npm install//启动服务$ node ./server.js$ nohup node ./server.js 2&gt;&amp;1 &amp; //后台启动 参考：https://segmentfault.com/a/1190000008159508 http://www.code-push.com/ https://www.npmjs.com/package/code-push-server https://blog.csdn.net/wnma3mz/article/details/77618475 node:https://www.cnblogs.com/lyzg/p/6012886.html","link":"/2018/05/02/CodePush/CodePush%E9%83%A8%E7%BD%B2/"},{"title":"vsftpd搭建FTP文件服务器","text":"1、查看是否安装 1vsftpd -version 2、安装vsftpd 1apt-get install vsftpd 3、配置vsftpdvim /etc/vsftpd.conf 12345678910111213#禁止匿名访问anonymous_enable=NO#接受本地用户local_enable=YES#允许上传write_enable=YES#用户只能访问限制的目录chroot_local_user=YES#设置固定目录，在结尾添加。如果不添加这一行，各用户对应自己的目录（用户家目录），当然这个文件夹自己建local_root=/home/uftpuserlist_file=/etc/vsftpd.user_listuserlist_enable=YESuserlist_deny=NO 4、新建一个文件夹用于FTP的工作目录 1$ mkdir /home/uftp 5、新建FTP用户并设置密码以及工作目录 12$ useradd -d /home/ftp -s /bin/bash uftp$ passwd uftp 6、启动服务 1$ service vsftpd start 7、访问ftp://192.168.1.90/ 待补充，配置待了解 参考：http://wiki.ubuntu.org.cn/Vsftpdhttps://www.cnblogs.com/stinson/p/5730681.html","link":"/2018/04/24/FTP/vsftpd%E6%90%AD%E5%BB%BAFTP%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"title":"git服务器的初步简单部署","text":"git服务器的初步简单部署环境：git服务器Ubuntu，开发机器Windows 7。 1、安装git 1$ apt-get install git2.创建git用户及权限 12root@ubuntu:/# adduser -m gitroot@ubuntu:/# passwd git 添加git用户后会在/home下生成git目录，我们并不希望这个用户通过ssh连接到服务器上面去，所以，我们要禁止这个用户使用ssh连接上去进行操作。我们通过编辑/etc/passwd权限文件来处理。 12#git:x:1001:1001:,,,:/home/git:/bin/bashgit:x:1001:1001:,,,:/home/git:/usr/bin/git-shell3、在开发机器上生成公钥 首先下载安装git 在本机生成密钥：1234567891011121314151617181920212223admin@admin-PC MINGW64 ~$ ssh-keygen.exeGenerating public/private rsa key pair.Enter file in which to save the key (/c/Users/admin/.ssh/id_rsa):Created directory '/c/Users/admin/.ssh'.Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /c/Users/admin/.ssh/id_rsa.Your public key has been saved in /c/Users/admin/.ssh/id_rsa.pub.The key fingerprint is:SHA256:49440Ss8DHEeufZG9U7sQWhe+zUOkkCvyEMjReHdwcg admin@admin-PCThe key's randomart image is:+---[RSA 2048]----+| .oo o. || ...E... || ...o.. . || ..o+. .+ o || ++S+o+.= . || .==ooo..*..|| =o+ ..+ooo|| .*o+ o..|| o=. |+----[SHA256]-----+ 把C:\\Users\\admin.ssh下的id_rsa.pub发送到git服务器上4、在服务器配置公钥1234$ cd /home/git/$ mkdir .ssh$ cd .ssh$ vi authorized_keys 把开发机器上的id_rsa.pub文件内容添加保存到authorized_keys文件。5、初始化一个git仓库12345678root@ubuntu:/home/git# su gitgit@ubuntu:~$ mkdir /home/git/repositoriesgit@ubuntu:~$ chown git:git /home/git/repositories/git@ubuntu:~$ chmod 755 /home/git/repositories/git@ubuntu:~$ cd repositories/git@ubuntu:~/repositories$ mkdir helloworld.gitgit@ubuntu:~/repositories$ cd helloworld.git/git@ubuntu:~/repositories/helloworld.git$ git --bare init 6、在本地克隆test仓库1$ git clone git@192.168.1.32:/home/git/repositories/helloworld.git 7、多用户与权限管理如果团队人数较少，把每个人的公钥收集起来放到服务器的/home/git/.ssh/authorized_keys文件里就是可行的。如果团队人数较多，就比较麻烦了，这时，可以用Gitosis来管理公钥。","link":"/2017/08/23/Git/git%E6%9C%8D%E5%8A%A1%E5%99%A8%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"git服务器的用户管理","text":"1、添加用户 要添加新用户alice，bob和carol，首先获取他们的公钥，并将它们分别添加到管理员“gitolite-admin/keydir”作为alice.pub，bob.pub和carol.pub。(以用户名进行命名。) 要添加一个新的仓库repo:foo,并给予上述这些用户不同级别的访问权限编辑 vim conf/gitolite.conf1234repo foo RW+ = alice RW = bob R = carol 完成这些更改后，请执行以下操作：1234git add confgit add keydirgit commit -m &quot;added foo, gave access to alice, bob, carol&quot;git push push完之后，gitolite将添加新的用户到 ~/.ssh/authorized_keys服务器上，以及创建一个名为foo的空的repo。 2、访问规则 1234567repo foo RW+ = alice - master = bob - refs/tags/v[0-9] = bob RW = bob RW refs/tags/v[0-9] = carol R = dave alice可以对任何分支或标签做任何事情, 创建，推送，删除,撤回，覆盖等。 bob 可以创建或推送名称不以“master”开头的分支，并创建名称不以“v”+数字开头的任何标签。 carol可以创建名称以“v”+数字开头的标签。 dave仅可以克隆。3、组 方便群组用户管理，下面是创建了两个组123456789@staff = alice bob carol@interns = ashokrepo secret RW = @staffrepo foss RW+ = @staff RW = @interns 组列表累积。以下两行与上面的@staff的早期定义具有相同的效果：12@staff = alice bob@staff = carol 可以在其它组中使用组名1@all-devs = @staff @interns 帮助用户1、用户可以通过 git clone git@host:reponame的形式克隆仓库。2、用户可以通过 ssh git@host info 查看可访问的仓库及权限。3、用户可以通过 ssh git@host help获取帮助。","link":"/2017/08/28/Git/git%E6%9C%8D%E5%8A%A1%E5%99%A8%EF%BC%88%E4%B8%89%EF%BC%89/"},{"title":"git服务器的权限控制","text":"权限控制git的权限控制是采用的gitolite，自身就是一个特殊的git版本库（gitolite-admin），他们的管理与配置都可以通过git的方式，分布式的进行修改，然后通过push的方式提交到服务器，服务器会通过所谓的钩子脚本自动更新权限控制文件。1、切换到git用户下(git仓库是在git用户下) 1su git gitolite本质就是根据你的配置，自动生成authorized_keys文件，所以它要求你的authorized_keys文件必须是空的，或者不存在，所以我们干脆删了它 1rm ~/.ssh/authorized_keys gitolite在初始化时需要通过某一用户的公钥文件指定一个超级管理员，gitolite安装成功后，只有这个超级管理员可以更新gitolite以更新各种权限控制（包括对其自身的更新权限控制），所以在初始化时需要指定该超级管理员账户的公钥文件（最好直接将其拷贝到git用户的主文件夹下）（下面的示例程序使用同一服务器上的另一常用管理员用户admin）。 新建admin用户 12root@ubuntu:~# useradd -m adminroot@ubuntu:~# passwd admin 切换到admin下，生成超级管理员账户的公钥文件 123root@ubuntu:~# su adminadmin@ubuntu:~$ ssh-keygenadmin@ubuntu:~$ sudo cp .ssh/id_rsa.pub /home/git/id_rsa.pub 2、安装gitolite``admin@ubuntu:/home/git$ su gitgit@ubuntu:$ cd ~git@ubuntu:$ git clone git://github.com/sitaramc/gitolitegit@ubuntu:$ mkdir -p $HOME/bin #为gitolite的二进制文件生成创建目录git@ubuntu:$ gitolite/install -to $HOME/bin/ # 编译生成安装文件git@ubuntu:~$ $HOME/bin/gitolite setup -pk id_rsa.pub # 安装并初始化，指定id_rsa.pub公钥文件对应的用户为超级管理员 1234 gitolite安装后本身是一个特殊的git版本库——gitolite-admin，分布式的进行修改，然后通过push的方式提交，其会通过钩子脚本执行权限更新。gitolite自动生成了两个版本库：gitolite-admin.git和testing.git，其中的gitol-admin.git就是那个权限控制的版本库。 接下来我们要做的，就是回到你刚刚指定的超级管理员账户的电脑跟账户下，clone出gitolite-admin这个特殊的git版本库（当前情况下，只有该超级管理员账户可以clone并更新gitolite-admin这个版本库），然后根据自己的需要对其进行配置（如添加更多的管理员账户、添加新的版本库并为不同的用户指定权限）3、权限设置 * root@ubuntu:# su adminadmin@ubuntu:/root$ cd ~admin@ubuntu:$ git clone git@192.168.1.32:gitolite-admin.git 123456如果上面的步骤都成功了的话，应该可以查看到有一个gitolite-admin的文件夹，文件夹下有两个目录conf、keydir。clone默认路径是/home/git/repositories，权限控制是只有当前的超级管理员用户可以访问gitolite-admin和testing两个版本库，你之前测试创建的版本库也已经无法访问，如果你尝试再次clone之前创建的测试版本库，就会提示没有权限。要继续访问之前创建的项目，需要将这个项目添加到gitolite的权限控制内。下面演示一下为当前的超级管理员用户指定之前创建的helloworld测试版本库的读写权限（可读可写），以此演示gitolite指定权限的一般流程：1、将需要指定权限的用户的ssh公钥文件，存放在gitolite-admin版本库的keydir目录下（如果提交的都是id_rsa.pub，可以将其重命名为该用户的id或者名称，同时也推荐这样重命名，以明示哪个公钥文件是哪个用户的），因为我们初始化时，gitolite已经将该超级管理员的公钥文件自动拷进去了，所以省略此步骤。2、编辑conf目录下的gitolite.conf文件，添加helloworld版本库管理组，为超级管理员指定读写权限（RW+，具体的权限定义，参考gitolite官方文档） repo gitolite-adminRW+ = id_rsa repo testing RW+ = @all repo helloworld RW+ = id_rsa 13、commit到本地 git commit -am ‘add the helloworld repo and add RW+ to id_rsa’ 1提交时，首先要用名称 git config –global user.email “you@example.com“git config –global user.name “Your Name” 14、push到git仓库 git push push成功，当前超级管理员用户应该就可以成功clone helloworld版本库，并进行添加、删除、修改与push等操作了。 参考：http://blog.csdn.net/xsl1990/article/details/25486211 https://github.com/sitaramc/gitolite","link":"/2017/08/28/Git/git%E6%9C%8D%E5%8A%A1%E5%99%A8%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"jenkins","text":"在构建服务器安装一个jenkins 服务在本机部署安装Jenkins很简单，但要在一个合适的构建服务器上安装Jenkins就需要稍微布置一下了。 在Linux上安装Jenkins，好的做法是为Jenkins常见一个用户和用户组，这使得在监控构建所使用的系统资源及排查问题构建更方便。 两种安装启动方式##一、Jenkins用户war包启动 准备构建服务器1、创建Jenkins用户及用户组。 12$ sudo groupadd build$ sudo useradd --create-home --shell /bin/bash --groups build jenkins 2、为Jenkins用户配置环境变量vim /home/jenkins/.bashrc 12export JAVA_HOME=/opt/java/jdk1.8.0_101export PATH=$JAVA_HOME/bin:$PATH 这样就可以在独立的环境中使用jenkins这个用户运行Jenkins了。 Jenkins主目录无论把war文件放在哪儿，Jenkins在运行服务后都会把它所有重要的数据放在一个专用的、隔离的Jenkins目录下。会存储关于构建服务器的配置信息、构建作业、构建产物、插件和一些其他的信息。默认情况下Jenkins主目录在当前用户主目录下的.jenkins。可以通过定义JENKINS_HONME环境变量改变Jenkins的主目录 以jenkins用户启动Jenkins12$ sudo su - jenkins$ java -jar /usr/local/jenkins/jenkins.war 其他参数：–httpPort=8080 –prefix=jenkins –daemon –logfile=/var/logs/jenkins.log ##二、安装为服务 在debian或ubuntu上安装Jenkins1234$ wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add -$ sudo sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ &gt; /etc/apt/sources.list.d/jenkins.list'$ sudo apt-get update$ sudo apt-get install jenkins 这种方式把Jenkins安装成一个服务，在/etc/init.d/jenkins配置了启动脚本。同时有一个相应的系统用户名‘jenkins’。Jenkins的主目录为/var/lib/jenkins。日志文件在/var/log/jenkins/jenkins.log。调整配置参数在/etc/default/jenkins。 其他安装参考：jenkins_install","link":"/2019/11/06/Jenkins/jenkins/"},{"title":"Jenkins全局工具配置","text":"jenkins系统管理》全局工具配置 安装好Jenkins,完成系统配置之后,然后配置全局工具，配置JDK，Git，Gradle，Ant，Maven等工具，单击Add（新增）按钮，添加实例的名称和系统绝对地址。jdk、ant、Maven","link":"/2018/01/16/Jenkins/jenkins%E5%85%A8%E5%B1%80%E5%B7%A5%E5%85%B7%E9%85%8D%E7%BD%AE(%E4%B8%89)/"},{"title":"利用Ant进行对Jenkins自动部署项目","text":"新建一个项目。 选择 ”构建一个自由风格的软件项目” 项目名称与描述 github project :里面配置响应的url和需要显示的名称就可以了。 throttle builds：节流构建，通过设置时间段内允许并发的次数来实现构建的控制。 丢弃旧的构建：设置构建历史的保存策略。 参数化构建过程：里面可以配置不同的参数，便于在构建时引用这些参数。 关闭构建：这样项目就没法进行构建了。 在必要时进行并发构建：满足策略要求时就会进行并发构建。 安静期：设置一个时间来间隔每次构建的间隔。 重试次数：这个和系统设置的一样，拉取源码重试的次数。 该项目的上游项目正在构建时阻止该项目构建与该项目的下游项目正在构建时阻止该项目构建：用于上下游项目有关联的构建策略。 使用自定义的工作空间：使该项目独立于系统的工作空间。 保留构建的依赖日志。 源码管理 以svn为例 repository url:填写仓库的地址 Credentials：这里需要配置拉取svn源码的用户名和密码 Local module directory：具体的项目的路径，默认从根目录拉取 Additional Credentials：增加额外认证 Check-out Strategy：代码检出策略 源码库浏览器：这里默认就可以了 构建触发器 触发远程构建 (例如,使用脚本)：这里使用于自动化构建，拼接url后写入代码中可以实现在脚本或者工具执行构建 Build after other projects are built:构建与其他项目构建后，用于上下游项目有关联的时候 Build periodically：定时执行构建 日程表的参数第一个参数代表的是分钟 minute，取值 059；第二个参数代表的是小时 hour，取值 023；第三个参数代表的是天 day，取值 131；第四个参数代表的是月 month，取值 112；最后一个参数代表的是星期 week，取值 0~7，0 和 7 都是表示星期天。 Poll SCM：设置定时检查代码仓库是否有变更，有变更则构建 构建环境 Delete workspace before build starts：在构建之前清空工作空间 Abort the build if it’s stuck：如果构建出现问题则终止构建 Add timestamps to the Console Output：给控制台输出增加时间戳 Use secret text(s) or file(s)：使用加密文件或者文本 构建 execute windows batch command:执行windows的cmd。 execute shell:执行shell命令。 invoke ant:调用ant ,调用ant的执行脚本来进行构建。 invoke gradle script :调用grade脚本，来帮助我们自动打包。 invoke top-level maven targets:调用maven。 构建后操作 build other projects:构建其他项目 e-mail notification:发送邮件 editable email notification:发送邮件（这是一个插件，以后会单独介绍这个插件） delete workspace when build is done:构建后删除工作空间 Deploy war/ear to a container：部署war包到服务器。注意：war包地址必须为相对路径。其绝对路径为/root/.jenkins/workspace/materielshop/materielshop.war修改相应tomcat配置文件 config/tomcat-users.xml添加如下： 1234&lt;role rolename=&quot;manager-script&quot;/&gt;&lt;role rolename=&quot;manager-gui&quot;/&gt;&lt;role rolename=&quot;manager-status&quot;/&gt; &lt;user username=&quot;deploy&quot; password=&quot;deploy&quot; roles=&quot;manager-script,manager-gui,manager-status&quot;/&gt; 如tomcat管理不在服务本机管理，需修改：webapps/manager/META-INF/context.xml注释掉如下信息： 1234&lt;!-- &lt;Valve className=&quot;org.apache.catalina.valves.RemoteAddrValve&quot; allow=&quot;127\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1&quot; /&gt; --&gt; 其它：ant构建时的build.xml(仅参考) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt; &lt;project basedir=&quot;.&quot; default=&quot;warFile&quot; name=&quot;materielshop&quot;&gt; &lt;property environment=&quot;env&quot;/&gt; &lt;property name=&quot;destdir&quot; value=&quot;${basedir}/build/classes&quot; /&gt; &lt;property name=&quot;srcdir&quot; value=&quot;${basedir}/src&quot; /&gt; &lt;property name=&quot;classpath_lib&quot; value=&quot;${basedir}/web/WEB-INF/lib&quot; /&gt; &lt;property name=&quot;tomcat&quot; value=&quot;/opt/tomcat/tomcat9100&quot; /&gt; &lt;property name=&quot;war.output.dir&quot; value=&quot;${basedir}&quot;&gt;&lt;/property&gt; &lt;property name=&quot;warFileName&quot; value=&quot;materielshop.war&quot;&gt;&lt;/property&gt; &lt;property name=&quot;debuglevel&quot; value=&quot;source,lines,vars&quot;/&gt; &lt;property name=&quot;target&quot; value=&quot;1.8&quot;/&gt; &lt;property name=&quot;source&quot; value=&quot;1.8&quot;/&gt; &lt;path id=&quot;tomcatlib&quot;&gt; &lt;fileset dir=&quot;${tomcat}/lib&quot;&gt; &lt;include name=&quot;*.jar&quot;/&gt; &lt;/fileset&gt; &lt;/path&gt; &lt;path id=&quot;classpath&quot;&gt; &lt;path refid=&quot;tomcatlib&quot;/&gt; &lt;fileset dir=&quot;${classpath_lib}&quot;&gt; &lt;include name=&quot;*.jar&quot;/&gt; &lt;/fileset&gt; &lt;/path&gt; &lt;target name=&quot;init&quot;&gt; &lt;mkdir dir=&quot;build/classes&quot;/&gt; &lt;copy includeemptydirs=&quot;false&quot; todir=&quot;build/classes&quot;&gt; &lt;fileset dir=&quot;src&quot;&gt; &lt;exclude name=&quot;**/*.launch&quot;/&gt; &lt;exclude name=&quot;**/*.java&quot;/&gt; &lt;/fileset&gt; &lt;/copy&gt; &lt;copy includeemptydirs=&quot;false&quot; todir=&quot;build/classes&quot;&gt; &lt;fileset dir=&quot;resources&quot;&gt; &lt;exclude name=&quot;**/*.launch&quot;/&gt; &lt;exclude name=&quot;**/*.java&quot;/&gt; &lt;/fileset&gt; &lt;/copy&gt; &lt;copy includeemptydirs=&quot;false&quot; todir=&quot;build/classes&quot;&gt; &lt;fileset dir=&quot;dbmodel&quot;&gt; &lt;exclude name=&quot;**/*.launch&quot;/&gt; &lt;exclude name=&quot;**/*.java&quot;/&gt; &lt;/fileset&gt; &lt;/copy&gt; &lt;/target&gt; &lt;target name=&quot;clean&quot;&gt; &lt;delete dir=&quot;build/classes&quot;/&gt; &lt;/target&gt; &lt;target depends=&quot;init&quot; name=&quot;build&quot;&gt; &lt;echo message=&quot;${ant.project.name}: ${ant.file}&quot;/&gt; &lt;javac debug=&quot;true&quot; debuglevel=&quot;${debuglevel}&quot; srcdir=&quot;${srcdir}&quot; destdir=&quot;${destdir}&quot; includeantruntime=&quot;false&quot; source=&quot;${source}&quot; target=&quot;${target}&quot;&gt; &lt;src path=&quot;src&quot;/&gt; &lt;src path=&quot;resources&quot;/&gt; &lt;src path=&quot;dbmodel&quot;/&gt; &lt;compilerarg line=&quot;-encoding UTF-8 &quot;/&gt; &lt;classpath refid=&quot;classpath&quot;/&gt; &lt;/javac&gt;&lt;/target&gt; &lt;target name=&quot;warFile&quot; depends=&quot;build&quot;&gt; &lt;!-- 删除原有war包。 --&gt; &lt;delete dir=&quot;${war.output.dir}/${warFileName}&quot; /&gt; &lt;!-- 建立新war包。 --&gt; &lt;war destfile=&quot;${war.output.dir}/${warFileName}&quot; webxml=&quot;${basedir}/web/WEB-INF/web.xml&quot;&gt; &lt;!-- 拷贝web下除了WEB-INF和META-INF的两个文件夹。 --&gt; &lt;fileset dir=&quot;web&quot;&gt; &lt;include name=&quot;**/**.*&quot; /&gt; &lt;exclude name=&quot;**/WEB-INF/lib/**&quot;/&gt; &lt;/fileset&gt; &lt;!-- 将jar和class文件拷贝到war包的对应路径下。 --&gt; &lt;lib dir=&quot;${basedir}/web/WEB-INF/lib&quot; /&gt; &lt;classes dir=&quot;${basedir}/build/classes&quot; /&gt; &lt;/war&gt;&lt;/target&gt;&lt;/project&gt; 参考：https://www.jianshu.com/p/a154f2a1d0c3","link":"/2018/01/18/Jenkins/jenkins%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE%EF%BC%88%E5%9B%9B%EF%BC%89/"},{"title":"Jenkins安装部署","text":"jenkins是基于Java开发的一种持续集成工具，用于监控持续重复的工作,使软件持续集成。 功能： 持续、自动地构建/测试软件项目。 监控一些定时执行的任务。特性： 易于安装-只要把jenkins.war部署到servlet容器，不需要数据库支持。 易于配置-所有配置都是通过其提供的web界面实现。 集成RSS/E-mail通过RSS发布构建结果或当构建完成时通过e-mail通知。 生成JUnit/TestNG测试报告。 分布式构建支持Jenkins能够让多台计算机一起构建/测试。 文件识别:Jenkins能够跟踪哪次构建生成哪些jar，哪次构建使用哪个版本的jar等。 插件支持:支持扩展插件。 安装：从Jenkins官方网站https://jenkins.io/下载最新的war包。设置jenkins工作空间及时间vim /etc/profile 123#jenkinsexport JENKINS_HOME=/usr/local/jenkinsexport JENKINS_JAVA_OPTIONS=&quot;-Dorg.apache.commons.jelly.tags.fmt.timeZone=Asia/Shanghai&quot; 启动 第一种 1$ java -jar jenkins.jar 在浏览器输入：http://localhost:8080/在后台以9999端口启动 1$ nohup java -jar jenkins.war --httpPort=9999 &amp; 第二种把war包放到tomcat的webapps目录下，然后启动tomcat即可。在浏览器输入：http://localhost:8080/jenkins 第一次启动Jenkins时，出于安全考虑，Jenkins会在控制台自动生成一个随机的安装口令。Jenkins默认工作空间为系统用户的根目录下.jenkins，即 ~/.jenkins。也可设定Jenkins的工作空间，即在环境变量中定义JENKINS_HOME变量。","link":"/2018/01/16/Jenkins/jenkins%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"Jenkins应用--上传文件至七牛","text":"上传前端文件至七牛 在Ubuntu服务器上搭建了Samba服务。 更新前端文件时，只要把压缩包上传至共享文件夹的指定目录，然后通过jenkins进行构建时，会解压前端的压缩包，然后把解压后的文件拷贝到jenkins工作空间，然后通过七牛上传插件上传到七牛空间，并把index文件上传到服务器nginx文件夹下。 12345678910111213141516171819202122232425262728#!/bin/bashQINIUPREFIX=jndjrd #七牛前缀FILE_DIR=/ssdb2/share/front/qiniu/jndjrdUNPACK_DIR=$FILE_DIR/unpack #解压输出目录PROJECT_DIR=$WORKSPACE/$QINIUPREFIX #上传文件目录cd $FILE_DIRzipCnt=`ls -l |grep \"^-\"|wc -l`echo \"zipCnt=$zipCnt\"if [ \"$zipCnt\" -eq \"1\" ];then cp $FILE_DIR/* /ssdb2/share/front/backup/ #备份 zipName=`find *.zip` echo \"zipName=$zipName\" unzip $zipName -d $UNPACK_DIRelse echo \"压缩文件存在 $zipCnt 个，构建退出\" set -e #注意，一定要先设置这个 exit 1 #然后再退出，jenkins就会报红显示构建失败fiecho $WORKSPACErm -r $PROJECT_DIR/mkdir $PROJECT_DIRcd $UNPACK_DIR/*/cp -r ./ $PROJECT_DIRrm -r $FILE_DIR/* #清空目录，注意：删除高危操作！！！！ 脚本实现的主要是判断上传要更新的文件夹的前端压缩包个数，如果压缩包个数为1，则 拷贝压缩包至备份目录下，然后解压压缩包到unpack文件夹下，然后清空jenkins工作空间上次构建的文件，接着把解压后的文件拷贝到工作空间，等待着通过jenkins插件进行上传。然后清空上传的目录，以便下次更新上传压缩包。","link":"/2019/12/27/Jenkins/jenkins%E5%BA%94%E7%94%A8--%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E8%87%B3%E4%B8%83%E7%89%9B/"},{"title":"Jenkins无法重启tomcat原因","text":"在使用Hudson的执行sh脚本的时候，如果sh脚本是一个后台进程，如 Tomcat 这样的服务。如果使用Hudson的默认配置，会发现这些sh 进程有启动的过程，但是不会常驻后台，看Hudson 输出的日志，发现Hudson在Job构建结束之后，kill所有未终止的衍生进程。 在Hudson另一wiki页面上进一步描述了Hudson杀掉衍生进程的情况。Hudson在执行Job时会设置一系列环境变量，这些环境变量将被Job衍生出的进程继承。Hudson在kill衍生进程的时候会查看进程的环境变量，如果找到它之前设置的环境变量，则将其杀掉。Wiki上给出了一个简单的方法来避免进程被kill掉：修改Hudson设置的环境变量BUILD_ID的值，从而让Hudson认为此进程不是由Job的构建过程衍生的。 解决：打开：系统管理 &gt; 系统设置在 全局属性 中的 环境变量 中设置BUILD_ID 值为 allow_to_run_as_daemon 参考：https://blog.csdn.net/maotongbin/article/details/53079921","link":"/2018/04/04/Jenkins/jenkins%E6%97%A0%E6%B3%95%E9%87%8D%E5%90%AFtomcat%E5%8E%9F%E5%9B%A0/"},{"title":"Jenkins系统配置","text":"jenkins系统管理》系统配置 jenkins 部署完成后，需要进行系统设置。 主目录：默认是用户目录下的 .jenkins，该目录下主要存储Jenkins所有的数据文件，可以通过设置系统环境变量JENKINS_HOME来修改该路径。 系统消息：设置了该信息之后，会显示在首页顶部，主要是用来发布系统公告。 执行者数量：表示本机同时可以执行的构建数目，默认为2，说明最多可同时进行2个项目构建，如果设置为0，表示禁止构建。 标记：用来记录这个机器的名称（为了分配节点使用)。 生成前等待时间：这个时间为构建开始前的等待时间。 SCM签出重试次数：如果从git、svn中下载代码失败，需要重试的次数。 Restrict project naming：限制项目命名，勾选后可以看到具体设置，可以设置为默认或者使用正则表达式进行限制。 全局属性environment variables:设置全局变量，在这里定义的全局变量可以在构建或者发送邮件时引用。tool locations:设置全局工具，也可以把需要的工具都在这里进行配置，比如maven，ant,jdk等。 设置时间格式 Jenkins locationjenkins url :设置jenkins的url(发送邮件引用jenkins的地址会取这个值，如果设错了，邮件的连接就会打不开)。系统管理员邮件地址：管理员的邮件地址（在构建需要发送邮件时，会用到这个邮件地址）。 代码托管仓库设置：这里根据实际情况进行设置。 Extended E-mail Notification(邮件插件)SMTP server :发送邮件的服务器Default user E-mail suffix:默认邮箱后缀（如果配置了这个后面的邮箱就不用写后缀了）use smtp authentication:使用smtp用户认证，这个选项需要配合邮箱开启smtp服务，这样邮箱才能通过第三方工具发送邮件。 百度开启smtp服务。user name:认证的邮箱password:认证的密码（并非邮箱的密码，是开启smtp时给的一串字符）如果邮箱是ssl链接，就需要勾选use sslsmtp port :如果你的smtp服务不是465的端口，需要配置对应的端口charset:邮件编码设置default content type:设置邮件发送的格式：文本格式或者html格式Use List-ID Email Header：设置邮件的发送的名称（便于过滤）Default Recipients：设置默认的收件人Reply To List：设置默认回复列表Emergency reroute:相当于一个邮件的转发（邮件先发送到这里，然后在进行进一步处理）Excluded Recipients：设置接收的黑名单（就是不发送给这些人）Default Subject：设置默认的邮件主题Maximum Attachment Size：这只邮件附件的最大值Default Content：设置邮件的默认内容（里面可以引用一些环境变量的参数，或者插件的一些变量）Default Pre-send Script：在发送邮件前执行的脚本default triggers:设置默认的发送邮件策略，根据情况选择 邮件通知：这是默认的邮件发送工具，配置和ext email插件设置差不多，只是不能设置邮件的默认发送策略，和邮件发送的内容等信息 根据需要设置。不需要可不设置。参考：https://www.jianshu.com/p/a154f2a1d0c3","link":"/2018/01/18/Jenkins/jenkins%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"前端文件更新方案","text":"前端文件(除index.html在服务器nginx下)存储在七牛中。 通过samba进行各项目前端文件的暂存。之后由jenkins各项目分别调取，然后上传至七牛及服务器。 jenkins相关配置 1234567891011121314151617181920212223242526272829#!/bin/bashQINIUPREFIX=xaxy #七牛前缀FILE_DIR=/ssdb2/share/front/qiniu/xaxyUNPACK_DIR=$FILE_DIR/unpack #解压输出目录PROJECT_DIR=$WORKSPACE/$QINIUPREFIX #上传文件目录cd $FILE_DIRzipCnt=`ls -l |grep \"^-\"|wc -l`echo \"zipCnt=$zipCnt\"if [ \"$zipCnt\" -eq \"1\" ];then cp $FILE_DIR/* /ssdb2/share/front/backup/ #备份 zipName=`find *.zip` echo \"zipName=$zipName\" unzip $zipName -d $UNPACK_DIRelse echo \"压缩文件存在 $zipCnt 个，构建退出\" set -e #注意，一定要先设置这个 exit 1 #然后再退出，jenkins就会报红显示构建失败fiecho $WORKSPACErm -r $PROJECT_DIR/mkdir $PROJECT_DIRcd $UNPACK_DIR/*/cp -r ./ $PROJECT_DIRrm -r $FILE_DIR/* #清空目录，注意：删除高危操作！！！！ 文件路径填写七牛前缀名。 要上传到的 bucket填写要上传至七牛空间名 下面是把index.html上传至的服务器目录。 由于项目是在太多，更新上传前端很多时非常费时，又容易出差错。 所以进行了改良，前端文件包名都带有(xx七牛前缀名)，所以把前端文件上传至统一目录，然后根据包上的前缀名，进行提取。 12345678910111213141516171819202122232425262728#!/bin/bashQINIUPREFIX=$qiniuPrefix FILE_DIR=/ssdb2/share/front/updateUNPACK_DIR=$FILE_DIR/unpack/$QINIUPREFIX #解压输出目录PROJECT_DIR=$WORKSPACE/$QINIUPREFIX #上传文件目录cd $FILE_DIRzipCnt=`find *$QINIUPREFIX*.zip |wc -l`if [ \"$zipCnt\" -eq \"1\" ];then zipName=`find *$QINIUPREFIX*.zip` echo \"zipName=$zipName\" mkdir -p $UNPACK_DIR unzip $zipName -d $UNPACK_DIR mv $FILE_DIR/$zipName /ssdb2/share/front/backup/ #备份 else echo \"压缩文件存在 $zipCnt 个，构建退出\" set -e #注意，一定要先设置这个 exit 1 #然后再退出，jenkins就会报红显示构建失败fiecho $WORKSPACErm -r $PROJECT_DIR/mkdir $PROJECT_DIRcd $UNPACK_DIR/*/cp -r ./ $PROJECT_DIRrm -r $UNPACK_DIR/* #清空目录，注意：删除高危操作！！！！##rm -r $FILE_DIR/*","link":"/2020/05/23/Jenkins/%E5%89%8D%E7%AB%AF%E6%96%87%E4%BB%B6%E6%9B%B4%E6%96%B0%E6%96%B9%E6%A1%88/"},{"title":"Jenkins综合","text":"1、设置jenkins工作空间及时区vim /etc/profile 123#jenkinsexport JENKINS_HOME=/usr/local/jenkinsexport JENKINS_JAVA_OPTIONS=&quot;-Dorg.apache.commons.jelly.tags.fmt.timeZone=Asia/Shanghai&quot; 2、启动jenkins服务把war包放到tomcat的webapps目录下，然后启动tomcat即可。在浏览器输入：http://localhost:8080/jenkins 3、安装插件 Publish over SSH Maven Integration plugin4、系统设置在 全局属性 中的 环境变量 中设置BUILD_ID 值为 allow_to_run_as_daemon原因见 Jenkins无法重启tomcat原因5、全局工具配置安装JDK、Maven、Ant等如JDK安装 别名：JDK1.8 JAVA_HOME：/usr/local/java/jdk1.8.0_1716、利用maven进行构建项目 从SVN检出代码（主项目和配置文件） 构建触发器 可提交代码后，自动检测更新，进行构建。 也可进行定时构建 Build periodically 5 23 * * * （每天晚上23点05分构建）。 ![](https://ww1.sinaimg.cn/large/007iUjdily1fyd268z0hsj31470cbt9b.jpg) 进行配置文件替换 上传服务器，并进行重启 重启服务脚本123456789101112131415161718#!/bin/bashexport JAVAHOME=/usr/local/java/jdk1.8.0_151echo ${JAVAHOME}PROJECT_DIR=/usr/local/bootserver/boot8100/fourworker/APP_NAME=\"fourworker_test\"PORT=8100pid=`ps -ef | grep -v grep | grep $APP_NAME | grep $PORT | awk '{print $2}'`echo \"pid=$pid\"if [ -n \"$pid\" ]thenkill -9 $pidfisleep 2cd $PROJECT_DIRnohup ${JAVAHOME}/bin/java -jar $PROJECT_DIR/cpnsp-api-1.0.0-SNAPSHOT.jar --name=$APP_NAME --server.port=$PORT &gt;$PORT.log 2&gt;&amp;1 &amp;exit","link":"/2018/05/03/Jenkins/jenkins%E7%BB%BC%E5%90%88/"},{"title":"将Jenkins安装为systemd服务","text":"Jenkins的部署方式是将jar放在了tomcat下(具体参考之前的部署方式)，然后通过系统环境变量(/etc/profile)中指定Jenkins工作空间及时区变量。 所以此文将Jenkins安装为systemd服务，也就是将tomcat安装为systemd服务。 1、新建项目的systemd管理文件jenkins.service vim /etc/systemd/system/jenkins.service 1234567891011121314151617[Unit]Description=jenkins-tomcat9900After=network.target[Service]Type=forkingWorkingDirectory=/ssdb1/tomcat/tomcat-jenkins/binEnvironment=JAVA_HOME==/usr/local/java/jdk1.8.0_231Environment=JENKINS_HOME=/ssdb1/jenkinsEnvironment=JENKINS_JAVA_OPTIONS=\"-Dorg.apache.commons.jelly.tags.fmt.timeZone=Asia/Shanghai\"ExecStart=/ssdb1/tomcat/tomcat-jenkins/bin/catalina.sh startExecReload=/ssdb1/tomcat/tomcat-jenkins/bin/catalina.sh restartExecStop=/ssdb1/tomcat/tomcat-jenkins/bin/catalina.sh stopSuccessExitStatus=143[Install]WantedBy=multi-user.target 主要注意点，通过systemd进行管理的服务，在/etc/profile中定义的环境变量，不会生效，所以需要通过Environment 定义环境变量。 2、管理 123$ systemctl daemon-reload$ systemctl enable jenkins.service$ systemctl start jenkins.service 3、查看状态 1$ systemctl status jenkins.service 4、查看服务日志 1$ vim /var/log/syslog 之前的相关记录：https://myqzf.github.io/2018/08/29/java/Spring-Boot/Spring-boot%E9%83%A8%E7%BD%B2/","link":"/2019/12/28/Jenkins/%E5%B0%86jenkins%E5%AE%89%E8%A3%85%E4%B8%BAsystemd%E6%9C%8D%E5%8A%A1/"},{"title":"通过URL触发Jenkins构建","text":"https://www.cnblogs.com/tyrionyang/p/8183819.html 几个插件：https://www.jianshu.com/p/0457aba7efcf","link":"/2020/04/17/Jenkins/%E9%80%9A%E8%BF%87URL%E8%A7%A6%E5%8F%91Jenkins%E6%9E%84%E5%BB%BA/"},{"title":"RabbitMQ安装","text":"erlang安装RabbitMQ是用erlang语言开发，所以需安装erlang。1、获取安装文件 1$ wget http://erlang.org/download/otp_src_20.2.tar.gz2、解压erlang安装包 1$ tar -zxvf otp_src_20.2.tar.gz3、进入目录，编译安装 123$ cd otp_src_20.2$ ./configure --prefix=/usr/local/erlang --enable-smp-support --enable-threads --enable-sctp --enable-kernel-poll --enable-hipe --with-ssl --without-javac$ make &amp;&amp; make install erlang安装编译选项： –prefix 指定安装目录 –enable-smp-support启用对称多处理支持（Symmetric Multi-Processing对称多处理结构的简称） –enable-threads启用异步线程支持 –enable-sctp启用流控制协议支持（Stream Control Transmission Protocol，流控制传输协议） –enable-kernel-poll启用Linux内核poll –enable-hipe启用高性能Erlang –with-ssl 启用ssl包 –without-javac 不用java编译4、加入系统变量vim /etc/profile 12export ERLANG_HOME=/usr/local/erlangexport PATH=$ERLANG_HOME/bin:$PATH 5、验证erlang是否安装成功 1234$ erl Erlang/OTP 20 [erts-9.2] [source] [smp:4:4] [ds:4:4:10] [async-threads:10] [kernel-poll:false] Eshell V9.2 (abort with ^G) 1&gt; halt(). 退出：halt(). rabbitMq的安装1、获取安装包 1$ wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.6.15/rabbitmq-server-generic-unix-3.6.15.tar.xz 2、解压rabbitMQ安装包(注意：tar.xz解压方式) 1$ tar -xvJf rabbitmq-server-generic-unix-3.6.15.tar.xz 3、加入系统变量vim /etc/profile 12export RABBITMQ_HOME=/usr/local/rabbitmq/rabbitmq_server-3.7.4export PATH=$RABBITMQ_HOME/sbin:$PATH 4、运行RabbitMQ (另开一终端) 1$ sbin/rabbitmq-server 5、使RabbitMQ后台运行 1$ rabbitmq-server -detached 6、查看运行状态 1$ sbin/rabbitmqctl status 7、关闭服务 1$ ./rabbitmqctl stop 其它：访问端口： 4369，epmd（Erlang Port Mapper Daemon），是Erlang的端口/结点名称映射程序，用来跟踪节点名称监听地址，在集群中起到一个类似DNS的作用。 5672, 5671， AMQP 0-9-1 和 1.0 客户端端口，used by AMQP 0-9-1 and 1.0 clients without and with TLS(Transport Layer Security) 25672，Erlang distribution，和4369配合 15672，HTTP_API端口，管理员用户才能访问，用于管理RbbitMQ，需要启用management插件，rabbitmq-plugins enable rabbitmq_management，访问http://server-name:15672/ 61613, 61614，当STOMP插件启用的时候打开，作为STOMP客户端端口（根据是否使用TLS选择） 1883, 8883，当MQTT插件启用的时候打开，作为MQTT客户端端口（根据是否使用TLS选择） 15674，基于WebSocket的STOMP客户端端口（当插件Web STOMP启用的时候打开） 15675，基于WebSocket的MQTT客户端端口（当插件Web MQTT启用的时候打开） 默认用户RabbitMQ默认用户帐号及密码都是guest，默认只能从本机访问。因此如果需要从其它机器访问RabbitMQ，需要做些设置。参考：RabbitMQ的配置 Access Control 相关的内容，里面会讲解如何创建用户，删除guest用户, 或设置允许guest用户远程访问RabbitMQ. 调整Linux系统的限制RabbitMQ如果是在生产环境中运行的话，需要调整系统限制和内核限制，以应对大量并发连接和高容量的队列。要调整的主要是允许打开文件的最大数量，即ulimit -n命令显示的值。该默认值对消息中间件来说太低了（一般是1024）。我们推荐在生产环境中对系统用户rabbitmq（默认运行RabbitMQ server的用户）至少要设置成65536，如果是开发环境则设置成4096。有两个限制需要修改：1、操作系统内核允许打开文件的最大数量(fs.file-max) 123456789#查看$ cat /proc/sys/fs/file-max184289$ cat /proc/sys/fs/file-nr1024 0 184289 #已分配文件句柄的数目 分配了但没有使用的句柄数 文件句柄最大数目#设置$ echo 284289 &gt; /proc/sys/fs/file-max 2、每个用户允许打开文件的最大数量(ulimit -n)，可以通过ulimit -n size设置。 前者必须高于后者。 验证是否生效 123456789$ rabbitmqctl status{file_descriptors, [{total_limit,65435}, {total_used,2}, {sockets_limit,58889}, {sockets_used,0}]}, # 查看设置的limits，$RABBITMQ_BEAM_PROCESS_PID用实际的进程id代替$ cat /proc/$RABBITMQ_BEAM_PROCESS_PID/limits 可参考：https://segmentfault.com/a/1190000011444627 ####问题1、编译erlang遇到的问题 12configure: error: No curses library functions foundconfigure: error: /bin/sh '/opt/erlang/otp_src_20.2/erts/configure' failed for erts 解决： 1$ apt-get install ncurses-dev 2、启动报错 123456789101112131415161718192021222324252627$ sbin/rabbitmq-serverBOOT FAILED===========Error description: {error,{missing_dependencies,[crypto,ssl], [cowboy,cowlib,rabbitmq_management, rabbitmq_management_agent, rabbitmq_trust_store]}}Log files (may contain more information): /usr/local/rabbitmq/rabbitmq_server-3.6.15/var/log/rabbitmq/rabbit@ubuntu.log /usr/local/rabbitmq/rabbitmq_server-3.6.15/var/log/rabbitmq/rabbit@ubuntu-sasl.logStack trace: [{rabbit_plugins,ensure_dependencies,1, [{file,\"src/rabbit_plugins.erl\"},{line,185}]}, {rabbit_plugins,prepare_plugins,1, [{file,\"src/rabbit_plugins.erl\"},{line,203}]}, {rabbit,broker_start,0,[{file,\"src/rabbit.erl\"},{line,300}]}, {rabbit,start_it,1,[{file,\"src/rabbit.erl\"},{line,424}]}, {init,start_em,1,[]}, {init,do_boot,3,[]}]{\"init terminating in do_boot\",{error,{missing_dependencies,[crypto,ssl],[cowboy,cowlib,rabbitmq_management,rabbitmq_management_agent,rabbitmq_trust_store]}}}init terminating in do_boot ({error,{missing_dependencies,[crypto,ssl],[cowboy,cowlib,rabbitmq_management,rabbitmq_management_agent,rabbitmq_trust_store]}}) 原因：缺少openssl 解决： 1$ apt-get install openssl libssl-dev 参考：http://www.rabbitmq.com/install-debian.html","link":"/2018/03/05/RabbitMQ/RabbitMQ%E5%AE%89%E8%A3%85(%E4%B8%80)/"},{"title":"RabbitMQ插件、用户权限管理","text":"RabbitMQ插件1、插件列表 1$ rabbitmq-plugins list 2、启用插件 1$ rabbitmq-plugins enable plugin-name 3、禁用插件 1$ rabbitmq-plugins disable plugin-name 示例：(1) 开启管理页面插件 1$ rabbitmq-plugins enable rabbitmq_management (2) 启用 rabbitmq stomp 插件 1rabbitmq-plugins enable rabbitmq_stomp 该插件默认监听的端口是61613 (3) RabbitMQ Web STOMP插件 1$ rabbitmq-plugins enable rabbitmq_web_stomp 该插件默认侦听端口15674 (4) Web STOMP Examples 源码 1$ rabbitmq-plugins enable rabbitmq_web_stomp_examples localhost:15670 用户权限管理rabbitmq默认会创建guest/guest账号密码，只能用于localhost登录页面管理员。注：需要开启管理页面插件。可以通过rabbitmqctl执行相关命令来维护用户、权限。用户管理 list_users，用户列表 add_user {username} {password}，添加用户 delete_user {username}，删除用户 change_password {username} {newpassword}，修改密码 clear_password {username}，删除密码，密码删除后就不能访问了 authenticate_user {username} {password}，用户认证 set_user_tags {username} {tag …}，为用户设置角色，tag可以是0个、一个、或多个权限管理当一个RabbitMQ客户端建立到服务器的连接时，在它的操作指令中指定了一个虚拟主机。此时实施第一级访问控制，服务器检查用户是否有权访问虚拟主机，否则拒绝连接尝试。资源（即exchanges和queues）在特定虚拟主机内被命名为实体; 相同的名称在每个虚拟主机中表示不同的资源。当对资源执行某些操作时，会强制执行第二级访问控制。RabbitMQ在某个资源上区分了配置、写和读操作。配置操作创建或者销毁资源，或者更改资源的行为。写操作将消息注入进资源之中。读操作从资源中获取消息。为了对资源执行操作，用户必须已被授予适当的权限。 list_vhosts [vhostinfoitem …]，获取vhosts列表 add_vhost {vhost}， eg：rabbitmqctl add_vhost test delete_vhost {vhost} set_permissions [-p vhost] {user} {conf} {write} {read}，给用户分在对应的vhost上分配相应的权限。 eg：rabbitmqctl set_permissions -p /myvhost chris “^chris-.*“ “.*“ “.*“，这条指令，给用户chris在myvhost分配了权限，权限包括：以”chris-“开头的全部资源的配置权限，和所有资源的读写权限. clear_permissions [-p vhost] {username}，清除权限 list_permissions [-p vhost]，vhost权限分配列表 list_user_permissions {username}，user权限列表 删除默认用户 1$ rabbitmqctl delete_user guest 添加用户 1$ rabbitmqctl add_user bjcscn yunyi123 设置用户角色 1$ rabbitmqctl set_user_tags bjcscn administrator 设置用户权限 1$ rabbitmqctl set_permissions -p / bjcscn \".*\" \".*\" \".*\" 参考：pluginsAccess Controlrabbitmqctl Access Control","link":"/2018/03/05/RabbitMQ/RabbitMQ%E6%8F%92%E4%BB%B6(%E4%BA%8C)/"},{"title":"RabbitMQ的配置","text":"从RabbitMQ 3.7.0开始 单个设置的所有信息都在一行上。 行是结构化的键=值。 任何以＃开头的行都是注释。 示例文件 12listeners.tcp.default = 5672 # RabbitMQ侦听客户端连接端口为5672。loopback_users = none # 允许guest用户从远程主机进行连接 完整文件：https://raw.githubusercontent.com/rabbitmq/rabbitmq-server/master/docs/rabbitmq.conf.example 参考：https://www.rabbitmq.com/configure.html","link":"/2018/03/05/RabbitMQ/RabbitMQ%E7%9A%84%E9%85%8D%E7%BD%AE(%E4%B8%89)/"},{"title":"RabbitMQ集群","text":"Rabbit集群模式大概分为：普通集群模式、镜像模式普通集群模式： 默认的集群模式，以两个节点（rabbit01、rabbit02）为例来进行说明。对于Queue来说，消息实体只存在于其中一个节点rabbit01（或者rabbit02），rabbit01和rabbit02两个节点仅有相同的元数据，即队列的结构。当消息进入rabbit01节点的Queue后，consumer从rabbit02节点消费时，RabbitMQ会临时在rabbit01、rabbit02间进行消息传输，把A中的消息实体取出并经过B发送给consumer。所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连rabbit01或rabbit02，出口总在rabbit01，会产生瓶颈。当rabbit01节点故障后，rabbit02节点无法取到rabbit01节点中还未消费的消息实体。如果做了消息持久化，那么得等rabbit01节点恢复，然后才可被消费；如果没有持久化的话，就会产生消息丢失的现象。镜像模式： 将需要消费的队列变为镜像队列，存在于多个节点，这样就可以实现RabbitMQ的HA高可用性。作用就是消息实体会主动在镜像节点之间实现同步，而不是像普通模式那样，在consumer消费数据时临时读取。缺点就是，集群内部的同步通讯会占用大量的网络带宽。 节点1、RabbitMQ集群中的所有节点都是相同的，不同于其它分布式系统具有领导者和追随者节点。RabbitMQ中没有特殊的节点。2、Erlang Cookie RabbitMQ节点和CLI工具（例如rabbitmqctl）使用cookie来确定它们是否被允许相互通信。要使两个节点能够通信，它们必须具有相同的共享密钥。 在UNIX系统上，cookie通常在 /var/lib/rabbitmq/.erlang.cookie 或者$HOME/.erlang.cookie3、节点类型：磁盘节点和RAM节点 在绝大多数情况下，希望所有节点都是磁盘节点; RAM节点是一种特殊情况，可用于改善具有高排队，交换或绑定流失的性能集群。RAM节点不提供更高的消息速率。如有疑问，请仅使用磁盘节点。 集群模式配置前提：首先RabbitMQ在两台机器上安装好，并且RabbitMQ的sbin目录已加入到PATH中. 1、修改/etc/hosts文件 12172.16.0.3 bp11_106172.16.0.2 bp13_253 在两台机器上分别修改。格式： ip hostname2、设置Erlang Cookie将其中一台的cookie复制到另一台中,文件权限是400。 1$ scp -P 10100 /root/.erlang.cookie root@172.16.0.2:/root 3、启动独立的节点 12rabbit1 $ rabbitmq-server -detachedrabbit2 $ rabbitmq-server -detached 4、分别查看状态 123456789101112131415rabbit1 $ rabbitmqctl cluster_statusCluster status of node rabbit@rabbit1 ...[{nodes,[{disc,[rabbit@rabbit1]}]},{running_nodes,[rabbit@rabbit1]},{cluster_name,&lt;&lt;&quot;rabbit@rabbit1&quot;&gt;&gt;},{partitions,[]},{alarms,[{rabbit@rabbit1,[]}]}]rabbit2 $ rabbitmqctl cluster_statusCluster status of node rabbit@rabbit2 ...[{nodes,[{disc,[rabbit@rabbit2]}]},{running_nodes,[rabbit@rabbit2]},{cluster_name,&lt;&lt;&quot;rabbit@rabbit2&quot;&gt;&gt;},{partitions,[]},{alarms,[{rabbit@rabbit2,[]}]}] 5、创建集群 将rabbit2与rabbit1连接起来 123rabbit2 $ rabbitmqctl stop_apprabbit2 $ rabbitmqctl join_cluster rabbit@rabbit1rabbit2 $ rabbitmqctl start_app 6、分别查看集群状态 123456789101112131415rabbit1 $ rabbitmqctl cluster_statusCluster status of node rabbit@rabbit1 ...[{nodes,[{disc,[rabbit@rabbit1,rabbit@rabbit2]}]}, {running_nodes,[rabbit@rabbit1,rabbit@rabbit2]}, {cluster_name,&lt;&lt;&quot;rabbit@rabbit1&quot;&gt;&gt;}, {partitions,[]}, {alarms,[{rabbit@rabbit1,[]},{rabbit@rabbit2,[]}]}]rabbit2 $ rabbitmqctl cluster_statusCluster status of node rabbit@rabbit2 ...[{nodes,[{disc,[rabbit@rabbit1,rabbit@rabbit2]}]},{running_nodes,[rabbit@rabbit1,rabbit@rabbit2]},{cluster_name,&lt;&lt;&quot;rabbit@rabbit1&quot;&gt;&gt;},{partitions,[]},{alarms,[{rabbit@rabbit1,[]},{rabbit@rabbit2,[]}]}] 可以看到这两个节点已加入群集 从集群中删除一个节点单机多节点创建内存节点 参考：http://www.rabbitmq.com/clustering.htmlhttps://www.cnblogs.com/myf008/p/8545322.htmlhttps://blog.csdn.net/woogeyu/article/details/51119101","link":"/2018/04/20/RabbitMQ/RabbitMQ%E9%9B%86%E7%BE%A4(%E5%9B%9B)/"},{"title":"RabbitMQ高可用性（镜像）队列","text":"RabbitMQ默认集群模式，但并不保证队列的高可用性，尽管exchanges、bindings这些可以复制到集群里的任何一个节点，但是集群内的队列内容位于单个节点（声明队列的节点）上，队列内容不会复制，虽然该模式解决一部分节点压力，但队列节点宕机直接导致该队列无法使用，只能等待重启，所以要想在队列节点宕机或故障也能正常使用，就要复制队列内容到集群里的每个节点，需要创建镜像队列。队列镜像会把发布到队列的消息将被复制到所有镜像。消费者无论连接到哪个节点都连接到主节点，并且镜像会丢弃已在主节点确认的消息。队列镜像因此增强了可用性，但不会跨节点分发负载。 配置镜像镜像使用策略配置，策略通过名称（使用正则表达式模式）匹配一个或多个队列，并包含添加到匹配队列的全部属性集中的定义（可选参数的映射） 策略管理使用：rabbitmqctl设置一个策略set_policy [-p vhost] [--priority priority] [--apply-to apply-to] name pattern definition -p Vhost： 可选参数，针对指定vhost下的queue进行设置 priority：可选参数，policy的优先级，默认为0。数字越大表示优先级越高。 apply-to：可选参数，适用于哪些类型的对象，值可选为queues、exchanges、all，默认为all Name: policy的名称 Pattern: queue的匹配模式(正则表达式) Definition：镜像定义，包括三个部分ha-mode, ha-params, ha-sync-modeha-mode:指明镜像队列的模式，有效值为 all/exactly/nodes all：表示在集群中所有的节点上进行镜像 exactly：表示在指定个数的节点上进行镜像，节点的个数由ha-params指定 nodes：表示在指定的节点上进行镜像，节点名称通过ha-params指定 ha-params：ha-mode模式需要用到的参数 ha-sync-mode：进行队列中消息的同步方式，有效值为automatic和manual示例：12$ rabbitmqctl set_policy ha-policy1 \"^\" '{\"ha-mode\":\"all\"}'$ rabbitmqctl set_policy ha-two \"^two\\.\" '{\"ha-mode\":\"exactly\",\"ha-params\":2,\"ha-sync-mode\":\"automatic\"}' clear_policy [-p vhost] name 删除一个策略list_policies [-p vhost] 策略列表 RabbitMQ负载均衡 http://www.rabbitmq.com/ha.htmlhttp://www.rabbitmq.com/parameters.html#policies","link":"/2018/04/20/RabbitMQ/RabbitMQ%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7%EF%BC%88%E9%95%9C%E5%83%8F%EF%BC%89%E9%98%9F%E5%88%97(%E4%BA%94)/"},{"title":"RabbitMq-rabbitmqctl","text":"rabbitmqctl 列出RabbitMQ中所有队列及对应的消息数。 12345$ sudo rabbitmqctl list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...task_queue 0hello 0 列出服务中所有的交换(exchange) 123456789$ sudo rabbitmqctl list_exchangesListing exchanges for vhost / ...amq.topic topicamq.match headers directamq.headers headersamq.direct directamq.fanout fanoutamq.rabbitmq.trace topic 列出绑定 1234$ rabbitmqctl list_bindingsListing bindings for vhost /... exchange hello queue hello [] exchange task_queue queue task_queue [] http://www.rabbitmq.com/rabbitmqctl.8.html","link":"/2018/07/26/RabbitMQ/RabbitMq-rabbitmqctl/"},{"title":"RabbitMq-rabbitmqctl","text":"RabbitMQ Web STOMP插件 http://www.rabbitmq.com/rabbitmqctl.8.html","link":"/2018/07/28/RabbitMQ/RabbitMq-web-stomp/"},{"title":"Dockerfile创建镜像","text":"Dockerfile 一般分为四部分：基础镜像信息、维护者信息、镜像操作指令和容器启动时执行指令。 指令 1、FROM 格式为FROM 或: 第一条指令必须为FROM，同一个Dockerfile可以创建多个镜像，使用多个FROM指令。 2、MAINTAINER 格式为MINTAINER ,指定维护者信息。 3、RUN 格式为RUN或RUN [“executable”,”paraml”,”param2”] 前者在shell终端中运行命令，即/bin/sh -c;后者用exec执行。 4、CMD 支持三种格式： CMD [“executable”,”paraml”,”param2”] 使用exec执行，推荐方式。 CMD command param1 param2，在/bin/sh中执行，提供给需要交互的应用。 CMD [“paraml”,”param2”],提供给ENTRYPOINT的默认参数。 指定启动容器时执行的命令，每个Dockerfile 只能有一条CMD命令。 如果指定多个，则只有最后一条会被执行。如果用户启动容器时指定了运行的命令，则会覆盖掉CMD指定的命令。 5、EXPOSE 格式为EXPOSE […] 告诉Docker服务端容器暴露的端口号。 6、ENV 格式为ENV 。指定一个环境变量，会被后续RUN指令使用，并在容器运行时保持。 7、ADD 格式为ADD 该指令将复制指定的到容器中的。其中可以是Dockerfile所在目录的相对路径；也可以是一个URL；还可以是tar文件（自动解压为目录）。 8、COPY 格式为COPY 复制本地主机的 （为Dockerfile所在目录的相对路径）到容器中的。目标路径不存在时，会自动创建。 当使用本地目录为源目录时，推荐用COPY。 9、ENTRYPOINT 两种格式： ENTRYPOINT [“executable”,”paraml”,”param2”] ENTRYPOINT command param1 param2（shell中执行）。 容器启动后执行的命令，并且不可被docker run 提供的参数覆盖。 每个Dockefile中只能用一个ENTRYPOINT，当指定了多个ENTRYPOINT，则只有最后一个生效。 10、VOLUME 格式为VOLUME [“/data”]。 创建一个可以从本地主机或其它容器挂载的挂载点，一般用来存放数据库和需要保存的数据。 11、USER 格式为USER daemon。 指定运行容器是的用户名或UID,后续的RUN也会使用指定用户。 当服务不需要管理权限时，可以通过改名了指定运行用户。并且可以在之前创建所需要的用户。要临时获取管理云权限可以用gosu，不推荐sudo。 12、WORKDIR 格式为WORKDIR /path/to/workdir。 为后续的RUN、CMD、ENTRYPOINT指令配置工作目录。 可以使用多个WORKDIR指令，后续命令如果参数为相对路径，则会基于之前命令指定的路径。 13、ONBUILD 格式为ONBUILD [INSTRCTION] 配置当所建镜像作为其他新建镜像的基础镜像时，所执行的操作指令 创建镜像 编写完Dockefile后，可通过docker build命令创建镜像。 格式为docker build [OPTIONS] PATH | URL | -","link":"/2017/10/25/docker/Dockerfile%E5%88%9B%E5%BB%BA%E9%95%9C%E5%83%8F/"},{"title":"Compose.yam文件","text":"Compose.yam文件是定义services、networks、volumes，默认文件与路径./docker-compose.yml.服务定义包含将被应用到为该服务启动的每个容器的配置，就像 docker run传递命令行参数一样。网络和卷的定义也类似于docker network create和docker volume create。 安装Docker Compose 123$ sudo curl -L https://github.com/docker/compose/releases/download/1.17.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose$ sudo chmod +x /usr/local/bin/docker-compose$ docker-compose --version 具体参考官方文档：https://docs.docker.com/compose/install/#install-compose build指定 Dockerfile 所在文件夹的路径。 12345678version: '2'services: webapp: build: ./dir``` #### context 要么是一个包含Dockerfile的目录的路径，要么是一个到git仓库的url。 build: context: ./dir 12#### dockerfile 指定Dockerfile build: context: . dockerfile: Dockerfile-alternate 1234#### args 构建参数，它们是仅在构建过程中可访问的环境变量。 就像 Dockerfile 中的 ARG 指令，它可以在构建过程中指定环境变量，但是在构建成功后取消.Dockerfile中ARG ARG buildnoARG password RUN echo “Build number: $buildno”RUN script-requiring-password.sh “$password” 12 build: context: . args: buildno: 1 password: secret build: context: . args: - buildno=1 - password=secret 1234注意：布尔值（true，false，yes，no，on，off）必须用引号括起来。 #### command 可以覆盖容器启动后默认执行的命令。 command: bundle exec thin -p 3000 1也可以是一个类似于 dockerfile文件中的格式 command: [“bundle”, “exec”, “thin”, “-p”, “3000”] 12345678910111213#### deploy指定与部署和运行服务相关的配置。 version: ‘3’services: redis: image: redis:alpine deploy: replicas: 6 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure 12345有几个子选项可用：##### endpoint_mode为连接到集群的外部客户端指定服务发现方法。 * endpoint_mode: vip， Docker为服务分配一个虚拟IP，作为客户端到达网络服务的“前端”。* endpoint_mode: dnsrr - DNS轮询，Docker为服务设置DNS条目，使得服务名称的DNS查询返回一个IP地址列表，客户端直接连接到其中的一个。负载平衡器。 version: “3.3” services: wordpress: image: wordpress ports: - 8080:80 networks: - overlay deploy: mode: replicated replicas: 2 endpoint_mode: vip mysql: image: mysql volumes: - db-data:/var/lib/mysql/data networks: - overlay deploy: mode: replicated replicas: 2 endpoint_mode: dnsrr volumes: db-data: networks: overlay: 123##### labels指定服务的标签。 version: “3”services: web: image: web deploy: labels: com.example.description: “This label will appear on the web service” 12##### mode两种模式：global（每个群集节点只有一个容器）或replicated（指定数量的容器）。默认是replicated。 version: ‘3’services: worker: image: dockersamples/examplevotingapp_worker deploy: mode: global 123##### replicas如果服务是replicated（这是默认的），指定在任何给定的时间应该运行的容器的数量。 version: ‘3’services: worker: image: dockersamples/examplevotingapp_worker networks: - frontend - backend deploy: mode: replicated replicas: 6 12##### resources配置资源限制。 version: ‘3’services: redis: image: redis:alpine deploy: resources: limits: cpus: ‘0.50’ memory: 50M reservations: cpus: ‘0.25’ memory: 20M 1234567在上面这个例子中，redis服务被限制使用不超过50M的内存和0.50（50％）可用处理时间（CPU），并且 保留20M了内存和0.25CPU时间（总是可用）。##### restart_policy配置是否以及如何在退出时重新启动容器。 * condition：其中之一none，on-failure或any（默认：）any。 * delay：在重启尝试之间等待多长时间（指定为 持续时间）（默认值：0）。 * max_attempts：在放弃之前尝试重启容器多少次（默认：永不放弃）。 * window：决定重新启动成功之前等待多长时间（指定为持续时间）（默认值：立即决定）。 version: “3”services: redis: image: redis:alpine deploy: restart_policy: condition: on-failure delay: 5s max_attempts: 3 window: 120s 12345678##### update_config配置如何更新服务。用于配置滚动更新。 * parallelism：一次更新的容器数量。 * delay：更新一组容器之间的等待时间。 * failure_action：如果更新失败，该怎么办。其中之一continue，rollback或pause （默认：）pause。 * monitor：每个任务更新后监视失败的时间(ns|us|ms|s|m|h)（默认为0）。 * max_failure_ratio：在更新期间容忍的失败率。 * order：更新期间的操作顺序。其中一个stop-first（旧的任务在开始新的任务之前停止）或start-first（新的任务首先启动，并且正在运行的任务将短暂地重叠）（默认stop-first）。 version: ‘3.4’services: vote: image: dockersamples/examplevotingapp_vote:before depends_on: - redis deploy: replicas: 2 update_config: parallelism: 2 delay: 10s order: stop-first 1234#### depends_on表示服务之间的依赖关系，这有两个作用： * docker-compose up将以依赖性顺序启动服务。在下面的例子中，db和redis会web之前启动。* docker-compose up SERVICE会自动包含SERVICE依赖项。在下面的例子中，docker-compose up web也将创建和启动db和redis。 version: ‘3’services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 12#### dns自定义DNS服务器。可以是单个值或列表。 dns: 8.8.8.8dns: 8.8.8.8 9.9.9.912#### dns_search自定义DNS搜索域。可以是单个值或列表。 dns_search: example.comdns_search: dc1.example.com dc2.example.com12#### tmpfs在容器中挂载一个临时文件系统。可以是单个值或列表。 tmpfs: /runtmpfs: /run /tmp12#### entrypoint覆盖默认入口点。 entrypoint: /code/entrypoint.sh1234#### env_file从文件添加环境变量。可以是单个值或列表。 如果您已经指定了一个Compose文件docker-compose -f FILE，则路径 env_file相对于该文件所在的目录。在environment部分中 声明的环境变量将覆盖这些值 - 即使这些值为空或未定义，也是如此。 env_file: .env env_file: ./common.env ./apps/web.env /opt/secrets.env1env文件中的每一行都是VAR=VAL格式。#以空白行开头的行（即注释）被忽略。 Set Rails/Rack environmentRACK_ENV=development12#### environment添加环境变量。您可以使用数组或字典。任何布尔值; true，false，yes，no需要用引号括起来，以确保它们不被YML解析器转换为True或False。 environment:RACK_ENV: developmentSHOW: ‘true’SESSION_SECRET: environment: RACK_ENV=development SHOW=true SESSION_SECRET123注意：如果你的服务指定了一个build选项，在build过程中定义的变量environment将不会自动可见。使用args子选项build来定义构建时环境变量。 #### expose公开端口而不将它们发布到主机 - 它们只能被链接的服务访问。只能指定内部端口。 expose: “3000” “800012#### external_links让Compose项目里面的容器连接到那些项目配置外部的容器,外部创建的容器必须连接到它们的服务相同的网络。 external_links: redis_1 project_db_1:mysql project_db_1:postgresql12#### extra_hosts添加主机名映射。使用与docker客户端--add-host参数相同的值。 extra_hosts: “somehost:162.242.195.82” “otherhost:50.31.209.229”1具有IP地址和主机名的条目将在/etc/hosts该服务的内部容器中创建，例如： 162.242.195.82 somehost50.31.209.229 otherhost12#### healthcheck配置运行的检查以确定此服务的容器是否“健康”。 healthcheck:test: [“CMD”, “curl”, “-f”, “http://localhost&quot;]interval: 1m30stimeout: 10sretries: 312interval和timeout指定持续时间。 test必须是一个字符串或一个列表。如果它是一个列表，第一项必须是NONE，CMD或CMD-SHELL。如果它是一个字符串，则相当于指定CMD-SHELL后跟该字符串。 Hit the local web apptest: [“CMD”, “curl”, “-f”, “http://localhost&quot;] As above, but wrapped in /bin/sh. Both forms below are equivalent.test: [“CMD-SHELL”, “curl -f http://localhost || exit 1”]test: curl -f https://localhost || exit 1 12#### image指定图像以从中启动容器。可以是存储库/标签或部分图像ID。 image: redisimage: ubuntu:14.04image: tutum/influxdbimage: example-registry.com:4000/postgresqlimage: a4bc65fd 123#### labels使用Docker labels将元数据添加到容器。您可以使用数组或字典。(元数据：为描述数据的数据。)建议使用反向DNS标记来防止您的标签与其他软件使用的标签冲突。 labels: com.example.description: “Accounting webapp” com.example.department: “Finance” com.example.label-with-empty-value: “” labels: “com.example.description=Accounting webapp” “com.example.department=Finance” “com.example.label-with-empty-value”12#### links链接到另一个服务中的容器。既可以指定服务名称，也可以指定链接别名（SERVICE:ALIAS），或者仅指定服务名称。 web:links: db db:database redis12#### logging配置服务的日志 logging:driver: syslogoptions:syslog-address: “tcp://192.168.0.42:123”12driver 名称为服务的容器指定了一个日志驱动程序。默认值是json-file。 driver: “json-file”driver: “syslog”driver: “none”1234参考：https://docs.docker.com/engine/admin/logging/overview/#configure-the-default-logging-driver#### network_mode网络模式。使用与docker客户端--net参数相同的值，加上特殊的形式service:[service name]。 network_mode: “bridge”network_mode: “host”network_mode: “none”network_mode: “service:[service name]”network_mode: “container:[container name/id]”12#### networks网络 services:some-service:networks: some-network other-network1234##### aliases别名,网络上此服务的别名（备用主机名）。同一网络上的其他容器可以使用服务名称或别名来连接到服务的一个容器。 由于aliases是网络范围的，相同的服务可以在不同的网络上具有不同的别名。 在下面的例子中，提供了三种服务（web，worker，和db），其中两个网络（沿new和legacy）。该db服务是在主机名db或database上new网络，和db或mysql上的legacy网络。 version: ‘2’ services: web: build: ./web networks: - new worker: build: ./worker networks: - legacy db: image: mysql networks: new: aliases: - database legacy: aliases: - mysql networks: new: legacy: 12#### ipv4_address,ipv6_address加入网络时，为此服务的容器指定静态IP地址。 version: ‘2.1’ services: app: image: busybox command: ifconfig networks: app_net: ipv4_address: 172.16.238.10 ipv6_address: 2001:3984:3989::10 networks: app_net: driver: bridge enable_ipv6: true ipam: driver: default config: - subnet: 172.16.238.0/24 - subnet: 2001:3984:3989::/64 1234#### ports公开端口 简洁语法： 既可以指定port（HOST:CONTAINER），也可以指定容器端口（将选择一个随机的主机端口）。 ports: “3000” “3000-3005” “8000:8000” “9090-9091:8080-8081” “49100:22” “127.0.0.1:8001:8001” “127.0.0.1:5000-5010:5000-5010” “6060:6060/udp” 12345长格式的语法： * target：容器内的端口。* published：公开曝光的端口。* protocol：端口协议（tcp或udp）。 * mode：host用于发布每个节点上的主机端口，或者ingress用于群集模式的端口，该端口将被负载均衡。 ports: target: 80published: 8080protocol: tcpmode: host12#### secrets使用每项服务secrets 配置授予对每项服务的秘密访问权限。 version: “3.1”services:redis:image: redis:latestdeploy: replicas: 1secrets: my_secret my_other_secretsecrets:my_secret:file: ./my_secret.txtmy_other_secret:external: true123授予对redis服务my_secret和my_other_secret秘密的访问权限。其值 my_secret被设置为文件的内容./my_secret.txt，并被 my_other_secret定义为外部资源. #### stop_signal设置一个替代信号来停止容器。默认情况下stop使用SIGTERM。使用替代信号stop_signal将会导致 stop发送该信号。 stop_signal: SIGUSR112#### stop_grace_period指定stop_signal在发送SIGKILL之前如果不处理SIGTERM（或指定的任何停止信号），则试图停止容器时要等待多长时间 。指定为持续时间。 stop_grace_period: 1sstop_grace_period: 1m30s12#### volumes载主机路径或命名卷，将其指定为服务的子选项。 version: “3.2”services:web:image: nginx:alpinevolumes: type: volumesource: mydatatarget: /datavolume: nocopy: true type: bindsource: ./statictarget: /opt/app/static db: image: postgres:latest volumes: “/var/run/postgres/postgres.sock:/var/run/postgres/postgres.sock” “dbdata:/var/lib/postgresql/data” volumes: mydata: dbdata: 1234此示例显示服务mydata正在使用的命名卷（）web，以及为单个服务（db服务 下的第一个路径volumes）定义的绑定挂载。该db服务还使用名为dbdata（在db服务下的第二个路径volumes）的命名卷，但使用旧的字符串格式定义它以装载命名卷。volumes如图所示，命名卷必须列在顶级密钥下 。#### restartno是默认的重启策略，在任何情况下都不会重启容器。当always指定时，容器总是重新启动。该 on-failure如果退出代码指示的故障错误政策重启的容器。 restart: “no”restart: alwaysrestart: on-failurerestart: unless-stopped 12345----------------------------------------------------------### volume使用volume：https://docs.docker.com/engine/admin/volumes/volumes/ 下面是一个双服务设置的示例，其中数据库的数据目录与另一个服务共享为一个卷，以便可以定期备份： version: “3” services: db: image: db volumes: - data-volume:/var/lib/db backup: image: backup-service volumes: - data-volume:/var/lib/backup/data volumes: data-volume: 123#### external如果设置为true，则指定该卷已在docker compose之外创建。docker-compose up不会尝试去创建它，如果它不存在就会引发一个错误。在下面的例子中，[projectname]dataCompose 不是试图创建一个被调用的卷，而是 查找一个简单调用的现有卷，data并将其挂载到db服务的容器中. version: ‘2’ services: db: image: postgres volumes: - data:/var/lib/postgresql/data volumes: data: external: true","link":"/2017/11/15/docker/compose.yam/"},{"title":"docker-machine","text":"之前，Docker的安装流程非常复杂，用户需要登录到相应的主机上，根据官方的安装和配置指南来安装Docker，并且不同的操作系统的安装步骤也是不一样的。而有了Machine后，不管是在笔记本、虚拟机还是公有云实例上，用户仅仅需要一个命令就轻松搞定安装。当然那你需要先安装Docker Machine。Docker Machine是一个简化Docker安装的命令行工具，通过一个简单的命令行即可在相应的平台上安装Docker，比如VirtualBox、 Digital Ocean、Microsoft Azure。 安装docker-machine linux: 123$ curl -L https://github.com/docker/machine/releases/download/v0.13.0/docker-machine-`uname -s`-`uname -m` &gt;/tmp/docker-machine &amp;&amp;chmod +x /tmp/docker-machine &amp;&amp;sudo cp /tmp/docker-machine /usr/local/bin/docker-machine 查看版本： 12$ docker-machine version docker-machine version 0.13.0, build 9371605 创建虚拟主机首先确保服务器含有 VirtualBox 软件后（如果没有装virtualbox我们使用#apt install virtualbox）， 我们可以直接安装docker提供的一个 Boot2Docker，Boot2Docker是一个专门用于运行Docker容器的轻量级Linux发行版。 123456$ docker-machine create --driver virtualbox default #创建名为default的machine Running pre-create checks... (default) Image cache directory does not exist, creating it at /root/.docker/machine/cache... (default) No default Boot2Docker ISO found locally, downloading the latest release... (default) Latest release for github.com/boot2docker/boot2docker is v17.11.0-ce (default) Downloading /root/.docker/machine/cache/boot2docker.iso from https://github.com/boot2docker/boot2docker/releases/download/v17.11.0-ce/boot2docker.iso... 说明：下载可能非常慢可以先下载好，然后移动到/root/.docker/machine/cache/文件夹下。 用虚拟机可能遇到如下错误： 12Running pre-create checks...Error with pre-create check: &quot;This computer doesn't have VT-X/AMD-v enabled. Enabling it in the BIOS is mandatory&quot; 解决方案就是在vmware当中开启虚拟化引擎就可以了。 查看创建的machine 123$ docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSdefault - virtualbox Running tcp://192.168.99.100:2376 v17.11.0-ce 查看machine的环境 1234567$ docker-machine env defaultexport DOCKER_TLS_VERIFY=&quot;1&quot;export DOCKER_HOST=&quot;tcp://192.168.99.100:2376&quot;export DOCKER_CERT_PATH=&quot;/root/.docker/machine/machines/default&quot;export DOCKER_MACHINE_NAME=&quot;default&quot;# Run this command to configure your shell:# eval $(docker-machine env default) 连接到新机器machine 1$ eval &quot;$(docker-machine env default)&quot; 获取machine主机ip 12$ docker-machine ip default192.168.99.100 在容器中运行Nginx Web服务器： 1$ docker run -d -p 8000:80 nginx 启动和停止机器 12$ docker-machine stop default$ docker-machine start default","link":"/2017/11/30/docker/docker-machine/"},{"title":"docker仓库","text":"官方镜像仓库：https://hub.docker.com 可通过docker login命令输入用户名、密码和邮箱完成注册和登录，会在本地用户目录.dockercfg中保存用户的认证信息。 阿里云仓库：https://dev.aliyun.com/search.html registry.cn-hangzhou.aliyuncs.com 创建私有仓库 安装docker后，可以通过官方提供的registry镜像搭建本地私有仓库环境 1、下载启动私有仓库 1$ docker run -d -p 5000:5000 registry 会在本地启动一个私有仓库服务，监听端口为5000. 2、标记一个image，指向私有仓库 1$ docker tag ubuntu localhost:5000/my_ubuntu 3、推向私有仓库 1$ docker push localhost:5000/my_ubuntu 4、从私有仓库拉下来 1$ docker pull localhost:5000/my_ubuntu 说明： 1$ docker exec -ti 2248c81af285 /bin/sh #进入私有仓库容器 私有仓库配置文件在容器/etc/docker/registry下。 push到仓库的images在/var/lib/registry/docker下。","link":"/2017/10/24/docker/docker%E4%BB%93%E5%BA%93/"},{"title":"docker容器","text":"创建容器 12345$ docker create -it ubuntu:latest782d307c281f26b47f10b53216ab34e69c7658f6112c5aadf5f52e74d5fab943$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES782d307c281f ubuntu \"/bin/bash\" 12 seconds ago Created boring_benz 说明：使用docker create 创建的容器处于停止状态。可使用docker start命令启动。 新建并启动容器启动容器有两种方式，一种是基于镜像新建一个容器并启动，另一个是将终止状态的容器重新启动。命令为：docker run 等价于 docker create 命令，再执行docker start命令。使用docker run 来创建容器并启动时，docker在后台运行的操作是1、检查本地是否存在指定的镜像，不存在就从公共仓库下载。2、利用镜像创建并启动一个容器。3、分配一个文件系统，并在只读的镜像层外挂载一层可读写层。4、从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中。5、从地址池配置一个IP地址给容器。6、执行用户指定的应用程序。7、执行完毕后容器终止。 12$ docker run -i -t ubuntu:16.04 /bin/bash$ docker start ubuntu -t:让docker分配一个伪终端并绑定到容器的标准输出上。-i：让容器的标准输入保持打开。 守护态运行 1$ docker run -d ubuntu /bin/sh -c \"while true; do echo hello world; sleep 1; done\" -d:让docker容器在后台以守护态形式运行。 终止容器 12$ docker stop [OPTIONS] CONTAINER [CONTAINER...]$ docker stop ubuntu 进入容器启动使用-d参数，容器启动后会进入后台，无法看见容器中的信息。可使用docker attach命令、docker exec 命令。以及naenter工具。docker attac 1$ docker attach ubuntu 说明： 当多个窗口同时attach到同一个容器时，所有窗口都会同步显示。当某个窗口因命令堵塞时，其它窗口也无法执行操作了。docker exec 12345$ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f1bdd171e79d ubuntu \"/bin/bash\" 16 hours ago Exited (0) 16 hours ago trusting_noyce$ docker start f1bdd171e79d$ docker exec -ti f1bdd171e79d /bin/bash 获取容器进程的pid 1$ docker inspect --format \"{{.State.Pid}}\" f1bdd171e79d 删除容器使用docker rm命令 1$ docker rm f1bdd171e79d -f,–force=false 强行终止并删除一个运行的容器。-l,–link=false删除容器的连接，但保留容器。-v,–volumes=false删除容器挂载的数据卷。 导出容器 1$ docker export f1bdd171e79d &gt; ubuntu.tar 导入容器导出的容器文件可以使用docker import导入，成为镜像。 1cat ubuntu.tar | docker import - ubuntu:v1.0 实际上，可以使用docker load命令导入镜像的储存文件，也可以，用docker import命令导入一个容器到本地镜像库。","link":"/2017/10/22/docker/docker%E5%AE%B9%E5%99%A8/"},{"title":"docker数据管理","text":"数据卷 创建一个数据卷 1$ docker volume create my-vol 查看卷列表 12$ docker volume ls local my-vol 卷详情 123456789101112$ docker volume inspect my-vol [ { \"CreatedAt\": \"2017-10-25T10:37:54+08:00\", \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/my-vol/_data\", \"Name\": \"my-vol\", \"Options\": {}, \"Scope\": \"local\" } ] 删除卷 1$ docker volume rm my-vol 使用 docker run -v 启动的容器被删除以后，在主机上会遗留下来孤单的卷。可以使用下面的简单方法来做清理： 123$ docker volume ls -qf dangling=true$ docker volume rm $(docker volume ls -qf dangling=true)$ docker volume ls 启动具有数据卷的容器 -v，–volume和–mount，都可实现相同目标，–mount更为明确和冗长。最大的区别是-v 语法将所有选项合并在一个字段中，而–mount 语法将它们分开。 –mount 由多个键值对组成，由逗号分隔，每个由=元组组成。 type 值可以是volume，bind或tmpfs。如果未指定类型，则默认为volume 123456789101112* volume将数据卷壮哉到容器。 * bind：将目录或文件从主机绑定到容器中。 * tmpfs：在容器中安装一个tmpfs。 src或source* type = volume，src是可选的，用来指定卷的名称，卷不存在，则会自动创建，未指定src，则会为该卷分配一个随机名称。 * type = bind：src是必需的。指定要绑定的文件或目录的绝对路径，文件或目录不存在，则会产生错误。 * type = tmpfs：src不受支持。 dst或 destination 或 target，指定的数据卷文件或目录将被安装在容器的路径。 * 容器内的安装路径，容器的文件系统中路径不存在，则会创建。 readonly或ro 绑定以只读的方式装载到容器。 * true或1或无值：挂载绑定或卷为只读。* false或0：挂载绑定或卷读写。 使用 -v 来挂载一个主机上的目录到容器的目录,-v参数参数可以多次使用，以添加多个数据卷 1$ docker run -d -p 80:80 -v /root:/usr/share/nginx/html nginx /bin/bash 如果启动一个不存在的卷的容器，docker会自动创建卷。 下述，-v和–mount 产生同样的效果。 -v –mount docker run -d -it –name test_nginx -v my-vol2:/app nginx:latest docker run -d -it –name test_nginx –mount source=my-vol2,target=/app nginx:latest 使用docker inspect test_nginx 验证创建并正确安装，寻找Mount部分。 123456789101112\"Mounts\": [ { \"Type\": \"volume\", \"Name\": \"my-vol2\", \"Source\": \"/var/lib/docker/volumes/my-vol2/_data\", \"Destination\": \"/app\", \"Driver\": \"local\", \"Mode\": \"z\", \"RW\": true, \"Propagation\": \"\" } ], 这表明mount是一个卷，它显示正确的源和目的地，并且mount是读写的。 停止容器并删除卷 123$ docker container stop test_nginx$ docker container rm test_nginx$ docker volume rm my-vol2 参考：https://docs.docker.com/engine/admin/volumes/volumes/#choose-the--v-or-mount-flaghttps://docs.docker.com/engine/reference/commandline/service_create/#set-metadata-on-a-service--l-labelhttps://docs.docker.com/engine/admin/volumes/tmpfs/#specify-tmpfs-options","link":"/2017/10/24/docker/docker%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/"},{"title":"docker的安装","text":"系统环境：Ubuntu 16.04 官方文档给出三种安装方式 1、设置docker的存储库，并从中进行安装，方便安装和升级，推荐。 2、下载deb软件包，手动安装、升级。不能访问互联网时的情况。 3、使用自动化脚本安装，测试和开发环境下使用。 使用脚本进行安装12$ curl -fsSL get.docker.com -o get-docker.sh$ sudo sh get-docker.sh docker镜像获取镜像123$ sudo docker pull ubuntu # 从hub.docker.com获取ubuntu:latest镜像$ sudo docker pull ubuntu:16.04 #下载指定的版本$ sudo docker pull registry.cn-hangzhou.aliyuncs.com/ubuntu/ubuntu #从阿里云仓库下载 查看所有镜像信息1234$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu 16.04 747cb2d60bbe 11 days ago 122MB hello-world latest 05a3bd381fc2 5 weeks ago 1.84kB REPOSITORY:仓库名 TAG：版本，标签信息 IMAGE ID:镜像ID CREATED：创建时间 SIZE：镜像大小 查看镜像详细信息1$ docker inspect ubuntu 从远端仓库搜索镜像1$ docker search ubuntu 更改镜像TAG1$ docker tag registry.cn-hangzhou.aliyuncs.com/ubuntu/ubuntu:latest ali-ubuntu:16.04 删除镜像1$ docker rmi ubuntu 注意：当有该镜像创建的容器存在时，则镜像文件默认无法删除，应先删除镜像创建的容器。 查看本机所有容器123$ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 75f6116e66fa hello-world \"/hello\" 2 hours ago Exited (0) 2 hours ago compassionate_dubinsky 删除容器1$ docker rm 75f6116e66fa 创建镜像三种方式： 1、基于已有镜像的容器创建。 2、基于本地模板导入。 3、基于Dockerfile创建。 基于已有镜像的容器创建。 1$ docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] -a,–author:作者信息 -m,–message:提交信息 -p,–pause：提交时暂停容器运行 待补充。。。 存出镜像1$ docker save -o ubuntu16.04.tar ubuntu:16.04 载入镜像1$ docker load --input ubuntu16.04.tar 上传镜像到仓库默认上传到DockerHub仓库，需要登录。 1$ docker push [OPTIONS] NAME[:TAG]","link":"/2017/10/22/docker/docker%E7%9A%84%E5%AE%89%E8%A3%85/"},{"title":"Elasticsearch-analyze","text":"_analyze 分析被存储到索引中的词条 12345GET /_analyze{ &quot;analyzer&quot;: &quot;index_ansj&quot;, &quot;text&quot;: &quot;六味地黄丸软胶囊.&quot;} analyzer: 指定分析器。 text: 要被分析的内容。 结果中每个元素代表一个单独的词条： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546{ &quot;tokens&quot;: [ { &quot;token&quot;: &quot;六味&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 2, &quot;type&quot;: &quot;mq&quot;, &quot;position&quot;: 0 }, { &quot;token&quot;: &quot;地黄&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 4, &quot;type&quot;: &quot;n&quot;, &quot;position&quot;: 1 }, { &quot;token&quot;: &quot;丸&quot;, &quot;start_offset&quot;: 4, &quot;end_offset&quot;: 5, &quot;type&quot;: &quot;q&quot;, &quot;position&quot;: 2 }, { &quot;token&quot;: &quot;软&quot;, &quot;start_offset&quot;: 5, &quot;end_offset&quot;: 6, &quot;type&quot;: &quot;a&quot;, &quot;position&quot;: 3 }, { &quot;token&quot;: &quot;胶囊&quot;, &quot;start_offset&quot;: 6, &quot;end_offset&quot;: 8, &quot;type&quot;: &quot;n&quot;, &quot;position&quot;: 4 }, { &quot;token&quot;: &quot;.&quot;, &quot;start_offset&quot;: 8, &quot;end_offset&quot;: 9, &quot;type&quot;: &quot;w&quot;, &quot;position&quot;: 5 } ]}","link":"/2018/06/08/elasticsearch/Elasticsearch-analyze/"},{"title":"Elasticsearch-映射","text":"映射是用于定义文档所包含的字段的数据类型进行存储和索引方式的过程 。 字段数据类型 Field datatypes 每个字段都有一个数据类型。可以是 基本数据类型：text，keyword，date，long， double，boolean或ip。 一种支持JSON的分层特性的类型，如 object或nested。 一种特殊类型 geo_point， geo_shape或completion。 以不同的目的对字段映射合适的数据类型。例如，字符串字段可以映射为text用于全文搜索，也可以映射keyword进行排序或聚合 。多数数据类型 都可以通过fields参数将 同一字段进行多个数据类型的索引方式。 映射爆炸在索引中定义太多字段是一种可能导致映射爆炸的情况，这可能导致内存不足错误和难以恢复的情况 ，例如，插入的每个新文档时引入新字段的情况。这在动态映射中非常常见。每次文档包含新字段时，这些字段最终都会出现在索引的映射中。 如果只是少量数据，这并不需要担心，但随着映射的增长，它可能会成为一个问题。 如需字段映射的数量 ，来防止映射爆炸。参考 mapping-limit-settings 动态映射在添加文档时不需要定义字段和映射类型 ，是因为Elasticsearch的动态映射，会自动添加新的字段名称。新字段既可以添加到映射类型。 显示映射 动态映射的字段类型可能不是理想的，可以显示指定映射。 可以在创建索引时创建字段映射 ，也可以使用PUT映射API将字段添加到现有索引 。 更新现有字段映射现有的字段映射无法更新。更改映射意味着使已编制索引的文档无效。 应该创建一个正确映射新的索引并重新索引的数据转换到index。 映射示例12345678910111213141516PUT my_index { \"mappings\": { \"doc\": { \"properties\": { \"title\": { \"type\": \"text\" }, \"name\": { \"type\": \"text\" }, \"age\": { \"type\": \"integer\" }, \"created\": { \"type\": \"date\", \"format\": \"strict_date_optional_time||epoch_millis\" } } } }} 参考：https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html","link":"/2018/07/11/elasticsearch/Elasticsearch-%E6%98%A0%E5%B0%84/"},{"title":"Elasticsearch与mongodb同步","text":"Elasticsearch与mongodb同步 利用mongo-connectormongodb官方介绍 github 安装根据具体Elasticsearch版本，利用pip安装最新版本mongo-connector 123$ pip install 'mongo-connector[elastic5]'$ mongo-connector --version mongo-connector version: 2.5.1 如果提示pip没装，则先安装pip 1$ sudo apt-get install python-pip mongodb开启副本集（必须开启），已开启则忽略此步。deploy-replica-set (1) 停止mongodb服务 1$ service mongodb stop (2) 通过 --replSet 设定副本集名称 1$ mongod --replSet myDevReplSet 或者在配置文件 mongodb.conf 中添加 12#副本集名称replSet=myDevReplSet 说明： myDevReplSet是副本集的名称 (3) 初始化副本集 123456&gt; rs.initiate(){ \"info2\" : \"no configuration specified. Using a default configuration for the set\", \"me\" : \"ubuntu:27017\", \"ok\" : 1} (4) 【验证】初始化副本集的配置 123456789101112131415161718192021222324252627282930313233343536myDevReplSet:OTHER&gt; rs.conf(){ &quot;_id&quot; : &quot;myDevReplSet&quot;, &quot;version&quot; : 1, &quot;protocolVersion&quot; : NumberLong(1), &quot;members&quot; : [ { &quot;_id&quot; : 0, &quot;host&quot; : &quot;ubuntu:27017&quot;, &quot;arbiterOnly&quot; : false, &quot;buildIndexes&quot; : true, &quot;hidden&quot; : false, &quot;priority&quot; : 1, &quot;tags&quot; : { }, &quot;slaveDelay&quot; : NumberLong(0), &quot;votes&quot; : 1 } ], &quot;settings&quot; : { &quot;chainingAllowed&quot; : true, &quot;heartbeatIntervalMillis&quot; : 2000, &quot;heartbeatTimeoutSecs&quot; : 10, &quot;electionTimeoutMillis&quot; : 10000, &quot;catchUpTimeoutMillis&quot; : 2000, &quot;getLastErrorModes&quot; : { }, &quot;getLastErrorDefaults&quot; : { &quot;w&quot; : 1, &quot;wtimeout&quot; : 0 }, &quot;replicaSetId&quot; : ObjectId(&quot;5b35a8568dccf16c7734a30b&quot;) }} (5)【验证】副本集的状态。 123456789101112131415161718192021222324252627282930313233343536373839404142myDevReplSet:PRIMARY&gt; rs.status(){ \"set\" : \"myDevReplSet\", \"date\" : ISODate(\"2018-06-29T03:34:53.131Z\"), \"myState\" : 1, \"term\" : NumberLong(1), \"heartbeatIntervalMillis\" : NumberLong(2000), \"optimes\" : { \"lastCommittedOpTime\" : { \"ts\" : Timestamp(1530243289, 1), \"t\" : NumberLong(1) }, \"appliedOpTime\" : { \"ts\" : Timestamp(1530243289, 1), \"t\" : NumberLong(1) }, \"durableOpTime\" : { \"ts\" : Timestamp(1530243289, 1), \"t\" : NumberLong(1) } }, \"members\" : [ { \"_id\" : 0, \"name\" : \"ubuntu:27017\", \"health\" : 1, \"state\" : 1, \"stateStr\" : \"PRIMARY\", \"uptime\" : 282, \"optime\" : { \"ts\" : Timestamp(1530243289, 1), \"t\" : NumberLong(1) }, \"optimeDate\" : ISODate(\"2018-06-29T03:34:49Z\"), \"electionTime\" : Timestamp(1530243158, 2), \"electionDate\" : ISODate(\"2018-06-29T03:32:38Z\"), \"configVersion\" : 1, \"self\" : true } ], \"ok\" : 1} 数据同步 官方文档命令格式 123mongo-connector -m &lt;mongodb server hostname&gt;:&lt;replica set port&gt; \\ -t &lt;replication endpoint URL, e.g. http://localhost:8983/solr&gt; \\ -d &lt;name of doc manager, e.g., solr_doc_manager&gt; 执行命令 1$ mongo-connector -m username:passwd@localhost:27017 -t username:passwd@localhost:9200 -d elastic2_doc_manager -n testDB.testCol 说明： -m 指定mongodb的地址与端口 。 ​ -t ES的地址与端口 。 ​ -d doc manager的名称，2.x版本为： elastic2-doc-manager。 ​ -n 指定要同步的数据库和集合名。 数据同步前应先建立索引，再进行数据同步 验证测试 mongodb中执行数据插入 12345$ myDevReplSet:PRIMARY&gt; use test; # test对应ES的Indexswitched to db test# 插入数据 blog对应ES的type$ myDevReplSet:PRIMARY&gt; db.blog.insert({\"title\":\"标题一\",\"time\":\"2018-06-29\",\"content\":\"测试MongoDB与ElasticSearch数据同步\"});WriteResult({ \"nInserted\" : 1 }) ElasticSearch中检索数据 12345678910111213141516171819202122232425262728&gt; GET /test/blog/_search{ \"took\": 0, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 1, \"max_score\": 1, \"hits\": [ { \"_index\": \"test\", \"_type\": \"blog\", \"_id\": \"5b35dafcad35569566d32bc7\", \"_score\": 1, \"_source\": { \"content\": \"测试MongoDB与ElasticSearch数据同步\", \"title\": \"标题一\", \"time\": \"2018-06-29\" } } ] }} mongo-connector工具支持MongoDB与ES之间的实时增insert、删delete、改update操作。 但对于历史数据 不能保存到ES中 MongoDB River的插件MongoDB River 版本较旧不建议使用。 其它方案：暂未深究 https://elasticsearch.cn/question/1167 通过Bulk API 参考：https://blog.csdn.net/u011801161/article/details/71726495","link":"/2018/06/29/elasticsearch/Elasticsearch%E4%B8%8Emongodb%E5%90%8C%E6%AD%A5/"},{"title":"SpringBoot与ElasticSearch集成","text":"springboot目前最新版本为2.0.3.RELEASE，虽然spring-data-elasticsearch最新版本(测试版)为3.1.0已集成了ElasticSearch6.2.2版本，但是SpringBoot集成的spring-data-elasticsearch为3.0.7版本，不支持ElasticSearch 6 版本。所以只得自己集成。 ElasticSearch计划在7.0中将会弃用TransportClient，并在8.0中完全删除它。所以选择对 Java High Level REST Client 集成。ElasticSearch 提供了一套基于restful风格的全文检索服务组件。 1、pom.xml 12345678910&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;6.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;6.3.0&lt;/version&gt;&lt;/dependency&gt; 2、ElasticsearchConfig 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293import org.apache.http.HttpHost;import org.apache.http.auth.AuthScope;import org.apache.http.auth.UsernamePasswordCredentials;import org.apache.http.client.CredentialsProvider;import org.apache.http.impl.client.BasicCredentialsProvider;import org.apache.http.impl.nio.client.HttpAsyncClientBuilder;import org.elasticsearch.action.admin.indices.create.CreateIndexRequest;import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;import org.elasticsearch.client.RestClient;import org.elasticsearch.client.RestClientBuilder;import org.elasticsearch.client.RestHighLevelClient;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.DisposableBean;import org.springframework.beans.factory.FactoryBean;import org.springframework.beans.factory.InitializingBean;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class ElasticsearchConfig implements FactoryBean&lt;RestHighLevelClient&gt;, InitializingBean, DisposableBean { private static final Logger LOGGER = LoggerFactory.getLogger(ElasticsearchConfig.class); @Value(\"${spring.data.elasticsearch.cluster-nodes}\") private String clusterNodes; private RestHighLevelClient restHighLevelClient; @Override public void afterPropertiesSet() throws Exception { restHighLevelClient = buildClient(); } private RestHighLevelClient buildClient() { try { final CredentialsProvider credentialsProvider = new BasicCredentialsProvider(); credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(\"username\", \"passwd\")); RestClientBuilder builder = RestClient.builder(new HttpHost(clusterNodes.split(\":\")[0], Integer.parseInt(clusterNodes.split(\":\")[1]),\"http\")) .setHttpClientConfigCallback(new RestClientBuilder.HttpClientConfigCallback() { @Override public HttpAsyncClientBuilder customizeHttpClient(HttpAsyncClientBuilder httpClientBuilder) { httpClientBuilder.disableAuthCaching(); return httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider); } }); restHighLevelClient = new RestHighLevelClient(builder); } catch (Exception e) { LOGGER.error(e.getMessage()); } return restHighLevelClient; } @Override public RestHighLevelClient getObject() throws Exception { return restHighLevelClient; } @Override public Class&lt;?&gt; getObjectType() { return RestHighLevelClient.class; } @Override public void destroy() throws Exception { try { if (restHighLevelClient != null) { restHighLevelClient.close(); } } catch (final Exception e) { LOGGER.error(\"Error closing ElasticSearch client: \", e); } } @Bean(name = \"cmsElasticSearchIndex\") public String cmsElasticSearchIndex() throws Exception { String cmsIndex= \"cms\"; GetIndexRequest getRequest = new GetIndexRequest(); getRequest.indices(cmsIndex); boolean exists = restHighLevelClient.indices().exists(getRequest); if(!exists) { CreateIndexRequest request = new CreateIndexRequest(cmsIndex); CreateIndexResponse createIndexResponse = restHighLevelClient.indices().create(request); boolean acknowledged = createIndexResponse.isAcknowledged(); // 是否所有节点都已确认请求 LOGGER.info(\"是否所有节点都已确认请求?\" + acknowledged); } return cmsIndex; }} 3、application.properties 12spring.data.elasticsearch.cluster-name=my-es-clusterspring.data.elasticsearch.cluster-nodes=localhost:9200 4、测试 123456789101112131415161718192021@Autowiredprivate BookServiceImpl bookService;@Autowiredprivate RestHighLevelClient client;@Testpublic void getIndexTest() { GetRequest request = new GetRequest(\"cms\", \"Book\", \"1\"); try { GetResponse response = client.get(request); System.out.println(response); } catch (IOException e) { e.printStackTrace(); }}@Testpublic void getIndexServiceTest() { Book book = bookService.findById(1L); System.out.println(book.toString());} 项目地址：springboot-elasticsearch-high ElasticSearch6.3.0已内置支持 SQL 模块 参考：SQL 模块","link":"/2018/06/15/elasticsearch/SpringBoot%E4%B8%8EElasticSearch%E9%9B%86%E6%88%90/"},{"title":"elastic-stack","text":"elastic-stack Elastic Stack能够以任何格式可靠的，安全地从任何来源获取数据，并实时搜索，分析和可视化。 由ELK (Elasticsearch、Logstash以及Kibana) +Beats 组成。 目前Beats包含六种工具： Packetbeat： 网络数据（收集网络流量数据） Metricbeat： 指标 （收集系统、进程和文件系统级别的 CPU 和内存使用情况等数据） Filebeat： 日志文件（收集文件数据） Winlogbeat： windows事件日志（收集 Windows 事件日志数据） Auditbeat：审计数据 （收集审计日志） Heartbeat：运行时间监控 （收集系统运行时的数据）","link":"/2018/08/20/elasticsearch/elastic-stack/"},{"title":"Elasticsearch（一）安装","text":"Elasticsearch是一个基于Apache Lucene(TM)的开源 的实时分布式搜索和分析引擎。它可用于全文搜索、结构化搜索、分析 。 关于Lucene ，Lucene是迄今为止最先进、性能最好的、功能最全的搜索引擎库。 但是，Lucene只是一个库。想要使用它，你必须使用Java来作为开发语言并将其直接集成到你的应用中 。 Elasticsearch也是使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。 安装1、新增elastic系统用户 123$ adduser elastic$ su elastic$ cd /home/elastic/ 2、下载并安装 12345$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.2.4.tar.gz$ tar -xzf elasticsearch-6.2.4.tar.gz$ cd elasticsearch-6.2.4/$ lsbin config lib LICENSE.txt logs modules NOTICE.txt plugins README.textile 类型 描述 默认位置 设置 home目录 Elasticsearch主目录或 $ES_HOME 解压后所创建的目录 （elasticsearch-6.2.4） bin 二进制脚本，包括elasticsearch启动节点和elasticsearch-plugin安装插件 $ES_HOME/bin config 配置文件 $ES_HOME/config ES_PATH_CONF data 在节点上分配的每个索引/分片的数据文件的位置。可以容纳多个地点。 $ES_HOME/data path.data logs 日志文件 $ES_HOME/logs path.logs plugins 插件文件的位置。每个插件都将包含在一个子目录中。 $ES_HOME/plugins scripts 脚本文件 $ES_HOME/scripts path.scripts 3、启动Elasticsearch 12$ ./bin/elasticsearch // 前台运行,日志打印到标准输出（stdout)$ ./bin/elasticsearch -d -p pid //后台运行，作为守护程序运行。 4、查看运行状态 12345678910111213141516$ curl localhost:9200 { \"name\" : \"Guwcwiz\", \"cluster_name\" : \"elasticsearch\", \"cluster_uuid\" : \"nlJI4RBQT56y2AViWjNm4A\", \"version\" : { \"number\" : \"6.2.4\", \"build_hash\" : \"ccec39f\", \"build_date\" : \"2018-04-12T20:37:28.497551Z\", \"build_snapshot\" : false, \"lucene_version\" : \"7.2.1\", \"minimum_wire_compatibility_version\" : \"5.6.0\", \"minimum_index_compatibility_version\" : \"5.0.0\" }, \"tagline\" : \"You Know, for Search\" } 问题启动过程可能遇到的问题 1、端口被占用 节点间交互的TCp端口，默认是9300。 对外服务HTTP端口，默认是9200。 12[2018-06-05T11:40:36,756][WARN ][o.e.t.n.Netty4Transport ] [Guwcwiz] exception caught on transport layer [NettyTcpChannel{localAddress=/127.0.0.1:58590, remoteAddress=/127.0.0.1:9300}], closing connectionio.netty.handler.codec.DecoderException: java.io.StreamCorruptedException: invalid internal transport message format, got (48,54,54,50) 解决：修改配置文件 $ vim ./config/elasticsearch.yml 12http.port: 9200transport.tcp.port: 19300 2、锁定内存失败 12ERROR: bootstrap checks failedmemory locking requested for elasticsearch process but memory is not locked memory_lock_check Elasticsearch 配置文件中elasticsearch.yml启用了bootstrap.memory_lock设置 ，但Elasticsearch无法锁定堆（例如，如果elasticsearch 用户没有memlock unlimited） 解决： 方法一：注释掉配置文件中 #bootstrap.memory_lock: true 并使用其它几种方法配置系统禁止交换 Disable swapping 方法二：编辑 /etc/security/limits.conf 文件为特定用户永久设置。在limits.conf文件中添加： 1elasticsearch - memlock unlimited 此更改仅在elasticsearch用户下次打开新会话时生效。 3、用户拥有的内存权限太小 12ERROR: [1] bootstrap checks failed[1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决： 编辑 /etc/sysctl.conf文件 在文件末行添加 1vm.max_map_count = 262144 然后在shell中执行 1$ sysctl -p 参考：https://www.elastic.co/guide/en/elasticsearch/reference/current/zip-targz.html","link":"/2018/06/05/elasticsearch/elasticsearch(%E4%B8%80)%E5%AE%89%E8%A3%85/"},{"title":"Elasticsearch（三）节点","text":"Elasticsearch 节点每启动一个Elasticsearch的实例，就相当于启动了一个node节点，多个节点的集合就是一个集群。集群中的每个节点默认都可以处理HTTP和Transport两种通信，transport通信用于节点间JavaTransportClient的通信 ; HTTP层仅由外部REST客户端使用。 集群中的Node都能相互发现，并且可以将客户端请求转发到适当的节点，每个Node会有以下的一个或多个作用： 有资格被选举的主节点。node.master设置为true（默认）的节点，使其有资格被选为控制集群的主节点。 数据节点 node.data设置为true（默认）的节点。数据节点保存数据并执行数据相关的操作，如CRUD，搜索和聚合。 ingest节点 node.ingest设置为true（默认）的节点。摄取节点能够将摄取管道应用于文档，以便在编制索引之前转换和丰富文档。由于负载较重，因此使用专用摄取节点并将主节点和数据节点标记为“是有意义的” tribe节点 通过tribe.*设置配置的tribe节点，它是一种特殊类型的协调节点，可以连接到多个群集并在所有连接的群集中执行搜索和其他操作。 主节点主节点负责轻量级群集范围的操作，例如创建或删除索引，跟踪哪些节点是群集的一部分，以及决定将哪些碎片分配给哪些节点。集群有一个稳定的主节点是很重要的。一般在较大的群集中分配专用主节点和专用数据节点。 1234node.master：true node.data：false node.ingest：false search.remote.connect：false //禁用跨群集搜索 数据节点数据节点保存包含您编入索引的文档的分片。数据节点处理与数据相关的操作，如CRUD，搜索和聚合。这些操作是I / O-，内存和CPU密集型的。监视这些资源并在过载时添加更多数据节点非常重要。 拥有专用数据节点的主要好处是分离主数据角色和数据角色 1234node.master：false node.data：true node.ingest：false search.remote.connect：false ingest节点 摄取节点可以执行由一个或多个摄取处理器组成的预处理流水线。根据摄取处理器执行的操作类型和所需资源，具有专用摄入节点可能是有意义的，它只会执行此特定任务。 1234node.master：false node.data：false node.ingest：true search.remote.connect：false 只协调节点 不具备处理主任务，保存数据和预处理文档的能力，只能处理请求，处理搜索缩减阶段以及分发批量索引。本质上，只协调节点就像智能负载均衡器一样。 1234node.master：false node.data：false node.ingest：false search.remote.connect：false 注意：以上设置仅适用于未安装X-Pack的情况 如果安装了X-Pack，则还有一个附加的节点类型： 机器学习节点 X-Pack机器学习功能提供了机器学习节点，它可以运行作业并处理机器学习API请求。如果xpack.ml.enabled设置为true并且node.ml设置为false，则节点可以为API请求提供服务，但不能运行作业。 机器学习节点xpack.ml.enabled和node.ml设置true的节点，这是X-Pack时的默认配置。如果想使用X-Pack机器学习功能，则群集中必须至少有一个机器学习节点。有关X-Pack机器学习功能的更多信息，参考弹性堆栈中的机器学习。 如果安装了X-Pack，则默认情况下，节点具有主节点资格，数据，摄取和机器学习节点。 安装了X-Pack各节点的配置在安装X-Pack时创建专用的主节点节点，配置：12345node.master：true node.data：false node.ingest：false node.ml：false xpack.ml.enabled：true 在安装X-Pack时创建专用数据节点，配置：1234node.master：false node.data：true node.ingest：false node.ml：false //禁用node.ml角色 安装X-Pack时创建专用ingest节点，配置：12345node.master：false node.data：false node.ingest：true search.remote.connect：false node.ml：false 安装X-Pack时创建专用协调节点，配置：12345node.master：false node.data：false node.ingest：false search.remote.connect：false node.ml：false 如果要在群集中使用X-Pack机器学习功能，则必须在所有主节点上启用机器学习（设置xpack.ml.enabled为true） 创建专用机器学习节点，设置：123456node.master：false node.data：false node.ingest：false search.remote.connect：false node.ml：true xpack.ml.enabled：true 参考：https://www.elastic.co/guide/en/elasticsearch/reference/6.2/modules-node.html","link":"/2018/06/08/elasticsearch/elasticsearch(%E4%B8%89)%E8%8A%82%E7%82%B9/"},{"title":"Elasticsearch（二）配置","text":"Elasticsearch设置Elasticsearch提供了很好的默认设置，并且只需要很少的配置。 虽然Elasticsearch只需要很少的配置，但在投入生产之前需要考虑以下设置。 elasticsearch.yml 配置1、path.data and path.logs 如果正在使用.zip或.tar.gz存档，则data和logs 目录在$ES_HOME下。如果这些重要文件夹保留在默认位置，那么在将Elasticsearch升级到新版本时，这些文件夹有可能会被删除。 在生产使用中，如果想要更改数据和日志文件夹的位置： 12path.data: /var/data/elasticsearchpath.logs: /var/log/elasticsearch 2、 cluster.name 某个节点只有和集群下的其他节点共享它的 cluster.name 才能加入一个集群。默认是elasticsearch ，应将其更改为描述集群用途的适当名称。 1cluster.name: logging-prod 3、 node.name 默认情况下，Elasticsearch将使用随机生成的UUID的前七个字符作为节点ID。请注意，节点ID是持久的，并且在节点重新启动时不会更改，因此默认节点名称也不会更改。 1node.name：prod-data-2 4、network.host 默认情况下，Elasticsearch仅绑定到回环地址 - 例如127.0.0.1 和[::1]。这足以在服务器上运行单个开发节点。 实际上，可以从$ES_HOME 单个节点上的相同位置启动多个节点。这可以用于测试Elasticsearch形成群集的能力，但它不是推荐用于生产的配置。 为了与其他服务器上的节点进行通信并形成群集，您的节点将需要绑定到非回送地址。虽然网络设置很多，但通常您需要配置的是 network.host： 1network.host：192.168.1.10 只要对network.host提供自定义设置，Elasticsearch就会假定您正在从开发模式转移到生产模式，并将多个系统启动检查从警告升级到异常。有关更多信息，请参阅开发模式与生产模式编辑。 5、Discovery settings Elasticsearch使用名为“Zen Discovery”的自定义发现实现进行节点到节点的群集和主选举。在投入生产之前，应该配置两个重要的发现设置。 discovery.zen.ping.unicast.hosts 开箱即用，没有任何网络配置，Elasticsearch将绑定到可用的环回地址，并将扫描端口9300到9305以尝试连接到运行在同一台服务器上的其他节点。这提供了自动集群体验，而无需进行任何配置。 当需要与其他服务器上的节点组成群集时，您必须提供群集中其他节点的种子列表，这些节点可能是活的并且可联系的。这可以指定如下： 1234discovery.zen.ping.unicast.hosts： - 192.168.1.10:9300 - 192.168.1.11 - seeds.mydomain.com 如果未指定端口，将默认为transport.profiles.default.port并回退到 transport.tcp.port。 如果输入的是主机名，被解析成多个地址，将会尝试连接所有地址。 discovery.zen.ping.unicast.hosts 为防止数据丢失，配置该discovery.zen.minimum_master_nodes设置至关重要， 以便每个符合主节点的节点都知道为了形成群集而必须可见的主节点的最小数量。 如果没有这种设置，遭受网络故障的集群就有可能将集群分成两个独立的集群 - 脑裂 - 这将导致数据丢失。在 Avoiding split brain with minimum_master_nodesedit 提供了更详细的解释 。 为避免分裂大脑，应将候选节点的数量设置为： 1（master_eligible_nodes / 2）+ 1 假如有3个节点，最小候选主节点数应该是（3/2)+1=2: 1discovery.zen.minimum_master_nodes：2 jvm.options1、Heap size 默认情况下，Elasticsearch设置JVM使用的最小和最大堆内存为1 GB。在转移到生产环境时，配置堆大小以确保Elasticsearch有足够的可用堆是非常重要的。 Elasticsearch将通过（最小堆大小）和（最大堆大小）设置来分配jvm.options中指定的整个堆 。Xms Xmx 这些设置的值取决于服务器上可用的RAM数量。好的经验法则是： 将最小堆大小（Xms）和最大堆大小（Xmx）设置为相等 . 设置Xmx为不超过物理RAM的50％，以确保有足够的物理内存留给内核文件系统缓存。 Elasticsearch可用的堆越多，可用于缓存的内存就越多。但请注意，太多的堆可能会使您长时间垃圾收集暂停。 不要设置Xmx为JVM用于压缩对象指针（压缩oops）的临界值以上; 确切的临界值有所不同，但接近32 GB。可以通过在日志中查找一行来验证您是否处于限制之下，如下所示： 1heap size [1.9gb], compressed ordinary object pointers [true] 尽量保持低于基于零的压缩oops的阈值; 准确的截止值会有所不同，但大多数系统上的26 GB是安全的，但在某些系统上可能高达30 GB。您可以通过使用JVM选项启动Elasticsearch -XX:+UnlockDiagnosticVMOptions -XX:+PrintCompressedOopsMode并查找以下行来验证您是否处于限制之下： 1heap address: 0x000000011be00000, size: 27648 MB, zero based Compressed Oops 而不是 1heap address: 0x0000000118400000, size: 28672 MB, Compressed Oops with base: 0x00000001183ff000 示例：通过jvm.options文件设置堆大小 12-Xms2g -Xmx2g 将最小堆大小设置为2g。 将最大堆大小设置为2g 。 2、Heap dump path 归档tar解压包默认情况下不配置堆转储路径。 JVM将默认转储到Elasticsearch进程的工作目录。 如果想配置一个堆转储路径，应该修改 jvm.options中条目#-XX:HeapDumpPath=/heap/dump/path 删除注释标记#，并指定一个实际的路径。 3、GC logging 默认情况下，Elasticsearch启用GC日志。jvm.options在Elasticsearch日志中默认配置 为默认位置。默认配置每64 MB轮换一次日志，最多可消耗2 GB磁盘空间。 系统设置理想情况下，Elasticsearch应该在服务器上独立运行并使用可用的所有资源。为此，需要配置操作系统以允许运行Elasticsearch的用户访问比默认允许的资源更多的资源。 在默认情况下，Elasticsearch假定您正在开发模式下工作。如果以下任何设置配置不正确，仍可以启动并运行Elasticsearch节点。 但会向日志文件写入警告。 但是只要配置好网络设置network.host，Elasticsearch就会假定您正在转向生产并将上述警告升级为异常。这些异常将阻止Elasticsearch节点启动。可确保您不会由于配置错误的服务器而丢失数据。 1、禁用交换分区 有三种方法禁用交换。首选选项是完全禁用交换。 其它如最小化swappiness与内存锁定 。 具体参考 禁用所有交换文件 在Linux系统上，临时禁用交换： 1sudo swapoff -a 要永久禁用它，需要编辑该/etc/fstab文件并注释掉包含swap的所有行。 配置swappiness Linux系统上可用的另一个选项是确保sysctl值 vm.swappiness设置为1。这减少了内核的交换趋势，在正常情况下不应该导致交换，同时仍然允许整个系统在紧急情况下进行交换。 启用bootstrap.memory_lock 另一种选择是在Linux / Unix系统上使用mlockall或 在Windows 上 使用 VirtualLock，以尝试将进程地址空间锁定到RAM中，防止任何Elasticsearch内存被换出。在config/elasticsearch.yml文件中添加： 1bootstrap.memory_lock：true 2、增加文件描述符 Elasticsearch使用了大量的文件描述符或文件句柄。如果用完文件描述符可能导致数据丢失。确保将运行Elasticsearch的用户的打开文件描述符数限制增加到65,536或更高。 在Linux系统上，可以通过编辑 /etc/security/limits.conf 文件为特定用户设置永久限制。要将elasticsearch用户的最大打开文件数设置为65,536，在limits.conf文件中添加： 1elasticsearch - nofile 65536 此更改仅在elasticsearch用户下次打开新会话时生效。 说明：在Ubuntu中启动进程的文件init.d 可能会忽略limits.conf ，要启用该limits.conf文件，取消/etc/pam.d/su以下注释行： 1# session required pam_limits.so 3、增加虚拟内存 Elasticsearch mmapfs默认使用一个目录来存储它的索引。mmap计数的默认操作系统限制可能太低，这可能会导致内存不足异常。 在Linux上，您可以通过运行以下命令来临时增加限制 ： 1sysctl -w vm.max_map_count = 262144 要永久设置，编辑 /etc/sysctl.conf 文件。添加： 1vm.max_map_count=262144 并执行命令： sysctl -p 4、增加可创建线程数量 Elasticsearch针对不同类型的操作使用多个线程池。能够在需要时创建新线程很重要。确保Elasticsearch用户可以创建的线程数至少为4096。 可以通过编辑 /etc/security/limits.conf 文件为特定用户设置永久限制。要将elasticsearch用户的最大创建线程数量设置为4096，在limits.conf文件中添加： 1elastic - nproc 4096 5、JVM DNS缓存设置 DNS cache settings 参考：https://www.elastic.co/guide/en/elasticsearch/reference/current/zip-targz.html https://www.elastic.co/guide/en/elasticsearch/reference/current/important-settings.html https://www.elastic.co/guide/en/elasticsearch/reference/current/system-config.html","link":"/2018/06/06/elasticsearch/elasticsearch(%E4%BA%8C)%E9%85%8D%E7%BD%AE/"},{"title":"Elasticsearch（五）API","text":"Elasticsearch APIElasticsearch是基于HTTP协议，以JSON为数据交互格式的RESTful API可以通过WEB客户端或curl命令与Elasticsearch通信。 向Elasticsearch发出的请求的组成部分 1curl -X&lt;VERB&gt; '&lt;PROTOCOL&gt;://&lt;HOST&gt;:&lt;PORT&gt;/&lt;PATH&gt;?&lt;QUERY_STRING&gt;' -d '&lt;BODY&gt;' VERB HTTP方法：GET, POST, PUT, HEAD, DELETEPROTOCOL http或者https协议（只有在Elasticsearch前面有https代理的时候可用）HOST Elasticsearch集群中的任何一个节点的主机名，如果是在本地的节点，那么就叫localhostPORT Elasticsearch HTTP服务所在的端口，默认为9200PATH API路径（例如_count将返回集群中文档的数量），PATH可以包含多个组件，例如_cluster/stats或者_nodes/stats/jvmQUERY_STRING 一些可选的查询请求参数，例如?pretty参数将使请求返回更加美观易读的JSON数据BODY 一个JSON格式的请求主体（如果请求需要的话） 查询集群中的文档数量 12345678910111213141516171819$ curl -i -H \"Content-Type: application/json\" -XGET '47.98.128.106:19200/_count?pretty' -d '{ \"query\": { \"match_all\": {} }}'HTTP/1.1 200 OKcontent-type: application/json; charset=UTF-8content-length: 114{ \"count\" : 0, \"_shards\" : { \"total\" : 0, \"successful\" : 0, \"skipped\" : 0, \"failed\" : 0 }} Elasticsearch与传统关系型数据库 的类比 12Relational DB -&gt; Databases -&gt; Tables -&gt; Rows -&gt; ColumnsElasticsearch -&gt; Indices -&gt; Types -&gt; Documents -&gt; Fields Elasticsearch集群可以包含多个索引(indices)（数据库），每一个索引可以包含多个类型(types)（表），每一个类型包含多个文档(documents)（行），然后每个文档包含多个字段(Fields)（列）。 简单搜索 123GET /megacorp/employee/1GET /megacorp/employee/_searchGET /megacorp/employee/_search?q=last_name:Smith DSL语句查询 搜索last_name包含Smith的 12345678GET /megacorp/employee/_search { &quot;query&quot; : { &quot;match&quot; : { &quot;last_name&quot; : &quot;Smith&quot; } } } filter: 搜索年龄大于30岁并且last_name包含Smith的 1234567891011121314151617GET /megacorp/employee/_search { &quot;query&quot; : { &quot;filtered&quot; : { &quot;filter&quot; : { &quot;range&quot; : { &quot;age&quot; : { &quot;gt&quot; : 30 } &lt;1&gt; } }, &quot;query&quot; : { &quot;match&quot; : { &quot;last_name&quot; : &quot;smith&quot; &lt;2&gt; } } } } } 全文搜索(match)：搜索about包含rock climbing的，结果会把包含rock 或climbing的查出来 12345678 GET /megacorp/employee/_search{ &quot;query&quot; : { &quot;match&quot; : { &quot;about&quot; : &quot;rock climbing&quot; } }} 短语搜索(match_phrase)：查询同时包含”rock”和”climbing”（并且是相邻的）的记录 12345678 GET /megacorp/employee/_search{ &quot;query&quot; : { &quot;match_phrase&quot; : { &quot;about&quot; : &quot;rock climbing&quot; } }} 高亮我们的搜索(highlight): 12345678910111213 GET /megacorp/employee/_search{ &quot;query&quot; : { &quot;match_phrase&quot; : { &quot;about&quot; : &quot;rock climbing&quot; } }, &quot;highlight&quot;: { &quot;fields&quot; : { &quot;about&quot; : {} } }}字段存在查询 123456GET /_search{ \"query\": { \"exists\" : { \"field\" : \"user\" } }} 字段不存在查询 123456789101112GET /_search{ \"query\": { \"bool\": { \"must_not\": { \"exists\": { \"field\": \"user\" } } } }} 学习可参考：https://es.xiaoleilu.com/index.html","link":"/2018/06/08/elasticsearch/elasticsearch(%E4%BA%94)API/"},{"title":"Elasticsearch（四）插件","text":"Elasticsearch HeadElasticsearch Head 是集群管理、数据可视化、增删改查、查询语句可视化工具 。 自5.0以后，head插件安装就比较麻烦了，可以安装谷歌插件的elasticsearch-head-chrome 参考 有docker环境的可使用docker启动： docker run -p 9100:9100 mobz/elasticsearch-head:5 其实elasticsearch6.*的版本是不需要安装head插件的，kibana+x-pack就可以了。 elasticsearch-analysis-ansj elasticsearch-analysis-ansj是一个elasticsearch的中文分词插件。 ansj_seg自定义词库：http://yucang52555.iteye.com/blog/2164829 安装 进入Elasticsearch目录执行命令 1$ ./bin/elasticsearch-plugin install https://github.com/NLPchina/elasticsearch-analysis-ansj/releases/download/v6.2.4/elasticsearch-analysis-ansj-6.2.4.0-release.zip Elasticsearch设置ansj默认分词 建议不要全局设置，在创建索引时去设置。 Elasticsearch6.X不能直接修改elasticsearch.yml issues Elasticsearch6不支持动态设置，indecis处于开启状态，需要先关闭，在进行设置，设置完成后在打开。参考 1$ curl -u user:passwd -XPOST 'localhost:9200/_all/_close' 1234$ curl -u user:passwd -H \"Content-Type: application/json\" -XPUT 'localhost:9200/_all/_settings?preserve_existing=true' -d '{ \"index.analysis.analyzer.default.type\" : \"index_ansj\", \"index.analysis.analyzer.default_search.type\" : \"query_ansj\"}' 1$ curl -u user:passwd -XPOST 'localhost:9200/_all/_open' 查看 123456789101112131415161718192021222324$ GET /test ... &quot;settings&quot;: { &quot;index&quot;: { &quot;number_of_shards&quot;: &quot;5&quot;, &quot;provided_name&quot;: &quot;test&quot;, &quot;creation_date&quot;: &quot;1529580829374&quot;, &quot;analysis&quot;: { &quot;analyzer&quot;: { &quot;default_search&quot;: { &quot;type&quot;: &quot;query_ansj&quot; }, &quot;default&quot;: { &quot;type&quot;: &quot;index_ansj&quot; } } }, &quot;number_of_replicas&quot;: &quot;1&quot;, &quot;uuid&quot;: &quot;EZPQ7kWjSee13sqR0P84BA&quot;, &quot;version&quot;: { &quot;created&quot;: &quot;6020499&quot; } } }","link":"/2018/06/06/elasticsearch/elasticsearch(%E5%9B%9B)%E6%8F%92%E4%BB%B6/"},{"title":"elasticsearch健康状态","text":"elasticsearch健康状态 green 所有的主分片和副本分片都已分配。你的集群是 100% 可用的。 yellow 所有的主分片已经分片了，但至少还有一个副本是缺失的。不会有数据丢失，所以搜索结果依然是完整的。不过，你的高可用性在某种程度上被弱化。如果 更多的 分片消失，你就会丢数据了。把 yellow 想象成一个需要及时调查的警告。 red 至少一个主分片（以及它的全部副本）都在缺失中。这意味着你在缺少数据：搜索只能返回部分数据，而分配到这个分片上的写入请求会返回一个异常。 健康状态为yellow或red时首先检查磁盘空间是否充足。","link":"/2018/07/05/elasticsearch/elasticsearch%E5%81%A5%E5%BA%B7%E7%8A%B6%E6%80%81/"},{"title":"elasticsearch分页","text":"elasticsearch分页 深度分页（from/size） 如果要查询第5000-5100数据，根据官方API 很容易做到 1234567GET /_search{ &quot;from&quot; : 5000, &quot;size&quot; : 5100, &quot;query&quot; : { &quot;term&quot; : { &quot;user&quot; : &quot;kimchy&quot; } }} 查询的流程如下： 1、客户端发送请求到某个node节点。 2、此node将请求广播到各分片，各分片各自查询前5100条数据。 3、查询结果返回给node节点，node对结果进行合并整合，取出前5100条数据。 4、返回给客户端。 深度分页查询的问题 ，如果你要深度获取1000000到1000100页的数据，性能问题会非常明显的暴露出来：CPU、内存、IO、网络带宽等等，而且Elasticsearch本身就是个Java应用，若并发上去，Elasticsearch会快就会OOM。 官方也对此进行了限制 Note that from + size can not be more than the index.max_result_window index setting which defaults to 10,000. See the Scroll or Search After API for more efficient ways to do deep scrolling. 大意为，from+size不再适用于查询数据超过index.max_result_window设置值，此默认值为10000 。查看 Scroll 或 Search After来获取更高效的深层分页（滚动）。 scroll API 它可用于从单个搜索请求中检索大量数据（甚至所有数据），这与在传统数据库上cursors (游标)的方式非常相似。 scroll不是针对实时用户请求，而是针对处理大量数据 。 Scroll整个遍历过程分两步： 1、初始化 123456789POST /index/type/_search?scroll=1m{ &quot;size&quot;: 100, &quot;query&quot;: { &quot;match&quot; : { &quot;title&quot; : &quot;elasticsearch&quot; } }} 说明：(1) 与普通查询一样，可以指定index、type、查询条件等。 ​ (2) scroll参数：初始化请求必须指定Scroll参数，此参数告诉Elasticsearch 他要保存此次搜索的上下文多长时间。 2、遍历 12345POST /_search/scroll { &quot;scroll&quot; : &quot;1m&quot;, &quot;scroll_id&quot; : &quot;DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==&quot; } 说明：(1) scroll: 指定上下文搜索的保持时间，超时scroll_id就过期不能再使用。但是设置时间不可过长，只要能让其保持到下一次遍历（两次遍历时间）完成即可。 (2) scroll_id: 初始化或上次遍历的返回的scroll_id。 (3) index、type、搜索条件不用指定。 这些是在原始search请求中指定的。 (4) 默认每次取10条。若需要修改，添加size参数，size的设置也要考虑性能问题，过大一次取数据过多不是自己应用OOM就是es服务OOM。 (5) 重复此请求直到返回数据为空，遍历结束。 java-rest-high-search-scroll Search After API scroll api 不建议用于实时用户请求 ，容忍情况下也可以使用。 search_after参数通过提供实时游标来解决此问题。原理是使用上一页的结果来帮助检索下一页 。 search_after不是自由跳转到随机页面而是并行滚动许多查询的解决方案 。 例如检索第一页如下 12345678910111213GET twitter/_search{ &quot;size&quot;: 10, &quot;query&quot;: { &quot;match&quot; : { &quot;title&quot; : &quot;elasticsearch&quot; } }, &quot;sort&quot;: [ {&quot;date&quot;: &quot;asc&quot;}, {&quot;_id&quot;: &quot;desc&quot;} ]} 上述请求的结果数组中每个文档会包括sort values。这些sort values可以与下面请求的search_after参数一起使用 ，可以在结果列表中的任何文档“之后”开始返回结果 。 请求下一页 1234567891011121314GET twitter/_search{ &quot;size&quot;: 10, &quot;query&quot;: { &quot;match&quot; : { &quot;title&quot; : &quot;elasticsearch&quot; } }, &quot;search_after&quot;: [1463538857, &quot;654323&quot;], &quot;sort&quot;: [ {&quot;date&quot;: &quot;asc&quot;}, {&quot;_id&quot;: &quot;desc&quot;} ]} 说明：使用时，from参数必须设置为0（或-1） 。 参考：https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-from-size.html https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-search-after.html https://www.sohu.com/a/165387407_465944","link":"/2018/07/16/elasticsearch/elasticsearch%E5%88%86%E9%A1%B5/"},{"title":"Kibana安装","text":"Kibana是一个开源的分析和可视化平台，旨在与Elasticsearch合作。可以使用Kibana来搜索，查看存储在Elasticsearch索引中的数据并与其进行交互。可以执行高级数据分析，并在各种图表，表格和图表中可视化数据。 安装1、下载并安装 123456$ wget https://artifacts.elastic.co/downloads/kibana/kibana-6.2.4-linux-x86_64.tar.gz$ tar -xzf kibana-6.2.4-linux-x86_64.tar.gz$ cd kibana-6.2.4-linux-x86_64/$ lsbin data node NOTICE.txt package.json README.txt ui_frameworkconfig LICENSE.txt node_modules optimize plugins src webpackShims 类型 描述 默认位置 home目录 Kibana 主目录或 $KIBANA_HOME 解压后所创建的目录 （kibana-6.2.4-linux-x86_64） bin 二进制脚本包括kibana启动Kibana服务器和kibana-plugin安装插件 $KIBANA_HOME\\bin config 配置文件 $KIBANA_HOME\\config data 由Kibana及其插件写入磁盘的数据文件的位置 $KIBANA_HOME\\data optimize 运行的源代码。某些管理操作（例如插件安装）会导致源代码被即时重新编译。 $KIBANA_HOME\\optimize plugins 插件文件的位置。每个插件都将包含在一个子目录中。 $KIBANA_HOME\\plugins 2、配置文件 参考vim ./config/kibana.yml 123server.port: 5601server.host: \"172.16.0.3\"elasticsearch.url: \"http://172.16.0.3:19200\" 3、启动 Kibana 12$ ./bin/kibana # 前台运行,日志打印到标准输出（stdout)$ nohup ./bin/kibana &gt;&gt; kibana.log 2&gt;&amp;1 &amp; #后台启动 4、访问：localhost:5601 其它： 获取kibana的PID 123$ lsof -i:5601COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEnode 18325 elastic 12u IPv4 2090814531 0t0 TCP bp11_106:5601 (LISTEN) 或者 ps -ef |grep node 生产环境中使用Kibanahttps://www.elastic.co/guide/en/kibana/6.2/production.html 参考：https://www.elastic.co/guide/en/kibana/6.2/targz.html","link":"/2018/06/07/elasticsearch/kibana%E7%9A%84%E5%AE%89%E8%A3%85/"},{"title":"logstash(一)","text":"简介Logstash可以动态收集不同来源的数据，并将数据标准化输出到选择的目的地。为各种分析和可视化清理和整理所有数据 。应用 工作原理logstash中有三个元素、input、filter 、output，对应事件处理管道的三个阶段：输入–&gt;过滤–&gt;输出。输入和输出支持编解码器，能够在数据进入或退出管道时对数据进行编码或解码，而无需使用单独的过滤器。 Logstash 配置文件Logstash 有两种类型的配置文件：管道配置文件—用于定义Logstash 的处理管道；设置文件—用于配置Logstash 启动和执行的选项。 管道配置文件在定义Logstash处理管道的各个阶段时，可以创建管道配置文件。 一般可放置在logstash/conf.d目录中 ，扩展名为.conf 有关详细信息，请参阅配置Logstash。 设置文件设置文件已在Logstash安装中定义。Logstash包含以下设置文件： logstash.yml ：可以在此文件中设置flags ，而不是在命令行传递flags ，当然在命令行中设置的任何flags都会覆盖logstash.yml文件中的相应设置 。具体可参阅logstash.yml。 pipelines.yml ：包含在单个Logstash实例中运行多个管道的框架和说明。具体可参阅多个管道。 jvm.options ：此文件设置总堆空间的初始值和最大值。还可以使用此文件为Logstash设置区域(local)设置。 log4j2.properties : 包含log4j 2库的默认设置。具体可参阅Log4j 2配置。 startup.options (Linux)： 包含系统安装脚本在 /usr/share/logstash/bin 中使用的选项为您的系统构建适当的启动脚本。安装 Logstash 软件包时，系统安装脚本将在安装过程结束时执行，并使用 startup.options 中指定的设置来设置用户，组，服务名称和服务描述等选项。 logstash.yml设置项详细参考：https://www.elastic.co/guide/en/logstash/current/logstash-settings-file.html 参数 描述 默认值 node.name 节点名 主机名 path.data Logstash及其插件用于任何持久性需求的目录。 LOGSTASH_HOME/data pipeline.workers 同时执行管道的过滤器和输出阶段的工作任务数量。如果发现事件正在备份，或CPU未饱和，请考虑增加此数字以更好地利用机器处理能力 。 Number of the host’s CPU cores pipeline.batch.size 尝试执行过滤器和输出之前，单个工作线程从输入管道收集的最大事件数量。较大的批量处理大小一般来说效率更高，但是以增加的内存开销为代价。您可能必须通过 jvm.options 设置 LS_HEAP_SIZE 变量来有效使用该选项来增加JVM堆大小。 125 pipeline.batch.delay 在创建管道事件批处理时，在将较小的批处理分派给管道工作者之前等待每个事件的时间（以毫秒为单位）。 50 pipeline.unsafe_shutdown 设置true为时，强制Logstash在关闭期间退出，即使内存中仍有 inflight 事件 。 false path.config 主管道的Logstash配置的路径。如果指定目录或通配符，则按字母顺序从目录中读取配置文件。 参阅Logstash目录布局。 config.string 包含用于主管道的管道配置的字符串。 none config.test_and_exit 设置为true时，检查配置是否有效，然后退出。请注意，使用此设置不会检查grok模式的正确性。 Logstash可以从目录中读取多个配置文件。如果将此设置与log.level：debug结合使用，则Logstash将记录组合的配置文件，并注掉其源文件的配置块。 false config.reload.automatic 设置true为时，定期检查配置是否已更改，并在配置发生更改时重新加载配置。这也可以通过SIGHUP信号手动触发。 false config.reload.interval Logstash 检查配置文件更改的时间间隔。 3s config.debug 设置为true时，将完全编译的配置显示为调试日志消息。您还必须设置log.level：debug。警告： 日志消息将包含作为纯文本传递给插件配置的任何密码选项，并可能导致明文密码出现在您的日志中！ false config.support_escapes 设置true为时，带引号的字符串将处理以下转义序列：\\n成为文字换行符（ASCII 10）。\\r成为文字回车（ASCII 13）。\\t成为文字标签（ASCII 9）。\\\\成为一个字面反斜杠\\。\\&quot;成为字面双引号。\\'成为字面引号。 false modules 配置时， modules 必须处于上表所述的嵌套YAML结构中。 none queue.type 用于事件缓冲的内部队列模型。指定memory基于内存的队列，或persisted基于磁盘的ACKed排队列。 memory path.queue 启用持久队列时将存储数据文件的目录路径（queue.type: persisted）。 path.data/queue http.host 标准REST端点的绑定地址。 “127.0.0.1” http.port 标准REST端点的绑定端口。 9600 log.level 日志级别。有效选项包括：fatal 、error、warn、info、debug、trace info log.format 日志格式。设置为json，或plain使用Object#.inspect。 plain path.log 日志存储的目录。 LOGSTASH_HOME/logs path.plugins 哪里可以找到自定义插件。您可以多次指定此设置以包含多个路径。插件预计将在一个特定的目录层次结构：PATH/logstash/TYPE/NAME.rb其中TYPE是inputs，filters，outputs，或codecs，并且NAME是插件的名称。 启动在命令行中启动 1$ bin/logstash [options] 加载指定管道配置文件 1$ bin/logstash -f mypipeline.conf 更多命令行启动参数：参考 在测试Logstash时，指定命令行选项很有用。但是，在生产环境中，建议您使用 logstash.yml来控制Logstash执行。使用设置文件可以更轻松地指定多个选项 。 管道配置文件结构1234567891011input { ...}filter { ...}output { ...} 每个部分都包含一个或多个插件的配置选项。如果指定了多个过滤器，则会按照它们在配置文件中的显示顺序应用它们。 插件配置插件的配置由插件名称和插件的一个设置块组成。 下面的例子中配置了两个输入文件配置： 1234567891011input { file { path =&gt; &quot;/var/log/messages&quot; type =&gt; &quot;syslog&quot; } file { path =&gt; &quot;/var/log/apache/access.log&quot; type =&gt; &quot;apache&quot; }} 在此示例中，为每个文件输入配置了两个设置：路径和类型。 您可以配置的设置因插件类型而异。有关每个插件的信息 ,请参阅 Input Plugins, Output Plugins, Filter Plugins, and Codec Plugins. 值类型插件可以要求设置的值为特定类型，例如布尔值，列表或散列。支持以下值类型。 Array这种类型大多不赞成使用，例如可以定义:list =&gt; true属性的插件以便更好地进行类型检查。但是仍然需要Array处理不需要类型检查的散列或混合类型的列表。 1users =&gt; [{id =&gt; 1，name =&gt; bob}，{id =&gt; 2，name =&gt; jane}] Lists可以通过指定:list =&gt; true何时声明参数来启用列表检查。 12path =&gt; [ &quot;/var/log/messages&quot;, &quot;/var/log/*.log&quot; ]uris =&gt; [ &quot;http://elastic.co&quot;, &quot;http://example.net&quot; ] Boolean布尔值必须是true或false。请注意，true和false关键字不包含在引号中。 1ssl_enable =&gt; true Bytes表示有效的字节单位 ，此字段不区分大小写，并允许值和单位之间存在空格。如果未指定单位，则整数字符串表示字节数。 1234my_bytes =&gt; &quot;1113&quot; # 1113 bytesmy_bytes =&gt; &quot;10MiB&quot; # 10485760 bytesmy_bytes =&gt; &quot;100kib&quot; # 102400 bytesmy_bytes =&gt; &quot;180 mb&quot; # 180000000 bytes codec编解码器是用于表示数据的Logstash编解码器的名称。编解码器可用于输入和输出。 输入编解码器提供了一种在数据进入输入之前对其进行解码的便捷方式。输出编解码器提供了一种在数据离开输出之前对数据进行编码的便捷方式。使用输入或输出编解码器无需在Logstash管道中使用单独的过滤器。 编解码器列表 1codec =&gt; &quot;json&quot; Hash哈希是格式中指定的键值对的集合&quot;field1&quot; =&gt; &quot;value1&quot;。请注意，多个键值条目由空格而不是逗号分隔。 12345match =&gt; { &quot;field1&quot; =&gt; &quot;value1&quot; &quot;field2&quot; =&gt; &quot;value2&quot; ...} Number数字必须是有效的数值（浮点或整数）。 1port =&gt; 33 Password密码是具有单个值但未记录或打印的字符串。 1my_password =&gt; &quot;password&quot; URLURI可以是完整的URL，如http://elastic.co/，也可以是像foobar这样的简单标识符。如果URI包含密码，例如http：// user：pass@example.net，则不会记录或打印URI的密码部分。 1my_uri =&gt; &quot;http://foo:bar@example.net&quot; String字符串必须是单个字符序列。请注意，字符串值用引号括起来，可以是double或single。 Path路径是表示有效操作系统路径的字符串。 1my_path =&gt; &quot;/tmp/logstash&quot; 转义字符默认情况下，不启用转义序列。如果您希望在带引号的字符串中使用转义序列，则需要在 logstash.yml 中设置config.support_escapes: true。 12name =&gt; &quot;Hello world&quot;name =&gt; 'It\\'s a beautiful day' 插件：input输入插件使Logstash能够读取特定的事件源。 常用 input 插件: file：从文件系统上的文件读取，就像UNIX命令 tail -0F 。 syslog： 侦听系统端口514上日志消息，并根据RFC3164格式进行解析 。 redis： 从Redis实例读取事件 ，Redis经常用作集中式Logstash安装中的“代理”，它将来自远程Logstash“托运人”的Logstash事件排队。 beats：处理由Filebeat发送的事件。 更多见：input-plugins output输出插件将事件数据发送到特定目标。输出是事件管道的最后阶段。 常用 output 插件: elasticsearch：将事件数据发送给 Elasticsearch。 file：将事件数据写入文件或磁盘。 graphite：将事件数据发送给 graphite（一个流行的开源工具，存储和绘制指标)。 statsd：将事件数据发送到 statsd （这是一种侦听统计数据的服务，如计数器和定时器，通过UDP发送并将聚合发送到一个或多个可插入的后端服务）。 更多见：Output Plugins filter过滤器插件对事件执行中间处理。过滤器通常根据事件的特征有条件地应用。 常用 filter 插件: grok：解析任意结构文本。 Grok目前是Logstash中将非结构化日志数据解析为结构化和可查询的最佳方法。 mutate：对mutate过滤器无法处理的字段执行常规更改 。可以重命名，删除，替换和修改事件中的字段。 drop：完全放弃一个事件，例如调试事件。 clone：制作一个事件的副本，可以添加或删除字段。 geoip：添加有关IP地址的地理位置的信息 更多见：Filter Plugins codec编解码器插件更改事件的数据表示。编解码器本质上是流过滤器，可以作为输入或输出的一部分运行。 常用 codec 插件： json：以JSON格式对数据进行编码或解码。 multiline：将多行文本事件（如java异常和堆栈跟踪消息）合并为单个事件。 更多见：Codec Plugins 参考：https://cloud.tencent.com/developer/article/1063984 logstash安装 1、切换至logstash管理用户，并下载 12$ su user$ wget https://artifacts.elastic.co/downloads/logstash/logstash-6.3.2.tar.gz https://www.elastic.co/downloads/logstash https://www.elastic.co/guide/en/logstash/6.2/installing-logstash.html","link":"/2018/06/08/elasticsearch/logstash/"},{"title":"Elasticsearch-analyze","text":"_analyze 分析被存储到索引中的词条 12345GET /_analyze{ &quot;analyzer&quot;: &quot;index_ansj&quot;, &quot;text&quot;: &quot;六味地黄丸软胶囊.&quot;} analyzer: 指定分析器。 text: 要被分析的内容。 结果中每个元素代表一个单独的词条： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546{ &quot;tokens&quot;: [ { &quot;token&quot;: &quot;六味&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 2, &quot;type&quot;: &quot;mq&quot;, &quot;position&quot;: 0 }, { &quot;token&quot;: &quot;地黄&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 4, &quot;type&quot;: &quot;n&quot;, &quot;position&quot;: 1 }, { &quot;token&quot;: &quot;丸&quot;, &quot;start_offset&quot;: 4, &quot;end_offset&quot;: 5, &quot;type&quot;: &quot;q&quot;, &quot;position&quot;: 2 }, { &quot;token&quot;: &quot;软&quot;, &quot;start_offset&quot;: 5, &quot;end_offset&quot;: 6, &quot;type&quot;: &quot;a&quot;, &quot;position&quot;: 3 }, { &quot;token&quot;: &quot;胶囊&quot;, &quot;start_offset&quot;: 6, &quot;end_offset&quot;: 8, &quot;type&quot;: &quot;n&quot;, &quot;position&quot;: 4 }, { &quot;token&quot;: &quot;.&quot;, &quot;start_offset&quot;: 8, &quot;end_offset&quot;: 9, &quot;type&quot;: &quot;w&quot;, &quot;position&quot;: 5 } ]}","link":"/2018/06/08/elasticsearch/logstashAPI-1/"},{"title":"Elasticsearch与mongodb同步","text":"Elasticsearch与mongodb同步 利用mongo-connectormongodb官方介绍 github 安装根据具体Elasticsearch版本，利用pip安装最新版本mongo-connector 123$ pip install 'mongo-connector[elastic5]'$ mongo-connector --version mongo-connector version: 2.5.1 如果提示pip没装，则先安装pip 1$ sudo apt-get install python-pip mongodb开启副本集（必须开启），已开启则忽略此步。deploy-replica-set (1) 停止mongodb服务 1$ service mongodb stop (2) 通过 --replSet 设定副本集名称 1$ mongod --replSet myDevReplSet 或者在配置文件 mongodb.conf 中添加 12#副本集名称replSet=myDevReplSet 说明： myDevReplSet是副本集的名称 (3) 初始化副本集 123456&gt; rs.initiate(){ \"info2\" : \"no configuration specified. Using a default configuration for the set\", \"me\" : \"ubuntu:27017\", \"ok\" : 1} (4) 【验证】初始化副本集的配置 123456789101112131415161718192021222324252627282930313233343536myDevReplSet:OTHER&gt; rs.conf(){ &quot;_id&quot; : &quot;myDevReplSet&quot;, &quot;version&quot; : 1, &quot;protocolVersion&quot; : NumberLong(1), &quot;members&quot; : [ { &quot;_id&quot; : 0, &quot;host&quot; : &quot;ubuntu:27017&quot;, &quot;arbiterOnly&quot; : false, &quot;buildIndexes&quot; : true, &quot;hidden&quot; : false, &quot;priority&quot; : 1, &quot;tags&quot; : { }, &quot;slaveDelay&quot; : NumberLong(0), &quot;votes&quot; : 1 } ], &quot;settings&quot; : { &quot;chainingAllowed&quot; : true, &quot;heartbeatIntervalMillis&quot; : 2000, &quot;heartbeatTimeoutSecs&quot; : 10, &quot;electionTimeoutMillis&quot; : 10000, &quot;catchUpTimeoutMillis&quot; : 2000, &quot;getLastErrorModes&quot; : { }, &quot;getLastErrorDefaults&quot; : { &quot;w&quot; : 1, &quot;wtimeout&quot; : 0 }, &quot;replicaSetId&quot; : ObjectId(&quot;5b35a8568dccf16c7734a30b&quot;) }} (5)【验证】副本集的状态。 123456789101112131415161718192021222324252627282930313233343536373839404142myDevReplSet:PRIMARY&gt; rs.status(){ \"set\" : \"myDevReplSet\", \"date\" : ISODate(\"2018-06-29T03:34:53.131Z\"), \"myState\" : 1, \"term\" : NumberLong(1), \"heartbeatIntervalMillis\" : NumberLong(2000), \"optimes\" : { \"lastCommittedOpTime\" : { \"ts\" : Timestamp(1530243289, 1), \"t\" : NumberLong(1) }, \"appliedOpTime\" : { \"ts\" : Timestamp(1530243289, 1), \"t\" : NumberLong(1) }, \"durableOpTime\" : { \"ts\" : Timestamp(1530243289, 1), \"t\" : NumberLong(1) } }, \"members\" : [ { \"_id\" : 0, \"name\" : \"ubuntu:27017\", \"health\" : 1, \"state\" : 1, \"stateStr\" : \"PRIMARY\", \"uptime\" : 282, \"optime\" : { \"ts\" : Timestamp(1530243289, 1), \"t\" : NumberLong(1) }, \"optimeDate\" : ISODate(\"2018-06-29T03:34:49Z\"), \"electionTime\" : Timestamp(1530243158, 2), \"electionDate\" : ISODate(\"2018-06-29T03:32:38Z\"), \"configVersion\" : 1, \"self\" : true } ], \"ok\" : 1} 数据同步 官方文档命令格式 123mongo-connector -m &lt;mongodb server hostname&gt;:&lt;replica set port&gt; \\ -t &lt;replication endpoint URL, e.g. http://localhost:8983/solr&gt; \\ -d &lt;name of doc manager, e.g., solr_doc_manager&gt; 执行命令 1$ mongo-connector -m username:passwd@localhost:27017 -t username:passwd@localhost:9200 -d elastic2_doc_manager -n testDB.testCol 说明： -m 指定mongodb的地址与端口 。 ​ -t ES的地址与端口 。 ​ -d doc manager的名称，2.x版本为： elastic2-doc-manager。 ​ -n 指定要同步的数据库和集合名。 数据同步前应先建立索引，再进行数据同步 验证测试 mongodb中执行数据插入 12345$ myDevReplSet:PRIMARY&gt; use test; # test对应ES的Indexswitched to db test# 插入数据 blog对应ES的type$ myDevReplSet:PRIMARY&gt; db.blog.insert({\"title\":\"标题一\",\"time\":\"2018-06-29\",\"content\":\"测试MongoDB与ElasticSearch数据同步\"});WriteResult({ \"nInserted\" : 1 }) ElasticSearch中检索数据 12345678910111213141516171819202122232425262728&gt; GET /test/blog/_search{ \"took\": 0, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 1, \"max_score\": 1, \"hits\": [ { \"_index\": \"test\", \"_type\": \"blog\", \"_id\": \"5b35dafcad35569566d32bc7\", \"_score\": 1, \"_source\": { \"content\": \"测试MongoDB与ElasticSearch数据同步\", \"title\": \"标题一\", \"time\": \"2018-06-29\" } } ] }} mongo-connector工具支持MongoDB与ES之间的实时增insert、删delete、改update操作。 但对于历史数据 不能保存到ES中 MongoDB River的插件MongoDB River 版本较旧不建议使用。 其它方案：暂未深究 https://elasticsearch.cn/question/1167 通过Bulk API 参考：https://blog.csdn.net/u011801161/article/details/71726495","link":"/2018/06/29/elasticsearch/mongo-connector/"},{"title":"x-pack安装","text":"X-Pack是一个Elastic Stack扩展，它将安全性，警报，监控，报告和图形功能捆绑到一个易于安装的软件包中。虽然X-Pack组件旨在无缝地协同工作，但您可以轻松启用或禁用要使用的功能。 安装1、将X-Pack安装到Elasticsearch中具体参考 1$ bin/elasticsearch-plugin install x-pack 2、启动Elasticsearch 1$ ./bin/elasticsearch -d -p pid 说明： 如果要在多节点群集上安装X-Pack，参考说明生成证书并配置TLS以进行加密通信。多节点群集需要执行此步骤。 3、将X-Pack安装到Kibana中具体参考 1$ bin/kibana-plugin install x-pack 4、生成默认密码 12345678910111213$ ./bin/x-pack/setup-passwords auto Initiating the setup of passwords for reserved users elastic,kibana,logstash_system. The passwords will be randomly generated and printed to the console. Please confirm that you would like to continue [y/N]y Changed password for user kibana PASSWORD kibana = fzKfd9h55Pndfr4oPWNm Changed password for user logstash_system PASSWORD logstash_system = 7mSq7JebAE5f3UMUb5g9 Changed password for user elastic PASSWORD elastic = ARS22mBM9YIrxFBGD4pO setup-passwords命令把elastic， kibana和logstash_system用户的随机密码输出到控制台。设置密码 5、修改kibana.yml文件 12345elasticsearch.username: &quot;kibana&quot;elasticsearch.password: &quot;&lt;pwd&gt;&quot;xpack.reporting.encryptionKey: &quot;a_random_string&quot;xpack.security.encryptionKey: &quot;something_at_least_32_characters&quot; 说明：是kibana步骤4中自动生成的用户的密码。如果您在步骤2中设置了TLS，则还要将您的证书添加到kibana.yml文件中 6、启动kibana 1$ bin/kibana 7、访问http://localhost:5601使用步骤4中自动生成的用户密码登录。 启用和禁用X-Pack功能默认情况下，启用所有基本X-Pack功能。可以启用或禁用特定的X-Pack功能elasticsearch.yml，kibana.yml以及 logstash.yml配置文件。 设置 描述 xpack.graph.enabled 设置为false禁用X-Pack图形功能。 xpack.ml.enabled 设置为false禁用X-Pack机器学习功能。 xpack.monitoring.enabled 设置为false禁用X-Pack监视功能。 xpack.reporting.enabled 设置为false禁用X-Pack报告功能。 xpack.security.enabled 设置为false禁用X-Pack安全功能。 xpack.watcher.enabled 设置false为禁用Watcher。 有关每个配置文件中存在哪些设置的详细信息，请参阅 X-Pack设置。 设置用户身份验证https://www.elastic.co/guide/en/x-pack/6.2/setting-up-authentication.html https://www.elastic.co/guide/en/elasticsearch/reference/6.2/security-api-users.html 跨群集搜索，部落，客户端和集成https://www.elastic.co/guide/en/x-pack/6.2/ccs-tribe-clients-integrations.html 参考：https://www.elastic.co/downloads/x-packhttps://www.elastic.co/guide/en/x-pack/current/installing-xpack.html","link":"/2018/06/08/elasticsearch/x-pack%E7%9A%84%E5%AE%89%E8%A3%85/"},{"title":"x-pack破解","text":"x-pack破解 安装完x-pack后 1、解压x-pack-core-6.2.4.jar 123$ cp ES_HOME/plugins/x-pack/x-pack-corex-pack-core-6.2.4.jar /tmp/x-pack$ cd /tmp/x-pack$ jar -xvf x-pack-core-6.2.4.jar 2、修改java文件 找到org.elasticsearch.license.LicenseVerifier.class、 org.elasticsearch.xpack.core.XPackBuild.class ，用反编译工具保存为Java文件。 (1) 修改LicenseVerifier LicenseVerifier 中有两个静态方法，这就是验证授权文件是否有效的方法，我们把它修改为全部返回true. 1234567891011121314151617181920212223242526272829303132package org.elasticsearch.license;import java.io.ByteArrayOutputStream;import java.io.IOException;import java.io.InputStream;import java.nio.ByteBuffer;import java.security.InvalidKeyException;import java.security.NoSuchAlgorithmException;import java.security.Signature;import java.security.SignatureException;import java.util.Arrays;import java.util.Base64;import java.util.Collections;import org.apache.lucene.util.BytesRef;import org.apache.lucene.util.BytesRefIterator;import org.elasticsearch.common.io.Streams;import org.elasticsearch.common.xcontent.XContentBuilder;import org.elasticsearch.common.xcontent.XContentFactory;import org.elasticsearch.common.xcontent.XContentType;import org.elasticsearch.common.xcontent.ToXContent.MapParams;import org.elasticsearch.license.CryptUtils;import org.elasticsearch.license.License;public class LicenseVerifier { public static boolean verifyLicense(License license, byte[] encryptedPublicKeyData) { return true; } public static boolean verifyLicense(License license) { return true; }} (2) 修改XPackBuild XPackBuild 中 最后一个静态代码块中 try的部分全部删除，这部分会验证jar包是否被修改. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package org.elasticsearch.xpack.core;import java.io.IOException;import java.net.URISyntaxException;import java.net.URL;import java.nio.file.Files;import java.nio.file.OpenOption;import java.nio.file.Path;import java.util.jar.JarInputStream;import java.util.jar.Manifest;import org.elasticsearch.common.SuppressForbidden;import org.elasticsearch.common.io.PathUtils;public class XPackBuild { public static final XPackBuild CURRENT; private String shortHash; private String date; @SuppressForbidden( reason = \"looks up path of xpack.jar directly\" ) static Path getElasticsearchCodebase() { URL url = XPackBuild.class.getProtectionDomain().getCodeSource().getLocation(); try { return PathUtils.get(url.toURI()); } catch (URISyntaxException arg1) { throw new RuntimeException(arg1); } } XPackBuild(String shortHash, String date) { this.shortHash = shortHash; this.date = date; } public String shortHash() { return this.shortHash; } public String date() { return this.date; } static { Path path = getElasticsearchCodebase(); String shortHash = null; String date = null; Label_0157: { shortHash = \"Unknown\"; date = \"Unknown\"; } CURRENT = new XPackBuild(shortHash, date); }} 3、重新编译以上两文件 123$ javac -cp \"$ES_HOME/lib/elasticsearch-6.2.4.jar:/opt/elasticsearch/lib/lucene-core-7.2.1.jar:$ES_HOME/plugins/x-pack/x-pack-core/x-pack-core-6.2.3.jar\" LicenseVerifier.java$ javac -cp \"$ES_HOME/lib/elasticsearch-6.2.4.jar:$ES_HOME/lib/elasticsearch-core-6.2.3.jar:$ES_HOME/lib/lucene-core-7.2.1.jar:$ES_HOME/plugins/x-pack/x-pack-core/x-pack-core-6.2.3.jar:$ES_HOME/plugins/x-pack/x-pack-core/netty-common-4.1.16.Final.jar\" XPackBuild.java 注意：如果是在Windows上操作，就把jar包的分隔符由冒号换成分号。 4、把编译的org.elasticsearch.license.LicenseVerifier.class org.elasticsearch.xpack.core.XPackBuild.class替换原来的class，重新压缩打包 12$ cd /tmp/x-pack$ jar -cvf x-pack-core-6.2.4.jar ./* 5、把之前elasricsearch安装的x-pack 中的x-pack-core-6.2.4.jar 替换掉 6、修改elasticsearch.yml 配置文件 elasticsearch 6.2.4 中默认开启了安全验证，我们暂时修改配置文件以方便导入自己的文件 在elasticsearch.yml 中 添加一下配置 1xpack.security.enabled: false 7、然后重启elasticserach 。kinaba 可以不重启。如果有多个节点ES集群 每个都替换下，并重启。 8、导入授权文件 12345678910111213{ \"license\": { \"uid\": \"22742aa9-068b-48b6-8b36-c36ff3a39ed7\", \"type\": \"platinum\", // 修改授权为白金版本 \"issue_date_in_millis\": 1526860800000, \"expiry_date_in_millis\": 2524579200999, //修改到期时间 \"max_nodes\": 100, // 修改最大节点数 \"issued_to\": \"aa\", \"issuer\": \"Web Form\", \"signature\": \"AAAAAwAAAA2+OXa0Aq7HFDzGSxl1AAABmC9ZN0hjZDBGYnVyRXpCOW5Bb3FjZDAxOWpSbTVoMVZwUzRxVk1PSmkxaktJRVl5MUYvUWh3bHZVUTllbXNPbzBUemtnbWpBbmlWRmRZb25KNFlBR2x0TXc2K2p1Y1VtMG1UQU9TRGZVSGRwaEJGUjE3bXd3LzRqZ05iLzRteWFNekdxRGpIYlFwYkJiNUs0U1hTVlJKNVlXekMrSlVUdFIvV0FNeWdOYnlESDc3MWhlY3hSQmdKSjJ2ZTcvYlBFOHhPQlV3ZHdDQ0tHcG5uOElCaDJ4K1hob29xSG85N0kvTWV3THhlQk9NL01VMFRjNDZpZEVXeUtUMXIyMlIveFpJUkk2WUdveEZaME9XWitGUi9WNTZVQW1FMG1DenhZU0ZmeXlZakVEMjZFT2NvOWxpZGlqVmlHNC8rWVVUYzMwRGVySHpIdURzKzFiRDl4TmM1TUp2VTBOUlJZUlAyV0ZVL2kvVk10L0NsbXNFYVZwT3NSU082dFNNa2prQ0ZsclZ4NTltbU1CVE5lR09Bck93V2J1Y3c9PQAAAQCi1V5EMmUXsTUKTeVHJugLj0daqCDI/eAALGG2FWAnE7p9F9ZcCNp2cybBmJ8okoxEIvsUVHUEv50eodAzsxR7qYra1j3pbjMY9BSl13DTVByhow+ZbsXojEpxtXPv18Fd88iP7NcQDs/ERI3xQePDl4O3vB1qkpTxZiY+BC/YlCHF4VTz/sGq6PWvT0G7T4oUb91KIB42oFYNvS4SRkv4gvHOQWRkwdthA2dwpf2QNeH/5vMw9VWFV8x7hw+8HTcqkf2De3TFq94VvhWw9ZpXPaO79fuQoj7vR79BHbBLYnlHxMNAEGnzgJwK13DGDnHdoz0mGsCHgUuswn7+nTEX\", \"start_date_in_millis\": 1526860800000 }} 执行导入 12$ curl -XPUT -u elastic:kY9j3OEFhQZ0LzD3kxEI 'http://127.0.0.1:9200/_xpack/license' -H \"Content-Type: application/json\" -d @/home/license.json{\"acknowledged\":true,\"license_status\":\"valid\"} 问题： 导入授权文件后，不能开启安全验证。 参考：https://www.jianshu.com/p/55b5c5d3a89c https://www.elastic.co/guide/en/elasticsearch/reference/6.2/update-license.html kinbana的汉化可参考：https://blog.csdn.net/yinlongfei_love/article/details/81063464","link":"/2018/08/08/elasticsearch/x-pack%E7%A0%B4%E8%A7%A3/"},{"title":"electron打包桌面应用","text":"electron是基于Node.js和Chromium做的一个工具,可以把前端资源文件打包成桌面应用。支持Windows、OS X、Linux平台。依赖： 需要 Node.js 4.0 + electron-packager打包全局安装： 1$ npm install electron-packager -g 首先进入应用资源目录下操作语法格式：electron-packager –platform= –arch= [optional flags…] 参数详解：sourcedir： 项目的位置appname： 应用名–platform: 打包的系统(darwin, linux, mas, win32)–arch: 系统位数(ia32, x64, armv7l)–icon=： 指定应用的图标(Mac 为 .icns 文件，Windows 为 .ico 或 .png)–out ： 指定输出的目录–version=： 指定编译的 electron-prebuilt 版本 示例：1、electron-packager . ks –plantform=win32 –arch=x64 –electron-version=1.7.3 –overwrite –ignore=node_moules2、electron-packager . qinfei –all –all –version=1.7.3 – overwrite –ignore=node_moules3、淘宝源（速度）electron-packager . hello –all -all –electron-version=1.7.3 –download.mirror=https://npm.taobao.org/mirrors/electron/ electron-builder打成.exe全局安装： 1$ npm install electron-builder –g linux下建立软连接: 1$ ln -s /opt/node-v8.1.2-linux-x64/bin/electron-builder /usr/local/bin/electron-builder 查看信息: 1$ electron-builder --version 打包 12$ build -help$ bulid --win --x64 连接超时，可把源切换到淘宝： 1npm config set registry https://registry.npm.taobao.org 在inux下 编辑 ~/.npmrc 加入下面内容 1234registry=https://registry.npm.taobao.orgsass_binary_site=https://npm.taobao.org/mirrors/node-sass/phantomjs_cdnurl=http://npm.taobao.org/mirrors/phantomjsELECTRON_MIRROR=http://npm.taobao.org/mirrors/electron/ 自动更新1、在应用目录中写完main.js、package.json（注意version）（参考：以前写的）2、执行 npm install3、然后执行 build –win –x64（win64版本，其它另查）4、把生成的dist目录下的exe文件和latest.yml与package.json放到tomcat中项目路径下（注意和package.json中url路径相同）5、安装第一个版本6、然后生成第二个版本7、删掉node_modules、dist目录8、重复2、3、49、启动第一次安装的版本，会自动更新。 可参考：https://electronjs.org/docshttps://www.electron.build/configuration/configurationhttps://www.electron.build/tutorials/two-package-structurehttps://github.com/megahertz/electron-simple-updaterhttps://github.com/iffy/electron-updater-examplehttps://gist.github.com/iffy/0ff845e8e3f59dbe7eaf2bf24443f104https://www.electron.build/auto-update 附：一个最简单的electron项目包含三个文件 index.html,package.json, main.js。index.html可看做前端资源文件。package.json是Node.js项目的配置文件。main.js是应用的启动入口文件。 以下是一个简单的package.json配置文件。 123456789101112131415161718192021222324252627282930313233343536373839{ &quot;name&quot;: &quot;zxks&quot;, &quot;version&quot;: &quot;2.1.1&quot;, &quot;main&quot;: &quot;main.js&quot;, &quot;description&quot;: &quot;在线考试0.1.0&quot;, &quot;author&quot;: &quot;云翼互联&quot;, &quot;devDependencies&quot;: { &quot;electron&quot;: &quot;^1.6.11&quot;, &quot;electron-builder&quot;: &quot;^19.6.3&quot;, &quot;http-server&quot;: &quot;^0.9.0&quot; }, &quot;dependencies&quot;: { &quot;electron-log&quot;: &quot;^1.3.0&quot;, &quot;electron-updater&quot;: &quot;^1.4.2&quot; }, //自动更新 &quot;build&quot;: { &quot;publish&quot;: [ { &quot;provider&quot;: &quot;generic&quot;, &quot;url&quot;: &quot;https://cloudtest.kszx365.com/cpnsp/&quot; } ], &quot;appId&quot;: &quot;com.kszx&quot;, &quot;mac&quot;: { &quot;category&quot;: &quot;your.app.category.type&quot;, &quot;target&quot;: [ &quot;zip&quot;, &quot;dmg&quot; ] }, &quot;nsis&quot;: { &quot;perMachine&quot;: true }, &quot;win&quot;:{ &quot;icon&quot;: &quot;res/icon2.ico&quot; } }} main.js文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253const {app, BrowserWindow, Menu, protocol, ipcMain} = require('electron')const log = require('electron-log');const {autoUpdater} = require(&quot;electron-updater&quot;);const path = require('path')const url = require('url')const electron = require('electron')const dialog = electron.dialogconst globalShortcut = electron.globalShortcut// 保持一个对于 window 对象的全局引用，如果你不这样做，// 当 JavaScript 对象被垃圾回收， window 会被自动地关闭let winfunction createWindow () { // 创建浏览器窗口。 win = new BrowserWindow({ width: 1920, height: 1080, resizable: false, movable: false, minimizable: false, kiosk: true, alwaysOnTop :true, fullscreen:true, webPreferences: { defaultEncoding: 'UTF-8' } }) // 加载应用的 index.html。 win.loadURL(url.format({ pathname: path.join(__dirname, 'index.html'), protocol: 'file:', slashes: true })) //设置全屏 win.setFullScreen(true) //让窗口不在任务栏中显示. //win.setSkipTaskbar(true) //kiosk 模式. win.setKiosk(true) // 打开开发者工具。 //win.webContents.openDevTools() win.on('move', () =&gt; { win.setFullScreen(true) }) win.on('leave-full-screen', () =&gt; { // win.setFullScreen(true) //app.quit() //dialog.showMessageBox({ // dialog.showErrorBox('一条错误信息', '错误消息演示.') //type: 'info', // message: '成功!', // detail: '你按下了一个全局注册的快捷键绑定.', // buttons: ['好的'] //}) }) win.on('blur', () =&gt; { //win.setFullScreen(true) //app.quit() // dialog.showMessageBox({ // dialog.showErrorBox('一条错误信息', '错误消息演示.') // type: 'info', // message: '成功!', // detail: 'sk你按下了一个全局注册的快捷键绑定.', // buttons: ['好的'] //}) }) // 当 window 被关闭，这个事件会被触发。 win.on('closed', () =&gt; { // 取消引用 window 对象，如果你的应用支持多窗口的话， // 通常会把多个 window 对象存放在一个数组里面， // 与此同时，你应该删除相应的元素。 win = null }) win.on('app-command', function (e, cmd) { // Navigate the window back when the user hits their mouse back button if (cmd === 'browser-backward' &amp;&amp; win.webContents.canGoBack()) { win.webContents.goBack() }})}// Electron 会在初始化后并准备// 创建浏览器窗口时，调用这个函数。// 部分 API 在 ready 事件触发后才能使用。app.on('ready', createWindow)//app.on('move', () =&gt; { // if (process.platform !== 'darwin') { // app.quit() // }//})app.on('ready', function () { globalShortcut.register('Super+D', function () { dialog.showMessageBox({ type: 'info', message: '成功!', detail: '你按下了一个全局注册的快捷键绑定.', buttons: ['好的'] }) })})app.on('ready', () =&gt; { // Register a 'CommandOrControl+Y' shortcut listener. globalShortcut.register('Alt+Tab', () =&gt; { // Do stuff when Y and either Command/Control is pressed. app.quit() })})//app.on('ready', function () {// var electronScreen = electron.screen// var size = electronScreen.getPrimaryDisplay().workAreaSize// mainWindow = new BrowserWindow({ width: size.width, height: size.height })//})// 当全部窗口关闭时退出。app.on('window-all-closed', () =&gt; { // 在 macOS 上，除非用户用 Cmd + Q 确定地退出， // 否则绝大部分应用及其菜单栏会保持激活。 if (process.platform !== 'darwin') { app.quit() }})app.on('activate', () =&gt; { // 在这文件，你可以续写应用剩下主进程代码。 // 也可以拆分成几个文件，然后用 require 导入。 if (win === null) { createWindow() }})// 在这文件，你可以续写应用剩下主进程代码。// 也可以拆分成几个文件，然后用 require 导入。//-------------------------------------------------------------------// Logging//// THIS SECTION IS NOT REQUIRED//// This logging setup is not required for auto-updates to work,// but it sure makes debugging easier :)//-------------------------------------------------------------------autoUpdater.logger = log;autoUpdater.logger.transports.file.level = 'info';log.info('App starting...');//-------------------------------------------------------------------// Define the menu//// THIS SECTION IS NOT REQUIRED//-------------------------------------------------------------------let template = []if (process.platform === 'darwin') { // OS X const name = app.getName(); template.unshift({ label: name, submenu: [ { label: 'About ' + name, role: 'about' }, { label: 'Quit', accelerator: 'Command+Q', click() { app.quit(); } }, ] })}//-------------------------------------------------------------------// Open a window that displays the version//// THIS SECTION IS NOT REQUIRED//// This isn't required for auto-updates to work, but it's easier// for the app to show a window than to have to click &quot;About&quot; to see// that updates are working.//-------------------------------------------------------------------function sendStatusToWindow(text) { log.info(text); win.webContents.send('message', text);}autoUpdater.on('checking-for-update', () =&gt; { sendStatusToWindow('Checking for update...');})autoUpdater.on('update-available', (ev, info) =&gt; { sendStatusToWindow('Update available.');})autoUpdater.on('update-not-available', (ev, info) =&gt; { sendStatusToWindow('Update not available.');})autoUpdater.on('error', (ev, err) =&gt; { sendStatusToWindow('Error in auto-updater.');})autoUpdater.on('download-progress', (ev, progressObj) =&gt; { sendStatusToWindow('Download progress...');})autoUpdater.on('update-downloaded', (ev, info) =&gt; { sendStatusToWindow('Update downloaded; will install in 5 seconds');});//-------------------------------------------------------------------// Auto updates//// For details about these events, see the Wiki:// https://github.com/electron-userland/electron-builder/wiki/Auto-Update#events//// The app doesn't need to listen to any events except `update-downloaded`//// Uncomment any of the below events to listen for them. Also,// look in the previous section to see them being used.//-------------------------------------------------------------------// autoUpdater.on('checking-for-update', () =&gt; {// })// autoUpdater.on('update-available', (ev, info) =&gt; {// })// autoUpdater.on('update-not-available', (ev, info) =&gt; {// })// autoUpdater.on('error', (ev, err) =&gt; {// })// autoUpdater.on('download-progress', (ev, progressObj) =&gt; {// })autoUpdater.on('update-downloaded', (ev, info) =&gt; { // Wait 5 seconds, then quit and install // In your application, you don't need to wait 5 seconds. // You could call autoUpdater.quitAndInstall(); immediately setTimeout(function() { autoUpdater.quitAndInstall(); }, 5000)})app.on('ready', function() { autoUpdater.checkForUpdates();});","link":"/2018/01/23/electron/electron%E6%89%93%E5%8C%85%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8/"},{"title":"nativefier打包应用","text":"nativefier打包工具 ，也是electron实现。优点：一条命令就可以把已存在的网站打包成桌面版，速度快。依赖： 需要 Node.js 4.0 + 安装： 1$ npm install nativefier -g 打包： 1$ nativefier &quot;http://baidu.com&quot; 具体其它参数参考：https://github.com/jiahaog/nativefier","link":"/2018/01/23/electron/nativefier%E6%89%93%E5%8C%85%E5%BA%94%E7%94%A8/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2017/07/30/hexo/Hello%20World/"},{"title":"创建步骤","text":"1、安装node.js(windows) Quick Start Create a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy 发布文章： 1234$ cd /d/ProgramFiles/GitHub/myqzf$ hexo clean$ hexo generate$ hexo deploy More info: Deployment 参考：http://www.jianshu.com/p/1656489eff01","link":"/2017/07/30/hexo/%E5%88%9B%E5%BB%BA%E6%AD%A5%E9%AA%A4/"},{"title":"hexo 增加相册功能","text":"hexo 增加相册功能 主题使用的 Yilia 主题。 1、创建可点击链接 进入博客目录执行 1$ hexo new page photos 会在source下生成photos/index.md文件。然后在主题站点的配置文件themes/yilia/_config.yml中添加点击的文案和跳转到位置 。 1234567menu: 主页: / 文章: /archives/ categories: /categories/ 随笔: /tags/随笔/ 相册: /photos/ about: /about 参考：https://blog.csdn.net/qq_22656383/article/details/79393146 https://github.com/maker997/backupBlog https://www.jianshu.com/p/370ca4ef808a https://github.com/luojinghui/luojinghui.github.io","link":"/2018/06/04/hexo/%E7%9B%B8%E5%86%8C%E5%8A%9F%E8%83%BD/"},{"title":"Java反编译","text":"Java反编译工具 JD-GUIJD-GUI 是一个用 C++ 开发的 Java 反编译工具，由 Pavel Kouznetsov开发，支持Windows、Linux和苹果Mac Os三个平台。而且提供了Eclipse平台下的插件JD-Eclipse。JD-GUI不需要安装，直接点击运行，可以反编译jar,class文件。 目前版本是1.4.0，停留在2015年 。可跟进后续更新。 ecd-plugin (在用)增强型类型反编译器将JD，Jad，FernFlower，CFR，Procyon与Eclipse无缝集成，并允许Java开发人员直接调试没有源代码的类文件。它还集成了eclipse类编辑器，m2e插件，支持Javadoc， 引用搜索，库源附加，字节码视图和JDK8 lambda表达式的语法。 一、eclipse中安装 启动Eclipse。 点击 *”Help &gt; Install New Software…”*。 点击按钮*”Add…”* 添加一个新的存储库。 输入名称为“Enhanced Class Decompiler Update Site”并输入位置为“ https://ecd-plugin.github.io/update ”，然后点击“OK”按钮。 选中“Enhanced Class Decompiler” 。 Next, next, next… 最后重启eclipse。 二、配置文件关联 点击*”Window &gt; Preferences &gt; General &gt; Editors &gt; File Associations”* 。 “\\ .class”：默认情况下选择“类反编译器查看器”*。 “\\ .class without source”：默认情况下选择“类反编译器查看器”*。 三、配置ecd插件 点击 “Window &gt; Preferences &gt; Java &gt; Decompiler”进行相关配置。 四、卸载ecd插件 点击*”Help &gt; About Eclipse &gt; Installation Details &gt; Installation Software”*。 选择 *”Enhanced Class Decompiler”*。 点击 *”Uninstall…”*。 JADJAD Java Decompiler Download Mirror 对java版本支持只到1.3，后面版本就搞不了。 其它反编译工具可参考：https://www.zhihu.com/question/20264247","link":"/2018/06/24/java/Java%E5%8F%8D%E7%BC%96%E8%AF%91%E5%B7%A5%E5%85%B7/"},{"title":"Jdk添加信任证书","text":"在Java程序中通过HttpClient访问https的web服务，报错：Caused by: javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path 环境：linux 1、查看javahome路径 12$ echo $JAVA_HOME/usr/local/jdk1.8 2、查看当前已加入信任的证书，需要输入密码changeit 12$ keytool -list -keystore /usr/local/jdk1.8/jre/lib/security/cacertsEnter keystore password: /usr/local/jdk1.8/是javahome的路径 3、从浏览器导出证书 从浏览器访问https服务，然后把证书导出，将证书上传至Linux服务器。 4、导入证书，需要输入密码changeit 12$ /usr/local/jdk1.8/jre/lib/security# keytool -import -alias LL1 -keystore /usr/local/jdk1.8/jre/lib/security/cacerts -file /usr/local/jdk1.8/jre/lib/security/cloudtestkszx365com.crtEnter keystore password: changeit 5、导入完成后，重启应用。","link":"/2017/09/28/java/Jdk%E6%B7%BB%E5%8A%A0%E4%BF%A1%E4%BB%BB%E8%AF%81%E4%B9%A6/"},{"title":"关于ckeditor编辑器图片上传","text":"上传方法 1234567891011121314151617181920212223242526272829@RequestMapping(value = \"/uploadCkImg\", method = RequestMethod.POST)@ResponseBodypublic void uploadImage(@RequestParam MultipartFile upload, @RequestParam String CKEditor,@RequestParam String CKEditorFuncNum,@RequestParam String langCode, HttpServletRequest request, HttpServletResponse response) { byte[] imgBytes = null; String callback = CKEditorFuncNum; response.setContentType(\"text/html;charset=UTF-8\"); response.setHeader(\"X-Frame-Options\", \"SAMEORIGIN\"); PrintWriter out = null; try { if (upload == null || upload.isEmpty()) { return ; } out = response.getWriter(); imgBytes = upload.getBytes(); CkImgData imgData = new CkImgData(); imgData.setImgData(imgBytes); imgData.setFileName(upload.getOriginalFilename()); imgData.setUploadTime(Utils.getTimeString(new Date())); jdbcService.save(imgData); // 图片访问路径 String imgurl =request.getContextPath() + \"/admin/imgfile/\" + imgData.getUid(); out.print(\"&lt;script type=\\\"text/javascript\\\"&gt;window.parent.CKEDITOR.tools.callFunction(\" + callback + \",'\" + imgurl + \"','');&lt;/script&gt;\"); } catch (Exception e) { out.println(\"&lt;script type=\\\"text/javascript\\\"&gt;window.parent.CKEDITOR.tools.callFunction(\" + callback + \",'',\" + \"'文件格式不正确');&lt;/script&gt;\"); }} 注意：1、跨域问题。2、返回的js代码不显示图片的问题 。 参考：http://wolfgangkiefer.blog.163.com/blog/static/86265503201421954732369/response要进行如下设置： 12response.setContentType(\"text/html;charset=UTF-8\");response.setHeader(\"X-Frame-Options\", \"SAMEORIGIN\"); 3、一个问题，本地通过ip+端口进行上传图片，一直不回显图片，即返回的js不执行。但放到网上用域名就没有问题。估计是跨域问题。 解决： 把上面的 response.setHeader(“X-Frame-Options”, “SAMEORIGIN”); 去掉或者改成 response.setHeader(“X-Frame-Options”, “allow-from http://xxxip:xxxport/&quot;); 获取图片方法 12345678910111213141516171819202122@RequestMapping(value = \"/imgfile/{uid}\")public void getCkImgfile(@PathVariable String uid, HttpServletRequest request, HttpServletResponse response) { CkImgData ckImg = jdbcDao.getByUid(CkImgData.class, uid, \"imgData\"); byte[] imgData = ckImg.getImgData(); showImg(imgData, withDefault, request, response);}private void showImg(byte[] imgData, Integer withDefault, HttpServletRequest request, HttpServletResponse response) { try { if (imgData != null) { IOUtils.write(imgData, response.getOutputStream()); } else { if (withDefault != null &amp;&amp; withDefault.intValue() == 1) { IOUtils.write(FileUtils.readFileToByteArray(new File(request.getSession().getServletContext().getRealPath(\"/assets/defaultUser.png\"))), response.getOutputStream()); } else { response.sendError(HttpServletResponse.SC_NOT_FOUND); } } } catch (IOException ioe) { } } X-Frame-Options HTTP响应头X-Frame-Options是用来确认是否浏览器可以在frame或iframe标签中渲染一个页面，网站可以用这个头来保证他们的内容不会被嵌入到其它网站中，以来避免点击劫持。 语法： X-Frame-Options DENY — 表示该页面不允许在 frame 中展示，即便是在相同域名的页面中嵌套也不允许。 X-Frame-Options SAMEORIGIN — 表示该页面可以在相同域名页面的 frame 中展示。 X-Frame-Options allow-from https://example.com/ — 表示该页面可以在指定来源的 frame 中展示。 还有一种（可参见）： X-Frame-Options ALLOWALL —表示允许任何站点。 在 nginx中配置： 若要配置nginx以发送X-Frame-Options标头，将其添加到http，server 或 location 配置中 1add_header X-Frame-Options sameorigin; 也可在代码中加入: 1response.setHeader(\"X-Frame-Options\", \"allow-from http://example.com/\"); 注意：chrome不支持 ALLOW-FROM，会有如下提示,但不影响使用。浏览器兼容性 参考：https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Frame-Options","link":"/2017/11/22/java/ckeditor%E7%BC%96%E8%BE%91%E5%99%A8/"},{"title":"jasperreports报表导出","text":"今天通知线上服务jasperreports报表pdf显示有问题，报错信息如下 1net.sf.jasperreports.engine.util.JRFontNotFoundException: Font '宋体' is not available to the JVM. See the Javadoc for more details. 本地是正常的，搜了下说和Linux字体有关。 拷贝windows下的字体到Ubuntu系统中，把字体放在项目class path下，都尝试了，没能解决问题。 下面是解决的过程 把windows下的需要的字体(C:\\Windows\\Fonts)到Ubuntu目录/usr/share/fonts/TTF(不存在则新建)下。 然后执行如下命令 1234$ apt-get update$ apt install xfonts-utils$ mkfontdir$ fc-cache -fv 最后重启服务，便正常显示了。 参考：Ubuntu系统安装字体方法","link":"/2019/12/28/java/jasperreports%E6%8A%A5%E8%A1%A8%E5%AD%97%E4%BD%93%E5%8A%A0%E8%BD%BD%E9%97%AE%E9%A2%98/"},{"title":"jasperreports报表导出","text":"一、导出PDFJAR包的依赖jasperreports-6.4.3.jar、jasperreports-chart-themes-6.4.3.jar、jasperreports-fonts-6.4.3.jar、jasperreports-functions-6.4.3.jar、commons-collections-3.2.1.jar、commons-digester-2.1.jar、joda-time_2.1.0.jar、itext-2.1.7.js6.jar、iTextAsian.jar 1、PDF中文字体显示问题在.jrxml文件中的Source选项卡的后面加上 1&lt;style name=&quot;myStyle&quot; isDefault=&quot;true&quot; pdfFontName=&quot;STSong-Light&quot; pdfEncoding=&quot;UniGB-UCS2-H&quot; isPdfEmbedded=&quot;true&quot;/&gt; 2、PDF中包含图片问题图片的url必须是一个确定的url图片路径如：http://jasperreports.sourceforge.net/jasperreports.png 1234567891011121314151617181920212223242526272829303132333435363738394041424344@RequestMapping(value = &quot;/contestEnrollReport/{contesterProjectUid}&quot;)public void contestEnrollReport(@PathVariable String contesterProjectUid,HttpServletRequest request, HttpServletResponse response) throws IOException { ScContesterProject contesterProject = mongoDao.getByUid(ScContesterProject.class, contesterProjectUid, null); ScContestProject contestProject = mongoDao.get(ScContestProject.class, contesterProject.getContestProjectId(), &quot;title&quot;); ScContester contester = mongoDao.get(ScContester.class, contesterProject.getContesterId(), &quot;id,uid,imgVer&quot;); File dir = TransferUtils.getStoreDir(SessionCookieUser.getSessionUserId().toString(), &quot;simg&quot;);//在临时目录下创建一个临时文件夹 ImgData contesterImg = mongoDao.get(ImgData.class, SkillContestUtils.IMGTYPE_CONTESTER+&quot;_&quot;+contester.getUid(), null); byte[] imgData; if (contesterImg != null) { imgData = contesterImg.getData(); }else { imgData = Utils.getFileData(request, &quot;/default/headImg.png&quot;); } FileUtils.writeByteArrayToFile(new File(dir, contester.getUid()+&quot;.png&quot;), imgData); InputStream is = null; String fileDir = dir+&quot;\\\\&quot;+contester.getUid()+&quot;.png&quot;; List&lt;Object&gt; contestEnrollDtos= new ArrayList&lt;&gt;(); ScContestEnrollDto contestEnrollDto = new ScContestEnrollDto(contestProject.getTitle() ,contesterProject, fileDir); resolveCardId(contestEnrollDto); contestEnrollDtos.add(contestEnrollDto); ServletContext context = request.getSession().getServletContext(); File reportFile = new File(context.getRealPath(&quot;/jasperReports/ContestEnroll.jasper&quot;));//选手报名表 try { SimpleXlsReportConfiguration configuration = new SimpleXlsReportConfiguration(); configuration.setAutoFitPageHeight(true); File targetFile = skillContestService.processReport(contestEnrollDtos, reportFile,configuration); is = new FileInputStream(targetFile); response.setContentType(&quot;application/pdf&quot;); String fileName = &quot;第45届世界技能大赛湖北省选拔赛选手报名表.pdf&quot;; response.setHeader(&quot;Content-Disposition&quot;, &quot;attachment;filename=&quot; + new String(fileName.getBytes(&quot;utf-8&quot;), &quot;ISO8859-1&quot;)); IOUtils.copy(is, response.getOutputStream()); } catch (Exception e) { e.printStackTrace(); } finally { if (is != null) { is.close(); } }} 12345678910111213141516171819202122public File processReport(List&lt;Object&gt; tableDto, File reportFile, SimpleXlsReportConfiguration configuration) throws Exception { JRDataSource datasource = new JRBeanCollectionDataSource(tableDto); Map&lt;String, Object&gt; parameters = new HashMap&lt;&gt;(); File targetFile = new File(TransferUtils.getStoreDir(SessionCookieUser.getSessionUserId().toString(), &quot;simge&quot;) + &quot;\\\\test.pdf&quot;); InputStream in = new FileInputStream(reportFile); JasperPrint jasperPrint; jasperPrint = JasperFillManager.fillReport(in, parameters, datasource);// byte[] bytes = JasperRunManager.runReportToPdf(in, parameters, datasource);// JRXlsExporter exporter = new JRXlsExporter(); JRPdfExporter exporter = new JRPdfExporter(); exporter.setExporterInput(new SimpleExporterInput(jasperPrint)); exporter.setExporterOutput(new SimpleOutputStreamExporterOutput(targetFile)); configuration.setRemoveEmptySpaceBetweenColumns(true); configuration.setRemoveEmptySpaceBetweenRows(true); configuration.setOnePagePerSheet(false);// configuration.setAutoFitPageHeight(true);// exporter.setConfiguration(configuration); exporter.exportReport(); return targetFile;} 其它设置条件 是否显示某元素在advanced中选择print when expression，在弹出框设置条件。如：new java.lang.Boolean($P{parameter1}.equals(“1”))。案例：可以实现复选框功能。可参考：http://blog.csdn.net/sinat_24702667/article/details/50867691","link":"/2017/12/06/java/jasperreports%E6%8A%A5%E8%A1%A8%E5%AF%BC%E5%87%BA/"},{"title":"lucene全文检索","text":"Lucene各版本，编程风格不同，此文以Lucene1.6.0为准。 Analyzer语言分析器，主要用于切词处理。 Analyzer是一个抽象类，它有多个实现。StandardAnalyzer、CJKAnalyzer、SmartChineseAnalyzer、BrazilianAnalyzer、KeywordAnalyzer、FrenchAnalyzer、CzechAnalyzer、GreekAnalyzer、PersianAnalyzer、StopAnalyzer、RussianAnalyzer、ThaiAnalyzer、WhitespaceAnalyzer。 根据不同的语言和应用选择合适的Analyzer，Analyzer把分词后的内容交给IndexWriter来建立索引。 Documentdocument类似数据库中的一条记录，可以有好几个字段（Filed）组成，并且字段可以套用不同的类型。 未完！！！ 练习 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899package com.flexcms.utils;import java.io.IOException;import org.apache.lucene.analysis.standard.StandardAnalyzer;import org.apache.lucene.document.Document;import org.apache.lucene.document.Field;import org.apache.lucene.document.StringField;import org.apache.lucene.document.TextField;import org.apache.lucene.index.DirectoryReader;import org.apache.lucene.index.IndexReader;import org.apache.lucene.index.IndexWriter;import org.apache.lucene.index.IndexWriterConfig;import org.apache.lucene.queryparser.classic.ParseException;import org.apache.lucene.queryparser.classic.QueryParser;import org.apache.lucene.search.IndexSearcher;import org.apache.lucene.search.Query;import org.apache.lucene.search.ScoreDoc;import org.apache.lucene.search.TopScoreDocCollector;import org.apache.lucene.store.Directory;import org.apache.lucene.store.RAMDirectory;import org.springframework.context.ApplicationContext;import org.springframework.context.annotation.AnnotationConfigApplicationContext;import org.topcloud.modules.mongodb.dao.MongoDao;import com.trainhelper.config.AppConfig; public class HelloLucene { // static MongoDao mongoDao; static Directory index; public static void main(String[] args) throws IOException, ParseException { ApplicationContext ac = new AnnotationConfigApplicationContext(AppConfig.class);// mongoDao = (MongoDao) ac.getBean(\"mongoDao\"); index = (Directory)ac.getBean(\"cmsIndexDirectory\"); // 0. Specify the analyzer for tokenizing text. // The same analyzer should be used for indexing and searching StandardAnalyzer analyzer = new StandardAnalyzer();// CJKAnalyzer analyzer = new CJKAnalyzer(); // 1. create the index Directory index = new RAMDirectory(); IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter w = new IndexWriter(index, config); addDoc(w, \"Lucene in Action\", \"193398817\"); addDoc(w, \"Lucene for Dummies\", \"55320055Z\"); addDoc(w, \"Managing Gigabytes\", \"55063554A\"); addDoc(w, \"The Art of Computer Science\", \"9900333X\"); w.close(); // 2. query String querystr = args.length &gt; 0 ? args[0] : \"Lucene\"; // BooleanQuery.Builder builder = new BooleanQuery.Builder();// Query q = new QueryParser( \"title\", analyzer).createBooleanQuery(\"title\", querystr, Occur.MUST); // Query query1 = new TermQuery(new Term(\"title\", querystr));// Query query2 = new TermQuery(new Term(\"title\", \"三\"));// BooleanClause bc1 = new BooleanClause(query1, Occur.MUST);// BooleanClause bc2 = new BooleanClause(query2, Occur.MUST_NOT);// BooleanQuery boolQuery = new BooleanQuery.Builder().add(bc1).add(bc2).build();// builder.add(new TermQuery(new Term(\"title\", querystr)), Occur.MUST); // the \"title\" arg specifies the default field to use // when no field is explicitly specified in the query. Query q = new QueryParser( \"title\", analyzer).parse(querystr); // 3. search int hitsPerPage = 10; IndexReader reader = DirectoryReader.open(index); IndexSearcher searcher = new IndexSearcher(reader); TopScoreDocCollector collector = TopScoreDocCollector.create(hitsPerPage); searcher.search(q, collector); ScoreDoc[] hits = collector.topDocs().scoreDocs; // 4. display results System.out.println(\"Found \" + hits.length + \" hits.\"); for(int i=0;i&lt;hits.length;++i) { int docId = hits[i].doc; Document d = searcher.doc(docId); System.out.println((i + 1) + \". \" + d.get(\"isbn\") + \"\\t\" + d.get(\"title\")); } // reader can only be closed when there // is no need to access the documents any more. reader.close(); } private static void addDoc(IndexWriter w, String title, String isbn) throws IOException { Document doc = new Document(); doc.add(new TextField(\"title\", title, Field.Store.YES)); // use a string field for isbn because we don't want it tokenized doc.add(new StringField(\"isbn\", isbn, Field.Store.YES)); w.addDocument(doc); }}","link":"/2017/10/16/java/lucene%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2/"},{"title":"MD5 salt 加密","text":"MD5 salt 加密 12345678910111213141516171819202122232425262728293031import java.math.BigInteger;import java.security.MessageDigest;import java.security.NoSuchAlgorithmException;import org.apache.commons.codec.digest.DigestUtils;public class MD5Utils { /** * 使用md5的算法进行加密 */ public static String md5(String plainText) { byte[] secretBytes = null; try { secretBytes = MessageDigest.getInstance(\"md5\").digest(plainText.getBytes()); } catch (NoSuchAlgorithmException e) { throw new RuntimeException(\"没有md5这个算法！\"); } String md5code = new BigInteger(1, secretBytes).toString(16);// 16进制数字 // 如果生成数字未满32位，需要前面补0 for (int i = 0; i &lt; 32 - md5code.length(); i++) { md5code += \"0\"; } return md5code; } public static void main(String[] args) { System.out.println(md5(\"123456\")); System.out.println(md5(\"123456{123456}\")); System.out.println(DigestUtils.md5Hex(\"123456\"+\"{123456}\")); }} DigestUtils.md5Hex(password+salt);//密码使用MD5加密,DigestUtils工具类 其中salt用于混淆的，一般取用户不变的信息，如身份证号码","link":"/2019/08/26/java/md5%E5%8A%A0%E5%AF%86/"},{"title":"tomcat单机多实例部署","text":"多实例部署tomcat，可以充分利用系统资源，方便tomcat的更新、升级维护。tomcat实例统一指向同一个应用程序，可以多个tomcat用一份应用源码，简单部署，单机高可用也能实现（要配合nginx）。 1、下载tomcat，并解压,比如放在/usr/local/tomcat目录下，作为tomcat程序主体存放位置。建议保留bin，lib和webapps目录。前两个目录必须有，因为其它实例都用这两个目录的程序。webapps的意义是可以供其它实例引用需要部署的webapp，这样可以达到一个目的，就是一份webapp的代码即可，无须copy很多份。 12$ tar -zxvf apache-tomcat-9.0.0.M17.tar.gz$ mv apache-tomcat-9.0.0.M17 /usr/local/tomcat 2、创建2个tomcat实例目录在/usr/local/tomcat_instance： 12$ mkdir -p /usr/local/tomcat_instance/tomcat1$ mkdir -p /usr/local/tomcat_instance/tomcat2 3、拷贝tomcat主体目录下的conf目录到实例中另外，logs,work,temp,webapps保留为空目录即可。webapps目录存在的意义是本实例独立部署的webapp，多实例共享的还是建议放在一个公用目录下。 12$ cp -R /usr/local/tomcat/conf /usr/local/tomcat_instance/tomcat1$ cp -R /usr/local/tomcat/conf /usr/local/tomcat_instance/tomcat2 4、在tomcat实例下创建启动和停止脚本启动和停止脚本放到tomcat实例的bin目录下 启动脚本vim /usr/local/tomcat_instance/tomcat1/bin/startup.sh12345678910111213141516171819#!/bin/bashexport CATALINA_HOME=/usr/local/tomcatexport CATALINA_BASE=/usr/local/tomcat_instance/tomcat1export CATALINA_TMPDIR=$CATALINA_BASE/tempexport CATALINA_PID=$CATALINA_BASE/bin/tomcat.pidexport JAVA_OPTS=&quot;-server -Xms1024m -Xmx1024m -Djava.awt.headless=true -Dtomcat.name=tomcat1&quot;#创建logs目录if [ ! -d &quot;$CATALINA_BASE/logs&quot; ]; then mkdir $CATALINA_BASE/logsfi#创建temp目录if [ ! -d &quot;$CATALINA_BASE/temp&quot; ]; then mkdir $CATALINA_BASE/tempfi# 调用tomcat启动脚本bash $CATALINA_HOME/bin/startup.sh &quot;$@&quot; 停止脚本vim /usr/local/tomcat_instance/tomcat1/bin/shutdown.sh1234567#!/bin/bashexport CATALINA_HOME=/usr/local/tomcatexport CATALINA_BASE=/usr/local/tomcat_instance/tomcat1export CATALINA_TMPDIR=$CATALINA_BASE/tempexport CATALINA_PID=$CATALINA_BASE/bin/tomcat.pidbash $CATALINA_HOME/bin/shutdown.sh &quot;$@&quot; 5、修改实例中server.xml端口及应用指向目录1234567891011&lt;Server port=&quot;9105&quot; shutdown=&quot;SHUTDOWN&quot;&gt; .... &lt;Connector port=&quot;9100&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; ....&lt;Connector port=&quot;9109&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; .... &lt;Host name=&quot;localhost&quot; appBase=&quot;/usr/local/tomcat/tomcat/webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; .... 注意:修改server.xml中Host节点的appBase属性的值。6、启动服务12$ /usr/local/tomcat_instance/tomcat1/bin/startup.sh$ /usr/local/tomcat_instance/tomcat2/bin/startup.sh 服务器启动之后，会分别在相应的实例目录下生成logs、temp、work和webapps目录。另外也可以在实例目录下创建lib目录，用于存放app的jar。现在来看实例的安装目录，就和tomcat的安装包解压后的目录结构一样了，但所有实例共享同一套tomcat安装程序的bin和lib。后面如果需要升级tomcat或修改tomcat脚本的相关配置，只需要更新这一套程序就行，也方便了日后的维护。参考：http://blog.csdn.net/xyang81/article/details/51997053","link":"/2017/11/17/java/tomcat%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%AE%9E%E4%BE%8B%E9%83%A8%E7%BD%B2/"},{"title":"二叉树的遍历规则(前序遍历、中序遍历、后序遍历)","text":"树的遍历顺序大体分为三种：前序遍历（先根遍历、先序遍历），中序遍历（中根遍历），后序遍历（后根遍历）。 如下二叉树 首先 观察这个二叉树 可见是这样的： 以B为根节点的左子树 A根节点 以C为根节点的右子树 。 以D为根节点的左子树 B根节点 以E为根节点的右子树 。 以G为根节点的左子树 D根节点 以H为根节点的右子树。 以K为根节点的左子树 C根节点 以F为根节点的右子树 。 以I为根节点的左子树 F根节点 右子树为空 。 左子树为空 I根节点 以J为根节点的右子树 。 接下来可以进行遍历了： 前序遍历规则是： 根 、左子树 、右子树： ​ 即先是根节点A 然后遍历 B子树 遍历完B子树后 再遍历C子树 。 ​ 即最后答案为： ABDGHECKFIJ 中序遍历规则是： 左子树 、根 、右子树 ​ 即先遍历 B子树 遍历完了 再是A节点 然后是右子树 ​ 答案为： GDHBEAKCIJF 后序遍历规则是： 左子树、 右子树 、根 ​ 答案为： GHDEBKJIFCA","link":"/2018/09/01/java/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86%E8%A7%84%E5%88%99/"},{"title":"判断字符串是否为日期类型","text":"12345678910111213public static boolean isDateString(String datevalue, String dateFormat) { try { SimpleDateFormat sdf = new SimpleDateFormat(dateFormat); Date date = sdf.parse(datevalue); if (datevalue.equals(sdf.format(date))) { return true; } else { return false; } } catch (Exception e) { return false; } }","link":"/2018/08/10/java/%E5%88%A4%E6%96%AD%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%98%AF%E5%90%A6%E4%B8%BA%E6%97%A5%E6%9C%9F%E7%B1%BB%E5%9E%8B/"},{"title":"第三方授权-QQ","text":"QQ第三方授权 申请appid和appkey申请地址 获取授权 在前台点击qq登录时去请求 1https://graph.qq.com/oauth2.0/authorize?response_type=code&amp;client_id=[YOUR_APPID]&amp;redirect_uri=[YOUR_REDIRECT_URI]&amp;scope=[THE_SCOPE] 3、通过Authorization Code获取Access Token通过回调获得的code 发送请求 1https://graph.qq.com/oauth2.0/token?grant_type=authorization_code&amp;client_id= [YOUR_APP_ID]&amp;client_secret=[YOUR_APP_Key]&amp;code=[The_AUTHORIZATION_CODE]&amp;state=[The_CLIENT_STATE]&amp;redirect_uri=[YOUR_REDIRECT_URI] 4、使用Access Token来获取用户的OpenID 发送请求 1https://graph.qq.com/oauth2.0/me?access_token=YOUR_ACCESS_TOKEN 5、使用Access Token以及OpenID来访问用户数据 1https://graph.qq.com/user/get_user_info?access_token=YOUR_ACCESS_TOKEN&amp;oauth_consumer_key=YOUR_APP_ID&amp;openid=YOUR_OPENID 参考文档：http://wiki.connect.qq.com/%e5%bc%80%e5%8f%91%e6%94%bb%e7%95%a5_server-side 微信第三方授权登录","link":"/2018/05/30/java/%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8E%88%E6%9D%83-QQ/"},{"title":"Linux命令之其它","text":"查看java的并发数：netstat -np|grep java|wc -l 两文件夹同步： rsync -ru –progress –delete /opt/rsync_test/f1/ /opt/rsync_test/f2/","link":"/2017/08/31/linux/Linux%E5%91%BD%E4%BB%A4%E4%B9%8B%E5%85%B6%E5%AE%83/"},{"title":"UbuntuServer18安装","text":"设置静态IP https://my.oschina.net/u/3264690/blog/1811424 开启root登录 https://www.cnblogs.com/longchang/p/11226236.html 更新软件源及升级版本 12$ apt update$ apt upgrade 磁盘挂载 https://help.aliyun.com/document_detail/116650.html?spm=5176.11065259.1996646101.searchclickresult.7c222b88yoD7P7&amp;aly_as=1K_0_fkc mongodb安装 wifi配置 https://www.cnblogs.com/floud/p/10545924.html wifi不稳定 https://blog.csdn.net/vivian_wanjin/article/details/82928315 redis 安装 https://www.cnblogs.com/ftl1012/p/9426231.html jenkis迁移 https://segmentfault.com/a/1190000019505621","link":"/2019/11/11/linux/UbuntuServer18%E5%AE%89%E8%A3%85/"},{"title":"Ubuntu下配置rsync","text":"目标：实现客户端开机自动同步服务端某个文件夹下文件 服务端1、查看系统是否已经安装rsync 12$ whereis rsyncrsync: /usr/bin/rsync /usr/share/man/man1/rsync.1.gz #说明已经安装否则（apt-get install rsync） 2、编辑配置文件，开启rsync vim /etc/default/rsync 1RSYNC_ENABLE=true #把false改为true 3、创建rsyncd.conf 1$ cp /usr/share/doc/rsync/examples/rsyncd.conf /etc/ vim /etc/rsyncd.conf 1234567891011121314151617# GLOBAL OPTIONS strict modes = yes#motd file=/etc/motd port = 873 log file=/var/log/rsyncd.log pid file=/var/run/rsyncd.pid auth users =cpnsp_rsyncd secrets file = /etc/rsyncd.secrets# for pid file, do not use /var/run/rsync.pid if# you are going to run rsync out of the init.d script.# The init.d script does its own pid file handling,# so omit the \"pid file\" line completely in that case.#syslog facility=daemon#socket options=# MODULE OPTIONS[cpnsp_static] path = /usr/local/nginx/html 说明：auth users 配制一定要和/etc/rsyncd.secrets里的用户名保持一致。 要备份的每个路径为一个module，可多个。 4、新建密码文件/etc/rsyncd.secrets 1cpnsp_rsyncd:admin123 用户名为cpnsp_rsyncd，密码为admin123，注意该文件属性为600 (其他用户没用读写执行权限) 5、开启rsync服务 1$ /etc/init.d/rsync start 可用netstat -tupln查看873端口有没有打开。 客户端1、在~下新建rsync工作目录 2、在工作目录内创建密码文件rsyncd.scrt 1cpnsp_rsyncd:admin123 内容和服务器端保持一样，属性也为600。 3、在工作目录创建client.conf 1234567891011121314# this is a configure file for client backup machine# NOTE:# OPTIONS=\"-vazu --progreess --delete\"# client will backup all same files at server# when server delete a specific file, client also delete it.# and OPTIONS=\"-vazu --progress\"# client will keep server deleted files# MODULE responding to [modules] in server, seperated by space# BACKUPPATH client backup pathBACKUPPATH=\"/root/\";SERVERIP=\"192.168.1.26\"MODULE=\"cpnsp_static\"#OPTIONS=\"-vazu --progress\"OPTIONS=\"-vazu --progress --delete\" 说明：其中BACKUPPATH为客户端同步文件存放路径。 MODULE对应服务端/etc/rsyncd.conf下的module，多个module以空格分开。 4、创建同步脚本rsyncclient.sh 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#!/bin/bashABSPATH=$(dirname $0)source ${ABSPATH}/client.conffunction get-user-pwd(){#obtain usrname and password iUSR=$(cat ${ABSPATH}/rsyncd.scrt|tr -d ' ' |grep -v \"^$\" | \\ grep -v \"^#\"|head -n 1|awk -F : '{print $1}') iPWD=$(cat ${ABSPATH}/rsyncd.scrt|tr -d ' ' |grep -v \"^$\" | \\ grep -v \"^#\"|head -n 1|awk -F : '{print $2}') if [ -z ${iUSR} ] || [ -z ${iPWD} ];then echo \"iUSR=$iUSR iPWD=$iPWD\" echo \"rsyncd.scrt format illegal, please check!\"; exit -1; fi# produce password file echo \"$iPWD\" &gt; ${ABSPATH}/.pass chmod 600 ${ABSPATH}/.pass [ ! -d $BACKUPPATH ] &amp;&amp; mkdir -p ${BACKUPPATH}}function backup-module(){# print key information iModule=$1 echo echo \"---------------------------------------------------\" echo \"---- backup module ${iModule}@${SERVERIP} begin \" echo \"---- TIME=`date`----\" echo \"ABSPATH=${ABSPATH}\" echo \"BACKUPPATH=${BACKUPPATH}\" echo \"iUSR=$iUSR iPWD=$iPWD\" echo \"OPTIONS=${OPTIONS}\" iModuleBackpath=${BACKUPPATH}/${iModule}; [ ! -d ${iModuleBackpath} ] &amp;&amp; mkdir -p ${iModuleBackpath}# begin backup rsync ${OPTIONS} ${iUSR}@${SERVERIP}::${iModule} ${iModuleBackpath} \\ --password-file=${ABSPATH}/.pass if [ $? != 0 ];then echo \"---- backup module ${iModule}@${SERVERIP} failed.\" else echo \"---- backup module ${iModule}@${SERVERIP} succuess. \" fi echo \"---- TIME=`date`----\" echo \"---------------------------------------------------\" echo}function __main__(){ get-user-pwd for md in $MODULE do backup-module $md done}__main__ chmod a+x rsyncclient.sh 5、 运行./rsyncclient.sh，就把服务端/usr/local/nginx/html下的文件同步到/root/cpnsp_stati下。 6、新建开机启动脚本 vim /etc/init.d/rsync_cpnsp 12345#!/bin/bashcd /root/html/./rsyncclient.shsleep 2/etc/init.d/tomcat8080 start 123$ chmod a+x rsync_cpnsp$ update-rc.d rsync_cpnsp defaults$ update-rc.d -f tomcat8080 remove 应用： 实现盒子的服务、手机端考试及PC端考试的自动更新 前提：盒子必须在联网状态下 可通过rsync实现盒子中服务和前端文件与服务端进行同步。 因避免在考试状态下服务更新的影响，所以只在开机时进行同步。 实现： . 在公网服务器上创建盒子中所需的服务及前端文件。. 配置rsync及开启rsync服务。. 在盒子中创建通信文件及rsync同步脚本。. 创建开机启动脚本。 参考： http://www.linuxidc.com/Linux/2014-03/97592.htm http://blog.csdn.net/zpf336/article/details/51659666 rsync参数：http://roclinux.cn/?p=2643","link":"/2017/08/24/linux/Ubuntu%E4%B8%8B%E9%85%8D%E7%BD%AErsync/"},{"title":"Ubuntu 设置开机自启动","text":"设置程序自启动或脚本开机执行，是经常用到的一个场景。 init基本说明1、init是内核在系统引导期间启动的第一个进程，并且是所有进程的父进程，在/sbin目录下可以找到init,它主要复制启动和终止系统中的基础服务进程。 2、Linux中发布了许多init系统版本，被广泛使用的主要有以下三个。 init类型 说明 识别 Systemd systemd是Linux操作系统的新的init系统和服务管理器。 很多linux发行版都已经或者计划转向Systemd 如果在系统目录文件中有/usr/lib/systemd和/etc/systemd,说明有systemd Upstart Upstart是/sbin/init守护程序的基于事件的替换。 系统目录有/etc/init,而且其中有许多conf文件,说明系统有upstart System V init 是UNIX / Linux操作系统的最早的传统初始化系统之一，大多数的linux发行版都会兼容。 系统有/etc/inittab文件,说明很有可能是System V init 关于init类型的识别可参考：how-to-determine-which-init-system-manager-is-running-on-linux-system 下面是几种设置自启动的方式 systemdsystemd是一个新的init系统和系统管理器，现在大多数Linux发行版都在传统的SysVinit管理器上采用了systemd。不在使用Upstart 管理系统。 systemctl是一个命令行应用程序，是管理systemd守护程序/服务的主要工具，允许用户启动，重新启动，停止，启用，禁用，重新加载和验证服务(start, restart, stop, enable, disable, reload, and verify )。 systemd 默认读取 /etc/systemd/system 下的配置文件，该目录下的文件会链接/lib/systemd/system/下的文件。 当使用systemd管理程序时，首先编写xxx.service文件，xxx.service的编写可参考：systemd-tutorial 然后就可使用systemctl 进行管理 1234567891011$ systemctl start example #开始服务$ systemctl stop example #停止服务$ systemctl restart example #重新启动服务$ systemctl reload example #重新加载配置文件$ systemctl condrestart example #如果服务已经在运行，则重新启动$ systemctl status example #查看服务的状态$ systemctl enable example #开启开机时自启动$ systemctl disable example #禁用开机时自启动$ systemctl is-enabled example #检查服务是否配置为开机时自启动$ systemctl list-unit-files –type=service #启动时显示带有运行级别信息的已启用或已禁用服务的列表$ systemctl daemon-reload #创建一个新的服务文件或修改任何配置时执行 具体应用见【mongodb设置开机自启（systemd方式）】【将spring-boot安装为systemd服务】 参考：SysVinit Vs systemd Cheatsheet 其它关于Systemd使用上的引导方向 https://www.centos.bz/tag/systemd/ sysv-rc-conf服务自启动管理工具在Ubuntu16.10之前可使用sysv-rc-conf，在Redhat下是chkconfig 也可用update-rc.d 在18.04里已经没有sysv-rc-conf安装包了，使用systemd 替代 1、安装 1$ apt-get install sysv-rc-conf 2、放置脚本服务 把需要自启动的脚本放置的 /etc/init.d 目录下 3、使用 1$ sysv-rc-conf 在图形界面进行设置 ubuntu的service,update-rc.d和systemctl命令 rc.local脚本rc.local脚本是一个ubuntu开机后会自动执行的脚本，我们可以在该脚本内添加命令行指令。该脚本位于/etc/路径下，需要root权限才能修改。 1234567891011121314#!/bin/sh -e## rc.local## This script is executed at the end of each multiuser runlevel.# Make sure that the script will \"exit 0\" on success or any other# value on error.## In order to enable or disable this script just change the execution# bits.## By default this script does nothing.exit 0 注意: 一定要将命令添加在 exit 0之前 在Ubuntu18.04中使用的是systemd，为了像以前一样，想在/etc/rc.local中设置开机启动程序，需要以下几步。 1、因为systemd默认读取/etc/systemd/system下的配置文件，该目录下的文件会链接/lib/systemd/system/下的文件。一般系统安装完/lib/systemd/system/下会有rc-local.service文件，所有我们需要将rc-local.service配置文件。 链接过来： 1$ ln -fs /lib/systemd/system/rc-local.service /etc/systemd/system/rc-local.service 2、编辑rc-local.service文件vim /etc/systemd/system/rc-local.service 在文件末尾添加 [Install] 区块 123[Install]WantedBy=multi-user.targetAlias=rc-local.service 3、创建/etc/rc.local文件 1$ touch /etc/rc.local 4、赋可执行权限 1$ chmod 755 /etc/rc.local 5、编辑rc.local，添加需要开机启动的任务 123#!/bin/bashecho \"test rc \" &gt; /var/test.log 6、执行reboot重启系统，然后查看test.log Ubuntu 18.04 rc.local systemd设置","link":"/2019/11/27/linux/Ubuntu%E8%AE%BE%E7%BD%AE%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF/"},{"title":"cwRsyncServer+rsync实现文件从windows同步到linux","text":"cwRsyncServer+rsync实现文件从windows同步到linux 需求：实现把Windows某文件夹同步到linux下 1、在Windows下安装cwRsyncServer4.1.0并配置 下载cwRsyncServer：https://pan.baidu.com/s/1ge6xpKn 图：安装1 设置用户名rsync 密码：rsync 修改rsyncd.conf配置文件 123456789101112131415161718use chroot = falsestrict modes = falsehosts allow = *log file = rsyncd.loguid = 0gid = 0# Module definitions# Remember cygwin naming conventions : c:\\work becomes /cygwin/c/work#[cpnsp] #指定模块的头信息path = /cygdrive/e/server/tomcat4/wtpwebapps #需要同步数据的目录，这个目录指E:\\server\\tomcat4\\wtpwebapps目录exclude from = rsync.exclude #排除要同步过去的文件列表或文件夹#exclude = test1/read only = false #是否为只读transfer logging = yeshosts allow =192.168.1.111 #允许访问的主机，多个用逗号分隔auth users = rsync #指定认证的用户名secrets file = /cygdrive/d/ProgramFiles/cwRsync/ICW/rsyncd.secrets #指定认证用户的密码文件存放路径，这个路径指d:\\ProgramFiles\\cwRsync\\ICW\\rsyncd.secrets,一会需要新建这个文件。 注意：要添加uid = 0及gid = 0。 创建rsyncd.secrets文件 1rsync:rsync 创建rsync.exclude文件（与rsyncd.conf同目录下） 12345WEB-INF/classes/sysproperty.propertiesWEB-INF/classes/mongodb.propertiesWEB-INF/classes/redis.propertiesckeditor/wlw/ 修改cpnsp文件夹的属性 图：文件夹属性 ​ 用户名填安装cwRsyncServer时创建的用户名 ​ 图：文件夹属性2 启动RsyncSever服务图：rsync服务 选中我的电脑–右键管理—服务和应用–服务，找到RsyncSever，双击–启动 检测 图：检测 在cmd下输入telnet 192.168.1.101 873 rsync的监听端口，它的默认监听的端口是873。 出现@RSYNCD:30.0这个就说明可以连接上去了 2、linux端配置 ubuntu16.04默认已安装rsync. 新建vim /etc/rsyncd.secrets 1rsync 客户端密码配置文件中只加入密码就行。 修改权限：chmod 600 /etc/rsyncd.secrets 新建同步要排除目录文件 vim rsync.exclude 12345WEB-INF/classes/sysproperty.propertiesWEB-INF/classes/mongodb.propertiesWEB-INF/classes/redis.propertiesckeditor/wlw/ 执行同步命令： 1rsync -vazrtopg --progress --delete --password-file=/etc/rsyncd.secrets --exclude-from=/opt/rsync_test/rsync.exclude rsync@192.168.1.101::cpnsp9.1/* /opt/rsync_test/ 参考：http://www.linuxidc.com/Linux/2014-08/105514.htm http://man.linuxde.net/rsync 2018-05-29更新 Windows到Linux的文件同步也可使用GoodSync软件，更方便，但不知安全性如何，暂未做生产服务器使用。","link":"/2017/09/06/linux/cwRsyncServer+rsync%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E4%BB%8Ewindows%E5%90%8C%E6%AD%A5%E5%88%B0linux/"},{"title":"inotify","text":"下载安装： 123456$ wget https://cloud.github.com/downloads/rvoicilas/inotify-tools/inotify-tools-3.14.tar.gz$ tar zxvf inotify-tools-3.14.tar.gz$ cd inotify-tools-3.14/$ ./configure --prefix=/usr/local/inotify$ make$ make install 未完成，日后补充。","link":"/2017/09/21/linux/inotify/"},{"title":"openssl升级","text":"问题：OpenSSL 安全漏洞(CVE-2016-8610)【原理扫描】修复方式：升级最新版本 1、查看openssl版本 12$ openssl versionOpenSSL 1.0.2g 1 Mar 2016 2、下载最新版本openssl 1$ wget https://www.openssl.org/source/openssl-1.1.1d.tar.gz 3、解压后进入目录进行编译安装 123$ cd /usr/local/src/openssl/openssl-1.1.1d$ ./config --prefix=/usr/local/openssl shared zlib$ make &amp;&amp; make install 4、备份当前版本 123$ find / -name openssl$ mv /usr/bin/openssl /usr/bin/openssl.bak$ mv /usr/include/openssl /usr/include/openssl.bak 5、配置使用新版本 1234$ ln -s /usr/local/openssl/bin/openssl /usr/bin/openssl$ ln -s /usr/local/openssl/include/openssl /usr/include/openssl$ echo \"/usr/local/openssl/lib/\" &gt;&gt; /etc/ld.so.conf #更新动态链接库数据$ ldconfig -v #重新加载动态链接库 6、验证 123$ openssl version -a$ openssl versionOpenSSL 1.1.1d 10 Sep 2019","link":"/2019/09/16/linux/openssl%E5%8D%87%E7%BA%A7/"},{"title":"rinetd linux端口转发工具","text":"rinetd，可以实现linux下端口映射/转发/重定向。Rinetd是为在一个Unix和Linux操作系统中为重定向传输控制协议(TCP)连接的一个工具。Rinetd是单一过程的服务器，它处理任何数量的连接到在配置文件etc/rinetd中指定的地址/端口对。尽管rinetd使用非闭锁I/O运行作为一个单一过程，它可能重定向很多连接而不对这台机器增加额外的负担。 1、安装 12345$ wget http://www.boutell.com/rinetd/http/rinetd.tar.gz$ tar -xvf rinetd.tar.gz &amp;&amp; cd rinetd$ sed -i 's/65536/65535/g' rinetd.c #(修改端口范围)$ mkdir /usr/man$ make &amp;&amp; make install 2、编辑配置文件vim /etc/rinetd.conf 1230.0.0.0 3306 172.19.94.3 33060.0.0.0 80 192.168.0.103 8080logfile /var/log/rinetd.log 将所有发往本机3306端口的请求转发到172.19.94.3的3306端口。将所有发往本机80端口的请求转发到192.168.0.103的8080端口.3、启动rinetd 1$ rinetd 注意：通过echo rinetd &gt;&gt;/etc/rc.local可以设置为自启动。4、停止rinetd 1$ pkill rinetd","link":"/2018/03/28/linux/rinetd%20linux%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"title":"ubuntu修改时区-timedatectl","text":"检查与修改时区查看时区12$ date -RWed, 10 Jan 2018 11:26:47 +0800shell 当前时间格式化输出1$ date \"+%Y-%m-%d %H:%M:%S\" 修改时区列出可用时区1$ timedatectl list-timezones 时区列表将打印到屏幕上。 可以按SPACE向下翻页，然后按b向上翻页。 找到正确的时区后，记下它，然后键入q退出列表。 设置时区1$ sudo timedatectl set-timezone Asia/Shanghai 控制时间同步查看时间状态12345678$ timedatectl Local time: Thu 2018-08-30 10:54:22 CST Universal time: Thu 2018-08-30 02:54:22 UTC RTC time: Thu 2018-08-30 02:54:22 Time zone: Asia/Shanghai (CST, +0800) System clock synchronized: yessystemd-timesyncd.service active: yes RTC in local TZ: no System clock synchronized: yes表示时间已成功同步， systemd-timesyncd.service active: yes表示timesyncd已启用并正在运行。 如果timesyncd未激活，请使用timedatectl将其打开： 1$ sudo timedatectl set-ntp on 再次运行timedatectl以确认网络时间状态。 实际同步可能需要一分钟，但最终Network time on:和NTP synchronized:应该读取yes 。 检查NTP同步的同步状态1234567891011121314$ systemctl status systemd-timesyncdsystemd-timesyncd.service - Network Time Synchronization Loaded: loaded (/lib/systemd/system/systemd-timesyncd.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2018-08-30 10:40:29 CST; 20min ago Docs: man:systemd-timesyncd.service(8) Main PID: 3266 (systemd-timesyn) Status: \"Synchronized to time server 202.118.1.130:123 (ntp.neu6.edu.cn).\" Tasks: 2 (limit: 4915) CGroup: /system.slice/systemd-timesyncd.service └─3266 /lib/systemd/systemd-timesyncdAug 30 10:40:29 ubuntu1804 systemd[1]: Starting Network Time Synchronization...Aug 30 10:40:29 ubuntu1804 systemd[1]: Started Network Time Synchronization.Aug 30 10:40:29 ubuntu1804 systemd-timesyncd[3266]: Synchronized to time server 202.118.1.130:123 (ntp.neu6.edu.cn). 最后一行和状态都清楚地显示成功的NTP同步状态。 修改NTP服务器列表更改 systemd-timesyncd的 配置：vim /etc/systemd/timesyncd.conf 1NTP=ntp.neu6.edu.cn 重启systemd-timesyncd1$ systemctl restart systemd-timesyncd ntp服务 东北大学 相关讨论https://www.v2ex.com/t/471414 参考：how-to-set-up-time-synchronization-on-ubuntu-18-04 [enable-ntp-sync](https://0049am.wordpress.com/2018/05/20/enable-ntp-sync-on-clean-ubuntu-18-04-server-installation/)","link":"/2018/08/30/linux/ubuntu%E4%BF%AE%E6%94%B9%E6%97%B6%E9%97%B4(%E4%BA%8C)/"},{"title":"ubuntu修改时区","text":"查看时区12$ date -RWed, 10 Jan 2018 11:26:47 +0800shell 修改时区1$ tzselect 1、选择区域 123456789101112131415$ tzselectPlease identify a location so that time zone rules can be set correctly.Please select a continent, ocean, \"coord\", or \"TZ\". 1) Africa 2) Americas 3) Antarctica 4) Asia 5) Atlantic Ocean 6) Australia 7) Europe 8) Indian Ocean 9) Pacific Ocean10) coord - I want to use geographical coordinates.11) TZ - I want to specify the time zone using the Posix TZ format.#? 4 2、选择国家 12345678910111213141516171819Please select a country whose clocks agree with yours. 1) Afghanistan 18) Israel 35) Palestine 2) Armenia 19) Japan 36) Philippines 3) Azerbaijan 20) Jordan 37) Qatar 4) Bahrain 21) Kazakhstan 38) Russia 5) Bangladesh 22) Korea (North) 39) Saudi Arabia 6) Bhutan 23) Korea (South) 40) Singapore 7) Brunei 24) Kuwait 41) Sri Lanka 8) Cambodia 25) Kyrgyzstan 42) Syria 9) China 26) Laos 43) Taiwan10) Cyprus 27) Lebanon 44) Tajikistan11) East Timor 28) Macau 45) Thailand12) Georgia 29) Malaysia 46) Turkmenistan13) Hong Kong 30) Mongolia 47) United Arab Emirates14) India 31) Myanmar (Burma) 48) Uzbekistan15) Indonesia 32) Nepal 49) Vietnam16) Iran 33) Oman 50) Yemen17) Iraq 34) Pakistan#? 9 3、选择时区 1234Please select one of the following time zone regions.1) Beijing Time2) Xinjiang Time#? 1 4、确认验证 123456789101112The following information has been given: China Beijing TimeTherefore TZ='Asia/Shanghai' will be used.Local time is now: Wed Jan 10 11:33:01 CST 2018.Universal Time is now: Wed Jan 10 03:33:01 UTC 2018.Is the above information OK?1) Yes2) No#? 1 5、复制文件到/etc目录下,防止系统重启后时区改变。 1$ cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 6.更新时间 1$ ntpdate time.windows.com 当前时间格式化输出 1$ date \"+%Y-%m-%d %H:%M:%S\" ntp服务 东北大学 相关讨论https://www.v2ex.com/t/471414","link":"/2018/01/10/linux/ubuntu%E4%BF%AE%E6%94%B9%E6%97%B6%E9%97%B4(%E4%B8%80)/"},{"title":"ubuntu系统上配置selenium运行chromeDriver","text":"可参考：https://tecadmin.net/setup-selenium-chromedriver-on-ubuntu/ 前提条件 1、系统处理器不是armv7l架构的。因使用的树莓派处理器架构是armv7l，所以实际操作未成功。 2、可以访问google (fq)。 3、系统最好是64位，因为chromeDriver 较新版linux只有64位的。chromedriver下载地址 也可参考：https://jiayi.space/post/zai-ubuntufu-wu-qi-shang-shi-yong-chrome-headless https://askubuntu.com/questions/79280/how-to-install-chrome-browser-properly-via-command-line","link":"/2018/09/30/linux/ubuntu%E7%B3%BB%E7%BB%9F%E4%B8%8A%E9%85%8D%E7%BD%AEselenium%E8%BF%90%E8%A1%8CchromeDriver/"},{"title":"主机间文件传输","text":"scp 与 rsync scp两主机间需要传输文件时，文件不太大可以使用scp进行传输。 常用参数： -P：指定数据传输用到的端口号。 -r：递归整个目录 1、从另一台/opt/back目录下文件复制到本地/root目录下 1$ scp -P 22 -r root@43.224.0.1:/opt/back /root 2、将本地/opt/back目录下文件复制到另一台/root目录下 1$ scp -P 22 -r /opt/back root@123.152.2.3:/root 免密码传输在需要输入密码的机器上执行 1$ ssh-keygen -t rsa 之后3次回车把产生的id_rsa.pub文件复制到另一台的~/.ssh下，并改名为 authorized_keys，如果该文件已存在，就把id_rsa.pub的内容复制到authorized_keys下。即可。 rsync如果传输的文件比较大，可能会在传输过程中断开，使用rsync可以在断开后继续传输而不用重新开始。 常用参数： -P：包含了“--partial --progress” ,部分传送和显示进度。 –rsh=ssh：表示使用ssh协议传送数据。 -r：递归整个目录。 1、文件断点下载 1$ rsync -P --rsh=ssh root@192.168.0.11:/root/large.tar.gz /dounine/targe.tar.gz 2、文件断点上传 1$ rsync -P --rsh=ssh /dounine/targe.tar.gz root@192.168.0.11:/root/large.tar.gz 3、文件目录断点下载 1$ rsync -P --rsh=ssh -r root@192.168.0.11:/root/storage /dounine 4、文件目录断点上传 1$ rsync -P --rsh=ssh -r /dounine root@192.168.0.11:/root/storage 另外wget命令也有断点续传(下载)的功能。","link":"/2019/09/16/linux/%E4%B8%BB%E6%9C%BA%E9%97%B4%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93/"},{"title":"ubuntu 无线连接","text":"安装无线管理工具1$ apt-get install wireless-tools 查看是否有无线网卡12345678910$ iwconfigwlan0 IEEE 802.11bgn ESSID:off/any Mode:Managed Access Point: Not-Associated Retry short limit:7 RTS thr:off Fragment thr:off Encryption key:off Power Management:onlo no wireless extensions.wnet no wireless extensions. 启用/禁用网卡12$ ifconfig wlan0 up# $ ifconfig wlan0 down 扫描无线网络12345678910111213141516171819202122232425$ iwlist wlan0 scanCell 04 - Address: 8C:A6:DF:43:C1:C5 Channel:11 Frequency:2.462 GHz (Channel 11) Quality=70/70 Signal level=-12 dBm Encryption key:on ESSID:&quot;wqyf2.4&quot; Bit Rates:1 Mb/s; 2 Mb/s; 5.5 Mb/s; 11 Mb/s; 6 Mb/s 9 Mb/s; 12 Mb/s; 18 Mb/s Bit Rates:24 Mb/s; 36 Mb/s; 48 Mb/s; 54 Mb/s Mode:Master Extra:tsf=0000000000000000 Extra: Last beacon: 80ms ago IE: Unknown: 000777717966322E34 IE: Unknown: 010882848B960C121824 IE: Unknown: 03010B IE: Unknown: 0506000101001008 IE: Unknown: 2A0100 IE: Unknown: 32043048606C IE: Unknown: 2D1AEE111BFFFFFF0000000000000000000100000000000000000000 IE: IEEE 802.11i/WPA2 Version 1 Group Cipher : CCMP Pairwise Ciphers (1) : CCMP Authentication Suites (1) : PSK .... 连接wqyf2.41、wqyf2.4为WPA2 Version 1,需要使用一个叫做wpasupplicant的工具 1$ apt-get install wpasupplicant 2、创建文件wpa_supplicant.confvim /etc/wpa_supplicant/wpa_supplicant.conf 123456789ctrl_interface=/var/run/wpa_supplicantap_scan=1network={ ssid=&quot;wqyf2.4&quot; psk=&quot;studio50&quot; priority=1} 3、在后台启动 1$ wpa_supplicant -i wlan0 -c /etc/wpa_supplicant/wpa_supplicant.conf &amp; 4、通过DHCP获取ip 1$ dhclient wlan0 OK! 其它ethtool ethtool命令网络配置 ethtool命令用于获取以太网卡的配置信息，或者修改这些配置。 1234567891011$ ethtool -i wlan0driver: brcmfmacversion: 7.45.41.26firmware-version: 01-4527cfabexpansion-rom-version:bus-info: mmc1:0001:1supports-statistics: nosupports-test: nosupports-eeprom-access: nosupports-register-dump: nosupports-priv-flags: no 补充：后期发现通过无线连接，网络传输异常慢，所以只做临时使用，长期最好还是通过网线连接。19.12.28","link":"/2017/11/09/linux/%E6%97%A0%E7%BA%BF%E8%BF%9E%E6%8E%A5/"},{"title":"Linux查看文件夹大小","text":"df 命令可以查看一级文件夹巨细、占用比例、挂入点等，但对文件却无能为力。 而 du command能查看文件及文件夹的巨细。 df：显现目前全部文件系统的可用空间及使用境地参数 -h,人性化输出，就是把获得的数据单元转为 GB、MB 等易读的格式。 输出的信息 Filesystem\\Mounted on分别为文件系统及其挂入点，Size、Used、Avail、Use% 分别是分区的容量、已使用巨细、下剩巨细、占用比例。 du：查询文件或文件夹的占用空间如果目录下文件许多，构造庞大，如果使用不带参数 du command，则会轮回列出目录下的全部文件与文件夹，以及其占用的巨细。 不有益查找究竟是哪个目录占用较大，因而需要给du command进入指定扫描目录的层数，参数：-d 或者 –max-depth 123#如：查看 /usr 下各个文件夹的巨细，-d 1 表示仅扫描一层目录$ du -h -d 1 /usr$ du -h --max-depth=1","link":"/2019/09/14/linux/%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E5%A4%B9%E5%A4%A7%E5%B0%8F/"},{"title":"流量统计工具-vnstat","text":"vnstat是一个基于控制台的网络流量监视器 ，它会记录指定网卡的每小时，每日和每月网络流量 。 它还自带了 vnstati 命令,通过它可以直接可以输出流量统计图. 安装一、安装vnstat两种方式： （1）在包管理程序中安装（ubuntu） 1$ sudo apt-get install vnstat vnstati （2）编译安装(安装最新稳定版本) 1234$ wget https://humdi.net/vnstat/vnstat-1.18.tar.gz$ tar -zxvf vnstat-1.18.tar.gz$ cd vnstat-1.18$ make &amp;&amp; make install 二、查看网卡 1$ ifcongig -a 三、初始化相应网卡的数据库 1$ vnstat -u -i wnet 四、启动 daemon 进程 1$ sudo /etc/init.d/vnstat start 五、默认开机启动 1$ sudo update-rc.d vnstat enable vnStat基本应用1、按小时统计 1$ vnstat -i wnet -h -i：指定网卡 2、按天统计 1$ vnstat -i wnet -d 3、按周统计 1$ vnstat -i wnet -w 4、按月统计 1$ vnstat -i wnet -m 5、统计消耗流量最多的10天的情况 1$ vnstat -i wnet -t 6、实时流量查看 1$ vnstat -i wnet -l 7、输出到图形：使用 vnstati 命令，更多详细的参数可以请 man vnstati。 1$ vnstati -i wnet -m -o /tmp/month.png 效果 官方主页： http://humdi.net/vnstat 参考：http://www.vpswe.com/vps-jiaocheng/483.html","link":"/2018/09/01/linux/%E6%B5%81%E9%87%8F%E7%BB%9F%E8%AE%A1%E5%B7%A5%E5%85%B7-vnstat/"},{"title":"让进程在后台运行方法","text":"我们经常遇到这样的问题，用telnet/ssh 登陆了远程的linux服务器，如果运行一些耗时较长的任务，结果却由于网络的不稳定导致任务中途失败。如何让命令提交后不受本地关闭终端窗口/网络断开连接的干扰呢？ 场景一：如果只是临时有一个命令需要长时间运行，什么方法能最简便的保证它在后台稳定运行呢？ 解决方法： 我们知道，当用户注销（logout）或者网络断开时，终端会收到 HUP（hangup）信号从而关闭其所有子进程。因此，我们的解决办法就有两种途径：要么让进程忽略 HUP 信号，要么让进程运行在新的会话里从而成为不属于此终端的子进程。 hangup 名称的来由 在 Unix 的早期版本中，每个终端都会通过 modem 和系统通讯。当用户 logout 时，modem 就会挂断（hang up）电话。 同理，当 modem 断开连接时，就会给终端发送 hangup 信号来通知其关闭所有子进程。 1、nohup nohup 的用途就是让提交的命令忽略 hangup 信号。 nohup的帮助信息 12345678910111213141516NOHUP(1) User Commands NOHUP(1)NAME nohup - run a command immune to hangups, with output to a non-ttySYNOPSIS nohup COMMAND [ARG]... nohup OPTIONDESCRIPTION Run COMMAND, ignoring hangup signals. --help display this help and exit --version output version information and exit 可见使用时非常方便的，只需在要处理的命令前加上 nohup 即可，标准输出和标准错误缺省会被重定向到 nohup.out 文件中。一般我们可在结尾加上“&amp;”来将命令同时放入后台运行，也可用&gt;filename 2&gt;&amp;1来更改缺省的重定向文件名。 示例： 123456root@sfkzw5mp4Z:~# nohup ping www.baidu.com &amp; # nohup ping www.baidu.com &gt;nohup.log 2&gt;&amp;1 &amp;[1] 13004root@sfkzw5mp4Z:~# nohup: ignoring input and appending output to ‘nohup.out’root@sfkzw5mp4Z:~# ps -ef |grep 13004root 13004 12957 0 10:23 pts/1 00:00:00 ping www.baidu.comroot 13006 12957 0 10:23 pts/1 00:00:00 grep --color=auto 13004 此处有个小问题 当用nohup命令使程序后台执行，但是直接关闭终端后，程序在后台就停止了。在其它机器上，并未出现此情况。以下是抚琴煮酒的《构建高可用linux服务器》里提到的这个问题 。 所以使用nohup命令执行后，出现了此类情况，不要直接关闭终端，使用exit命令退出会话。 2、setsid 暂未实际应用，不讨论 3、&amp; 待补充 场景二：我们已经知道，如果事先在命令前加上 nohup 或者 setsid 就可以避免 HUP 信号的影响。但是如果我们未加任何处理就已经提交了命令，该如何补救才能让它避免 HUP 信号的影响呢？ 解决方法： 想加 nohup 或者 setsid 已经为时已晚，只能通过作业调度和 disown 来解决这个问题了。 disown 的帮助信息 1234567891011disown: usage: disown [-h] [-ar] [jobspec ...] Without options, each jobspec is removed from the table of active jobs. If the -h option is given, each jobspec is not removed from the table, but is marked so that SIGHUP is not sent to the job if the shell receives a SIGHUP. If no jobspec is present, and neither the -a nor the -r option is supplied, the current job is used. If no jobspec is supplied, the -a option means to remove or mark all jobs; the -r option without a jobspec argument restricts operation to running jobs. The return value is 0 unless a jobspec does not specify a valid job. 我们可以用如下方式来达成我们的目的。 用disown -h jobspec来使某个作业忽略HUP信号 。 用disown -ah来使所有的作业都忽略HUP信号。 用disown -rh来使正在运行的作业忽略HUP信号。 需要注意的是，当使用过 disown 之后，会将把目标作业从作业列表中移除，我们将不能再使用jobs来查看它，但是依然能够用ps -ef查找到它。 但是还有一个问题，这种方法的操作对象是作业，如果我们在运行命令时在结尾加了“&amp;”来使它成为一个作业并在后台运行，那么就万事大吉了，我们可以通过jobs命令来得到所有作业的列表。但是如果并没有把当前命令作为作业来运行，如何才能得到它的作业号呢？答案就是用 CTRL-z（按住Ctrl键的同时按住z键）了！ CTRL-z 的用途就是将当前进程挂起（Suspend），然后我们就可以用jobs命令来查询它的作业号，再用bg jobspec来将它放入后台并继续运行。需要注意的是，如果挂起会影响当前进程的运行结果，请慎用此方法。 示例 如果提交命令时已经用“&amp;”将命令放入后台运行，则可以直接使用“disown”12345678[root@pvcent107 build]# cp -r testLargeFile largeFile &amp;[1] 4825[root@pvcent107 build]# jobs[1]+ Running cp -i -r testLargeFile largeFile &amp;[root@pvcent107 build]# disown -h %1[root@pvcent107 build]# ps -ef |grep largeFileroot 4825 968 1 09:46 pts/4 00:00:00 cp -i -r testLargeFile largeFileroot 4853 968 0 09:46 pts/4 00:00:00 grep largeFile （如果提交命令时未使用“&amp;”将命令放入后台运行，可使用 CTRL-z 和“bg”将其放入后台，再使用“disown”）1234567891011[root@pvcent107 build]# cp -r testLargeFile largeFile2 [1]+ Stopped cp -i -r testLargeFile largeFile2[root@pvcent107 build]# bg %1[1]+ cp -i -r testLargeFile largeFile2 &amp;[root@pvcent107 build]# jobs[1]+ Running cp -i -r testLargeFile largeFile2 &amp;[root@pvcent107 build]# disown -h %1[root@pvcent107 build]# ps -ef |grep largeFile2root 5790 5577 1 10:04 pts/3 00:00:00 cp -i -r testLargeFile largeFile2root 5824 5577 0 10:05 pts/3 00:00:00 grep largeFile2 注意：直接在shell中不断输出结果的命令，如ping 并未达到预想目标，此命令还待深究。 场景三：我们已经知道了如何让进程免受 HUP 信号的影响，但是如果有大量这种命令需要在稳定的后台里运行，如何避免对每条命令都做这样的操作呢？ 解决方法： 此时最方便的方法就是 screen 了。简单的说，screen 提供了 ANSI/VT100 的终端模拟器，使它能够在一个真实终端下运行多个全屏的伪终端。screen 的参数很多，具有很强大的功能，我们在此仅介绍其常用功能以及简要分析一下为什么使用 screen 能够避免 HUP 信号的影响。 使用screen需要安装 其它：另一神器：supervisor 参考：https://www.ibm.com/developerworks/cn/linux/l-cn-nohup/","link":"/2018/07/01/linux/%E8%BF%9B%E7%A8%8B%E5%90%8E%E5%8F%B0%E8%BF%90%E8%A1%8C/"},{"title":"进程管理工具htop","text":"1、 安装htop 下载 123456$ tar -zxvf htop-2.0.2.tar.gz$ mv htop-2.0.2 htop$ cd htop/$ ./configure$ make$ make install 说明： 执行configure时可能遇到如下错误： 1configure: error: You may want to use --disable-unicode or install libncursesw. 需要安装libncursesw ncurses包的作用：提供字符终端处理库，包括面板和菜单。 1$ apt-get install libncursesw5 默认情况下make install会安装到/usr/local，用于更改路径使用./configure –prefix=/some/path。","link":"/2017/09/11/linux/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7htop/"},{"title":"Linux通过pid查找对应应用程序及所在目录","text":"有时通过top命令看到某些进程占用内存较大。如图： 如果要查找具体进程执行文件及目录。可以通过以下两种方法：1、通过ps命令定位： 1$ ps -ef |grep -v grep |grep PID 2、通过查看进程目录： 1$ ll /proc/PID/","link":"/2018/05/25/linux/%E9%80%9A%E8%BF%87pid%E6%9F%A5%E6%89%BE%E5%AF%B9%E5%BA%94%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E5%8F%8A%E6%89%80%E5%9C%A8%E7%9B%AE%E5%BD%95/"},{"title":"ubuntu镜像源","text":"Debain stretch(stable) 1234567891011echo &quot;deb http://mirrors.ustc.edu.cn/debian/ stretch main contrib non-free&quot; &gt;&gt; sources.listecho &quot;deb-src http://mirrors.ustc.edu.cn/debian/ stretch main contrib non-free&quot; &gt;&gt; sources.listecho &quot;deb http://mirrors.ustc.edu.cn/debian/ stretch-updates main contrib non-free&quot; &gt;&gt; sources.listecho &quot;deb-src http://mirrors.ustc.edu.cn/debian/ stretch-updates main contrib non-free&quot; &gt;&gt; sources.listecho &quot;deb http://mirrors.ustc.edu.cn/debian/ stretch-backports main contrib non-free&quot; &gt;&gt; sources.listecho &quot;deb-src http://mirrors.ustc.edu.cn/debian/ stretch-backports main contrib non-free&quot; &gt;&gt; sources.listecho &quot;deb http://mirrors.ustc.edu.cn/debian-security/ stretch/updates main contrib non-free&quot; &gt;&gt; sources.listecho &quot;deb-src http://mirrors.ustc.edu.cn/debian-security/ stretch/updates main contrib non-free&quot; &gt;&gt; sources.list","link":"/2017/11/09/linux/%E9%95%9C%E5%83%8F%E6%BA%90/"},{"title":"echo-nginx-module模块","text":"使用 Nginx Upload Module 实现上传文件功能 下载nginx及echo-nginx-module模块 12$ wget http://nginx.org/download/nginx-1.16.1.tar.gz$ wget https://github.com/openresty/echo-nginx-module/archive/v0.61.tar.gz 编译执行nginx 1234$ ./configure --prefix=/usr/local/nginx --with-http_ssl_module --add-module=/usr/local/src/nginx/echo-nginx-module-0.61 --add-module=/usr/local/src/nginx/nginx-upload-module-2.3.0# --with-http_ssl_module 开启SSL模块 --add-module添加附加模块 nginx_upload_module模块$ make$ make install #注意如果之前安装过，不要make install 配置 nginx-upload.conf 12345678#echo-nginx-module moduleserver { location /sub { echo \"querystring: $query_string\"; echo \"method: $echo_request_method\"; } } 在浏览器请求 http://localhost/sub?name=11 123#输出querystring: name=11method: GET 如果请求后nginx把响应作为未知类型的文件保存，可以指定一下Content-Type： default_type text/plain; 配置参数参考：echo-nginx-module","link":"/2020/04/29/nginx/echo-nginx-module%E6%A8%A1%E5%9D%97/"},{"title":"nginx-upload-module模块","text":"使用 Nginx Upload Module 实现上传文件功能 下载nginx及nginx_upload_module模块 12$ wget http://nginx.org/download/nginx-1.16.1.tar.gz$ wget https://github.com/fdintino/nginx-upload-module/archive/2.3.0.tar.gz 编译执行nginx 1234$ ./configure --prefix=/usr/local/nginx --with-http_ssl_module --add-module=/usr/local/src/nginx/nginx-upload-module-2.3.0# --with-http_ssl_module 开启SSL模块 --add-module添加附加模块$ make$ make install #注意如果之前安装过，不要make install 配置 nginx-upload.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#nginx-upload moduleserver { listen 80; server_name localhost; client_max_body_size 100m; #上传大小限制 client_body_buffer_size 512k; # Upload form should be submitted to this location location /upload { # nginx接收完上传的文件后，然后交给后端处理的地址。 upload_pass @test; #临时保存路径，可以使用散列， #指定level 1 时，需提前创建对应的文件夹，从 0 到 9 upload_store /usr/local/nginx/upload; # upload_store /usr/local/nginx/upload 1; #上传文件的权限，rw 读写，r只读 upload_store_access user:rw; #这里写入http报头，pass到后台页面能获取这里set的报头字段 upload_set_form_field \"${upload_field_name}_name\" $upload_file_name; upload_set_form_field \"${upload_field_name}_content_type\" $upload_content_type; upload_set_form_field \"${upload_field_name}_path\" $upload_tmp_path; #Upload模块自动生成的一些信息，如文件大小与文件md5值等 upload_aggregate_form_field \"${upload_field_name}_md5\" $upload_file_md5; upload_aggregate_form_field \"${upload_field_name}_size\" $upload_file_size; # 允许的字段，允许全部可以 \"^.*$\" #upload_pass_form_field \"^submit$|^description$\"; upload_pass_form_field \"^.*$\"; # 指定上载速率限制，以每秒字节数为单位 0表示不限制。 upload_limit_rate 0; # 如果pass页面是以下状态码，就删除此次上传的临时文件 upload_cleanup 400 404 499 500-505; # 打开开关，意思就是把前端脚本请求的参数会传给后端,如/upload?id=5 upload_pass_args on; } # Pass altered request body to a backend location @test { #后端服务路径：http://192.168.1.101:8080/cpnsp/admin/ta/nginxUploadFile #如果存在参数可通过set设置，可参考http://www.udpwork.com/item/12552.html rwrite . /cpnsp/admin/ta/nginxUploadFile break; proxy_pass http://192.168.1.101:8080; #proxy_pass http://localhost:8080; # default_type text/html; # return 200 \"success\"; ## 如果不需要后端程序处理，直接返回200 }} upload.html 12345678910111213141516171819&lt;html&gt; &lt;head&gt; &lt;title&gt;Test upload&lt;/title&gt; &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"/&gt; &lt;/head&gt; &lt;body&gt; &lt;h2&gt;Select files to upload&lt;/h2&gt; &lt;form enctype=\"multipart/form-data\" action=\"/upload\" method=\"post\"&gt; &lt;input type=\"file\" name=\"file1\"&gt;&lt;br&gt; &lt;input type=\"file\" name=\"file2\"&gt;&lt;br&gt; &lt;input type=\"file\" name=\"file3\"&gt;&lt;br&gt; &lt;input type=\"file\" name=\"file4\"&gt;&lt;br&gt; &lt;input type=\"file\" name=\"file5\"&gt;&lt;br&gt; &lt;input type=\"file\" name=\"file6\"&gt;&lt;br&gt; &lt;input type=\"submit\" name=\"submit\" value=\"Upload\"&gt; &lt;input type=\"hidden\" name=\"test\" value=\"value\"&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 后端处理程序 12345678910111213@RequestMapping(value = \"/nginxUploadFile\", method = RequestMethod.POST)@ResponseBody@RequiresPermissions(AuthorizerInterceptor.PERMISSION_NONE)public ResponseData&lt;Map&lt;String, Object&gt;&gt; nginxUploadFile(HttpServletRequest request, HttpServletResponse response) { ResponseData&lt;Map&lt;String, Object&gt;&gt; rd = new ResponseData&lt;&gt;(new HashMap&lt;&gt;()); rd.getData().put(\"fileName\", request.getParameter(\"file1_name\")); rd.getData().put(\"contentType\", request.getParameter(\"file1_content_type\")); rd.getData().put(\"filePath\", request.getParameter(\"file1_path\")); rd.getData().put(\"fileSize\", request.getParameter(\"file1_size\")); rd.getData().put(\"fileMd5\", request.getParameter(\"file1_md5\")); return rd;} 配置参数参考：upload","link":"/2019/09/18/nginx/nginx-upload-module%E6%A8%A1%E5%9D%97/"},{"title":"nginx安装","text":"安装依赖库1、安装g++依赖库 123$ sudo apt-get update$ apt-get install build-essential #安装GCC$ apt-get install libtool 2、安装 pcre依赖库（http://www.pcre.org/） 1$ sudo apt-get install libpcre3 libpcre3-dev 3、安装 zlib依赖库（http://www.zlib.net） 1$ apt-get install zlib1g-dev 4、安装 ssl依赖库 1$ apt-get install openssl libssl-dev 安装nginx123456$ wget http://nginx.org/download/nginx-1.12.1.tar.gz$ tar -zxvf nginx-1.12.1.tar.gz$ cd nginx-1.12.1$ ./configure --prefix=/usr/local/nginx # --with-http_ssl_module$ make$ make install nginx开机启动1、编写启动脚本 vim /etc/init.d/nginx 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#! /bin/sh### BEGIN INIT INFO# Provides: nginx# Required-Start: $local_fs $remote_fs $network $syslog $named# Required-Stop: $local_fs $remote_fs $network $syslog $named# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: starts the nginx web server# Description: starts nginx using start-stop-daemon### END INIT INFOPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/binDESC=\"nginx daemon\"NAME=nginxDAEMON=/usr/local/nginx/sbin/$NAMECONFIGFILE=/usr/local/nginx/conf/$NAME.confPIDFILE=/usr/local/nginx/logs/$NAME.pidSCRIPTNAME=/etc/init.d/$NAMEset -e[ -x \"$DAEMON\" ] || exit 0do_start() {$DAEMON -c $CONFIGFILE || echo -n \"nginx already running\"}do_stop() {kill -INT `cat $PIDFILE` || echo -n \"nginx not running\"}do_reload() {kill -HUP `cat $PIDFILE` || echo -n \"nginx can't reload\"}case \"$1\" instart)echo -n \"Starting $DESC: $NAME\"do_startecho \".\";;stop)echo -n \"Stopping $DESC: $NAME\"do_stopecho \".\";;reload|graceful)echo -n \"Reloading $DESC configuration...\"do_reloadecho \".\";;restart)echo -n \"Restarting $DESC: $NAME\"do_stopdo_startecho \".\";;*)echo \"Usage: $SCRIPTNAME {start|stop|reload|restart}\" &gt;&amp;2exit 3;;esacexit 0 2、注册为服务 12$ chmod a+x /etc/init.d/nginx$ update-rc.d nginx defaults","link":"/2017/09/27/nginx/nginx%E5%AE%89%E8%A3%85/"},{"title":"nginx日志切割","text":"一、脚本切割 1、编写切割脚本 12345678910#!/bin/bash## Nginx 日志文件所在的目录LOGS_PATH=/var/log/nginx/bjcscn## 获取昨天的 yyyy-MM-ddYESTERDAY=$(date -d \"yesterday\" +%Y-%m-%d)## 移动文件mv ${LOGS_PATH}/access.log ${LOGS_PATH}/access_${YESTERDAY}.logmv ${LOGS_PATH}/error.log ${LOGS_PATH}/error_${YESTERDAY}.log## 向 Nginx 主进程发送 USR1 信号。USR1 信号是重新打开日志文件kill -USR1 $(cat /run/nginx.pid) 添加执行权限：chmod a+x bjcscn_cutlog.sh 2、加入定时任务crontab -e 10 0 * * * /bin/bash /etc/nginx/scripts/bjcscn_cutlog.sh 这样就会在每天零点零分对日志进行切割 二、logrotate切割 logrotate日志切割是linux自带的 配置目录：/etc/logrotate.d/ 执行时间由cron控制： cat /etc/crontab logrotate是基于cron运行的：脚本为：/etc/cron.daily/logrotate logrotate命令 123456Usage: logrotate [OPTION...] &lt;configfile&gt;-d, --debug ：debug模式，测试配置文件是否有错误。-f, --force ：强制转储文件。-m, --mail=command ：压缩日志后，发送日志到指定邮箱。-s, --state=statefile ：使用指定的状态文件。-v, --verbose ：显示转储过程。 logrotate配置文件参数 1234567891011121314151617181920212223242526compress 通过gzip 压缩转储以后的日志nocompress 不做gzip压缩处理copytruncate 用于还在打开中的日志文件，把当前日志备份并截断；是先拷贝再清空的方式，拷贝和清空之间有一个时间差，可能会丢失部分日志数据。nocopytruncate 备份日志文件不过不截断create mode owner group 轮转时指定创建新文件的属性，如create 0777 nobody nobodynocreate 不建立新的日志文件delaycompress 和compress 一起使用时，转储的日志文件到下一次转储时才压缩nodelaycompress 覆盖 delaycompress 选项，转储同时压缩。missingok 如果日志丢失，不报错继续滚动下一个日志errors address 专储时的错误信息发送到指定的Email 地址ifempty 即使日志文件为空文件也做轮转，这个是logrotate的缺省选项。notifempty 当日志文件为空时，不进行轮转mail address 把转储的日志文件发送到指定的E-mail 地址nomail 转储时不发送日志文件olddir directory 转储后的日志文件放入指定的目录，必须和当前日志文件在同一个文件系统noolddir 转储后的日志文件和当前日志文件放在同一个目录下sharedscripts 运行postrotate脚本，作用是在所有日志都轮转后统一执行一次脚本。如果没有配置这个，那么每个日志轮转后都会执行一次脚本prerotate 在logrotate转储之前需要执行的指令，例如修改文件的属性等动作；必须独立成行postrotate 在logrotate转储之后需要执行的指令，例如重新启动 (kill -HUP) 某个服务！必须独立成行daily 指定转储周期为每天weekly 指定转储周期为每周monthly 指定转储周期为每月rotate count 指定日志文件删除之前转储的次数，0 指没有备份，5 指保留5 个备份dateext 使用当期日期作为命名格式dateformat .%s 配合dateext使用，紧跟在下一行出现，定义文件切割后的文件名，必须配合dateext使用，只支持 %Y %m %d %s 这四个参数size(或minsize) log-size 当日志文件到达指定的大小时才转储，log-size能指定bytes(缺省)及KB (sizek)或MB(sizem). nginx例子参考(默认)： 12345678910111213141516171819$ cat /etc/logrotate.d/nginx/var/log/nginx/*.log { daily missingok rotate 14 compress delaycompress notifempty create 0640 www-data adm sharedscripts prerotate if [ -d /etc/logrotate.d/httpd-prerotate ]; then \\ run-parts /etc/logrotate.d/httpd-prerotate; \\ fi \\ endscript postrotate invoke-rc.d nginx rotate &gt;/dev/null 2&gt;&amp;1 endscript} invoke-rc.d的用法与service基本相同 配置步骤 1、编写配置文件 vim /etc/logrotate.d/nginx 123456789101112131415161718#需要备份的日志路径，一个或多个都可以/usr/local/nginx/logs/*.log/usr/local/nginx/logs/teachhelper/*.log{ daily missingok rotate 14 compress delaycompress notifempty create 0640 www-data adm sharedscripts prerotate if [ -f /usr/local/nginx/logs/nginx.pid ]; then kill -USR1 `cat /usr/local/nginx/logs/nginx.pid` fi endscript} 2、测试 1$ logrotate -vf /etc/logrotate.d/nginx 3、定时执行 执行时间由cron控制： cat /etc/crontab logrotate的脚本是按 /etc/cron.daily任务的执行时间执行。 暂时是默认即可，即每天早上6:25","link":"/2017/08/29/nginx/nginx%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2/"},{"title":"nginx限制页面访问","text":"限制页面访问权限 可参考： http://nginx.org/en/docs/http/ngx_http_auth_basic_module.html https://www.sunzhongwei.com/nginx-http-authentication.html","link":"/2019/09/19/nginx/nginx%E9%99%90%E5%88%B6%E9%A1%B5%E9%9D%A2%E8%AE%BF%E9%97%AE/"},{"title":"python2与python3版本的切换","text":"ubuntu系统 python2与python3版本的切换 系统中python2与python3同时存在，如果要在两者之间切换。要更改python的软链接，比较麻烦。可以使用 alternatives进行管理命令的软链接。 1、添加对python软链接的管理 12$ sudo update-alternatives --install /usr/local/bin/python python /usr/bin/python2 100$ sudo update-alternatives --install /usr/local/bin/python python /usr/bin/python3 150 2、查看 123456$ ls -al `which python` lrwxrwxrwx 1 root root 7 May 27 16:06 /usr/local/bin/python -&gt; /etc/alternatives/python$ python --version Python 3.5.2$ ls -al /etc/alternatives/python lrwxrwxrwx 1 root root 16 May 27 17:27 /etc/alternatives/python -&gt; /usr/bin/python3 这样python版本默认就为python3。 3、切换到python2 1234567$ update-alternatives --config python Selection Path Priority Status------------------------------------------------------------* 0 /usr/bin/python3 150 auto mode 1 /usr/bin/python2 100 manual mode 2 /usr/bin/python3 150 manual mode 按照提示输入选择数字2回车即可。 同样思路可以对java版本进行如此管理。 关于alternatives命令的具体使用待了解。","link":"/2018/05/27/python/Python%E7%89%88%E6%9C%AC%E5%88%87%E6%8D%A2/"},{"title":"Python2.7编译安装","text":"ubuntu16.04系统自带Python版本为Python3，有时会使用到python2.7版本。就需要进行安装。 1、从python官网下载2.7版本。官网 1$ wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz 2、解压 1$ tar zxvf Python-2.7.15.tgz -C /usr/local/src/ 3、编译 1234$ cd /usr/local/src/Python-2.7.15/$ ./configure --prefix=/usr/local$ make$ make install 4、验证 12345$ pythonPython 2.7.15 (default, May 27 2018, 15:08:52)[GCC 5.4.0 20160609] on linux2Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; exit() python2与python3的切换暂不深究。","link":"/2018/05/27/python/python2.7%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/"},{"title":"samba的安装","text":"samba的编译安装 samba 是用于Linux和windows之间文件共享的服务。 ubuntu16.04 进行samba 安装 编译安装1、首先要检查python的默认版本是否为2。不是的话，先安装python2 或者切换版本为2 12$ python --version Python 2.7.15 2、从官网下载samba官网 1$ wget https://download.samba.org/pub/samba/stable/samba-4.8.2.tar.gz 1、解压 1$ tar zxvf samba-4.8.2.tar.gz -C /usr/local/src/ 4、编译 1234$ cd /usr/local/src/samba-4.8.2/$ ./configure --prefix=/usr/local/samba/$ make$ make install 未解决： 12345Checking for Python version &gt;= 2.6.0 : ok 2.7.15Checking for library python2.7 : yesChecking for program python2.7-config : /usr/local/bin/python2.7-configChecking for custom code : Could not find the python development headers/opt/compile/samba/samba-4.8.2/wscript:124: error: the configuration failed (see '/opt/compile/samba/samba-4.8.2/bin/config.log') 很是郁闷。最终编译安装失败！！！ apt 安装 1、直接apt进行安装apt-get install samba 2、新建共享文件夹 12$ mkdir /opt/share/$ chmod 777 /opt/share/ 2、修改samba配置文件 ​ /etc/samba/smb.conf 123456789[usershare] comment = Home Directories path = /opt/share public = yes browseable = yes writable = yes guest ok = yes create mask = 0777 directory mask = 0777 3、重启服务 1$ service smbd restart 在Windows中cmd 输入 \\192.168.1.90 进入共享文件夹","link":"/2018/05/27/samba/samba%E5%AE%89%E8%A3%85/"},{"title":"TOMCAT 关闭报错：Tomcat did not stop in time. PID file was not removed","text":"参考：http://blog.csdn.net/mchdba/article/details/46482499由此引发 ScheduledThreadPoolExecutor、quartz调度、内存泄漏检测、分析。","link":"/2018/03/15/windows/TOMCAT%20%E5%85%B3%E9%97%AD%E6%8A%A5%E9%94%99%EF%BC%9ATomcat%20did%20not%20stop%20in%20time.%20PID%20file%20was%20not%20removed/"},{"title":"tomcat启动后报 to the cache because there was insufficient free space available after evicting expired cache entri","text":"tomcat 启动后一直报一大堆警告 XX…to the cache because there was insufficient free space available after evicting expired cache entri，大致是意思是tomcat的缓存因为没有足够的可用空间后加载文件。 解决方法修改tomcat/conf/context.xml文件，增加资源最大可缓存的大小：在标签中添加 1&lt;Resources cacheMaxSize=&quot;200000&quot; cachingAllowed=&quot;true&quot;/&gt; 如果添加后还是出现，则重新添加一个tomcat。 说明：Resources 是资源定义元素，cachingAllowed和cacheMaxSize是公共属性。cachingAllowed：静态资源缓存的最大大小，以千字节为单位。如果未指定，则默认值为10240 （10兆字节）。在Web应用程序运行时（例如，通过JMX），可能会更改此值。如果缓存使用的内存大于新的限制，那么缓存将尝试缩小规模以适应新的限制。如有必要，cacheObjectMaxSize将被缩小以确保它不大于 cacheMaxSize/20。cachingAllowed：如果此标志的值是true，则将使用静态资源的缓存。如果没有指定，标志的默认值是true。在Web应用程序运行时（例如，通过JMX），可能会更改此值。当禁用高速缓存时，高速缓存中的当前任何资源都将从高速缓存中清除。 具体含义和属性参考：https://tomcat.apache.org/tomcat-8.0-doc/config/resources.html#Attributes","link":"/2018/01/10/windows/tomcat%E5%90%AF%E5%8A%A8%E5%90%8E%E6%8A%A5%20to%20the%20cache%20because%20there%20was%20insufficient%20free%20space%20available%20after%20evicting%20expired%20cache%20entri/"},{"title":"windows下tomcat注册为服务","text":"在免安装tomcat的bin目录下有service.bat文件，利用此文件进行注册为服务。 1、命令窗口下，目录切换到tomcat的bin目录下。2、安装tomcat服务 ： service install3、查看服务 ： win + R、services.msc、Enter 打开服务管理界面，找到tomcat服务项 确定tomcat服务已经安装，并右键查看服务的名称，我的就是tomcat7。4、启动tomcat服务：net start tomcat75、停止tomcat服务: net stop tomcat76、卸载Tomcat服务：service remove 其它问题可查看logs/错误日志，根据日志进行分析。1、安装时出现 Failed to install Tomcat7 service 可能是没有权限，以管理员身份运行cmd。2、Windows 无法在本地计算机启动Apache tomcat 可能是tomcat位数不对，下载系统jdk对应版本Tomcat.","link":"/2018/01/09/windows/tomcat%E6%B3%A8%E5%86%8C%E4%B8%BA%E6%9C%8D%E5%8A%A1/"},{"title":"jira的安装与配置","text":"参考：jira confluence参考：confluence_1confluence_2confluence_3confluence_4","link":"/2018/03/28/%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/jira%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"},{"title":"无题","text":"​ 如果我们总在等待绝对的一切就绪，那我们将永远无法开始。 —— 伊万·屠格涅夫","link":"/2018/06/10/%E5%85%B6%E5%AE%83/2018-06-10/"},{"title":"termux","text":"termux 切换root: $ termux-chroot cd /storage/emulated/0/ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149$ du -h -d 1 ./328.2M ./Movies22.9M ./Music253.3M ./Pictures2.1M ./baidu8.0K ./Themes4.5K ./Documents4.0K ./.tbs3.9M ./ColorOS1.3M ./QQBrowser42.9M ./Download402.8M ./netease20.5K ./.com.oupeng.max.sdk60.6M ./Market1.1G ./Android4.8M ./data8.0K ./zapya213.0K ./.mcs8.0K ./.UTSystemConfig672.9M ./DCIM8.0K ./.OnePlusH2Ota94.0K ./backups420.1M ./alipay4.0K ./.DataStorage612.0K ./Backucup9.5K ./.com.taobao.dp3.5K ./Podcasts6.8M ./amap8.0K ./com.eg.android.AlipayGphone37.8M ./UCDownloads 10.8G ./tencent7.4M ./.system20.0K ./tbs10.8M ./backup10.5K ./KMP112.8M ./sina19.9M ./.wbadcache22.9M ./autonavi3.5K ./douban36.0K ./com.sina.weibo32.0K ./.skynet79.0K ./.unicomCache24.0K ./.nearme235.2M ./Snapseed8.0K ./InAppBillingLibrary136.0K ./.plugin64.0K ./appstat8.0K ./egame16.0K ./skynet2.5G ./Telegram4.2M ./Youdao8.0K ./netease_pushservice16.0K ./bluetooth819.5K ./Qmap16.0K ./sysdata140.0K ./tencentmapsdk3.5K ./KMP_SUBTITLES24.0K ./didi9.4M ./Browser16.0K ./.AppCenterWebBuffer_QQ8.0K ./tmpaeucache64.0K ./Mob4.5K ./Alarms12.0K ./Ctrip16.0K ./CtripPushSDK68.3M ./Record8.0K ./mfcache149.5K ./amap_ams41.1M ./ting8.0K ./ickeck3.4M ./games16.0K ./.growingio16.0K ./.jgads38.6M ./vue25.7M ./500pxme92.0K ./appubk140.0K ./dobest48.0K ./sgsupdate267.7M ./KineMaster8.0K ./.fileManager8.0K ./umeng_cache3.5K ./.vue815.0K ./cmgame1.5M ./oem_log8.0K ./.Ota60.0K ./com.youdao.dict8.0K ./.chinaunicomfs7.5K ./.omgid3.1M ./JDIM3.5K ./keep1.4M ./autohome12.5K ./txrtmp3.5K ./com.tencent.edu80.0K ./com.netease.vopen11.5K ./com.tencent.qqlive227.7M ./com.tencent.litchi2.6M ./migu2.5M ./UCMobile947.5K ./autohomemain8.0K ./autolog8.0K ./autohome_ums8.0K ./com.cubic.autohome12.5K ./.uxx12.5K ./.cc109.0K ./txcache8.0K ./XHS24.0K ./360131.6M ./nk_download3.9M ./PicsArt3.1M ./牛客19.0K ./cache28.0K ./.vivo62.0K ./msc52.0K ./PayGateWayLibrary35.5K ./HelloImageLoader24.5K ./com.bankcomm.Bankcomm16.0K ./jtyh7.0K ./zhuntiku11.5K ./Unicom13.0K ./app12.5K ./bytedance4.0K ./dgdf_configqwpo12.5K ./.jds140.0K ./cnb8.2M ./soul180.2M ./baidunetdisk12.5K ./.zp19.5K ./Geetest28.0K ./com.hpbr.bosszhipin23.0K ./com.UCMobile4.0K ./at4.0K ./MQ4.7M ./weishi_yt_model4.0K ./dgdf_configqwpo1112.7M ./.videocache43.5K ./com.netease.cloudmusic4.0K ./.xiachufang_first_install_info4.5K ./Ringtones3.5K ./OnePlusBBS4.5K ./userexperience3.0M ./Mindmaster5.5K ./Catfish5.0K ./zhihu3.5K ./OSSLog15.5K ./cqrcb87.2M ./sogou7.0K ./.awp355.5K ./.shareTemp18.1G ./","link":"/2019/10/31/%E5%85%B6%E5%AE%83/termux/"},{"title":"浏览器网页去除广告","text":"每当查资料翻新闻总有广告出来恶心人。像csdn侧边栏的百度广告。 chrome浏览器安装 Adblock Plus 扩展程序 QQ浏览器安装 Adblock Plus 或者 广告屏蔽+页面元素隐藏助手 插件","link":"/2018/11/15/%E5%85%B6%E5%AE%83/%E6%B5%8F%E8%A7%88%E5%99%A8%E5%8E%BB%E9%99%A4%E5%B9%BF%E5%91%8A/"},{"title":"Ubuntu下配置rsync","text":"目标：实现客户端开机自动同步服务端某个文件夹下文件 服务端1、查看系统是否已经安装rsync 12$ whereis rsyncrsync: /usr/bin/rsync /usr/share/man/man1/rsync.1.gz #说明已经安装否则（apt-get install rsync）2、编辑配置文件，开启rsync vim /etc/default/rsync 1RSYNC_ENABLE=true #把false改为true 3、创建rsyncd.conf cp /usr/share/doc/rsync/examples/rsyncd.conf /etc/ vim /etc/rsyncd.conf1234567891011121314151617181920 # GLOBAL OPTIONS strict modes = yes#motd file=/etc/motd port = 873 log file=/var/log/rsyncd.log pid file=/var/run/rsyncd.pid auth users =cpnsp_rsyncd secrets file = /etc/rsyncd.secrets# for pid file, do not use /var/run/rsync.pid if# you are going to run rsync out of the init.d script.# The init.d script does its own pid file handling,# so omit the &quot;pid file&quot; line completely in that case.#syslog facility=daemon#socket options=# MODULE OPTIONS[cpnsp_static] path = /usr/local/nginx/html 说明：auth users 配制一定要和/etc/rsyncd.secrets里的用户名保持一致。 要备份的每个路径为一个module，可多个。4、新建密码文件/etc/rsyncd.secrets1cpnsp_rsyncd:admin123 用户名为cpnsp_rsyncd，密码为admin123，注意该文件属性为600 (其他用户没用读写执行权限)5、开启rsync服务 1$ /etc/init.d/rsync start 可用netstat -tupln查看873端口有没有打开。客户端1、在~下新建rsync工作目录 2、在工作目录内创建密码文件rsyncd.scrt 1cpnsp_rsyncd:admin123 内容和服务器端保持一样，属性也为600。 3、在工作目录创建client.conf 123456789101112131415# this is a configure file for client backup machine# NOTE:# OPTIONS=&quot;-vazu --progreess --delete&quot;# client will backup all same files at server# when server delete a specific file, client also delete it.# and OPTIONS=&quot;-vazu --progress&quot;# client will keep server deleted files# MODULE responding to [modules] in server, seperated by space# BACKUPPATH client backup pathBACKUPPATH=&quot;/root/&quot;;SERVERIP=&quot;192.168.1.26&quot;MODULE=&quot;cpnsp_static&quot;#OPTIONS=&quot;-vazu --progress&quot;OPTIONS=&quot;-vazu --progress --delete&quot; 说明：其中BACKUPPATH为客户端同步文件存放路径。 MODULE对应服务端/etc/rsyncd.conf下的module，多个module以空格分开。4、创建同步脚本rsyncclient.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#!/bin/bashABSPATH=$(dirname $0)source ${ABSPATH}/client.conffunction get-user-pwd(){#obtain usrname and password iUSR=$(cat ${ABSPATH}/rsyncd.scrt|tr -d ' ' |grep -v &quot;^$&quot; | \\ grep -v &quot;^#&quot;|head -n 1|awk -F : '{print $1}') iPWD=$(cat ${ABSPATH}/rsyncd.scrt|tr -d ' ' |grep -v &quot;^$&quot; | \\ grep -v &quot;^#&quot;|head -n 1|awk -F : '{print $2}') if [ -z ${iUSR} ] || [ -z ${iPWD} ];then echo &quot;iUSR=$iUSR iPWD=$iPWD&quot; echo &quot;rsyncd.scrt format illegal, please check!&quot;; exit -1; fi# produce password file echo &quot;$iPWD&quot; &gt; ${ABSPATH}/.pass chmod 600 ${ABSPATH}/.pass [ ! -d $BACKUPPATH ] &amp;&amp; mkdir -p ${BACKUPPATH}}function backup-module(){# print key information iModule=$1 echo echo &quot;---------------------------------------------------&quot; echo &quot;---- backup module ${iModule}@${SERVERIP} begin &quot; echo &quot;---- TIME=`date`----&quot; echo &quot;ABSPATH=${ABSPATH}&quot; echo &quot;BACKUPPATH=${BACKUPPATH}&quot; echo &quot;iUSR=$iUSR iPWD=$iPWD&quot; echo &quot;OPTIONS=${OPTIONS}&quot; iModuleBackpath=${BACKUPPATH}/${iModule}; [ ! -d ${iModuleBackpath} ] &amp;&amp; mkdir -p ${iModuleBackpath}# begin backup rsync ${OPTIONS} ${iUSR}@${SERVERIP}::${iModule} ${iModuleBackpath} \\ --password-file=${ABSPATH}/.pass if [ $? != 0 ];then echo &quot;---- backup module ${iModule}@${SERVERIP} failed.&quot; else echo &quot;---- backup module ${iModule}@${SERVERIP} succuess. &quot; fi echo &quot;---- TIME=`date`----&quot; echo &quot;---------------------------------------------------&quot; echo}function __main__(){ get-user-pwd for md in $MODULE do backup-module $md done}__main__ chmod a+x rsyncclient.sh 5、 运行./rsyncclient.sh，就把服务端/usr/local/nginx/html下的文件同步到/root/cpnsp_stati下。 6、新建开机启动脚本 vim /etc/init.d/rsync_cpnsp 12345#!/bin/bashcd /root/html/./rsyncclient.shsleep 2/etc/init.d/tomcat8080 start 123$ chmod a+x rsync_cpnsp$ update-rc.d rsync_cpnsp defaults$ update-rc.d -f tomcat8080 remove 应用：实现盒子的服务、手机端考试及PC端考试的自动更新 前提：盒子必须在联网状态下 可通过rsync实现盒子中服务和前端文件与服务端进行同步。 因避免在考试状态下服务更新的影响，所以只在开机时进行同步。 实现： 在公网服务器上创建盒子中所需的服务及前端文件。. 配置rsync及开启rsync服务。. 在盒子中创建通信文件及rsync同步脚本。. 创建开机启动脚本。 参考： http://www.linuxidc.com/Linux/2014-03/97592.htm http://blog.csdn.net/zpf336/article/details/51659666 rsync参数：http://roclinux.cn/?p=2643","link":"/2017/08/24/%E5%90%8C%E6%AD%A5/Ubuntu%E4%B8%8B%E9%85%8D%E7%BD%AErsync/"},{"title":"cwRsyncServer+rsync实现文件从windows同步到linux","text":"cwRsyncServer+rsync实现文件从windows同步到linux需求：实现把Windows某文件夹同步到linux下1、在Windows下安装cwRsyncServer4.1.0并配置 下载cwRsyncServer：https://pan.baidu.com/s/1ge6xpKn图：安装1设置用户名rsync 密码：rsync 修改rsyncd.conf配置文件12345678910111213141516171819use chroot = falsestrict modes = falsehosts allow = *log file = rsyncd.loguid = 0gid = 0# Module definitions# Remember cygwin naming conventions : c:\\work becomes /cygwin/c/work#[cpnsp] #指定模块的头信息path = /cygdrive/e/server/tomcat4/wtpwebapps #需要同步数据的目录，这个目录指E:\\server\\tomcat4\\wtpwebapps目录exclude from = rsync.exclude #排除要同步过去的文件列表或文件夹#exclude = test1/read only = false #是否为只读transfer logging = yeshosts allow =192.168.1.111 #允许访问的主机，多个用逗号分隔auth users = rsync #指定认证的用户名secrets file = /cygdrive/d/ProgramFiles/cwRsync/ICW/rsyncd.secrets #指定认证用户的密码文件存放路径，这个路径指d:\\ProgramFiles\\cwRsync\\ICW\\rsyncd.secrets,一会需要新建这个文件。 注意：要添加uid = 0及gid = 0。 创建rsyncd.secrets文件1rsync:rsync 创建rsync.exclude文件（与rsyncd.conf同目录下）12345WEB-INF/classes/sysproperty.propertiesWEB-INF/classes/mongodb.propertiesWEB-INF/classes/redis.propertiesckeditor/wlw/ 修改cpnsp文件夹的属性图：文件夹属性用户名填安装cwRsyncServer时创建的用户名图：文件夹属性2 启动RsyncSever服务图：rsync服务 选中我的电脑–右键管理—服务和应用–服务，找到RsyncSever，双击–启动 检测图：检测在cmd下输入telnet 192.168.1.101 873 rsync的监听端口，它的默认监听的端口是873。出现@RSYNCD:30.0这个就说明可以连接上去了2、linux端配置 ubuntu16.04默认已安装rsync. 新建vim /etc/rsyncd.secrets1rsync 客户端密码配置文件中只加入密码就行。 修改权限：chmod 600 /etc/rsyncd.secrets 新建同步要排除目录文件 vim rsync.exclude12345WEB-INF/classes/sysproperty.propertiesWEB-INF/classes/mongodb.propertiesWEB-INF/classes/redis.propertiesckeditor/wlw/ 执行同步命令：1rsync -vazrtopg --progress --delete --password-file=/etc/rsyncd.secrets --exclude-from=/opt/rsync_test/rsync.exclude rsync@192.168.1.101::cpnsp9.1/* /opt/rsync_test/ 参考：http://www.linuxidc.com/Linux/2014-08/105514.htm http://man.linuxde.net/rsync 2018-05-29更新 Windows到Linux的文件同步也可使用GoodSync软件，更方便，但不知安全性如何，暂未做生产服务器使用。","link":"/2017/09/06/%E5%90%8C%E6%AD%A5/cwRsyncServer+rsync%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E4%BB%8Ewindows%E5%90%8C%E6%AD%A5%E5%88%B0linux/"},{"title":"inotify","text":"inotify 下载安装： 123456wget https://cloud.github.com/downloads/rvoicilas/inotify-tools/inotify-tools-3.14.tar.gztar zxvf inotify-tools-3.14.tar.gzcd inotify-tools-3.14/./configure --prefix=/usr/local/inotifymakemake install 未完成，日后补充。","link":"/2017/09/21/%E5%90%8C%E6%AD%A5/inotify/"},{"title":"rsync同步","text":"rsync同步，可配合inotify做到实时同步 把112.124.41.198上的/dbdata/目录下文件同步到本地/tmp目录下。 1$ rsync -avzP -e 'ssh -p 22' root@112.124.41.198:/dbdata/ /tmp 同步112.124.41.198上的mongoDB_ali下的testenroll180228文件夹到本地/tmp目录下 1$ rsync -vazrtopgP --password-file=/etc/rsync.password cpnsp@112.124.41.198::mongoDB_ali/testenroll180228 /tmp/ nohup rsync -avzrtopgL –progress /data/opt /data2/ &gt;/var/log/$(date +%Y%m%d).mail.log &amp; -v, –verbose 详细模式输出。-q, –quiet 精简输出模式。-a, –archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD。-z, –compress 对备份的文件在传输时进行压缩处理。-r, –recursive 对子目录以递归模式处理。-t, –times 保持文件时间信息。-o, –owner 保持文件属主信息。-p, –perms 保持文件权限。-g, –group 保持文件属组信息。-P 等同于 –partial ––progress。––partial 保留那些因故没有完全传输的文件，以是加快随后的再次传输。–progress 显示备份过程。–password-file=FILE 从FILE中得到密码。","link":"/2018/03/12/%E5%90%8C%E6%AD%A5/rsync/"},{"title":"Jmeter压测","text":"首先使用chrome插件BlazeMeter，录制jmeter请求脚本，导入到jmeter中。 对需要引用大量的外部数据，如用户名密码，可以添加 配置原件–&gt;CSV 数据文件设置变量，在请求中进行引用。 对需要引用获取到的请求数据，可以在所需请求后添加 后置处理器–&gt;正则表达式提取器,对变量值进行提取，然后再后续请求中引用。 使用集合点，阻塞线程，直到指定的线程数量到达后，再一起释放，可以瞬间产生很大的压力。（添加–&gt;定时器–&gt;同步定时器）（可能会导致部分线程组一直不结束） 压测 开启5000个线程组时，大量请求报错 java.net.BindException: Address already in use: connect 原因：可能是由TCP / IP端口耗尽引起的。在非常高的负载下，反复连接到其他服务的服务器可能会耗尽临时端口。 刚刚关闭的端口号在重新使用之前，会保持一段时间的等待状态。如果连接速率足够高，则所有端口最终都将处于等待状态，并且操作系统将无法再将连接绑定到端口。 排查：可以使用以下内容确定端口耗尽是否是真正的瓶颈 。 1、在峰值负载下，运行“ netstat -ano -p tcp”将列出所有正在使用的端口。 2、使用“ netsh int ipv4 show dynamicport tcp”监视范围内的可用端口。 确定了如是导致的原因，解决 1、增加动态端口范围，默认情况下，最大值为5000，最多可以将其设置为65534， HKLM\\System\\CurrentControlSet\\Services\\Tcpip\\Parameters\\MaxUserPort 。 2、减少TIME_WAIT 状态 的时间 ，默认为4分钟，可以将其设置为30秒 ， HKLM\\System\\CurrentControlSet\\Services\\Tcpip\\Parameters\\TCPTimedWaitDelay 。 参考：Address already in use: connect” in EngageOne Vault 接下来测试 后台服务中报 org.apache.catalina.connector.ClientAbortException: java.io.IOException: Broken pipe。 主要原因是 客户端先关闭了连接，服务器端没有执行关闭连接的操作。 压测时在服务器执行 netstat -n | awk ‘/^tcp/ {++state[$NF]} END {for(key in state) print key,”\\t”,state[key]}’ 查看了下当时tcpip连接的状态，进一步排查。 这个原因是因为jmeter线程组一直不结束，在jmeter中手动停止了所有线程导致。 在jmeter请求中也会出现这样的错误java net SocketException: Socket closed 参考:[java.io.IOException: Broken pipe](https://blog.csdn.net/zqz_zqz/article/details/52235479 N ) 接着测试 使用nginx进行负载均衡到两个后台服务时，nginx日志发现socket() failed (24: Too many open files) while connecting to upstream 修改linux打开文件句柄数(可能遇到修改后不生效问题) 参考:ulimit: open files: cannot modify limit 123456789$ vim /etc/security/limits.confroot soft nproc 16384root hard nproc 16384root soft nofile 65535root hard nofile 65535root soft memlock 4000000root hard memlock 4000000$ shutdown –r now #重启服务器$ ulimit -a #检查生效否 修改nginx打开文件数 在nginx.conf 添加了worker_rlimit_nofile 20480; 接着测试 后面测试nginx又报1024 worker_connections are not enough。 修改nginx.conf中配置 worker_connections 10240 再次测试 发现有些请求nginx异常 131175 no live upstreams while connecting to upstream 发现nginx负载到的其中一个服务没启动。 插件 jp@gc - PerfMon Metrics Collector：服务器性能监测控件，包括CPU，Memory，Network，Ｉ/Ｏ等等（此功能用到在需监听的服务器上启动startAgent） 根据需要选择CPU，Memory，Network Ｉ/Ｏ等 PerfMon wiki jp@gc - Respose Times Over Time： 响应时间超时，显示每个采样以毫秒为单位的平均响应时间 jp@gc - Transactions per Second： 每秒事务数，服务器每秒处理的事务数 jp@gc - Actiive Threads Over Time：不同时间的活动用户数量展示 jp@gc - Reponse Times Distribution： 显示测试的响应时间分布，X轴显示由时间间隔分组的响应时间，Y轴包含每个区间的样本数 Distribution/Percentile Graphs JMeter分布式并发时，几个问题解决方法，1、每个request的具体response返回。2、禁掉不使用的虚拟机网卡 https://www.cnblogs.com/jane4321/p/11013042.html https://www.zhihu.com/question/45406520 https://www.cnblogs.com/zonlo/p/8422583.html","link":"/2019/12/16/%E5%B7%A5%E4%BD%9C/Jmeter%E5%8E%8B%E6%B5%8B-DESKTOP-S52MH0E/"},{"title":"Jmeter压测","text":"首先使用chrome插件BlazeMeter，录制jmeter请求脚本，导入到jmeter中。 对需要引用大量的外部数据，如用户名密码，可以添加 配置原件–&gt;CSV 数据文件设置变量，在请求中进行引用。 对需要引用获取到的请求数据，可以在所需请求后添加 后置处理器–&gt;正则表达式提取器,对变量值进行提取，然后再后续请求中引用。 使用集合点，阻塞线程，直到指定的线程数量到达后，再一起释放，可以瞬间产生很大的压力。（添加–&gt;定时器–&gt;同步定时器）（可能会导致部分线程组一直不结束） 压测 开启5000个线程组时，大量请求报错 java.net.BindException: Address already in use: connect 原因：可能是由TCP / IP端口耗尽引起的。在非常高的负载下，反复连接到其他服务的服务器可能会耗尽临时端口。 刚刚关闭的端口号在重新使用之前，会保持一段时间的等待状态。如果连接速率足够高，则所有端口最终都将处于等待状态，并且操作系统将无法再将连接绑定到端口。 排查：可以使用以下内容确定端口耗尽是否是真正的瓶颈 。 1、在峰值负载下，运行“ netstat -ano -p tcp”将列出所有正在使用的端口。 2、使用“ netsh int ipv4 show dynamicport tcp”监视范围内的可用端口。 确定了如是导致的原因，解决 1、增加动态端口范围，默认情况下，最大值为5000，最多可以将其设置为65534， HKLM\\System\\CurrentControlSet\\Services\\Tcpip\\Parameters\\MaxUserPort 。 2、减少TIME_WAIT 状态 的时间 ，默认为4分钟，可以将其设置为30秒 ， HKLM\\System\\CurrentControlSet\\Services\\Tcpip\\Parameters\\TCPTimedWaitDelay 。 参考：Address already in use: connect” in EngageOne Vault 接下来测试 后台服务中报 org.apache.catalina.connector.ClientAbortException: java.io.IOException: Broken pipe。 主要原因是 客户端先关闭了连接，服务器端没有执行关闭连接的操作。 压测时在服务器执行 netstat -n | awk ‘/^tcp/ {++state[$NF]} END {for(key in state) print key,”\\t”,state[key]}’ 查看了下当时tcpip连接的状态，进一步排查。 这个原因是因为jmeter线程组一直不结束，在jmeter中手动停止了所有线程导致。 在jmeter请求中也会出现这样的错误java net SocketException: Socket closed 参考:[java.io.IOException: Broken pipe](https://blog.csdn.net/zqz_zqz/article/details/52235479 N ) 接着测试 使用nginx进行负载均衡到两个后台服务时，nginx日志发现socket() failed (24: Too many open files) while connecting to upstream 修改linux打开文件句柄数(可能遇到修改后不生效问题) 参考:ulimit: open files: cannot modify limit 123456789$ vim /etc/security/limits.confroot soft nproc 16384root hard nproc 16384root soft nofile 65535root hard nofile 65535root soft memlock 4000000root hard memlock 4000000$ shutdown –r now #重启服务器$ ulimit -a #检查生效否 修改nginx打开文件数 在nginx.conf 添加了worker_rlimit_nofile 20480; 接着测试 后面测试nginx又报1024 worker_connections are not enough。 修改nginx.conf中配置 worker_connections 10240 再次测试 发现有些请求nginx异常 131175 no live upstreams while connecting to upstream 发现nginx负载到的其中一个服务没启动。 插件 jp@gc - PerfMon Metrics Collector：服务器性能监测控件，包括CPU，Memory，Network，Ｉ/Ｏ等等（此功能用到在需监听的服务器上启动startAgent） 根据需要选择CPU，Memory，Network Ｉ/Ｏ等 PerfMon wiki jp@gc - Respose Times Over Time： 响应时间超时，显示每个采样以毫秒为单位的平均响应时间 jp@gc - Transactions per Second： 每秒事务数，服务器每秒处理的事务数 jp@gc - Actiive Threads Over Time：不同时间的活动用户数量展示 jp@gc - Reponse Times Distribution： 显示测试的响应时间分布，X轴显示由时间间隔分组的响应时间，Y轴包含每个区间的样本数 Distribution/Percentile Graphs JMeter分布式并发时，几个问题解决方法，1、每个request的具体response返回。2、禁掉不使用的虚拟机网卡 https://www.cnblogs.com/jane4321/p/11013042.html 1./bin/jmeter-server -Djava.rmi.server.hostname=192.168.1.80 https://www.zhihu.com/question/45406520","link":"/2019/12/16/%E5%B7%A5%E4%BD%9C/Jmeter%E5%8E%8B%E6%B5%8B/"},{"title":"fastdfs","text":"编译环境 1$ apt-get install build-essential libtool libpcre3-dev libpcre3 zlib1g-dev openssl libssl-dev 一个tracker服务对应一个storage，storage中存在一个store_path。 位置 相关安装包路径 /usr/local/src/fastdfs fastdf配置文件 /etc/fdfs tracker基础信息位置 /ssdb2/data/fastdfs/tracker storage基础信息位置 /ssdb2/data/fastdfs/storage/storage_base storage文件存储路径 /ssdb2/data/fastdfs/storage/storage_data1 2、 2.1 libfastcommon包安装 123$ git clone https://github.com/happyfish100/libfastcommon.git --depth 1$ cd libfastcommon/$ ./make.sh &amp;&amp; ./make.sh install 2.2 FastDFS 安装 1234567891011$ cd ../ #返回上一级目录$ git clone https://github.com/happyfish100/fastdfs.git --depth 1$ cd fastdfs/$ ./make.sh &amp;&amp; ./make.sh install##配置文件准备$ cp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf$ cp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf$ cp /etc/fdfs/client.conf.sample /etc/fdfs/client.conf #客户端文件，测试用$ cp /usr/local/src/fastdfs/fastdfs/conf/http.conf /etc/fdfs/ #供nginx访问使用$ cp /usr/local/src/fastdfs/fastdfs/conf/mime.types /etc/fdfs/ #供nginx访问使用 2.3 下载fastdfs-nginx-module 123$ cd ../ #返回上一级目录$ git clone https://github.com/happyfish100/fastdfs-nginx-module.git --depth 1$ cp /usr/local/src/fastdfs/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs/ 2.4 安装nginx 1234567$ cd /usr/local/src/nginx$ wget http://nginx.org/download/nginx-1.16.1.tar.gz$ tar -zxvf nginx-1.16.1.tar.gz$ cd nginx-1.16.1/## 添加fastdfs-nginx-module模块$ ./configure --prefix=/usr/local/nginx --with-http_ssl_module --add-module=/usr/local/src/fastdfs/fastdfs-nginx-module/src$ make &amp;&amp; make install #编译安装 2.5 Tracker 安装 创建Tracker服务器的文件路径，用于存储Tracker的数据文件和日志文件等： 1$ makdir /ssdb2/data/fastdfs/tracker 编辑tracker配置文件/etc/fdfs/tracker.conf，部分配置参数释义如下： 12345678910111213141516vim /etc/fdfs/tracker.confdisabled=false #启用配置文件(默认false)bind_addr= #解析主机地址，空则解析所有主机port=22122 #tracker服务端口connect_timeout=30 #连接超时时间30Snetwork_timeout=60 #网络超时时间60Sbase_path=/ssdb2/data/fastdfs/tracker #tracker基础数据存储路径及日志存放路径max_connections=256 #最大并发连接数work_threads=4 #工作线程数，最好和cpu核数保持一致store_lookup=0 #选择上传文件模式 0代表group轮询 1指定特定group 2选择空间最大的group#store_group= #上传文件组，如果模式为1，则必须设置成核特定group一致的组名store_server=0 #选择存储服务器上传文件 0代表轮询，1根据通过IP第的顺序 2通过优先级store_path=0 #选择哪块存储盘上传文件 0代表轮询，2代表优先最大存储空间盘(路径)download_server=0 #选择哪台存储服务器下载文件0代表轮询，1代表当前文件上传的源服务器reserved_storage_space = 10% #系统保留存储空间10%######其余都默认就好 启动tracker服务 12$ /etc/init.d/fdfs_trackerd start$ netstat -unltp|grep fdfs # 检查服务运行的22122端口是否正常 2.6 Storage安装 创建Storage服务器的文件目录，注意同Tracker相比要多建一个目录，因为Storage还需要一个文件存储路径，用于存放接收的文件： 12$ mkdir /ssdb2/data/fastdfs/storage/storage_base$ mkdir /ssdb2/data/fastdfs/storage/storage_data1 修改/etc/fdfs/storage.conf配置文件，部分配置参数释义如下 123456789group_name=group1 #存储组名client_bind=true #当连接其他服务器时解析该主机地址port=23000 #storage端口 23000store_path_count=1 #存储路径个数，需要和store_path个数匹配base_path=/ssdb2/data/fastdfs/storage/storage_base #基础存储数据和日志文件store_path0=/ssdb2/data/fastdfs/storage/storage_data #group所占用的目录或硬盘，有几个写几个tracker_server=192.168.1.80:22122 #指定tracker1服务器#tracker_server=10.124.164.138:22122 #指定tracker2服务器#tracker_server=10.124.164.139:22122 #指定tracker3服务器 启动Storage服务： 12$ /etc/init.d/fdfs_storaged start #启动storage服务$ netstat -unltp|grep fdfs # 检查一下storage服务的端口监听情况 成功后，将在/ssdb2/data/fastdfs/storage/storage_data/data目录下生成文件夹，data下有256个1级目录，每级目录下又有256个2级子目录，总共65536个文件夹。 新写的文件会以hash的方式被路由到其中某个子目录下，然后将文件数据直接作为一个本地文件存储到该目录中。 2.7 修改本地客户端配置 创建了客户端基础数据和日志文件目录 1$ mkdir /ssdb2/data/fastdfs/client 修改客户端配置 12345vim /etc/fdfs/client.confbase_path=/ssdb2/data/fastdfs/client #基础数据和日志文件tracker_server=192.168.1.80:22122 #tracker1服务器#tracker_server=10.124.164.138:22122 #tracker2服务器#tracker_server=10.124.164.139:22122 #tracker3服务器 2.8 编辑mod_fastdfs.conf文件 12345678vim /etc/fdfs/mod_fastdfs.conf：base_path=/ssdb2/data/fastdfs/storage/storage_base #修改成和storage 存放路径一致tracker_server=192.168.1.80:22122 #配置成tracker server 地址和端口#tracker_server=10.124.164.138:22122 #配置成tracker server 地址和端口#tracker_server=10.124.164.139:22122 #配置成tracker server 地址和端口url_have_group_name = true #url中是否包组名(默认为false，需要改成true)store_path0=/ssdb2/data/fastdfs/storage/storage_data1 #文件存放路径，与storage 一致group_count = 0 #0代表单组，非零代表多组，一般设置几就为几组 2.9 配置nginx访问 12345678910111213$ vim /usr/local/nginx/conf/conf.d/fastdfs.conf#添加如下配置server { listen 8888; ## 该端口为storage.conf中的http.server_port相同 server_name localhost; location ~/group[0-9]/ { ngx_fastdfs_module; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; }} 2.10 client测试 12$ fdfs_upload_file /etc/fdfs/client.conf /ssdb1/temp.jpggroup1/M00/00/00/wKgBUF3Lnq6ALtZwAAC9nZtf_Qw171.jpg 访问 1http://192.168.1.80:8888/group1/M00/00/00/wKgBUF3Lnq6ALtZwAAC9nZtf_Qw171.jpg 参考：fastdfs/wiki FastDFS部署及使用简介","link":"/2019/11/12/%E5%B7%A5%E4%BD%9C/fastdfs/"},{"title":"fastdfs添加分组","text":"fastdfs添加group。 多个group，就需要多个storage，每个storage对应一个group 每个group可对应多个store_path（store_path0、store_path1、store_path2等）作用是为了扩容，即其中一个store_path0空间存储将要满了，可自动存储到store_path1、store_path2里。 需求：添加group2组，以及group2组对应存储路径storage2 1、复制storage配置文件 cp /etc/fdfs/storage.conf /etc/fdfs/storage2.conf 2、修改 storage2.conf 12345group_name=group2port=24000base_path=/ssdb2/data/fastdfs/storage2/storage_basestore_path0=/ssdb2/data/fastdfs/storage2/storage_data1store_path1=/ssdb2/data/fastdfs/storage2/storage_data2 其它的按group1设置的默认即可。 3、修改mod_fastdfs.conf 123456789101112131415161718192021group_count = 2# group settings for group #1# since v1.14# when support multi-group on this storage server, uncomment following section[group1]group_name=group1storage_server_port=23000store_path_count=2store_path0=/ssdb2/data/fastdfs/storage1/storage_data1store_path1=/ssdb2/data/fastdfs/storage1/storage_data2#store_path1=/home/yuqing/fastdfs1# group settings for group #2# since v1.14# when support multi-group, uncomment following section as neccessary[group2]group_name=group2storage_server_port=24000store_path_count=2store_path0=/ssdb2/data/fastdfs/storage2/storage_data1store_path1=/ssdb2/data/fastdfs/storage2/storage_data2 设置了多个group后，其它参数如base_path、storage_server_port、group_name、store_path0可不用设置， 4、启动group2 storage 1$ fdfs_storaged /etc/fdfs/storage2.conf 5、检测集群 12/usr/bin/fdfs_monitor /etc/fdfs/storage.conf# 会显示会有几台服务器 有3台就会 显示 Storage 1-Storage 2的详细信息 一台服务器可以装多个组(group)，就需要多个storage，每个storage对应一个group。 不能同一台服务器装同组的多个Storage，同组(group)的Storage2和Storage3 FastDFS服务端口必须一致","link":"/2019/11/20/%E5%B7%A5%E4%BD%9C/fastdfs%E5%88%86%E7%BB%84/"},{"title":"Windows查看端口占用进程","text":"查看8080端口对应的进程pid 1&gt; netstat -ano |findstr 8080 即可得到 pid，由下图知，8080端口对应进程pid为11200 查看该PID对应的进程名称。 1&gt; tasklist |findstr 11200 由下图知，进程pid 11200对应进程名称为javaw.exe。 如下图： 然后调出任务管理器 点击：查看–&gt;选择列–&gt;勾选pid 之后即可在任务管理器的进程中对该进程执行操作（结束进程）。","link":"/2018/09/28/%E5%B7%A5%E4%BD%9C/Windows%E6%9F%A5%E7%9C%8B%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E8%BF%9B%E7%A8%8B/"},{"title":"java服务CPU占用高","text":"由上篇内存占用过高，未定位到准确的问题，今天某时段服务的CPU突然占用高，或许是引起内存占用的元凶。 ①通过top找到占用cpu最高的 pid[进程id] 通过Shift+P按CUP排序，定位到pid是 13748 ②通过 top -Hp pid 查看进程中占用cpu过高的 tid[线程id] 占用cpu过高的线程有五个，以其中一个线程做示例 ③通过 printf ‘%x/n’ tid 把线程id转化为十六进制 12$ printf '%x/n' 1379635e4 ④通过 jstack pid | grep tid -A 50 定位线程堆栈信息 ⑤ 根据堆栈信息就可以定位代码 发现occupationIds进行了无限循环。 ⑥同样把剩余的4个线程分析下也是此原因 之前通过dump线上环境的JVM内存进行分析，有此方法的影子，但是并不能完全确定。 在网上看到一个较快定位问题请求的方法(JVM 堆内存使用率持续上升的一种排查思路) ，直接在nginx日志中搜索响应码为504的请求，然后看日志时间是否与内存或CPU上升时间点吻合，分析504的请求，确认是否存在死循环。504响应码为网关超时，当一个请求到Tomcat后，tomcat如果陷入死循环，那么这个请求自然无法得到响应，nginx等待响应超时，响应给用户504。 参考：https://zhuanlan.zhihu.com/p/69342660","link":"/2020/04/20/%E5%B7%A5%E4%BD%9C/java%E6%9C%8D%E5%8A%A1CPU%E5%8D%A0%E7%94%A8%E9%AB%98/"},{"title":"jvisualvm远程监控JVM","text":"jvm进程启动项配置 1$ nohup /usr/local/java/jdk1.8.0_231/bin/java -Djava.rmi.server.hostname=192.168.1.80 -Dcom.sun.management.jmxremote.port=1100 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=true -Dcom.sun.management.jmxremote.password.file=/ssdb1/bootserver/jmxremote.passwd -Dcom.sun.management.jmxremote.access.file=/ssdb1/bootserver/jmxremote.access -jar /ssdb1/bootserver/boot8100/cpnspcms/cpnsp-api-1.0.0-SNAPSHOT.jar --server.port=8100 --name=cpnspcms_box &gt; 8100.log 2&gt;&amp;1 &amp; 123456-Djava.rmi.server.hostname=192.168.1.80 # 配置远程服务IP-Dcom.sun.management.jmxremote.port=1100 # 配置远程 connection 的端口号-Dcom.sun.management.jmxremote.ssl=false # 是否启用 ssl-Dcom.sun.management.jmxremote.authenticate=true # 是否启用鉴权（需要用户名，密码鉴权）-Dcom.sun.management.jmxremote.password.file=/ssdb1/bootserver/jmxremote.passwd -Dcom.sun.management.jmxremote.access.file=/ssdb1/bootserver/jmxremote.access 如果authenticate=false的时候不需要配置jmxremote.passwd 和jmxremote.access 否则需要在jmxremote.access中指定用户名和读写权限 12monitorRole readonlycontrolRole readwrite jmxremote.passwd中指定用户名和密码，格式如 12monitorRole tomcatcontrolRole tomcat 设置文件权限 12$ chmod 400 jmxremote.access$ chmod 400 jmxremote.passwd 然后在jvisualvm添加JMX连接。","link":"/2020/04/15/%E5%B7%A5%E4%BD%9C/jvisualvm%E8%BF%9C%E7%A8%8B%E7%9B%91%E6%8E%A7JVM/"},{"title":"java服务内存占用定位","text":"top部分交互命令 1234c: 显示完整的命令d： 更改刷新频率P： 根据CPU资源使用大小进行排序M： 根据内存资源使用大小进行排序 通过jinfo查看JVM启动信息 123456789101112131415161718# 查看内存占用，rsz为实际内存，单位kb# ps -eo 'pid,rsz,vsz' |grep pid$ ps -eo 'pid,rsz,vsz' |grep 2784327843 1684668 12343528# 查看系统信息# jinfo -sysprops pid$ jinfo -sysprops 27843# 查看JVM信息# jinfo -flags pid$ jinfo -flags 27843Attaching to process ID 27843, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.231-b11Non-default VM flags: -XX:CICompilerCount=3 -XX:InitialHeapSize=528482304 -XX:+ManagementServer -XX:MaxHeapSize=8434745344 -XX:MaxNewSize=2811232256 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=176160768 -XX:OldSize=352321536 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGCCommand line: ... 通过jmap查看堆内存 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# jmap -heap pid$ jmap -heap 497Attaching to process ID 497, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.221-b11using thread-local object allocation.Parallel GC with 4 thread(s)Heap Configuration: MinHeapFreeRatio = 0 MaxHeapFreeRatio = 100 MaxHeapSize = 8434745344 (8044.0MB) NewSize = 176160768 (168.0MB) MaxNewSize = 2811232256 (2681.0MB) OldSize = 352321536 (336.0MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 21807104 (20.796875MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB)Heap Usage:PS Young GenerationEden Space: capacity = 1774190592 (1692.0MB) used = 156138392 (148.9051742553711MB) free = 1618052200 (1543.094825744629MB) 8.800542213674415% usedFrom Space: capacity = 1048576 (1.0MB) used = 0 (0.0MB) free = 1048576 (1.0MB) 0.0% usedTo Space: capacity = 1048576 (1.0MB) used = 0 (0.0MB) free = 1048576 (1.0MB) 0.0% usedPS Old Generation capacity = 606601216 (578.5MB) used = 90496000 (86.3037109375MB) free = 516105216 (492.1962890625MB) 14.91853257346586% used47600 interned Strings occupying 4865784 bytes. dump内存，使用jvisualvm分析 12# jmap -dump:format=b,file=file.dump pid$ jmap -dump:format=b,file=497.dump 497 将dump文件导入jvisualvm,在堆中包含的类中，逐步展开至实例。 堆内存分析 https://heaphero.io/ https://docs.oracle.com/javase/8/docs/technotes/guides/troubleshoot/index.html 参考：https://zhuanlan.zhihu.com/p/73727459 相关：https://www.v2ex.com/t/669244","link":"/2020/04/19/%E5%B7%A5%E4%BD%9C/java%E6%9C%8D%E5%8A%A1%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E5%AE%9A%E4%BD%8D/"},{"title":"mongodb-修改备案职业级别中科目Id(0->5)","text":"修改备案职业级别中科目职业道德的科目Id(0 -&gt;5 )，及对应的默认报名费用{0:0 -&gt; 5:0} 数据结构 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205{ \"_id\" : NumberLong(8), \"recordPlanId\" : NumberLong(3), \"userGroup\" : \"45\", \"occupationId\" : NumberLong(2567), \"occupationTitle\" : \"车工\", \"testLevels\" : [1, 2, 3, 4, 5], \"testSubjects\" : { \"5\" : [{ \"subjectId\" : 0, \"title\" : \"职业道德\", \"testType\" : 0, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 1, \"title\" : \"理论\", \"testType\" : 100, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 2, \"title\" : \"技能\", \"testType\" : 200, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 4, \"title\" : \"工作业绩\", \"testType\" : 0, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }], \"4\" : [{ \"subjectId\" : 0, \"title\" : \"职业道德\", \"testType\" : 0, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 1, \"title\" : \"理论\", \"testType\" : 100, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 2, \"title\" : \"技能\", \"testType\" : 200, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 4, \"title\" : \"工作业绩\", \"testType\" : 0, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }], \"3\" : [{ \"subjectId\" : 0, \"title\" : \"职业道德\", \"testType\" : 0, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 1, \"title\" : \"理论\", \"testType\" : 100, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 2, \"title\" : \"技能\", \"testType\" : 200, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 4, \"title\" : \"工作业绩\", \"testType\" : 0, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }], \"2\" : [{ \"subjectId\" : 0, \"title\" : \"职业道德\", \"testType\" : 0, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 1, \"title\" : \"理论\", \"testType\" : 100, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 2, \"title\" : \"技能\", \"testType\" : 200, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 3, \"title\" : \"综合\", \"testType\" : 300, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 4, \"title\" : \"工作业绩\", \"testType\" : 0, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }], \"1\" : [{ \"subjectId\" : 0, \"title\" : \"职业道德\", \"testType\" : 0, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 1, \"title\" : \"理论\", \"testType\" : 100, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 2, \"title\" : \"技能\", \"testType\" : 200, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 3, \"title\" : \"综合\", \"testType\" : 300, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }, { \"subjectId\" : 4, \"title\" : \"工作业绩\", \"testType\" : 0, \"isComputerTest\" : false, \"isReadCard\" : false, \"isMobileScore\" : false }] }, \"enrollFees\" : { \"1\" : { \"0\" : 0, \"1\" : 0, \"2\" : 0, \"3\" : 0, \"4\" : 0 }, \"2\" : { \"0\" : 0, \"1\" : 0, \"2\" : 0, \"3\" : 0, \"4\" : 0 }, \"3\" : { \"0\" : 0, \"1\" : 0, \"2\" : 0, \"4\" : 0 }, \"4\" : { \"0\" : 0, \"1\" : 0, \"2\" : 0, \"4\" : 0 }, \"5\" : { \"0\" : 0, \"1\" : 0, \"2\" : 0, \"4\" : 0 } }, \"uid\" : \"d75f8deffe5b4e81babbf6b76ae02144\", \"unitId\" : NumberLong(2)} 12345678910111213141516171819202122# 修改备案职业级别中科目职业道德的科目Id(0-&gt;5)db.irTestRange.find({\"testSubjects.1\":{\"$elemMatch\":{\"subjectId\":0}}})db.irTestRange.find({\"testSubjects.2\":{\"$elemMatch\":{\"subjectId\":0}}})db.irTestRange.find({\"testSubjects.3\":{\"$elemMatch\":{\"subjectId\":0}}})db.irTestRange.find({\"testSubjects.4\":{\"$elemMatch\":{\"subjectId\":0}}})db.irTestRange.find({\"testSubjects.5\":{\"$elemMatch\":{\"subjectId\":0}}})db.irTestRange.update({\"testSubjects.1\":{\"$elemMatch\":{\"subjectId\":0}}},{\"$set\":{\"testSubjects.1.$.subjectId\":NumberInt(5),\"enrollFees.1.5\":NumberInt(0)},\"$unset\":{\"enrollFees.1.0\":1}},false,true)db.irTestRange.update({\"testSubjects.2\":{\"$elemMatch\":{\"subjectId\":0}}},{\"$set\":{\"testSubjects.2.$.subjectId\":NumberInt(5),\"enrollFees.2.5\":NumberInt(0)},\"$unset\":{\"enrollFees.2.0\":1}},false,true)db.irTestRange.update({\"testSubjects.3\":{\"$elemMatch\":{\"subjectId\":0}}},{\"$set\":{\"testSubjects.3.$.subjectId\":NumberInt(5),\"enrollFees.3.5\":NumberInt(0)},\"$unset\":{\"enrollFees.3.0\":1}},false,true)db.irTestRange.update({\"testSubjects.4\":{\"$elemMatch\":{\"subjectId\":0}}},{\"$set\":{\"testSubjects.4.$.subjectId\":NumberInt(5),\"enrollFees.4.5\":NumberInt(0)},\"$unset\":{\"enrollFees.4.0\":1}},false,true)db.irTestRange.update({\"testSubjects.5\":{\"$elemMatch\":{\"subjectId\":0}}},{\"$set\":{\"testSubjects.5.$.subjectId\":NumberInt(5),\"enrollFees.5.5\":NumberInt(0)},\"$unset\":{\"enrollFees.5.0\":1}},false,true)","link":"/2019/12/12/%E5%B7%A5%E4%BD%9C/mongodb-%E4%BF%AE%E6%94%B9%E5%A4%87%E6%A1%88%E8%81%8C%E4%B8%9A%E7%BA%A7%E5%88%AB%E4%B8%AD%E7%A7%91%E7%9B%AEId(0-5)/"},{"title":"mongodb数据导入到mysql","text":"1、首先把mongodb数据导出，类型为csv 1$ mongoexport --host 192.168.1.101 --authenticationDatabase admin -u root -d hbcms -c ostaCert -q '{certType:\"osta\"}' -f cardId,name,occupation,testLevel,certNum --type=csv -o /dbdata/db_backup/mongodb_ali/ostaCert.csv 参数说明：-d 指明导出的数据库。 -c 指明要导出的表。 -f 指明导出的字段，以逗号分隔。如：-f name,email,age -q 可以根据查询条件导出，如：-q &apos;{ &quot;uid&quot; : &quot;100&quot; }&apos; 导出uid为100的数据 -o 指明要到处的文件名及目录。 --csv 表示导出的文件格式为csv的，因为大部分的关系型数据库都是支持csv。其它参数 说明查看 mongoexport –help 导出后可能打开是乱码，用记事本或者Notepad另存为UTF8即可。 2、将CSV导入到MySQL 创建MySQL数据库和接收数据的表，注意表的顺序和字段要和MongoDB导出的字段及CSV中的文件表头一样。 在此处要注意，将编码都设置为utf8。 执行： 12345mysql&gt; load data infile '/opt/ostaCert.csv' -&gt; into table `tweets` character set utf8 -&gt; fields terminated by ',' optionally enclosed by '&quot;' -&gt; lines terminated by '\\n' -&gt; ignore 1 lines; 可能会报出这个错误： 1ERROR 1290 (HY000): The MySQL server is running with the --secure-file-priv option so it cannot execute this statement 因为MySQL导入导出不是任意文件下的文件都是可以的。 所以我们把这个csv文件放到指定文件夹下即可。 使用命令行查看可进行操作的文件夹： 所以把文件放到该位置即可。 再次执行上面的导入语句，即可导入成功。 参考：https://blog.csdn.net/gpf951101/article/details/79907393","link":"/2018/09/10/%E5%B7%A5%E4%BD%9C/mongodb%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5%E5%88%B0mysql/"},{"title":"nethogs与nload单位比较","text":"通过执行如下命令 12$ nload eth0$ nethogs -U h eth0 nload 上图中单位是 KB/sec nethogs通过 -U指定了单位是 bit 1Byte = 8bits 383KB/sec = 383*8 = 3064Kbit/s = 3.06Mbit/s 与nload中的2.69相差不大 因为存在刷新频率和间隔，所以存在误差。 暂时先这样理解","link":"/2018/09/21/%E5%B7%A5%E4%BD%9C/nethogs%E4%B8%8Enload%E5%8D%95%E4%BD%8D%E6%AF%94%E8%BE%83/"},{"title":"tomcat日志分析","text":"tomcat 请求日志格式为 1server.tomcat.accesslog.pattern=%t %a \"%r\" %s %S (%D ms) 如下： 1[19/Sep/2018:11:18:00 +0800] 127.0.0.1 \"GET /cpnsp/ws/ths/getSignToken HTTP/1.0\" 200 - (4 ms) 每秒请求量统计统计每秒的请求数,top100的时间点(精确到秒) 1$ awk '{print $1}' access_log.2018-09-19.log |cut -c 14-21|sort|uniq -c|sort -nr|head -n 100 每分钟请求量统计统计每分钟的请求数,top100的时间点(精确到分钟) 1$ awk '{print $1}' access_log.2018-09-19.log |cut -c 14-18|sort|uniq -c|sort -nr|head -n 100 每小时请求量统计每小时的请求数,top100的时间点(精确到小时) 1$ awk '{print $1}' access_log.2018-09-19.log |cut -c 14-15|sort|uniq -c|sort -nr|head -n 100 查看java的并发数：netstat -np|grep java|wc -l 两文件夹同步： rsync -ru –progress –delete /opt/rsync_test/f1/ /opt/rsync_test/f2/","link":"/2018/09/19/%E5%B7%A5%E4%BD%9C/tomcat%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"},{"title":"两路由局域网服务访问","text":"两路由组建局域网，实现服务访问 需求：在不修改和影响原有网络及盒子IP的情况下，通过pc访问盒子上的服务。 约定 1、原有网络局域网现状 主路由：网关：192.168.1.2 子网掩码：255.255.255.0 IP:192.168.1.xxx PC : IP：192.168.1.101 子网掩码：255.255.255.0 网关：192.168.1.2 2、副路由 LAN口： IP:10.10.10.1 子网掩码：255.0.0.0 WAN口： IP:192.168.1.20 子网掩码：255.255.255.0 网关：192.168.1.2 3、盒子 IP:10.10.10.100 子网掩码：255.0.0.0 网关：10.10.10.1 副路由 （TP-LINK）设置 1、路由通电后，通过浏览器访问路由地址（192.168.0.1）。 2、LAN口设置：IP地址：10.10.10.1（可任意），子网掩码：255.0.0.0（根据IP定）。 3、保存，重启路由。 4、通过浏览器访问路由地址10.10.10.1 5、WAN口设置 模式：静态IP IP地址：192.168.1.20（在原局域网内不冲突即可，此IP用于盒子服务的访问） 子网掩码：255.255.255.0 网关：192.168.1.2 DNS服务器：192.168.1.2 6、虚拟服务器 端口映射 把80端口映射到盒子ip:10.10.10.100 7、把网线从原路由LAN口连接到副路由WAN口。 盒子服务安装及设置 1、安装好Tomcat及nginx服务。(注意：静态页面中IP要为动态获取。) 2、修改nginx配置：监听80端口，转发到tomcat。即可在PC上通过192.168.1.20访问盒子上的tomcat服务。 下面实现可以域名访问前提：拥有主路由的管理权（要修改DNS） 因要考虑在无网络的情况及不修改原有网络机器，所以在盒子上部署DNS服务器。 1、在盒子上部署DNS服务器。（参考上篇：DNS主备服务） 2、配置域名指向,域名指向的IP地址应为副路由WAN口地址（192.168.1.20） 3、在副路由中配置DNS 在虚拟服务器 端口映射添加记录，把53端口指向到盒子IP:10.10.10.100,协议为全部。 4、在主路由中配置DNS 在DHCP服务器中首选DNS输入192.168.1.20，备用DNS输入114.114.114.114即可在PC上通过域名访问盒子上服务。 其它如若在准备阶段就可给盒子分配一该网络下固定的IP，就可省去路由这一步。","link":"/2020/01/02/%E5%B7%A5%E4%BD%9C/%E4%B8%A4%E8%B7%AF%E7%94%B1%E5%B1%80%E5%9F%9F%E7%BD%91%E6%9C%8D%E5%8A%A1%E8%AE%BF%E9%97%AE/"},{"title":"关于移动端的流式分页","text":"关于移动端app分页的记录 一般项目中web管理端分页通常使用 页码pageNo和分页大小pageSize进行分页 。 如果app分页采用web端分页的话，通常会出现以下问题。 1、数据重复。 2、数据丢失。 3、效率底。 app应用面向人群为c端用户，数据量一大，limit性能就急剧下降。 所以web端分页方式不太适合。 之前项目移动端分页采用 refreId (即最后一条数据的Id)作为下一页查询的条件，这样满足对排序没有确切要求或者按Id排序的情况。 如果要按发布时间进行排序，或许可以用 referTime (最后一条数据的发布时间)作为条件，这样也可满足对按发布时间进行排序的需求。但是前提条件是 referTime 的精确值（一般是用精确到毫秒的时间戳），考虑到发布时间可能存在相同的值，这样在移动端就可能会出现永久丢失数据的情况。 另一种方案，在发布的时候维护一个排序字段 sortNum 使其值为时间+Id，如下这种： lite1234public Long getPublishSortNum(Long contentId) { SimpleDateFormat sdf = new SimpleDateFormat(\"yyMMddHHmm\"); return Long.valueOf(sdf.format(Utils.getDateFromStr(Utils.getNowTimeShortString(), \"yy-MM-dd HH:mm\")) + StringUtils.leftPad(contentId.toString(), 8, \"0\")); } 这样既可避免掉发布时间相同的情况下的排序。 寻到其他可行方案。 引申：https://www.jianshu.com/p/13941129c826 ​ https://www.v2ex.com/t/328806","link":"/2018/07/07/%E5%B7%A5%E4%BD%9C/%E5%85%B3%E4%BA%8E%E7%A7%BB%E5%8A%A8%E7%AB%AF%E7%9A%84%E6%B5%81%E5%BC%8F%E5%88%86%E9%A1%B5/"},{"title":"微信支付XXE漏洞","text":"近几天从日志文件中发现，每天凌晨3点多种就会有几个微信支付的回调，很是奇怪。 具体报错如下： 前几天听说微信支付存在什么漏洞，因有同事负责修复，没太在意，由报错信息查找确实和XXE攻击有关系， 幸好已经被修复了， 接下来就应该做好防护，禁用掉该恶意请求。 从nginx日志中查到该恶意IP： 然后在nginx中禁用掉该IP: 12345 location / { deny 101.91.62.170; #禁用恶意IP ....} $ service nginx reload 漏洞的修复可参考：https://pay.weixin.qq.com/wiki/doc/api/jsapi.php?chapter=23_5 https://my.oschina.net/u/574353/blog/1841103 https://blog.csdn.net/u013224189/article/details/49759845 https://my.oschina.net/u/1788620/blog/2051289","link":"/2018/11/28/%E5%B7%A5%E4%BD%9C/%E5%BE%AE%E4%BF%A1%E6%94%AF%E4%BB%98XXE%E6%BC%8F%E6%B4%9E/"},{"title":"用Clonezilla再生龙备份系统及还原系统","text":"多台机器系统的克隆 准备：2个U盘 1、 下载Clonezilla系统 download 2、使用UltraISO制作启动盘 可参考：ultraiso 现在一般用 rufus 制作系统。 3、备份：在要备份的系统使用U盘启动 可参考：http://forum.ubuntu.org.cn/viewtopic.php?p=2643583 4、还原：在要还原的系统使用U盘启动 可参考：http://tiancong.blog.51cto.com/783138/776309 因图片还不会用，待完善。","link":"/2017/08/21/%E5%B7%A5%E4%BD%9C/%E7%94%A8Clonezilla%E5%86%8D%E7%94%9F%E9%BE%99%E5%A4%87%E4%BB%BD%E7%B3%BB%E7%BB%9F%E5%8F%8A%E8%BF%98%E5%8E%9F%E7%B3%BB%E7%BB%9F/"},{"title":"记录","text":"质量督导、物料平台中连接MySQL数据库是封装的jdbcTemplate。 保存证书的中继服务使用的是springboot-jpa，因为业务较简单，没有复杂的 SQL ，所以直接使用的jpa，没有涉及mybatis Spring是通过任务执行器(TaskExecutor)来实现多线程和并发编程，使用ThreadPoolTaskExecutor来创建一个基于线城池的TaskExecutor。在使用线程池的大多数情况下都是异步非阻塞的。我们配置注解@EnableAsync可以开启异步任务。然后在实际执行的方法上配置注解@Async上声明是异步任务。 win10中Java执行属性复制文件路径的坑（从右到左复制路径时，会带有特殊字符，只有在cmd下才能看出来）","link":"/2019/10/24/%E5%B7%A5%E4%BD%9C/%E8%AE%B0%E5%BD%95/"},{"title":"访问七牛资源跨域问题","text":"系统中ts文件是存在七牛上的，通过在系统后台（http://resbank.bjuri.com）通过浏览器请求ts文件时，出现了跨域的问题。 1、首先在nginx下配置 12345678910111213location /cpnsp/{ proxy_connect_timeout 3; proxy_send_timeout 600; proxy_read_timeout 600; proxy_pass http://resstrem1; proxy_set_header REMOTE_ADDR $remote_addr; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # add_header X-Frame-Options sameorigin; # add_header X-Frame-Options ALLOW-FROMhttp://qiniu.resbank.bjuri.com; # add_header Access-Control-Allow-Origin *; } 不起作用，然后复原配置。 2、然后把七牛绑定的域名改成了系统的子域名。（即把七牛绑定的域名改为了http://qiniu.resbank.bjuri.com）。 不起作用。 3、然后让前端看，前端把请求七牛资源时携带的cookie去掉了，便解决了。 https://blog.csdn.net/zhangxiaohui4445/article/details/100162317","link":"/2018/12/19/%E5%B7%A5%E4%BD%9C/%E8%AE%BF%E9%97%AE%E4%B8%83%E7%89%9B%E8%B5%84%E6%BA%90%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98/"},{"title":"部署服务步骤","text":"通过jenkins自动部署 1、在112.124.xx.xxx上新建svn仓库（配置文件用） 12345$ cd /usr/local/svn/repos$ svnadmin create testenroll$ cd testenroll/conf/$ rm authz$ rm passwd 2、使用统一密码权限管理vim svnserve.conf 1234anon-access = noneauth-access = writepassword-db = /usr/local/svn/repos/codeAuth/passwdauthz-db = /usr/local/svn/repos/codeAuth/authz 3、重启svnserve 123$ ps -ef |grep svnserve$ pkill svnserve$ svnserve -d -r /usr/local/svn 4、之后本地检出 建立相应目录结构（只需配置文件） 最后jenkins 创建项目","link":"/2018/09/15/%E5%B7%A5%E4%BD%9C/%E9%83%A8%E7%BD%B2%E6%9C%8D%E5%8A%A1%E6%AD%A5%E9%AA%A4/"},{"title":"阿里云SLB证书","text":"通过https://freessl.org 申请的 类型为RSA 的 TrustAsia 证书下载后包含两个文件，full_chain.pem 和private.key。 在阿里云SLB上传服务器证书 1、私钥 上传证书的私钥类型必须为RSA私钥。即必须以-----BEGIN RSA PRIVATE KEY-----, -----END RSA PRIVATE KEY-----开头和结尾。 而下载的私钥private.key 是以-----BEGIN PRIVATE KEY-----,``-----BEGIN PRIVATE KEY-----的开头和结尾。所以需要先进行转换： 1$ openssl rsa -in private.key -out new_server_key.pem 2、公钥证书 为了确保兼容到所有浏览器，我们必须在阿里云上部署中间证书，如果不部署中间证书，虽然安装过程可以完全也不会报错，但可能导致Android系统，Chrome 和 Firefox等浏览器无法识别。如微信小程序可能会出现request:fail ssl hand shake error 错误。 可以把full_chain.pem 通过 中间证书生成工具，生成中间证书，再进行上传。(把full_chain.pem及生成的chain.crt粘贴进去) 会包含三段以-----BEGIN CERTIFICATE-----,-----END CERTIFICATE-----开头结尾的字符。 保存后，即完成了阿里云SLB的证书上传。 阿里云SLB HTTPS 扩展域名（一个监听端口，多个域名，多个证书，进行转发）配置参考：https://help.aliyun.com/document_detail/87023.html 其它： 使用阿里云控制台申请的Symantec 免费证书，配置SLB时遇到的一个问题： SLB配置监听端口是443，转发策略中配置的转发后台服务端口为443，后台nginx服务监听443与80端口，与之前并无不同，但是nginx 错误日志中一直是： 12018/12/14 11:03:19 [error] 11429#0: *655 no \"ssl_certificate\" is defined in server listening on SSL port while SSL handshaking, client: 100.116.145.180, server: 0.0.0.0:443 暂未发现其原因。 临时解决办法，在SLB的转发策略中配置的转发后台服务端口为80。 18.12.14 参考：https://www.cnblogs.com/sslwork/p/5984167.html","link":"/2018/09/25/%E5%B7%A5%E4%BD%9C/%E9%98%BF%E9%87%8C%E4%BA%91SLB%E8%AF%81%E4%B9%A6/"},{"title":"JRebel激服务器","text":"Jrebel 可快速实现热部署，节省了大量重启时间，提高了个人开发效率。 可参考：自己搭建内网可用的Jrebel License Server激活Jrebel 项目地址：https://gitee.com/gsls200808/JrebelLicenseServerforJava 可用的激活服务：https://blog.xihefeng.com/archives/205.html Guid生成：GUID","link":"/2018/10/19/%E5%B7%A5%E5%85%B7/JRebel%E6%BF%80%E6%B4%BB%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"title":"USB启动盘制作Rufus","text":"Rufus Rufus 是一个开源免费的快速制作 U 盘系统启动盘和格式化 USB 的实用小工具，它可以快速把 ISO 格式的系统镜像文件快速制作成可引导的 USB 启动安装盘，支持 Windows 或 Linux 启动。Rufus 小巧玲珑，软件体积仅几百多 KB，然而麻雀虽小，它却五脏俱全，而且速度极快。 地址：http://rufus.akeo.ie/?locale=zh_CN","link":"/2018/08/30/%E5%B7%A5%E5%85%B7/USB%E5%90%AF%E5%8A%A8%E7%9B%98%E5%88%B6%E4%BD%9CRufus/"},{"title":"百度网盘下载proxyee-down","text":"Proxyee-down 这款开源工具可帮助我们构建网页代理嗅探百度下载地址，嗅探后的地址直接在网页建立多个连接加速下载。 实测该工具在百兆带宽下下载速度可以达到6~9MB每秒。 开源项目地址：https://github.com/monkeyWie/proxyee-down 1、下载proxyee-down压缩包后， 运行proxyee-down.exe 2、安装SwitchyOmega插件（Firefox或chrome） 3、然后在chrome中进入百度云，选择要下载的文件，就正常点击下载就好了。 此时会调用Proxyee-down。 解释：可以把proxyee-down理解为一个下载器，正常下载会调用chrome的内置下载器，而SwitchyOmega会引导你的chrome打开proxyee-down进行下载，简单的运行原理就是如此。 其它： 另一工具：BaiduPCS-Go 参考：proxyee-down [SwitchyOmega插件安装与设置](https://github.com/proxyee-down-org/proxyee-down/blob/v2.5/.guide/common/switchy/read.md) [doub.io 需fq](https://doub.io/dbrj-9/)","link":"/2018/08/30/%E5%B7%A5%E5%85%B7/%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98%E4%B8%8B%E8%BD%BDproxyee-down/"},{"title":"阿里云服务器漏洞修复","text":"系统版本：Ubuntu 16.04.4 LTS 登录阿里云控制台发现有如下漏洞： 举例修复如下漏洞 修复： 12$ apt-get update$ apt-get install krb5-locales 验证： 在控制台点击验证，等会会看到修复成功。 附此批次其它漏洞修复命令： 12345678910111213141516171819202122232425262728293031323334353637383940414243$ apt-get update$ apt-get install krb5-locales$ apt-get install patch$ apt-get install libprocps4$ apt-get install libelf1$ apt-get install file$ apt-get install libssl1.0.0$ apt-get install libnss3$ apt-get install libgcrypt20$ apt-get install ntp$ apt-get install libx11-6$ apt-get install libpython2.7 -y$ apt-get install libpython3.5 -y$ apt-get install libtiff5$ apt-get install curl -y$ apt-get install openssh-client -y$ apt-get install busybox-static$ apt-get install libjpeg-turbo8$ apt-get install libcups2$ apt-get install ntfs-3g$ apt-get install libarchive13$ apt-get install libbind9-140 -y$ apt-get install libldap-2.4-2$ apt-get install libperl5.22 -y$ apt-get install libxml2$ apt-get install libglib2.0-0$ apt-get install libavahi-client3$ apt-get install libpam-systemd$ apt-get install python3-requests$ apt-get install libsqlite3-0$ apt-get install sudo$ apt-get install dbus -y$ apt-get install vim -y$ apt-get install wget$ apt-get install gnupg$ apt-get install libpng12-0$ apt-get install libarchive-zip-perl$ apt-get install libpolkit-gobject-1-0$ apt-get install apt -y$ apt-get install linux-image-generic$ apt-get install linux-image-4.4.0-117-generic","link":"/2019/08/15/%E6%9C%8D%E5%8A%A1%E5%99%A8/%E9%98%BF%E9%87%8C%E4%BA%91%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D/"},{"title":"http 304问题","text":"http 请求状态码304 说明内容未改变，说明无需再次传输请求的内容，也就是说可以使用缓存的内容 。 通常是在一些安全的方法（safe），例如GET 或HEAD 请求 或在请求中附带了头部信息： If-None-Match 或If-Modified-Since。 如果是 200 OK ，响应会带有头部 Cache-Control, Content-Location, Date, ETag, Expires，和 Vary. 如果不想客户端对其进行缓存 可以在 respone中设置一个属性 cache-control:no-store 或者在nginx配置客户端缓存清除 1234location / { ...... add_header Cache-Control no-cache; } []","link":"/2018/06/21/%E6%9C%AA%E5%88%86%E7%B1%BB/http%E8%AF%B7%E6%B1%82304%E9%97%AE%E9%A2%98/"},{"title":"tesseract_OCR 图片文字识别","text":"OCR图片文字识别","link":"/2018/12/03/%E6%9C%AA%E5%88%86%E7%B1%BB/tesseract_OCR%20%E5%9B%BE%E7%89%87%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB/"},{"title":"静态资源客户端缓存问题","text":"1、对前台静态资源更新后，客户端浏览器访问如果之前访问过，可能会访问的是缓存文件。2、生成环境部署时，由于前端静态资源文件较大，容易占用服务器的带宽，访问量过大时，导致服务器带宽跑满现象。问题一可以通过强制刷新或者清除浏览器缓存来避免。问题二可以升级带宽解决。上面两者都不是最优解决方案。我们可以使用CDN解决的问题。 以七牛为例，也可使用阿里云。我们把前台静态资源放在七牛的对象存储空间bucket中，默认进行了cdn加速。绑定自定义域名假设为 bucket.yewuxitong.com，将域名 cname 添加到域名解析。静态文件中的后台服务地址为另外解析一个A记录指向后台服务地址 。如api.yewuxitong.com这样即解决了问题二，避免了前端静态资源占用服务器带宽。 这样七牛默认的缓存策略会导致 七牛CDN缓存问题，现象同问题一类似。 可以通过CDN 缓存规则设置来解决。参考七牛官方文档 CDN 缓存规则设置 也可参考此文 关于七牛CDN缓存问题的处理方式 问题：会需要解析两个域名一个七牛前端文件的cname记录域名，一个后端服务的A记录域名。 理想状态：静态资源放在服务器，更新只对服务器文件更新，如参考文中所说的文件名可以做相应调整。源站（服务器）更新的内容同步更新到七牛的空间，不知七牛的回源 HOST或者镜像存储可否实现。","link":"/2018/05/22/%E6%9C%AA%E5%88%86%E7%B1%BB/%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98/"},{"title":"关于问答爬虫需求的分析","text":"知乎爬虫 爬取话题 1、知乎根话题（https://www.zhihu.com/topic/19776749/hot） 1https://www.zhihu.com/api/v4/topics/19776749/feeds/top_activity?include=data[?(target.type=topic_sticky_module)].target.data[?(target.type=answer)].target.content,relationship.is_authorized,is_author,voting,is_thanked,is_nothelp;data[?(target.type=topic_sticky_module)].target.data[?(target.type=answer)].target.is_normal,comment_count,voteup_count,content,relevant_info,excerpt.author.badge[?(type=best_answerer)].topics;data[?(target.type=topic_sticky_module)].target.data[?(target.type=article)].target.content,voteup_count,comment_count,voting,author.badge[?(type=best_answerer)].topics;data[?(target.type=topic_sticky_module)].target.data[?(target.type=people)].target.answer_count,articles_count,gender,follower_count,is_followed,is_following,badge[?(type=best_answerer)].topics;data[?(target.type=answer)].target.content,relationship.is_authorized,is_author,voting,is_thanked,is_nothelp;data[?(target.type=answer)].target.author.badge[?(type=best_answerer)].topics;data[?(target.type=article)].target.content,author.badge[?(type=best_answerer)].topics;data[?(target.type=question)].target.comment_count&amp;offset=5&amp;limit=10 1https://www.zhihu.com/api/v4/topics/19776749/feeds/top_activity?include=data[?(target.type=topic_sticky_module)].target.data[?(target.type=answer)].target.content,relationship.is_authorized,is_author,voting,is_thanked,is_nothelp;data[?(target.type=topic_sticky_module)].target.data[?(target.type=answer)].target.is_normal,comment_count,voteup_count,content,relevant_info,excerpt.author.badge[?(type=best_answerer)].topics;data[?(target.type=topic_sticky_module)].target.data[?(target.type=article)].target.content,voteup_count,comment_count,voting,author.badge[?(type=best_answerer)].topics;data[?(target.type=topic_sticky_module)].target.data[?(target.type=people)].target.answer_count,articles_count,gender,follower_count,is_followed,is_following,badge[?(type=best_answerer)].topics;data[?(target.type=answer)].target.content,relationship.is_authorized,is_author,voting,is_thanked,is_nothelp;data[?(target.type=answer)].target.author.badge[?(type=best_answerer)].topics;data[?(target.type=article)].target.content,author.badge[?(type=best_answerer)].topics;data[?(target.type=question)].target.comment_count&amp;limit=10&amp;after_id=4847.84338&amp;offset=5 2、言说知乎最热（爬取全部150多页）（https://www.yanshuo.me/r/zhihuhot） 解析https://www.yanshuo.me/r/zhihuhot 获取列表网址，即可获得具体话题的ID，然后就可拼接出如下接口。 https://www.zhihu.com/api/v4/answers/147785918https://www.zhihu.com/api/v4/questions/31271400 3、新媒体管家知乎精选（爬取今日最热、编辑推荐和33个话题下的问题）（https://article.xmt.cn/#/zhihu/hot） （1）今日最热http://zhihu.sogou.com/include/pc/pc/hot/hot0.html解析以上类似html即可，页数是后面的0。 （2）编辑推荐http://zhihu.sogou.com/include/pc/pc/recommend/recommend0.html同今日最热。 （3）33个话题 123v_categoryList: [{ name: '游戏', index: 0, nav: 'topic0_0' }, { name: '运动', index: 1, nav: 'topic1_0' }, { name: '互联网', index: 2, nav: 'topic2_0' }, { name: '艺术', index: 3, nav: 'topic3_0' }, { name: '阅读', index: 4, nav: 'topic4_0' }, { name: '美食', index: 5, nav: 'topic5_0' }, { name: '动漫', index: 6, nav: 'topic6_0' }, { name: '汽车', index: 7, nav: 'topic7_0' }, { name: '生活方式', index: 8, nav: 'topic8_0' }, { name: '教育', index: 9, nav: 'topic9_0' }, { name: '摄影', index: 10, nav: 'topic10_0' }, { name: '历史', index: 11, nav: 'topic11_0' }, { name: '文化', index: 12, nav: 'topic12_0' }, { name: '旅行', index: 13, nav: 'topic13_0' }, { name: '职业发展', index: 14, nav: 'topic14_0' }],v_categoryList2: [{ name: '经济学', index: 15, nav: 'topic15_0' }, { name: '足球', index: 16, nav: 'topic16_0' }, { name: '篮球', index: 17, nav: 'topic17_0' }, { name: '投资', index: 18, nav: 'topic18_0' }, { name: '音乐', index: 19, nav: 'topic19_0' }, { name: '电影', index: 20, nav: 'topic20_0' }, { name: '法律', index: 21, nav: 'topic21_0' }, { name: '自然科学', index: 22, nav: 'topic22_0' }, { name: '设计', index: 23, nav: 'topic23_0' }, { name: '创业', index: 24, nav: 'topic24_0' }, { name: '健康', index: 25, nav: 'topic25_0' }, { name: '商业', index: 26, nav: 'topic26_0' }, { name: '体育', index: 27, nav: 'topic27_0' }, { name: '科技', index: 28, nav: 'topic28_0' }, { name: '化学', index: 29, nav: 'topic29_0' }, { name: '物理学', index: 30, nav: 'topic30_0' }, { name: '生物学', index: 31, nav: 'topic31_0' }, { name: '金融', index: 32, nav: 'topic32_0' }] 解析http://zhihu.sogou.com/include/pc/5/topic/topic0_0.html 4、X 是种怎样的体验 1https://www.zhihu.com/api/v4/topics/20011035/feeds/top_activity?include=data[?(target.type=topic_sticky_module)].target.data[?(target.type=answer)].target.content,relationship.is_authorized,is_author,voting,is_thanked,is_nothelp;data[?(target.type=topic_sticky_module)].target.data[?(target.type=answer)].target.is_normal,comment_count,voteup_count,content,relevant_info,excerpt.author.badge[?(type=best_answerer)].topics;data[?(target.type=topic_sticky_module)].target.data[?(target.type=article)].target.content,voteup_count,comment_count,voting,author.badge[?(type=best_answerer)].topics;data[?(target.type=topic_sticky_module)].target.data[?(target.type=people)].target.answer_count,articles_count,gender,follower_count,is_followed,is_following,badge[?(type=best_answerer)].topics;data[?(target.type=answer)].target.content,relationship.is_authorized,is_author,voting,is_thanked,is_nothelp;data[?(target.type=answer)].target.author.badge[?(type=best_answerer)].topics;data[?(target.type=article)].target.content,author.badge[?(type=best_answerer)].topics;data[?(target.type=question)].target.comment_count&amp;offset=5&amp;limit=10 悟空问答 以社会标签为例， concern_id 为“社会”标签Id,t为当前时间的毫秒数。_signature为一个签名。max_behot_time 为上一接口返回的最后一条中的behot_time的值。 每次请求最多返回15条数据。 https://www.wukong.com/wenda/web/nativefeed/brow/?concern_id=6215497899397089794&amp;t=1535695219126&amp;_signature=EpFuSRAcSR4Gf9W44qy9xxKRbl https://www.wukong.com/wenda/web/nativefeed/brow/?concern_id=6215497899397089794&amp;t=1535695230470&amp;max_behot_time=1535695169&amp;_signature=EpFuSRAcSR4Gf9W44qzD4BKRbl https://www.wukong.com/wenda/web/nativefeed/brow/?concern_id=6215497899397089794&amp;t=1535695757329&amp;max_behot_time=1535695107&amp;_signature=EpFuSRAcSR4Gf9W44qzCChKRbl https://www.wukong.com/wenda/web/nativefeed/brow/?concern_id=6215497899397089794&amp;t=1535696088148&amp;max_behot_time=1535694957&amp;_signature=EpFuSRAcSR4Gf9W44qzwwxKRbl 然后爬取问题对应的所有回答。 需解析https://www.wukong.com/question/6474295200058441997/ 类型html页面 芝麻问答接口为post请求，请求时需拿着上次的cookie去请求 https://www.zhimawenda.com/api/client/moon_index.json 然后获取每个问题的所有回答https://www.zhimawenda.com/api/questions/43519/answers.json?page=1","link":"/2018/08/31/%E7%88%AC%E8%99%AB/%E5%85%B3%E4%BA%8E%E9%97%AE%E7%AD%94%E7%88%AC%E8%99%AB%E9%9C%80%E6%B1%82%E7%9A%84%E5%88%86%E6%9E%90/"},{"title":"我的2018","text":"熬啊熬，到了距离2019还有4个钟头的时间，开始对这一年的回顾总结。 大概是从年初的时候开始对现在的工作开始有些不满的，不知不觉的就到了年底了，也没有迈出这一步，原因大概有这几点吧，一对劳动合同的理解有问题，因为入职时签的是三年的合同，认为必须要干满三年，否则会有什么违约金或其它比较麻烦的东西，其实事实上并不是这样，如果需要离职，只需提前一个月提出申请，便可。导致一直以来变得很焦躁。二是对自己技术没有信心，因为经历的之前的一次找工作，真是对当时的情景有些绝望，害怕踏出去，会如之前一样。三是临近年末听到这种裁员的消息，心里也是没底。反正不管以后会怎么样，都必须要勇敢的踏出去。这里已不再需要你了。 其实心里感觉挺寒心的，想之初去面试的情景历历在目，当时也是很激动的，认为可以安稳踏实的奋斗几年， 现在想起来也是觉得有些可笑，也是明白了当时是我通过了的原因，当时就被云召说中了，其实也是自己不愿意去相信罢了，刚入公司的那半年至一年像是着了魔似的，一般都要九点、十点下班，有时甚至到了凌晨一点、两点也是常有，当时的日夜拼命，到头来也不过换回这样一个结局。资本家眼中不会有人情，有也是装出的可怜，让你更加的去卖命吧。好在现在已经明白了些许，不会再被蒙蔽。 想想在这里接触的也不少，mongodb、redis、springboot、ubuntu、nginx、rabbitmq、elasticsearch、websocket、jenkins、srs、ssl配置、阿里云服务管理、七牛、云片、域名解析、mongo数据库优化等。但是对有些东西不够深入，还有一些，因只学习了一次，未在实际中应用，经常忘记。还有就是对java基础的掌握还是很欠缺。 关与对象，年初时介绍与你认识的，之前还有些不太情愿，总是感觉年龄相差有点大，之前你的腿伤着了，我也没有太上心，加上父母的催促，和你一直也联系着，虽说是不太积极，但是每次都是很认真的、绞尽脑汁的想着要发送的内容，每次不理我之后，我都很害怕，心情也变得很烦躁，我妈询问的时候，我就会默不作声，有时也就发了脾气，因为我不确定到底会怎样，我心里也很着急，大约是从十月份你开始换工作那时起，我与你的聊天的氛围感才稍稍好些，我猜测有两点，一是我参加完大胜的婚礼后，我心里着急，二是你回家那几天你父母也在催促你。到了十一月中旬，你终于答应我去找你了，我当时好开心，可是那次见面我表现真是糟糕透了，你对我建了起的少许好感也随之飘去了，好在你没有完全不理我，我深深地反省，才觉着我的非常幼稚与不成熟。这一年的接触，感受着你的强大，你热爱生活，有爱心。才觉着我的自卑。加油吧，努力吧，去改变，既然喜欢就勇敢些吧，不要再错过。希望过年时能有好消息。 关于锻炼，上半年基本上就没有锻炼过，只是每天上下班的时候骑得两趟自行车，夏天时有段时间还坚持做俯卧撑和仰望起坐，天冷了，也就没再做了，希望明年天气回暖后继续坚持。总算是赶在了前年学习了游泳，虽说还没完全学会，要凑空去练习。也算是跨出了一步，之前可是不敢去想的。因为这段时间天冷，每天跑步上下班，只要是这边栏杆可以翻，以后也都坚持步行。 关于父母，慢慢的父母变老了，可是我还未长大，小时候听得最多的就是我听话、懂事，可是长大了，我却是最不懂事的那个，我的心理上并没有成长，以后多去尝试，多去冒险，不要害怕失败，多帮爸妈分担些，就拿买车来说吧，爸并不了解多少，他只是听别人说好就是好的，他们对新生事物多少有些跟不上了，他们还不如我在网上了解的多，就因为我的这种性格，我把它推给了我爸，我爸也只能自己去摸索，或许也会被人骗。以后不要总把事情推向家里，不会的要自己去琢磨，去学习，去分辨，你不去锻炼，你永远都不会。 关于2019，希望2019能顺利找到一个比较满意的工作，希望把基础知识打扎实，探索新知识，学习后都做到学以致用，学习完之后做出一些小的东西。希望2019能与你结婚。希望2019能学会生活，学会长大，学会成熟。","link":"/2018/12/31/%E7%94%9F%E6%B4%BB/%E6%88%91%E7%9A%842018/"},{"title":"扶摇剧","text":"宗越是一个带着仇恨长大的孩子，自己亲眼目睹父母的被害，家族的灭门，使他不得不背负这样的使命，或许只有最终完成这个使命，他才会归于平静，做真正的医圣吧。云痕是被仇人养大，自己丝毫不知，内心也是感激其养育之恩。或许如果不是宗越的告知，自己一生也就如此。哥哥的出现对他是一个晴天霹雳，一时间会无法接受这样的现实，可毕竟流的是轩辕的血，最终是要面对的。 有的人生下来就是带着使命的，他将为这个使命而活","link":"/2018/07/08/%E7%94%9F%E6%B4%BB/%E6%89%B6%E6%91%87%E5%89%A7/"},{"title":"Keepalived实现mongoDB的高可用","text":"实现目标： A(192.168.1.34)、B(192.168.1.33)两机器同时工作，互为主从，其中一台宕机，业务自动切换到另一台，不影响用户访问。 此篇是以mongoDB数据库的双向复制完成数据库的高可用性。 安装mongoDB1、解压 1$ tar -zxvf mongodb-linux-x86_64-ubuntu1604-3.4.2.tgz -C /usr/local 2、添加path路径 vim /etc/profile 123#MONGODBexport MONGO_HOME=/usr/local/mongodbexport PATH=$PATH:$MONGO_HOME/bin 执行source /etc/profile，使profile生效。 3、创建配置文件：vim /etc/mongodb.conf 1234567bind_ip = 127.0.0.1port = 27017dbpath =/usr/local/mongodb/datalogpath = /usr/local/mongodb/logs/master.logpidfilepath = /var/run/mongodb/mongodb.pidfork = truejournal = true 4、创建服务脚本vim /etc/init.d/mongodb 1234567891011121314151617181920212223242526272829303132333435#!/bin/sh### BEGIN INIT INFO# Provides: mongodb# Required-Start:# Required-Stop:# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: mongodb# Description: mongo db server### END INIT INFO. /lib/lsb/init-functionsPROGRAM=/usr/local/mongodb/bin/mongodMONGOPID=`ps -ef | grep 'mongod' | grep -v grep | awk '{print $2}'`test -x $PROGRAM || exit 0case \"$1\" in start) ulimit -n 3000 log_begin_msg \"Starting MongoDB server\" $PROGRAM --config /etc/mongodb.conf log_end_msg 0 ;; stop) log_begin_msg \"Stopping MongoDB server\" if [ ! -z \"$MONGOPID\" ]; then kill -15 $MONGOPID fi log_end_msg 0 ;; status) ;; *) log_success_msg \"Usage: /etc/init.d/mongodb {start|stop|status}\" exit 1esacexit 0 5、赋予脚本执行权限 1$ chmod +x mongodb 6、注册为服务 1$ update-rc.d mongodb defaults MONGODB的双向复制1、修改主服务A的配置文件:vim /etc/mongodb.conf 123456789#master.confdbpath=/usr/local/mongodb/datalogpath=/usr/local/mongodb/logs/master.logmaster=trueslave=truesource=192.168.1.33:27017fork=trueport=27017oplogSize=2048 2、修改从服务B的配置文件: vim /etc/mongodb.conf 123456789#master.confdbpath=/usr/local/mongodb/datalogpath=/usr/local/mongodb/logs/slave.logmaster=trueslave=truesource=192.168.1.34:27017fork=trueport=27017autoresync=true 3、测试双向复制 启动两机器mongoDB服务后登录进去 123456789101112&gt; db.isMaster(){ \"ismaster\" : true, \"maxBsonObjectSize\" : 16777216, \"maxMessageSizeBytes\" : 48000000, \"maxWriteBatchSize\" : 1000, \"localTime\" : ISODate(\"2017-08-08T01:44:45.150Z\"), \"maxWireVersion\" : 5, \"minWireVersion\" : 0, \"readOnly\" : false, \"ok\" : 1} 可以看到两机器都为主服务。 1、在A机器添加一条数据 123456&gt; use testswitched to db test&gt; db.test.save({age:18})WriteResult({ \"nInserted\" : 1 })&gt; db.test.find(){ \"_id\" : ObjectId(\"59883e2ca5f50d892813d7af\"), \"age\" : 18 } 在B机器上查询 1234&gt; use testswitched to db test&gt; db.test.find(){ \"_id\" : ObjectId(\"59883e2ca5f50d892813d7af\"), \"age\" : 18 } 看到可以查到 2、在B机器上添加一条数据 12345&gt; db.test.save({age:22})WriteResult({ \"nInserted\" : 1 })&gt; db.test.find(){ \"_id\" : ObjectId(\"59883e2ca5f50d892813d7af\"), \"age\" : 18 }{ \"_id\" : ObjectId(\"598917c62e7723e440d366a7\"), \"age\" : 20 } 在A机器上查询 123&gt; db.test.find(){ \"_id\" : ObjectId(\"59883e2ca5f50d892813d7af\"), \"age\" : 18 }{ \"_id\" : ObjectId(\"598917c62e7723e440d366a7\"), \"age\" : 20 } 看到也可以查到 3、把A服务停掉：service mongodb stop 在B机器上添加一条数据 123456&gt; db.test.save({age:22})WriteResult({ \"nInserted\" : 1 })&gt; db.test.find(){ \"_id\" : ObjectId(\"59883e2ca5f50d892813d7af\"), \"age\" : 18 }{ \"_id\" : ObjectId(\"598917c62e7723e440d366a7\"), \"age\" : 20 }{ \"_id\" : ObjectId(\"59891827da882ffb1ce7b7e3\"), \"age\" : 22 } 再启动A服务：service mongodb start 然后在A机器上查询 1234&gt; db.test.find(){ \"_id\" : ObjectId(\"59883e2ca5f50d892813d7af\"), \"age\" : 18 }{ \"_id\" : ObjectId(\"598917c62e7723e440d366a7\"), \"age\" : 20 }{ \"_id\" : ObjectId(\"59891827da882ffb1ce7b7e3\"), \"age\" : 22 } 可以看到数据已经从B服务上同步过来。 已经实现预期目标。 KEEPALIVED监控MONGODB服务状态待完善 目前实现检测到主服务A的mongoDB挂掉后自动把A机器上的keepalived服务也停掉。 修改keepalived配置文件：vim /etc/keepalived/keepalived.conf 1234567891011121314151617181920212223242526272829303132333435363738394041vrrp_script chk_mongodb { script \"/etc/keepalived/mongodb_check.sh\" interval 2 weight 2 } vrrp_instance VI_1 { #state MASTER #主服务器 state BACKUP #主服务器 interface ens33 virtual_router_id 51 mcast_src_ip 192.168.1.34 priority 250 nopreempt #不抢占MASTER advert_int 1 authentication { auth_type PASS auth_pass 123456 } track_script { chk_redis chk_mongodb } virtual_ipaddress { 192.168.1.35 }}virtual_server 192.168.1.35 27017 { delay_loop 6 lb_algo rr persistence_timeout 5 protocol TCP real_server 192.168.1.34 27017 { notify_down /etc/keepalived/killkeep.sh TCP_CHECK { connect_timeout 3 nb_get_retry 3 delay_before_retry 3 connect_port 27017 } } } 创建killkeep.sh脚本 12#!/bin/bashservice keepalived stop 测试 把A机器上的mongoDB服务停掉后 ps -ef |grep keepalived 发现keepalived服务也停掉了。","link":"/2017/08/08/%E9%AB%98%E5%8F%AF%E7%94%A8/Keepalived%E5%AE%9E%E7%8E%B0mongoDB%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"title":"keepalived实现nginx高可用负载均衡","text":"需求：两台盒子服务器（内网服务器）相同配置、相同规格，实现其中一台挂掉，自动切换到另一台备份服务器，从而不影响用户的访问。 设置虚拟IP临时设置：1$ ifconfig ens33:0 192.168.1.35 netmask 255.255.255.0 up 执行ifconfig便看到效果，重启后自动失效。 永久配置 :写入/etc/network/interfaces配置文件 123456#虚拟ipauto ens33:0iface ens33:0 inet staticaddress 192.168.1.35netmask 255.255.255.0gateway 192.168.1.2 重启网卡：123$ service networking restart $ nohup service network restart &amp; # 或者#（虽然没在控制台报错，但在日志中可以查看） 重启后会出错，但ifconfig查看已经成功，所以暂忽略。 设置完虚拟ip后已满足需求 由于关掉正在服务的nginx或tomcat不能马上切换到另一台服务上所以还需keepalived KEEPALIVED安装及配置准备：（虚拟ip为192.168.1.35，主服务器为192.168.1.34 从服务器为192.168.1.33）主从服务器都已安装nginx、tomcat，且nginx已做好转发 1、安装keepalived： 1$ apt-get install keepalived 2、创建keepalived.conf文件 (vim /etc/keepalived/keepalived.conf) 主服务器keepalived.conf文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#vrrp_script chk_nginx { # script \"/etc/keepalived/check_nginx.sh\" //检测nginx进程的脚本 # interval 2 # weight 2 #} global_defs { # notification_email { # poiu00998@126.com #可以添加邮件提醒 # } # notification_email_from root #配置发件人 # smtp_server 127.0.0.1 #配置邮件服务器 # smtp_connect_timeout 30 # router_id LVS_DEVEL } vrrp_instance VI_1 { state MASTER #主服务器 interface ens33 virtual_router_id 51 mcast_src_ip 192.168.1.34 priority 250 advert_int 1 authentication { auth_type PASS auth_pass 123456 } track_script { chk_nginx } virtual_ipaddress { 192.168.1.35 }}virtual_server 192.168.1.35 80 { delay_loop 6 lb_algo rr lb_kind DR nat_mask 255.255.255.0 #persistence_timeout 50 protocol TCP real_server 192.168.1.34 80 { #配置realaserver weight 1 HTTP_GET { #监控配置 url { path / status_code 200 } connect_timeout 2 nb_get_retry 3 delay_before_retry 1 } } real_server 192.168.1.33 80 { weight 1 HTTP_GET { url { path / status_code 200 } connect_timeout 2 nb_get_retry 3 delay_before_retry 1 } } sorry_server 127.0.0.1 80 #错误页面} 从服务器keepalived.conf文件除了优先级，state和mcast_src_ip不一样，其他的完全一致，但是需要注意的几点是： 主服务器的state为MASTER,从服务器的state为BACKUP 主服务器的priority一定要比从服务器的priority大 mcast_src_ip就是对应服务器的局域网ip “{”前面一定要有个空格，不能跟前面的字符连起来，否则出现问题很难发现 real_server ip为真实IP。 服务器的邮件服务smtp未配置，暂不可发送邮件通知。 keepalived里的check_nginx.sh脚本(暂未用) 12345678910#!/bin/bash#代码一定注意空格，逻辑就是：如果nginx进程不存在则启动nginx,如果nginx无法启动则kill掉keepalived所有进程A=ps -C nginx --no-header |wc -lif [ $A -eq 0 ];then/etc/init.d/nginx startsleep 3if [ ps -C nginx --no-header |wc -l -eq 0 ];thenkillall keepalivedfifi 3、启动主、从的keepalived服务 1$ service keepalived start 4、查看 keepalived的日志 1$ vim /var/log/syslog 5、查看一下LVS状态： 1234567$ /var/log# ipvsadm -L -nIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags-&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.1.35:80 rr-&gt; 192.168.1.33:80 Route 1 0 0-&gt; 192.168.1.34:80 Route 1 0 103 6、测试 在浏览器访问192.168.1.35 多次刷新，就会看到服务的切换。 模拟故障 停止其中一台tomcat或者nginx(停掉的192.168.1.33的nginx) ，然后查看lvs 123456$ /var/log# ipvsadm -L -nIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags-&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.1.35:80 rr-&gt; 192.168.1.34:80 Route 1 0 103 可以看到192.168.1.33便不存在了，浏览器访问192.168.1.35只转向192.168.1.34了（停止另一台，效果相同）","link":"/2017/08/02/%E9%AB%98%E5%8F%AF%E7%94%A8/keepalived%E5%AE%9E%E7%8E%B0nginx%E9%AB%98%E5%8F%AF%E7%94%A8%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"title":"keepalived实现redis主从复制高可用","text":"实现目标： A 、B 依次启动，A（192.168.1.34）作为主、B（192.168.1.33）为从 主A 挂掉，B接管业务，作为主 A 起来，作为从SLAVEOF B B 挂掉，A 切回主 redis主从配置主从两台机器都按安装好redis后 1、 编辑修改主服务配置文件 12345bind 0.0.0.0daemonize yes #后台启动logfile \"/var/log/redis/redis.log\"slave-server-stale-data no #同步未完成从机不能接收除slaveof和info之外的命令，相当重要slave-read-only no #从机时也可以执行写命令 2、 编辑修改从服务配置文件 123456bind 0.0.0.0daemonize yes #后台启动logfile \"/var/log/redis/redis.log\"slaveof 192.168.1.34 6379slave-server-stale-data no #同步未完成从机不能接收除slaveof和info之外的命令，相当重要slave-read-only no #从机时也可以执行写命令 3、 重启服务后redis-cli登录主从服务输入info查看是否正确 主服务 123456789101112# Replication role:master connected_slaves:1 slave0:ip=192.168.1.33,port=6379,state=online,offset=98646,lag=1 master_replid:5b18fec8936e046d517269c36d1ab538626962a1 master_replid2:a7ba915e664ecdfdb17be4ebd8d5b3ec1f95b9e1 master_repl_offset:98646 second_repl_offset:449 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:407 repl_backlog_histlen:98240 从服务 12345678910111213141516171819# Replicationrole:slavemaster_host:192.168.1.34master_port:6379master_link_status:upmaster_last_io_seconds_ago:3master_sync_in_progress:0slave_repl_offset:98870slave_priority:100slave_read_only:1connected_slaves:0master_replid:5b18fec8936e046d517269c36d1ab538626962a1master_replid2:a7ba915e664ecdfdb17be4ebd8d5b3ec1f95b9e1master_repl_offset:98870second_repl_offset:449repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:407repl_backlog_histlen:98464 可以看到redis主从服务的关系。 4、 测试 在主服务上set key1 value1 可以在从服务上查到get key1 说明redis的主从复制部署成功。 KEEPALIVED配置在keepalived 有两个角色：Master(一个)、Backup（多个），如果设置一个为Master，但Master挂了后再起来，必然再次业务又一次切换，这对于有状态服务是不可接受的。 解决方案就是两台机器都设置为Backup，而且优先级高的Backup设置为nopreemt 不抢占。 1、 主服务keepalived配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#vrrp_script chk_nginx {# script \"/etc/keepalived/check_nginx.sh\" //检测nginx进程的脚本# interval 2# weight 2#}vrrp_script chk_redis { script \"/etc/keepalived/scripts/check_redis.sh 127.0.0.1 6379\" #redis 检查健康状态 interval 2 #健康状态检查时间间隔 2秒 timeout 2 # 请求超时时间 2秒 fall 3 #失败次数}global_defs {# notification_email {# poiu00998@126.com #可以添加邮件提醒# }# notification_email_from root #配置发件人# smtp_server 127.0.0.1 #配置邮件服务器# smtp_connect_timeout 30# router_id LVS_DEVEL router_id node1}vrrp_instance VI_1 {# state MASTER #主服务器 state BACKUP #主服务器 interface ens33 virtual_router_id 51 mcast_src_ip 192.168.1.34 priority 250 nopreempt #不抢占MASTER advert_int 1 authentication { auth_type PASS auth_pass 123456 } track_script { chk_redis } virtual_ipaddress { 192.168.1.35 } notify_master \"/etc/keepalived/scripts/redis_master.sh 127.0.0.1 192.168.1.33 6379\" #当keepalived 切换到master的时候执行此脚本 notify_backup \"/etc/keepalived/scripts/redis_backup.sh 127.0.0.1 192.168.1.33 6379\" #当keepalived 切换到bakcup的时候执行此脚本 notify_fault /etc/keepalived/scripts/redis_fault.sh #当keepalived 出现故障的时候执行此脚本 notify_stop /etc/keepalived/scripts/redis_stop.sh #当keepalived 停止运行前执行此脚本} #以下为nginx配置所需virtual_server 192.168.1.35 80 { delay_loop 6 lb_algo rr lb_kind DR nat_mask 255.255.255.0 #persistence_timeout 50 protocol TCP real_server 192.168.1.34 80 { #配置realaserver weight 1 HTTP_GET { #监控配置 url { path / status_code 200 } connect_timeout 2 nb_get_retry 3 delay_before_retry 1 } } real_server 192.168.1.33 80 { weight 1 HTTP_GET { url { path / status_code 200 } connect_timeout 2 nb_get_retry 3 delay_before_retry 1 } } sorry_server 127.0.0.1 80 #错误页面} 2、 从服务keepalived配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#vrrp_script chk_nginx { # script \"/etc/keepalived/check_nginx.sh\" //检测nginx进程的脚本 # interval 2 # weight 2 #} vrrp_script chk_redis { script \"/etc/keepalived/scripts/check_redis.sh 127.0.0.1 6379\" #redis 检查健康状态 interval 2 #健康状态检查时间间隔 2秒 timeout 2 # 请求超时时间 2秒 fall 3 #失败次数 } global_defs { # notification_email { # poiu00998@126.com #可以添加邮件提醒 # } # notification_email_from root #配置发件人 # smtp_server 127.0.0.1 #配置邮件服务器 # smtp_connect_timeout 30 router_id node2 } vrrp_instance VI_1 { state BACKUP #从服务器 interface ens33 virtual_router_id 51 mcast_src_ip 192.168.1.33 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 123456 } track_script { chk_redis } virtual_ipaddress { 192.168.1.35 } notify_master \"/etc/keepalived/scripts/redis_master.sh 127.0.0.1 192.168.1.34 6379\" #当keepalived 切换到master的时候执行此脚本 notify_backup \"/etc/keepalived/scripts/redis_backup.sh 127.0.0.1 192.168.1.34 6379\" #当keepalived 切换到bakcup的时候执行此脚本 notify_fault /etc/keepalived/scripts/redis_fault.sh #当keepalived 出现故障的时候执行此脚本 notify_stop /etc/keepalived/scripts/redis_stop.sh #当keepalived 停止运行前执行此脚本 }# 以下主要为nginx配置所需 virtual_server 192.168.1.35 80 { delay_loop 6 lb_algo rr lb_kind DR nat_mask 255.255.255.0 #persistence_timeout 50 protocol TCP real_server 192.168.1.33 80 { #配置realaserver weight 1 HTTP_GET { #监控配置 url { path / status_code 200 } connect_timeout 2 nb_get_retry 3 delay_before_retry 1 } } real_server 192.168.1.34 80 { weight 1 HTTP_GET { url { path / status_code 200 } connect_timeout 2 nb_get_retry 3 delay_before_retry 1 } } sorry_server 127.0.0.1 80 #错误页面} 3、 创建keepalived配置文件里所需的脚本文件 vim /etc/keepalived/scripts/check_redis.sh 12345678910111213#!/bin/bashALIVE=`/usr/local/bin/redis-cli -h $1 -p $2 PING`#redis-cli命令所在路径，根据自己配置更改，可用用which redis-cli命令查看路径。LOGFILE=\"/var/log/keepalived-redis-check.log\"echo \"[CHECK]\" &gt;&gt; $LOGFILEdate &gt;&gt; $LOGFILEif [ $ALIVE == \"PONG\" ]; then : echo \"Success: redis-cli -h $1 -p $2 PING $ALIVE\" &gt;&gt; $LOGFILE 2&gt;&amp;1 exit 0else echo \"Failed:redis-cli -h $1 -p $2 PING $ALIVE \" &gt;&gt; $LOGFILE 2&gt;&amp;1 exit 1fi vim /etc/keepalived/scripts/redis_master.sh 123456789101112#!/bin/bashREDISCLI=\"/usr/local/bin/redis-cli -h $1 -p $3\" #redis-cli命令所在路径，根据自己配置所更改。LOGFILE=\"/var/log/keepalived-redis-state.log\"echo \"[master]\" &gt;&gt; $LOGFILEdate &gt;&gt; $LOGFILEecho \"Being master....\" &gt;&gt; $LOGFILE 2&gt;&amp;1echo \"Run SLAVEOF cmd ... \" &gt;&gt; $LOGFILE#$REDISCLI SLAVEOF $2 $3 &gt;&gt; $LOGFILE 2&gt;&amp;1#echo \"SLAVEOF $2 cmd can't excute ... \" &gt;&gt; $LOGFILEsleep 10 ##delay 15 s wait data sync exchange roleecho \"Run SLAVEOF NO ONE cmd ...\" &gt;&gt; $LOGFILE$REDISCLI SLAVEOF NO ONE &gt;&gt; $LOGFILE 2&gt;&amp;1 vim /etc/keepalived/scripts/redis_backup.sh 1234567891011#!/bin/bashREDISCLI=\"/usr/local/bin/redis-cli\"#设置redis-cli的命令所在路径即可LOGFILE=\"/var/log/keepalived-redis-state.log\"echo \"[BACKUP]\" &gt;&gt; $LOGFILEdate &gt;&gt; $LOGFILEecho \"Being slave....\" &gt;&gt; $LOGFILE 2&gt;&amp;1echo \"Run SLAVEOF cmd ...\" &gt;&gt; $LOGFILE 2&gt;&amp;1$REDISCLI SLAVEOF $2 $3 &gt;&gt; $LOGFILEsleep 100 #delay 10 s wait data async cancel syncexit(0) vim /etc/keepalived/scripts/redis_fault.sh 1234#!/bin/bashLOGFILE=/var/log/keepalived-redis-state.logecho \"[fault]\" &gt;&gt; $LOGFILEdate &gt;&gt; $LOGFILE vim /etc/keepalived/scripts/redis_stop.sh 1234#!/bin/bashLOGFILE=/var/log/keepalived-redis-state.logecho \"[stop]\" &gt;&gt; $LOGFILEdate &gt;&gt; $LOGFILE 接下来就可以测试了注：redis SLAVEOF命令 可以动态更改从属的复制设置。如果Redis服务器已经充当从站命令SLAVEOF NO ONE 会关掉复制，转Redis服务器为主。 在适当的形式SLAVEOF主机端口将使另一台服务器监听指定的主机名和端口为从机。 如果服务器已经是一个从于一个主，SLAVEOF主机端口将停止对旧服务器的复制，并开始对新的同步，丢弃旧的数据集。 语法： 1redis 127.0.0.1:6379&gt; SLAVEOF host port","link":"/2017/08/05/%E9%AB%98%E5%8F%AF%E7%94%A8/keepalived%E5%AE%9E%E7%8E%B0redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"title":"XPack Watcher","text":"概述可以对ElasticSearch通过添加Watcher实现当满足某些条件时执行某些操作，比如当logs索引中出现ERROR日志时，自动发送报警邮件或钉钉消息，可以简单的理解为Watcher是一个基于ElasticSearch实现的监控报警服务。 功能介绍XPack Watcher功能主要由Trigger、Input、Condition、Actions组成。 Trigger确定何时检查，在配置Watcher时必须设置。支持丰富的时间计划方式，详情请参见Schedule Trigger。 Input可以理解为您需要对监控的索引执行的筛选条件，详情请参见Inputs。 Condition执行Actions的条件。 Actions当条件发生时，执行的具体操作。 具体使用参考：https://www.elastic.co/guide/en/x-pack/current/xpack-alerting.html https://www.elastic.co/guide/en/elasticsearch/reference/current/watcher-api.html 本文主要是 .watcher-history* 索引 的清理 在Elasticsearch5.0默认watcher是启用的，它每天产生一个.watcher-history* 的索引，时间长了，占用较多的磁盘空间。 可以设置启用自动清理。 1234567PUT _cluster/settings{ \"persistent\": { \"xpack.monitoring.history.duration\": \"1d\", \"xpack.watcher.history.cleaner_service.enabled\": true }} 查看设置情况： 1234567891011121314151617181920&gt; GET _cluster/settings{ \"persistent\": { \"xpack\": { \"monitoring\": { \"history\": { \"duration\": \"1d\" } }, \"watcher\": { \"history\": { \"cleaner_service\": { \"enabled\": \"true\" } } } } }, \"transient\": {}} 通过监控发现，具体执行清理的时间为上午8：00 参考：https://www.elastic.co/guide/en/elasticsearch/reference/current/notification-settings.html https://help.aliyun.com/document_detail/74927.html","link":"/2018/09/12/elasticsearch/elastic%E9%97%AE%E9%A2%98/XPack%20Watcher/"},{"title":"构建成功后发送QQ消息","text":"安装插件Post-Build Script Plug-in该插件作用是，支持构建成功后，执行shell脚本（用于触发QQ消息通知）。目前官方已经停止该插件的下载。可通过Post-Build Script下载。安装方法： 系统管理&gt;管理插件&gt;高级&gt;上传插件 安装完便会有如下选项： 这里使用Mojo-Webqq完成QQ消息发送使用方法：Mojo-Webqq构建成功后执行shell脚本，使用curl模拟发送post请求 12message=&quot;构建成功&quot;curl -d &quot;id=4112877221&amp;content=$message&quot; &quot;http://192.168.1.101:5000/openqq/send_group_message&quot; | iconv -f utf-8 -t utf-8 使用Mojo-Webqq通过QQ号或群组号发送时，因为腾讯屏蔽可能发送不成功。可通过 /openqq/get_friend_info 获取好友数据 /openqq/get_group_info 获取群组数据 /openqq/get_discuss_info 获取讨论组数据 /openqq/stop_client 终止程序运行获取相应的id后通过id进行发送 示例：http://192.168.1.101:5000/openqq/send_friend_message?id=1069850124&amp;content=消息http://127.0.0.1:5000/openqq/send_group_message?id=4112877221&amp;content=消息 参考：https://blog.csdn.net/YLSHELLO/article/details/76026737https://github.com/sjdy521/Mojo-StrawberryPerlhttps://github.com/sjdy521/Mojo-Webqq","link":"/2018/04/24/Jenkins/%E6%8F%92%E4%BB%B6/%E6%9E%84%E5%BB%BA%E6%88%90%E5%8A%9F%E5%90%8E%E5%8F%91%E9%80%81QQ%E6%B6%88%E6%81%AF/"},{"title":"elasticsearch监控日志","text":"默认情况下 x-pack 监控客户端，会每隔10s采集集群的监控信息到您购买实例的以.monitoring-*为前缀的索引中。 目前主要有.monitoring-es-6-*、.monitoring-kibana-6-*这两种索引，以天为单位滚动创建。采集完的信息会保存在以.monitoring-es-6-为前缀，加当前日期为后缀的索引中。 其中.monitoring-es-6-*索引相对占用磁盘空间较大，主要存放了集群状态、集群统计、节点统计、索引统计等信息。 日志保留设置默认保留最近7天的监控索引，此类.monitoring-es-6-*索引会占用一定的存储空间，索引的大小跟集群中索引个数（包含系统索引）节点个数有关系。为了避免服务器大部分磁盘空间被监控索引所占用，可通过以下两种方案优化。 1、可通过以下 API 设置监控索引保留天数。 1234567PUT _cluster/settings{ \"persistent\": { \"xpack.monitoring.history.duration\": \"1d\" }}# 需要保留的天数按照您的需求而定，最少保留一天。 2、设置需要采集监控的索引。 可以通过 API 设置，哪些索引需要监控及哪些索引不需要监控。以减少.monitoring-es-6-*索引占用磁盘空间，本文以禁掉采集系统索引为例。 1234567PUT _cluster/settings{ \"persistent\": { \"xpack.monitoring.collection.indices\": \"+*,-.*\" }}# 禁掉的索引监控信息将不会在Kibana页面中Montioring模块中看到，比如在索引列表及索引监控信息页面，都看不到禁掉的索引信息。就会出现_cat/indices获取的索引列表，跟在Kibana页面中Montioring模块中看到的索引列表不同的情况。 具体设置可参考：monitoring-collection-settings 通过监控发现，具体执行清理的时间为上午8：00 参考：https://help.aliyun.com/document_detail/68017.html https://www.elastic.co/guide/en/cloud/saas-release/ec-add-user-settings.html https://www.elastic.co/guide/en/elasticsearch/reference/6.4/cluster-get-settings.html#cluster-get-settings .watcher-history* 的清理 123456PUT _cluster/settings{ \"persistent\": { \"xpack.watcher.history.cleaner_service.enabled\": true }} 参考：https://www.elastic.co/guide/en/elasticsearch/reference/current/notification-settings.html https://help.aliyun.com/document_detail/74927.html","link":"/2018/09/04/elasticsearch/elastic%E9%97%AE%E9%A2%98/elasticsearch%E7%9B%91%E6%8E%A7%E6%97%A5%E5%BF%97/"},{"title":"elasticsearch索引分片index只读read-only处理","text":"Eleastisearch 在更新索引数据的时候报了一个错误 ClusterBlockException[blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];] 这是由于服务器磁盘空间剩余量超过了警戒阈值。此时ES集群为了保护数据，会自动把索引分片index置为只读read-only。 解决步骤： 1、提供足够的存储空间。（清理磁盘、磁盘扩容、清理elasticsearch监控日志 可参考） 2、放开索引只读设置。 1234PUT /_all/_settings{ \"index.blocks.read_only_allow_delete\": null} 可参考：https://www.elastic.co/guide/en/elasticsearch/reference/current/disk-allocator.html","link":"/2018/09/05/elasticsearch/elastic%E9%97%AE%E9%A2%98/elasticsearch%E7%B4%A2%E5%BC%95%E5%88%86%E7%89%87index%E5%8F%AA%E8%AF%BBread-only%E5%A4%84%E7%90%86/"},{"title":"Java8InAction","text":"Lambda表达式有三个部分：参数列表，箭头、Lambda主体。 函数式接口：只定义一个抽象方法的接口。可以有默认方法。 Predicate、Consumer、Function&lt;T, R&gt; 避免对原始类型进行装箱操作 IntPredicate、DoublePredicate、IntConsumer、LongBinaryOperator、IntFunction。 函数式接口 函数描述符 原始类型转化 Predicate T-&gt;boolean IntPredicate、LongPredicate、DoublePredicate Consumer T-&gt;void IntConsumer、LongConsumer、DoubleConsumer Function&lt;T,R&gt; T-&gt;R IntFunction、IntToDoubleFunction、LongToIntFunction… Supplier ()-&gt;T BooleanSupplier、IntSupplier、LongSupplier、DoubleSupplier UnaryOperator T-&gt;T IntUnaryOperator、LongUnaryOperator、DoubleUnaryOperator BinaryOperator (T,T)-&gt;T IntBinaryOperator、LongBinaryOperator、DoubleBinaryOperator 方法引用 目标引用放在分隔符::前，方法的名称放在后面，方法引用就是Lambda表达式的快捷写法。 123inventory.sort((Apple a1, Apple a2) &gt; a1.getWeight().compareTo(a2.getWeight()));//最初inventory.sort(Comparator.comparing((Apple a) -&gt; a.getWeight()));//使用lambda表达式inventory.sort(Comparator.comparing(Apple::getWeight)); //使用了方法引用 //示例 12345List&lt;SpAggreCnt&gt; recordPlanStats = mongoDao.aggregate(planAggre, SpAggreCnt.class);recordPlanStats = new ArrayList&lt;&gt;(recordPlanStats);//由于java.lang.UnsupportedOperationException，所以把list重新构造了一遍 recordPlanStats.sort(Comparator.comparing(SpAggreCnt::getId, (s1, s2) -&gt; { return String.valueOf(s1).compareTo(String.valueOf(s2)); }));//SpAggreCnt的Id为Object类型 复合lambda表达式 1、比较器符合(Comparator) 12inventory.sort(comparing(Apple::getWeight).reversed()); //逆序inventory.sort(comparing(Apple::getWeight).reversed().thenComparing(Apple::getCountry)); //比较器链（按重量递减排序，若重量相同时，再按原产地排序） 2、谓词复合（Predicate） 谓词接口包括三个方法：negate、and和or 123Predicate&lt;Apple&gt; notRedApple = redApple.negate(); //negate: 产生现有Predicate 对象redApple的非Predicate&lt;Apple&gt; redAndHeavyApple = redApple.and(a -&gt; a.getWeight() &gt; 150); //and:既是红色又比较重的Predicate&lt;Apple&gt; redAndHeavyAppleOrGreen = redApple.and(a -&gt; a.getWeight() &gt; 150).or(a -&gt; \"green\".equals(a.getColor())); //or: 要么是重（150克以上）的红苹果，要么是绿苹果： 3、函数复合 （Function） andThen和compose两个默认方法，注意两者的区别。 12345Function&lt;Integer, Integer&gt; f = x -&gt; x + 1; Function&lt;Integer, Integer&gt; g = x -&gt; x * 2; Function&lt;Integer, Integer&gt; h = f.andThen(g); //先给数字加1，再给结果乘2Function&lt;Integer, Integer&gt; h = f.compose(g); //先给数字乘2，再给结果加1int result = h.apply(1);","link":"/2019/10/15/java/Java8InAction/lambda/"},{"title":"StingJoiner可变字符串拼接","text":"StringJoiner是Java 8中提供的可变字符串类，可以用于字符串拼接。是java.util包中的一个类。 123456789101112public static void testStringJoiner() { StringJoiner sj = new StringJoiner(\":\", \"[\", \"]\"); sj.add(\"George\").add(\"Sally\").add(\"Fred\"); String desiredString = sj.toString(); System.out.println(desiredString); //[George:Sally:Fred] List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4); String commaSeparatedNumbers = numbers.stream() .map(i -&gt; i.toString()) .collect(Collectors.joining(\", \")); System.out.println(commaSeparatedNumbers); //1, 2, 3, 4 } StringJoiner是通过StringBuilder实现的，所以它的性能和StringBuilder差不多，它也是非线程安全的。 如果日常开发中中，需要进行字符串拼接，如何选择？ 1、如果只是简单的字符串拼接，考虑直接使用”+”即可。 2、如果是在for循环中进行字符串拼接，考虑使用StringBuilder和StringBuffer。 3、如果是通过一个集合（如List）进行字符串拼接，则考虑使用StringJoiner。 4、如果是对一组数据进行拼接，则可以考虑将其转换成Stream，并使用StringJoiner处理。","link":"/2019/11/15/java/Java8InAction/StringJoiner/"},{"title":"Java8InAction","text":"Stream 中间流操作：filter 、limit 、skip、sorted 、distinct 、map 、flatmap 终端流操作：forEach 、count 、collect、anyMatch、allMatch、noneMatch 筛选、切片 filter、distinct、limit、skip 映射 map、flatMap(把所有的流连接 起来成为一个流) 查找和匹配 anyMatch(是否有一个元素能匹配给定的谓词)、allMatch(是否匹配所有元素)、noneMatch 、findAny(返回当前流中的任意元素)、findFirst(找到第一个元素) 归约 reduce 构建流 收集器-collect Collectors.counting 12long howManyDishes = menu.stream().collect(Collectors.counting()); long howManyDishes = menu.stream().count(); Collectors.maxBy、Collectors.minBy：计算流中的大或小值 1Optional&lt;Dish&gt; mostCalorieDish = menu.stream().collect(maxBy( Comparator.comparingInt(Dish::getCalories))); Collectors.summingInt: 求和 1int totalCalories = menu.stream().collect(summingInt(Dish::getCalories)); Collectors.averagingInt: 求平均数 1double avgCalories = menu.stream().collect(averagingInt(Dish::getCalories)); Collectors.summarizing: 返回总和、平均值、最大值和最小值 12IntSummaryStatistics menuStatistics = menu.stream().collect(summarizingInt(Dish::getCalories)); IntSummaryStatistics{count=9, sum=4300, min=120, average=477.777778, max=800} Collectors.joining：连接字符串 1String shortMenu = menu.stream().map(Dish::getName).collect(joining(\", \")); Collectors.reducing: 广义的归约汇总 (所有收集器，都是一个可以用reducing工厂方法定义的归约过程 的特殊情况而已) 1int totalCalories = menu.stream().collect(reducing(0, Dish::getCalories, (i, j) -&gt; i + j)); Collectors.groupingBy：分组 12Map&lt;Dish.Type, List&lt;Dish&gt;&gt; dishesByType = menu.stream().collect(groupingBy(Dish::getType)); Map&lt;Dish.Type, Long&gt; typesCount = menu.stream().collect(groupingBy(Dish::getType, counting())); Collectors.collectingAndThen: 把收集器返回的结果转换为另一种类型 1Map&lt;Dish.Type, Dish&gt; mostCaloricByType = menu.stream().collect(Collectors.groupingBy(Dish::getType, Collectors.collectingAndThen(Collectors.maxBy(Comparator.comparing(Dish::getCalories)), Optional::get))); Collectors.mapping 123456789Map&lt;Dish.Type, Set&lt;CaloricLevel&gt;&gt; caloricLevelsByType = menu.stream().collect(Collectors.groupingBy(Dish::getType, Collectors.mapping(dish -&gt; { if(dish.getCalories()&lt;=400) { return CaloricLevel.DIET; }else if(dish.getCalories()&lt;=700) { return CaloricLevel.NORMAL; }else { return CaloricLevel.FAT; } }, Collectors.toSet()))); 分区 partitioningBy 123Map&lt;Boolean, Map&lt;Dish.Type, List&lt;Dish&gt;&gt;&gt; vegetarianDishesByType = menu.stream().collect( Collectors.partitioningBy(Dish::isVegetarian, Collectors.groupingBy(Dish::getType)));","link":"/2019/12/01/java/Java8InAction/stream/"},{"title":"Spring-boot自定义错误页面","text":"spring boot中配置错误页面 首先在 src/main/resources下新建resources文件夹，里面再建一个 error 的文件夹。在error 文件夹里 新建一个404.html页面，这是 springboot 默认的 错误处理页面，当然也可以建立500 页面。 404.html页面自定义内容： 1234567891011&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;404&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;404&lt;/h1&gt; &lt;p&gt;对不起，您请求的页面不存在&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 之后访问项目404页面便会显示此页面。","link":"/2018/12/06/java/Spring-Boot/Spring-boot%E5%AE%9A%E4%B9%89404%E9%A1%B5%E9%9D%A2/"},{"title":"Spring-boot对应servelet中web.xml配置","text":"刚开始使用原生servlet（不使用web框架），web.xml就是非常重要的一个配置，无论是servlet、filter、listener都需要在web.xml里面配置下。 但是在servlet3.0里，这个配置得到了简化。可以通过java配置（注解等）省去web.xml配置。 一、servlet 123456789&lt;servlet&gt; &lt;servlet-name&gt;LoginServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;com.jit.servlet.UIASLoginServlet&lt;/servlet-class&gt; &lt;!--&lt;load-on-startup&gt;1&lt;/load-on-startup&gt;--&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;LoginServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/uias_login.do&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; springboot中配置 1234567@Beanpublic ServletRegistrationBean&lt;UIASLoginServlet&gt; uiasLoginServletRegistration() {ServletRegistrationBean&lt;UIASLoginServlet&gt; registration = new ServletRegistrationBean&lt;UIASLoginServlet&gt;(new UIASLoginServlet(), \"/uias_login.do\");//registration.setLoadOnStartup(1);registration.setOrder(Ordered.HIGHEST_PRECEDENCE); return registration;} 说明： load-on-startup标记容器是否在启动的时候实例化并调用其init()方法的优先级。 当值为0或者大于0时，表示容器在应用启动时就加载并初始化这个servlet。 二、context-param 例如, 有如下web.xml配置 123456&lt;web-app xmlns=\"http://java.sun.com/xml/ns/javaee\" version=\"2.5\"&gt; &lt;context-param&gt; &lt;param-name&gt;backgroundColor&lt;/param-name&gt; &lt;param-value&gt;red&lt;/param-value&gt; &lt;/context-param&gt;&lt;/web-app&gt; springboot中有三种方法进行配置 1、application.properties 1server.context_parameters.backgroundColor=red 2、通过ServletContextInitializer bean SpringBootWebApplication.java 123456789101112131415161718192021222324252627import javax.servlet.ServletContext;import javax.servlet.ServletException;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.web.servlet.ServletContextInitializer;import org.springframework.context.annotation.Bean;@SpringBootApplicationpublic class SpringBootWebApplication { public static void main(String[] args) { SpringApplication.run(SpringBootWebApplication.class, args); } @Bean public ServletContextInitializer initializer() { return new ServletContextInitializer() { @Override public void onStartup(ServletContext servletContext) throws ServletException { servletContext.setInitParameter(\"backgroundColor\", \"red\"); } }; }} 3、通过InitParameterConfiguringServletContextInitializer bean 1234567891011121314151617181920212223import java.util.HashMap;import java.util.Map;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.context.embedded.InitParameterConfiguringServletContextInitializer;import org.springframework.context.annotation.Bean;@SpringBootApplicationpublic class SpringBootWebApplication { public static void main(String[] args) { SpringApplication.run(SpringBootWebApplication.class, args); } @Bean public InitParameterConfiguringServletContextInitializer initParamsInitializer() { Map&lt;String, String&gt; contextParams = new HashMap&lt;&gt;(); contextParams.put(\"backgroundColor\", \"red\"); return new InitParameterConfiguringServletContextInitializer(contextParams); }} 参考：https://www.cnblogs.com/wangxiaomei/p/8885470.html https://bytenota.com/java-set-a-context-param-in-spring-boot/","link":"/2018/09/11/java/Spring-Boot/Spring-boot%E5%AF%B9%E5%BA%94servelet%E4%B8%ADweb.xml%E9%85%8D%E7%BD%AE/"},{"title":"Spring-boot访问日志","text":"springboot访问日志在spring boot的配置文件中添加server.tomcat.accesslog配置tomcat的access日志 12345678910server.tomcat.accesslog.buffered=true ＃是否缓冲输出以使其仅定期刷新。server.tomcat.accesslog.directory=logs＃创建日志文件的目录。可以是绝对的或相对于Tomcat基础目录。server.tomcat.accesslog.enabled=false ＃启用访问日志。server.tomcat.accesslog.file-date-format=.yyyy-MM-dd ＃要放在日志文件名中的日期格式。server.tomcat.accesslog.pattern=common ＃访问日志的格式模式。server.tomcat.accesslog.prefix=access_log ＃日志文件名前缀。server.tomcat.accesslog.rename-on-rotate=false ＃是否延迟在文件名中包含日期戳，直到旋转时间。server.tomcat.accesslog.request-attributes-enabled=false＃设置请求的IP地址，主机名，协议和端口的请求属性。server.tomcat.accesslog.rotate=true ＃是否启用访问日志轮换。server.tomcat.accesslog.suffix=.log ＃日志文件名后缀。 常用的配置： 1234server.tomcat.accesslog.directory=logs＃创建日志文件的目录。server.tomcat.accesslog.enabled=false ＃是否启用访问日志。server.tomcat.accesslog.pattern=%t %a \"%r\" %s %S (%D ms) ＃访问日志的格式模式。server.tomcat.accesslog.rotate=true ＃是否启用访问日志轮转。默认为true。这个参数决定是否需要切割日志文件，如果设置成false，则日志文件不会切换，即所有的文件打印到同一个日志文件中。 日志的格式模式 ％a - 远程IP地址，注意不一定是原始ip地址，中间可能经过nginx等的转发 ％A - 本地IP地址 ％b - 发送的字节数，不包括HTTP标头，如果为零则为“ - ” ％B - 发送的字节数，不包括HTTP标头 ％h - 远程主机名（或enableLookups连接器的IP地址 为false） ％H - 请求协议 ％l - 来自identd的远程逻辑用户名（始终返回’ - ‘） ％m - 请求方法（GET，POST等） ％p - 收到此请求的本地端口。另见%{xxx}p下文。 ％q - 查询字符串（前缀为’？’，如果存在） ％r - 请求的第一行（方法和请求URI） ％s - 响应的HTTP状态代码 ％S - 用户会话ID ％t - 日期和时间，采用通用日志格式 ％u - 经过身份验证的远程用户（如果有），否则为“ - ” ％U - 请求的URL路径 ％v - 本地服务器名称 ％D - 以毫秒为单位处理请求所用的时间 ％T - 处理请求所用的时间，以秒为单位 ％F - 提交响应所用的时间，以毫秒为单位 ％I - 当前请求线程名称（稍后可以与stacktraces进行比较） ％X - 响应完成时的连接状态： Access log 也支持将cookie、header、session或者其他在ServletRequest中的对象信息打印到日志中，其配置遵循Apache配置的格式（{xxx}指值的名称）： %{xxx}i 用名称传入headers，request heade的值 xxx %{xxx}o 用名称传出response headers，response header的值 xxx %{xxx}c 用名字写下cookie的值 xxx %{xxx}r 用名称写ServletRequest属性的值 xxx %{xxx}s 用名称写入HttpSession属性的值 xxx %{xxx}p写本地（服务器）端口（xxx==local）或远程（客户端）端口（xxx=remote） %{xxx}t 在使用增强的SimpleDateFormat模式格式化的请求结束时写入时间戳 xxx 可参考：Access_Logging 常用的配置有： %t %a &quot;%r&quot; %s %S (%D ms)，日期和时间，请求来自的IP（不一定是原始IP），请求第一行，response code，用户会话ID，响应时间（毫秒），样例：[30/Oct/2018:20:10:25 +0800] 185.53.91.51 “GET / HTTP/1.1” 200 - (7 ms)，这里请求来自IP就是经过本机的nginx转发的。 %t %{X-Forwarded-For}i %a &quot;%r&quot; %s %S (%D ms) ,日期和时间，原始IP，请求来自的IP（不一定是原始IP），请求第一行，response code，用户会话ID，响应时间（毫秒）,样例：[01/Nov/2018:11:47:38 +0800] 106.38.223.102 127.0.0.1 “GET /logout HTTP/1.0” 200 - (10 ms) nginx配置文件添加： 1234proxy_set_header REMOTE_ADDR $remote_addr;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 参考：https://docs.spring.io/spring-boot/docs/2.1.0.RELEASE/reference/htmlsingle/#howto-configure-accesslogs server.use-forward-headers 待测试","link":"/2018/11/01/java/Spring-Boot/Spring-boot%E8%AE%BF%E9%97%AE%E6%97%A5%E5%BF%97/"},{"title":"Spring-boot部署","text":"spring-boot打包jar文件 使用nohup命令使其后台运行1$ nohup /usr/local/java/bin/java -jar /opt/bootapp/spring-boot-1.0-SNAPSHOT.jar &gt; log.file 2&gt;&amp;1 &amp; 作为系统init.d服务安装参考：deployment-initd-service 作为系统systemd服务安装systemd是System V init系统的后继者，现在许多现代Linux发行版都在使用它。虽然可以继续使用init.d脚本 systemd，但也可以使用systemd “服务”脚本启动Spring Boot应用程序。 创建Systemd service文件在/etc/systemd/system目录中新建bootapp.service (bootapp可任意) 文件。 123456789101112[Unit]Description=myapp-cpnspAfter=syslog.target[Service]WorkingDirectory=/opt/bootappExecStart=/opt/java/jdk1.8.0_101/bin/java -jar /opt/bootapp/cpnsp-api-1.0.0-SNAPSHOT.jarExecStop=/bin/kill $MAINPIDSuccessExitStatus=143[Install]WantedBy=multi-user.target ExecStart可以写执行命令，也可以写脚本所在路径。 可进一步丰富此配置，可增加 Group、User、Restart 等配置 jar 包的执行用户组。 注意，与作为init.d服务运行时不同，运行应用程序的用户，PID文件和控制台日志文件由其systemd自身管理，因此必须使用“服务”脚本中的相应字段进行配置。有关更多详细信息，请参阅 服务单元配置手册页。 整合到systemctl 添加到systemctl 12$ systemctl enable bootapp.serviceCreated symlink /etc/systemd/system/multi-user.target.wants/bootapp.service → /etc/systemd/system/bootapp.service. 启动 1$ systemctl start bootapp.service 其它可用命令：status、stop 等，具体可参见 Systemd 文档 重新加载bootapp.service文件 (修改bootapp.service后执行) 1$ systemctl daemon-reload 查看项目日志： 12$ journalctl -u bootapp$ journalctl -u bootapp service 参考：deployment-service systemd.service、spring-boot jar包的运行方式","link":"/2018/08/29/java/Spring-Boot/Spring-boot%E9%83%A8%E7%BD%B2/"},{"title":"将spring-boot安装为systemd服务","text":"springboot项目使用maven打成的jar文件，使用systemd安装为服务进行管理。 1、新建项目的systemd管理文件boot_cpnspcms.service vim /etc/systemd/system/boot_cpnspcms.service 123456789101112[Unit]Description=spring-boot-cpnspcmsAfter=syslog.target[Service]WorkingDirectory=/ssdb1/bootserver/boot8100/cpnspcmsExecStart=/usr/local/java/jdk1.8.0_231/bin/java -jar /ssdb1/bootserver/boot8100/cpnspcms/cpnsp-api-1.0.0-SNAPSHOT.jar --server.port=8100 --name=cpnspcms_boxExecStop=/bin/kill $MAINPIDSuccessExitStatus=143[Install]WantedBy=multi-user.target 2、管理 123$ systemctl daemon-reload$ systemctl enable boot_cpnspcms.service$ systemctl start boot_cpnspcms.service 3、查看状态 1$ systemctl status boot_cpnspcms.service 4、查看服务日志 1$ vim /var/log/syslog 参考：将spring boot安装为systemd服务 及之前的一篇记录：https://myqzf.github.io/2018/08/29/java/Spring-Boot/Spring-boot%E9%83%A8%E7%BD%B2/","link":"/2019/11/27/java/Spring-Boot/%E5%B0%86springboot%E5%AE%89%E8%A3%85%E4%B8%BAsystemd%20%E6%9C%8D%E5%8A%A1/"},{"title":"HttpCilent(一)","text":"HttpCilent 超文本传输协议（HTTP）是当今Internet上使用的最重要的协议之一。尽管java.net包提供了通过HTTP访问资源的基本功能，但它并未提供许多应用程序所需的完全灵活性或功能。HttpClient提供了一个高效，且功能丰富的包。 请求执行http请求HttpClient的支持了在HTTP/1.1规范中定义的所有HTTP方法：GET，HEAD， POST，PUT，DELETE， TRACE和OPTIONS。每个方法类型对应一个特定的类HttpGet， HttpHead，HttpPost， HttpPut，HttpDelete， HttpTrace，和HttpOptions。 12HttpGet httpget = new HttpGet( \"http://www.google.com/search?hl=en&amp;q=httpclient&amp;btnG=Google+Search&amp;aq=f&amp;oq=\"); HttpClient提供了URIBuilder实用程序类来简化请求URI的创建和修改。 1234567891011URI uri = new URIBuilder() .setScheme(\"http\") .setHost(\"www.google.com\") .setPath(\"/search\") .setParameter(\"q\", \"httpclient\") .setParameter(\"btnG\", \"Google Search\") .setParameter(\"aq\", \"f\") .setParameter(\"oq\", \"\") .build();HttpGet httpget = new HttpGet(uri);System.out.println(httpget.getURI()); stdout &gt; 1http://www.google.com/search?q=httpclient&amp;btnG=Google+Search&amp;aq=f&amp;oq= HTTP响应HTTP响应是服务器在接收并解释请求消息后发送回客户端的消息。该消息的第一行包括协议版本，后跟数字状态代码及其相关的文本短语。 1234567HttpResponse response = new BasicHttpResponse(HttpVersion.HTTP_1_1, HttpStatus.SC_OK, \"OK\");System.out.println(response.getProtocolVersion());System.out.println(response.getStatusLine().getStatusCode());System.out.println(response.getStatusLine().getReasonPhrase());System.out.println(response.getStatusLine().toString()); stdout &gt; 1234HTTP/1.1200OKHTTP/1.1 200 OK HTTP message headersHTTP消息可以包含许多描述消息属性的标题，例如内容长度，内容类型等。HttpClient提供了检索，添加，删除和枚举标头的方法。 123456789101112HttpResponse response = new BasicHttpResponse(HttpVersion.HTTP_1_1, HttpStatus.SC_OK, \"OK\");response.addHeader(\"Set-Cookie\", \"c1=a; path=/; domain=localhost\");response.addHeader(\"Set-Cookie\", \"c2=b; path=\\\"/\\\", c3=c; domain=\\\"localhost\\\"\");Header h1 = response.getFirstHeader(\"Set-Cookie\");System.out.println(h1);Header h2 = response.getLastHeader(\"Set-Cookie\");System.out.println(h2);Header[] hs = response.getHeaders(\"Set-Cookie\");System.out.println(hs.length); stdout &gt; 123Set-Cookie: c1=a; path=/; domain=localhostSet-Cookie: c2=b; path=\"/\", c3=c; domain=\"localhost\"2 获取给定类型的所有标头的最有效方法是使用HeaderIterator接口。 123456789HttpResponse response = new BasicHttpResponse(HttpVersion.HTTP_1_1, HttpStatus.SC_OK, \"OK\");response.addHeader(\"Set-Cookie\", \"c1=a; path=/; domain=localhost\");response.addHeader(\"Set-Cookie\", \"c2=b; path=\\\"/\\\", c3=c; domain=\\\"localhost\\\"\");HeaderIterator it = response.headerIterator(\"Set-Cookie\");while (it.hasNext()) { System.out.println(it.next());} stdout &gt; 12Set-Cookie: c1=a; path=/; domain=localhostSet-Cookie: c2=b; path=\"/\", c3=c; domain=\"localhost\" HeaderIterator还提供了将HTTP消息解析为单个头元素的便捷方法。 123456789101112131415HttpResponse response = new BasicHttpResponse(HttpVersion.HTTP_1_1, HttpStatus.SC_OK, \"OK\");response.addHeader(\"Set-Cookie\", \"c1=a; path=/; domain=localhost\");response.addHeader(\"Set-Cookie\", \"c2=b; path=\\\"/\\\", c3=c; domain=\\\"localhost\\\"\");HeaderElementIterator it = new BasicHeaderElementIterator( response.headerIterator(\"Set-Cookie\"));while (it.hasNext()) { HeaderElement elem = it.nextElement(); System.out.println(elem.getName() + \" = \" + elem.getValue()); NameValuePair[] params = elem.getParameters(); for (int i = 0; i &lt; params.length; i++) { System.out.println(\" \" + params[i]); }} stdout &gt; 1234567c1 = apath=/domain=localhostc2 = bpath=/c3 = cdomain=localhost HTTP entityHTTP消息可以携带与请求或响应相关联的内容实体。实体可以在某些请求和某些响应中找到，因为它们是可选的。使用实体的请求称为包含实体的请求。HTTP规范定义了两个封闭请求方法的实体：POST和 PUT。通常http响应会包含一个内容实体。当然也有例外的情况，如应对 HEAD方法204 No Content， 304 Not Modified，205 Reset Content 响应。 HttpClient根据来源的不同，划分了三种不同的Http实体内容。 streamed: 内容从流中接收，或在运行中生成，包括从HTTP响应接收的实体。streamed实体通常不可重复。 self-contained: 内容在内存中或通过独立于连接或其他实体的方式获得。自包含实体通常是可重复的。这种类型的实体主要是封装HTTP请求的实体。 wrapping: 内容从另一个实体获得。 可重复的实体实体可以是可重复的，这意味着其内容可以被多次读取。这仅适用于自包含的实体（如 ByteArrayEntity或 StringEntity）。 使用HTTP实体如果要从Http实体中读取内容，我们可以利用HttpEntity类的getContent方法来获取实体的输入流（java.io.InputStream)，或者利用HttpEntity类的writeTo(OutputStream)方法来获取输出流，这个方法会把所有的内容写入到给定的流中。 取Content-Type和Content-Length两个头消息（如果有的话）。由于Content-Type包含mime-types的字符编码，比如text/plain或者text/html,HttpEntity类的getContentEncoding()方法就是读取这个编码的。如果头信息不存在，getContentLength（）会返回-1,getContentType()会返回NULL。如果Content-Type信息存在，就会返回一个Header类。 1234567StringEntity myEntity = new StringEntity(\"important message\", ContentType.create(\"text/plain\", \"UTF-8\"));System.out.println(myEntity.getContentType());System.out.println(myEntity.getContentLength());System.out.println(EntityUtils.toString(myEntity));System.out.println(EntityUtils.toByteArray(myEntity).length); stdout &gt; 1234Content-Type: text/plain; charset=utf-817important message17 确保底层的资源连接被释放为了确保正确释放系统资源，必须关闭与实体关联的内容流或响应本身. 1234567891011121314151617CloseableHttpClient httpclient = HttpClients.createDefault();HttpGet httpget = new HttpGet(\"http://localhost/\");CloseableHttpResponse response = httpclient.execute(httpget);try { HttpEntity entity = response.getEntity(); if(entity != null) { InputStream instream = entity.getContent(); try { //do something useful }finally { instream.close(); } }}finally { response.close();} 关闭内容流和关闭响应之间的区别在于前者将尝试通过使用实体内容来保持底层连接处于活动状态，而后者立即关闭并丢弃连接。 使用实体内容HttpClient推荐使用HttpEntity的getConent()方法或者HttpEntity的writeTo(OutputStream)方法来消耗掉Http实体内容。HttpClient也提供了EntityUtils这个类，这个类提供一些静态方法可以更容易地读取Http实体的内容和信息。和以java.io.InputStream流读取内容的方式相比，EntityUtils提供的方法可以以字符串或者字节数组的形式读取Http实体。但是，强烈不推荐使用EntityUtils这个类，除非目标服务器发出的响应是可信任的，并且http响应实体的长度不会过大。 12345678910111213141516CloseableHttpClient httpclient = HttpClients.createDefault();HttpGet httpget = new HttpGet(\"http://localhost/\");CloseableHttpResponse response = httpclient.execute(httpget);try { HttpEntity entity = response.getEntity(); if (entity != null) { long len = entity.getContentLength(); if (len != -1 &amp;&amp; len &lt; 2048) { System.out.println(EntityUtils.toString(entity)); } else { // Stream content out } }} finally { response.close();} 在某些情况下，可能需要能够多次读取实体内容。在这种情况下，实体内容必须以某种方式缓冲，无论是在内存中还是在磁盘上。实现这一目标的最简单方法是将原始实体与BufferedHttpEntity类包装在一起。这将导致原始实体的内容被读入内存缓冲区。 12345CloseableHttpResponse response = &lt;...&gt; HttpEntity entity = response.getEntity（）; if（entity！= null）{ entity = new BufferedHttpEntity（entity）; } 创建HTTP实体内容HttpClient提供了几个最常见的数据的容器类，这些类可以通过http连接高效地输出Http实体内容。如字符串，字节数组，输入流，和文件：StringEntity， ByteArrayEntity， InputStreamEntity，和 FileEntity。 1234File file = new File(\"somefile.txt\");FileEntity entity = new FileEntity(file, ContentType.create(\"text/plain\", Consts.UTF_8));HttpPost httppost = new HttpPost(\"http://localhost/action.do\");httppost.setEntity(entity); 注意 :InputStreamEntity不可重复，因为它只能从基础数据流中读取一次。建议，实通过继承HttpEntity这个自包含的类来自定义HttpEntity类，而不是直接使用InputStreamEntity这个类。FileEntity就是一个很好的起点（FileEntity就是继承的HttpEntity）。 HTML表单许多应用程序需要模拟提交HTML表单的过程，例如，登录到Web应用程序或提交输入数据。HttpClient提供实体类 UrlEncodedFormEntity来实现该过程。 123456List&lt;NameValuePair&gt; formparams = new ArrayList&lt;NameValuePair&gt;();formparams.add(new BasicNameValuePair(\"param1\", \"value1\"));formparams.add(new BasicNameValuePair(\"param2\", \"value2\"));UrlEncodedFormEntity entity = new UrlEncodedFormEntity(formparams, Consts.UTF_8);HttpPost httppost = new HttpPost(\"http://localhost/handler.do\");httppost.setEntity(entity); 该UrlEncodedFormEntity实例将使用所谓的URL编码来编码参数并生成以下内容： 1param1=value1&amp;param2=value2 内容分块一般来说，推荐让HttpClient自己根据Http消息传递的特征来选择最合适的传输编码。当然，如果非要手动控制也是可以的，可以通过设置HttpEntity的setChunked()为true。请注意：HttpClient仅会将这个参数看成是一个建议。如果Http的版本（如http 1.0)不支持内容分块，那么这个参数就会被忽略。 1234StringEntity entity = new StringEntity(\"important message\", ContentType.create(\"text/plain\", Consts.UTF_8));entity.setChunked(true);HttpPost httppost = new HttpPost(\"http://localhost/action.do\");httppost.setEntity(entity); 响应处理最方便的处理http响应的方法就是使用ResponseHandler接口，这个接口中有handleResponse(HttpResponse response)方法。使用这个方法，用户完全不用关心http连接管理器。当使用ResponseHandler时，HttpClient会自动地将Http连接释放给Http管理器，即使http请求失败了或者抛出了异常。 123456789101112131415161718192021222324252627CloseableHttpClient httpclient = HttpClients.createDefault();HttpGet httpget = new HttpGet(\"http://localhost/json\");ResponseHandler&lt;MyJsonObject&gt; rh = new ResponseHandler&lt;MyJsonObject&gt;() { @Override public JsonObject handleResponse( final HttpResponse response) throws IOException { StatusLine statusLine = response.getStatusLine(); HttpEntity entity = response.getEntity(); if (statusLine.getStatusCode() &gt;= 300) { throw new HttpResponseException( statusLine.getStatusCode(), statusLine.getReasonPhrase()); } if (entity == null) { throw new ClientProtocolException(\"Response contains no content\"); } Gson gson = new GsonBuilder().create(); ContentType contentType = ContentType.getOrDefault(entity); Charset charset = contentType.getCharset(); Reader reader = new InputStreamReader(entity.getContent(), charset); return gson.fromJson(reader, MyJsonObject.class); }};//设置responseHandler，当执行http方法时，就会返回MyJsonObject对象。MyJsonObject myjson = client.execute(httpget, rh); HttpClient 接口对于Http请求执行过程来说，HttpClient的接口有着必不可少的作用。HttpClient接口没有对Http请求的过程做特别的限制和详细的规定，连接管理、状态管理、授权信息和重定向处理这些功能都单独实现。这样用户就可以更简单地拓展接口的功能（比如缓存响应内容）。 一般说来，HttpClient实际上就是一系列特殊的handler或者说策略接口的实现，这些handler负责处理Http协议的某一方面，比如重定向、认证处理、有关连接持久性和keep alive持续时间的决策。这样就允许用户使用自定义的参数来代替默认配置，实现个性化的功能。 12345678910111213ConnectionKeepAliveStrategy keepAliveStrat = new DefaultConnectionKeepAliveStrategy() { @Override public long getKeepAliveDuration(HttpResponse response, HttpContext context) { long keepAlive = super.getKeepAliveDuration(response, context); if(keepAlive == -1) { //如果服务器没有设置keep-alive这个参数，我们就把它设置成5秒 keepAlive = 5000; } return keepAlive; }};//自定义httpclientCloseableHttpClient httpclient = HttpClients.custom().setKeepAliveStrategy(keepAliveStrat).build(); HttpClient线程安全性HttpClient已经实现了线程安全。所以建议在实例化HttpClient后，可以重用于多个请求使用。 HttpClient资源释放当一个CloseableHttpClient的实例不再被使用，并且它的作用范围即将失效，和它相关的连接必须被关闭，关闭方法可以调用CloseableHttpClient的close()方法。 123456CloseableHttpClient httpclient = HttpClients.createDefault();try { &lt;...&gt;} finally { httpclient.close();} 1.3 Http执行上下文最初，HTTP被设计为无状态，面向响应请求的协议。但是，现实世界的应用程序通常需要能够通过几个逻辑上相关的请求 - 响应交换来持久保存状态信息。为了使应用程序能够维持处理状态，HttpClient允许在特定的执行上下文中执行HTTP请求，称为HTTP上下文。如果在连续请求之间重用相同的上下文，则多个逻辑相关的请求可以参与逻辑会话。HTTP上下文就和一个java.util.Map&lt;String, Object&gt;功能类似。它实际上就是一个任意命名的值的集合。应用程序可以在Http请求执行前填充上下文的值，也可以在请求执行完毕后检查上下文。 HttpContext可以包含任意对象，因此在多个线程之间共享可能不安全。建议每个执行线程维护自己的上下文。 在Http请求执行的过程中，HttpClient会自动添加下面的属性到Http上下文中： HttpConnection 表示客户端与服务器之间的连接。 HttpHost 表示连接目标的实例。 HttpRoute 表示全部的连接路由。 HttpRequest表示实际HTTP请求的实例。在执行上下文中，最终的HttpRequest对象会代表http消息的状态。Http/1.0和Http/1.1都默认使用相对的uri。但是如果使用了非隧道模式的代理服务器，就会使用绝对路径的uri。 HttpResponse 表示实际HTTP响应的实例。 java.lang.Boolean 表示是否请求被成功的发送给目标服务器。 RequestConfig 表示http request的配置信息。 java.util.List&lt;URI&gt; 表示Http响应中的所有重定向地址。 可以使用HttpClientContext适配器类来简化与上下文状态的交互。 123456HttpContext context = &lt;...&gt;HttpClientContext clientContext = HttpClientContext.adapt(context);HttpHost target = clientContext.getTargetHost();HttpRequest request = clientContext.getRequest();HttpResponse response = clientContext.getResponse();RequestConfig config = clientContext.getRequestConfig(); 同一个逻辑会话中的多个Http请求，应该使用相同的Http上下文来执行，这样就可以自动地在http请求中传递会话上下文和状态信息。 在下面的例子中，我们在开头设置的参数，会被保存在上下文中，并且会应用到后续的http请求中。 123456789101112131415161718192021CloseableHttpClient httpclient = HttpClients.createDefault();RequestConfig requestConfig = RequestConfig.custom() .setSocketTimeout(1000) .setConnectTimeout(1000) .build();HttpGet httpget1 = new HttpGet(\"http://localhost/1\");httpget1.setConfig(requestConfig);CloseableHttpResponse response1 = httpclient.execute(httpget1, context);try { HttpEntity entity1 = response1.getEntity();} finally { response1.close();}HttpGet httpget2 = new HttpGet(\"http://localhost/2\");CloseableHttpResponse response2 = httpclient.execute(httpget2, context);try { HttpEntity entity2 = response2.getEntity();} finally { response2.close();} Http 协议拦截器HTTP协议拦截器是一种实现一个特定的方面的HTTP协议的代码程序。通常情况下，协议拦截器会将一个或多个头消息加入到接受或者发送的消息中。协议拦截器也可以操作消息的内容实体—消息内容的压缩/解压缩就是个很好的例子。通常，这是通过使用“装饰”开发模式，一个包装实体类用于装饰原来的实体来实现。一个拦截器可以合并，形成一个逻辑单元。 协议拦截器可以通过共享信息协作——比如处理状态——通过HTTP执行上下文。协议拦截器可以使用Http上下文存储一个或者多个连续请求的处理状态。 通常，只要拦截器不依赖于一个特定状态的http上下文，那么拦截执行的顺序就无所谓。如果协议拦截器有相互依赖关系，必须以特定的顺序执行，那么它们应该按照特定的顺序加入到协议处理器中。 协议处理器必须是线程安全的。类似于servlets，协议拦截器不应该使用变量实体，除非访问这些变量是同步的（线程安全的）。 下面是个例子，讲述了本地的上下文时如何在连续请求中记录处理状态的： 12345678910111213141516171819202122CloseableHttpClient httpclient = HttpClients.custom().addInterceptorLast(new HttpRequestInterceptor() { @Override public void process(HttpRequest request, HttpContext context) throws HttpException, IOException { AtomicInteger count = (AtomicInteger)context.getAttribute(\"count\"); request.addHeader(\"Count\", Integer.toString(count.getAndIncrement())); }}).build();AtomicInteger count = new AtomicInteger(1);HttpClientContext localContext = HttpClientContext.create();localContext.setAttribute(\"count\", count);HttpGet httpget = new HttpGet(\"http://localhost\");for(int i = 0; i&lt;10; i++) { CloseableHttpResponse response = httpclient.execute(httpget, localContext); try { HttpEntity entity = response.getEntity(); }finally { response.close(); } } 上面代码在发送http请求时，会自动添加Count这个header，可以使用wireshark抓包查看。 异常处理HttpClient会被抛出两种类型的异常，一种是java.io.IOException，当遇到I/O异常时抛出（socket超时，或者socket被重置）;另一种是HttpException,表示Http失败，如Http协议使用不正确。通常认为，I/O错误时不致命、可修复的，而Http协议错误是致命了，不能自动修复的错误。注意，HttpClient实现重新抛出HttpException 如ClientProtocolException，它是java.io.IOException的子类。这使程序能够从单个catch子句处理I / O错误和协议违规。 HTTP传输安全Http协议不能满足所有类型的应用程序，HTTP是一种简单的面向请求/响应的协议，最初设计用于支持静态或动态生成的内容检索。它从未打算支持事务操作。例如，如果HTTP服务器成功接收和处理请求，生成响应并将状态代码发送回客户端，这个过程是Http协议应该保证的。如果客户端由于读取超时，请求取消或系统崩溃而未能完全接收响应，则服务器将不会尝试回滚事务。如果客户端决定重试相同的请求，则服务器将不可避免地多次执行同一事务。在某些情况下，这可能会导致应用程序数据损坏或应用程序状态不一致。 尽管HTTP从未被设计为支持事务处理，但如果满足某些条件，它仍可用作关键任务应用程序的传输协议。为确保HTTP传输层安全，系统必须确保应用层上HTTP方法的幂等性。 方法的幂等性应用程序需要正确地处理同一方法多次执行造成的影响。例如，这可以通过提供唯一的事务id和通过避免执行相同逻辑操作的其他手段来实现。 注意：这个问题不只是HttpClient才会有，基于浏览器的应用程序也会遇到Http方法不幂等的问题。 HttpClient默认把非实体方法get、head方法看做幂等方法，把实体方法post、put方法看做非幂等方法。 异常自动修复默认情况下，HttpClient会尝试自动修复I/O异常。默认的自动恢复机制仅限于一些已知安全的异常情况。 HttpClient不会尝试修复任何逻辑或者http协议错误（即从HttpException衍生出来的异常）。 HttpClient将自动重试那些被认为是幂等的方法。 会自动再次发送遇到transport异常的方法，前提是Http请求仍旧保持着连接（即请求尚未完全传输到服务器），HttpClient将自动重试那些因传输异常而失败的方法。 请求重试HANDLER如果要自定义异常处理机制，我们需要实现HttpRequestRetryHandler接口。 12345678910111213141516171819202122232425262728293031323334353637HttpRequestRetryHandler retryHandler = new HttpRequestRetryHandler() { @Override public boolean retryRequest(IOException exception, int executionCount, HttpContext context) { if(executionCount &gt;= 5) { //超过最大重试次数 return false; } if(exception instanceof InterruptedIOException) { //超时 return false; } if(exception instanceof UnknownHostException) { //目标服务不可达 return false; } if(exception instanceof ConnectTimeoutException) { //连接被拒绝 return false; } if(exception instanceof SSLException) { //ssl握手异常 return false; } HttpClientContext clientContext = HttpClientContext.adapt(context); HttpRequest request = clientContext.getRequest(); boolean idempotent = !(request instanceof HttpEntityEnclosingRequest); if(idempotent) { //如果请求时幂等的，就再次尝试 return false; } return false; }}; CloseableHttpClient httpclient = HttpClients.custom() .setRetryHandler(retryHandler) .build(); 终止请求在某些情况下，由于目标服务器上的高负载或客户端上发出的并发请求太多，HTTP请求执行无法在预期的时间范围内完成。在这种情况下，可能需要提前终止请求并取消阻止在I / O操作中阻塞的执行线程。可以在执行的任何阶段通过调用HttpUriRequest#abort()方法中止由HttpClient执行的HTTP请求 。此方法是线程安全的，可以从任何线程调用。当HTTP请求中止时，其执行线程 - 即使当前在I / O操作中被阻塞 - 也可以通过抛出一个InterruptedIOException来解除阻塞 ，释放资源。 重定向处理HttpClient会自动处理所有类型的重定向，除了那些Http规范明确禁止的重定向。See Other (status code 303) redirects on POST and PUT requests are converted to GET requests as required by the HTTP specification. 可以使用自定义的重定向策略来放松Http规范对Post方法重定向的限制。 12345////LaxRedirectStrategy可以自动重定向所有的HEAD，GET，POST请求，解除了http规范对post请求重定向的限制。LaxRedirectStrategy redirectStrategy = new LaxRedirectStrategy(); CloseableHttpClient httpclient = HttpClients.custom() .setRedirectStrategy(redirectStrategy) .build(); HttpClient通常必须在执行过程中重写请求消息。默认情况下，HTTP / 1.0和HTTP / 1.1通常使用相对请求URI。同样，原始请求可能会多次从一个位置重定向到另一个位置。可以使用原始请求和上下文构建最终解释的绝对HTTP路径。URIUtils 类的 resolve`方法可用于构建用于生成最终请求的绝对URI。此方法包括重定向请求或原始请求中的最后一个片段标识符。 12345678910111213CloseableHttpClient httpclient = HttpClients.createDefault();HttpClientContext context = HttpClientContext.create();HttpGet httpget = new HttpGet(\"http://localhost:8080/\");CloseableHttpResponse response = httpclient.execute(httpget, context);try { HttpHost target = context.getTargetHost(); List&lt;URI&gt; redirctLocations = context.getRedirectLocations(); URI location = URIUtils.resolve(httpget.getURI(), target, redirctLocations); System.out.println(\"Final HTTP location: \"+ location.toASCIIString()); // 一般会取得一个绝对路径的uri}finally { response.close();} 参考：http://hc.apache.org/httpcomponents-client-4.5.x/ https://www.yeetrack.com/?p=773","link":"/2018/09/27/java/httpclient/HttpClient%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"HttpClient（三）- HTTP状态管理","text":"HTTP状态管理 最初，HTTP被设计为一种无状态的，面向请求/响应的协议，它没有对跨越几个逻辑相关的请求/响应交换的有状态会话做出特殊规定。随着HTTP协议的普及和采用越来越多的系统开始将其用于应用程序，它从未打算用于例如电子商务应用程序的传输。因此，对状态管理的支持成为必要。 Netscape Communications当时是Web客户端和服务器软件的领先开发商，它基于专有规范在其产品中实现了对HTTP状态管理的支持。后来，Netscape尝试通过发布规范草案来标准化该机制。这些努力促成了通过RFC标准轨道定义的正式规范。但是，大量应用程序中的状态管理仍然主要基于Netscape草案，并且与官方规范不兼容。Web浏览器的所有主要开发人员都被迫兼容这两种协议，这极大地促成了标准合规性的碎片化。 3.1、HTTP cookieHTTP cookie是HTTP代理和目标服务器可以交换以维持会话的令牌或短状态信息包。Netscape的工程师过去常把它称为“magic cookie”。 HttpClient使用Cookie接口来表示抽象cookie。在其最简单的形式中，HTTP cookie仅仅是名称/值对。通常，HTTP cookie还包含许多属性，例如有效的域，版本号，一个指定此cookie适用的源服务器上的URL子集的路径，以及cookie有效期。 SetCookie接口表示由服务器发给HTTP代理的一个Set-Cookie响应头，以维持一个会话状态。SetCookie2接口对SetCookie接口进行了拓展，添加了Set-Cookie2方法。 ClientCookie接口继承了Cookie接口，并进行了功能扩展，例如能够取出服务器发送来的原始cookie属性。这对于生成Cookie 标头很重要，因为某些cookie规范要求 Cookie 被指定为Set-Cookie时才应包含某些特定的属性 。 1234567BasicClientCookie cookie = new BasicClientCookie(\"name\", \"value\");//设置有效的域和路径属性cookie.setDomain(\".mycompany.com\");cookie.setPath(\"/\");//设置服务器发送的属性cookie.setAttribute(ClientCookie.PATH_ATTR, \"/\");cookie.setAttribute(ClientCookie.DOMAIN_ATTR, \".mycompany.com\"); 3.2、Cookie规范CookieSpec接口代表了Cookie管理规范。Cookie管理规范规定了： 解析Set-Cookie标头的规则。 解析cookie的验证规则。 将给定主机名，端口和原始路径格式化成Cookie`的标头。 HttpClient附带了几个CookieSpec 实现： Standard strict：状态管理策略，符合RFC 6265第4节定义的良好行为的配置文件的语法和语义。 Standard：状态管理策略，符合RFC 6265定义的更宽松的配置文件，第4节旨在与不符合良好行为的配置文件的现有服务器进行互操作。 Netscape draft (obsolete)：此政策符合Netscape Communications发布的原始草案规范。除非绝对有必要与遗留代码兼容，否则应该避免使用它。 RFC 2965 (obsolete)：符合RFC 2965 定义的过时状态管理规范的状态管理策略。请勿在新应用程序中使用。 RFC 2109 (obsolete)：符合RFC 2109定义的过时状态管理规范的状态管理策略。请勿在新应用程序中使用。 Browser compatibility (obsolete)： 此策略致力于严密模仿旧版浏览器应用程序（如IE和FireFox）的（错误）行为。请不要在新的应用程序中使用。 Default：默认cookie策略是一种综合策略，它根据与HTTP响应一起发送的cookie的属性（例如版本属性，现在已过时）选择RFC 2965，RFC 2109或Netscape草案兼容实现。在HttpClient的下一个次要版本中，将弃用此策略以支持标准（符合RFC 6265）实现。 Ignore cookies：忽略 所有cookie。 强烈建议在新应用程序中使用其中一个Standard或 Standard strict策略。 3.3、选择Cookie策略如果需要，可以在HTTP客户端设置Cookie策略，也可在HTTP请求是覆盖指定。 1234567891011RequestConfig globalConfig = RequestConfig.custom() .setCookieSpec(CookieSpecs.DEFAULT) .build();CloseableHttpClient httpclient = HttpClients.custom() .setDefaultRequestConfig(globalConfig) .build();RequestConfig localConfig = RequestConfig.custom() .setCookieSpec(CookieSpecs.STANDARD_STRICT) .build();HttpGet httpGet = new HttpGet(\"/\");httpGet.setConfig(localConfig); 3.4、自定义Cookie策略如果要创建自定义cookie策略，就要自己实现CookieSpec接口，然后创建一个CookieSpecProvider接口来新建、初始化自定义CookieSpec接口，最后把CookieSpecProvider注册到HttpClient中。一旦我们注册了自定义策略，就可以像其他标准策略一样使用了。 1234567891011PublicSuffixMatcher publicSuffixMatcher = PublicSuffixMatcherLoader.getDefault();Registry&lt;CookieSpecProvider&gt; r = RegistryBuilder.&lt;CookieSpecProvider&gt;create() .register(CookieSpecs.DEFAULT, new DefaultCookieSpecProvider(publicSuffixMatcher)) .register(CookieSpecs.STANDARD, new RFC6265CookieSpecProvider(publicSuffixMatcher)) .register(\"easy\", new EasySpecProvider()) .build();RequestConfig requestConfig = RequestConfig.custom().setCookieSpec(\"easy\").build();CloseableHttpClient httpClient = HttpClients.custom() .setDefaultCookieSpecRegistry(r) .setDefaultRequestConfig(requestConfig) .build(); 3.5、Cookie持久化HttpClient可以使用任何存储方式的cookie store，只要这个cookie store实现了CookieStore接口。默认的CookieStore通过java.util.ArrayList简单实现了BasicCookieStore。存在在BasicCookieStore中的Cookie，当载体对象被当做垃圾回收掉后，就会丢失。如果必要，用户可以自己实现更为复杂的方式。 12345678CookieStore cookieStore = new BasicCookieStore();BasicClientCookie cookie = new BasicClientCookie(\"name\", \"value\");cookie.setDomain(\".mycompany.com\");cookie.setPath(\"/\");cookieStore.addCookie(cookie);CloseableHttpClient httpclient = HttpClients.custom() .setDefaultCookieStore(cookieStore) .build(); 3.6、 HTTP状态管理和执行上下文在Http请求执行过程中，HttpClient会自动向执行上下文中添加下面的状态管理对象： Lookup：表示实际cookie规范registry的实例，在当前上下文中的这个值优先于默认值。 CookieSpec：代表实际的Cookie规范的实例。 CookieOrigin：表示服务器的实际origin server详细信息的实例。 CookieStore：表示实际cookie存储的实例。在本地上下文中设置的此属性的值优先于默认值。 本地HttpContext对象可用于在请求执行之前自定义HTTP状态管理上下文，或在请求执行后检查其状态。还可以使用单独的执行上下文来实现每个用户（或每个线程）状态管理。在本地上下文中定义的cookie规范registry和cookie store将优先于在HTTP客户端级别设置的默认值. 123456789101112131415CloseableHttpClient httpClient = HttpClients.custom().build(); Lookup&lt;CookieSpecProvider&gt; cookieSpecReg = &lt;...&gt;;CookieStore cookieStore = &lt;...&gt;;HttpClientContext context = HttpClientContext.create();context.setCookieSpecRegistry(cookieSpecReg);context.setCookieStore(cookieStore);HttpGet httpget = new HttpGet(\"http://somehost/\");CloseableHttpResponse response = httpClient.execute(httpget, context);//cookie origin CookieOrigin cookieOrigin = context.getCookieOrigin();//Cookie specCookieSpec cookieSpec = context.getCookieSpec(); 参考：http://hc.apache.org/httpcomponents-client-4.5.x/tutorial/html/statemgmt.html","link":"/2018/11/19/java/httpclient/HttpClient%EF%BC%88%E4%B8%89%EF%BC%89-%20HTTP%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/"},{"title":"HttpClient（二）- 连接管理","text":"HttpCilent连接管理 2.1、持久连接从一个主机到另一个主机建立连接的过程非常复杂，涉及两个端点之间的多个分组交换，这可能非常耗时。连接握手的开销可能很大，尤其是对于比较小的HTTP消息，但是如果我们直接使用已经建立好的http连接来执行多个请求，则可以实现更高的数据吞吐量。 HTTP/1.1默认就支持Http连接复用。兼容HTTP/1.0的终端也可以通过声明来保持连接，实现连接复用。HTTP代理也可以在一定时间内保持连接不释放，方便后续向这个主机发送http请求。这种保持连接不释放的情况实际上是建立的持久连接。HttpClient也支持持久连接。 2.2、HTTP连接路由HttpClient既可以直接、又可以通过多个中转路由（hops）和目标服务器建立连接 - 也成为跳 。HttpClient把路由分为三种plain（明文 ），tunneled（隧道）和layered（分层）。隧道连接中使用的多个中间代理被称作代理链。 客户端直接连接到目标主机或者只通过了一个中间代理，这种就是Plain路由。客户端通过第一个代理建立连接，通过代理链tunnelling，这种情况就是Tunneled路由。不通过中间代理的路由不可能时tunneled路由。客户端在一个已经存在的连接上进行协议分层，这样建立起来的路由就是layered路由。协议只能在隧道—&gt;目标主机，或者直接连接（没有代理），这两种链路上进行分层。 2.2.1、路由计算 RouteInfo接口包含了数据包发送到目标主机过程中，经过的路由信息。HttpRoute类继承了RouteInfo接口，是RouteInfo的具体实现，这个类是不允许修改的。HttpTracker类也实现了RouteInfo接口，它是可变的，HttpClient会在内部使用这个类来探测到目标主机的剩余路由。HttpRouteDirector是个辅助类，可以帮助计算数据包的下一步路由信息。这个类也是在HttpClient内部使用的。 HttpRoutePlanner接口可以用来表示基于http上下文计算客户端到服务器的完整路由策略。HttpClient有两个HttpRoutePlanner的实现类。SystemDefaultRoutePlanner这个类基于java.net.ProxySelector，它默认使用jvm的代理配置信息，这个配置信息一般来自系统配置或者浏览器配置。DefaultProxyRoutePlanner这个类既不使用java本身的配置，也不使用系统或者浏览器的配置。它通常通过默认代理来计算路由信息。 2.2.2.、安全的HTTP连接 如果未经授权的第三方无法读取或篡改两个连接端点之间传输的信息，则可以认为HTTP连接是安全的。SSL / TLS协议是确保HTTP传输安全性的最广泛使用的技术。但是，也可以采用其他加密技术。通常，HTTP传输通过SSL / TLS加密连接分层。 2.3、HTTP连接管理器2.3.1. 管理连接和连接管理器 HTTP连接是复杂的，有状态的，线程不安全的对象，需要正确管理才能正常运行。HTTP连接在同一时间内只能由一个执行线程使用。HttpClient使用一个特殊实体来管理对HTTP连接的访问，称为HTTP连接管理器，并由HttpClientConnectionManager接口表示 。 HTTP连接管理器的目的是充当新HTTP连接的工厂，管理持久连接的生命周期以及同步对持久连接的访问，确保同一时间内只有一个线程可以访问连接。内部HTTP连接管理器使用的实例ManagedHttpClientConnection充当管理连接状态的实际连接的代理并控制I / O操作的执行，如果Http连接被释放或由其使用者显式关闭,，则底层连接将从其代理中分离并返回给管理器。即使服务使用者仍然拥有对代理实例的引用，它也不能再执行任何I / O操作或更改连接的状态。 下面的代码展示了如何从连接管理器中取得一个http连接： 1234567891011121314151617HttpClientContext context = HttpClientContext.create();HttpClientConnectionManager connMrg = new BasicHttpClientConnectionManager();HttpRoute route = new HttpRoute(new HttpHost(\"www.baidu.com\", 80));// 获取新的连接. 这里可能耗费很多时间ConnectionRequest connRequest =connMrg.requestConnection(route, null);//等待10秒 超时HttpClientConnection conn = connRequest.get(10, TimeUnit.SECONDS);try { // 如果创建连接失败 if(!conn.isOpen()) { connMrg.connect(conn, route, 1000, context); connMrg.routeComplete(conn, route, context); } // 进行自己的操作...}finally { connMrg.releaseConnection(conn, null, 1, TimeUnit.MINUTES);} 如果要终止连接，可以调用ConnectionRequest的cancel()方法。这个方法会解除被ConnectionRequest类get()方法阻塞的线程。 2.3.2.简单连接管理器 BasicHttpClientConnectionManager是个简单的连接管理器，它一次只能维护一个连接。尽管这个类是线程安全的，它在同一时间也只能被一个线程使用。BasicHttpClientConnectionManager会尽量重用旧的连接来发送后续的请求，并且使用相同的路由。如果后续请求的路由和旧连接中的路由不匹配，BasicHttpClientConnectionManager就会关闭当前连接，使用请求中的路由重新建立连接。如果当前的连接正在被占用，会抛出java.lang.IllegalStateException异常。 2.3.3、连接池管理器 PoolingHttpClientConnectionManager是一个更复杂的实现，它管理客户端连接池，并且能够为来自多个执行线程的连接请求提供服务。连接以每个路由为基础进行池化。管理员已经在池中提供持久连接的路由请求将通过从池租用连接而不是创建全新连接来进行服务。 PoolingHttpClientConnectionManager维护的连接数在每个路由基础和总数上都有限制。默认，每个路由基础上的连接不超过2个，总连接数不能超过20。在实际应用中，这个限制可能会太小了，尤其是当服务也使用Http协议时。 此示例显示如何调整连接池参数： 12345678910111213PoolingHttpClientConnectionManager cm = new PoolingHttpClientConnectionManager();//将最大总连接数增加到200cm.setMaxTotal(200);//将每条路由的默认最大连接数增加到20 cm.setDefaultMaxPerRoute(20);//将目标主机的最大连接数增加到50HttpHost localhost = new HttpHost(\"localhost\", 80);cm.setMaxPerRoute(new HttpRoute(localhost), 50);CloseableHttpClient httpclient = HttpClients.custom().setConnectionManager(cm).build();} 2.3.4.关闭连接管理器 当一个HttpClient的实例不在使用，或者已经脱离它的作用范围，我们需要关掉它的连接管理器，来关闭掉所有的连接，释放掉这些连接占用的系统资源。 12CloseableHttpClient httpClient = &lt;...&gt;httpClient.close(); 2.4、多线程请求执行当使用了请求连接池管理器（比如PoolingClientConnectionManager）后，HttpClient就可以同时执行多个线程的请求了。 PoolingClientConnectionManager会根据它的配置来分配请求连接。如果连接池中的所有连接都被占用了，那么后续的请求就会被阻塞，直到有连接被释放回连接池中。为了防止永远阻塞的情况发生，我们可以把http.conn-manager.timeout的值设置成一个整数。如果在超时时间内，没有可用连接，就会抛出ConnectionPoolTimeoutException异常。 1234567891011121314151617181920212223242526PoolingHttpClientConnectionManager cm = new PoolingHttpClientConnectionManager();CloseableHttpClient httpClient = HttpClients.custom() .setConnectionManager(cm) .build();//要执行GET的URIString[] uriToGet = { \"http://www.baidu.com/\", \"http://www.qq.com/\", \"http://www.sohu.com/\", \"http://www.sina.com.cn/\"};//为每个url创建一个线程GetThread[] threads = new GetThread[uriToGet.length];for(int i = 0; i&lt;threads.length; i++) { HttpGet httpget = new HttpGet(uriToGet[i]); threads[i] = new GetThread(httpClient, httpget);}//启动线程for(int j = 0; j&lt;threads.length;j++) { threads[j].start();}for (int j = 0; j &lt; threads.length; j++) { threads[j].join();} 虽然HttpClient实例是线程安全的，并且可以在多个执行线程之间共享，但强烈建议每个线程维护自己的专用实例HttpContext。 12345678910111213141516171819202122232425262728public class GetThread extends Thread { private final CloseableHttpClient httpClient; private final HttpContext context; private final HttpGet httpget; public GetThread(CloseableHttpClient httpClient, HttpGet httpget) { this.httpClient = httpClient; this.context = HttpClientContext.create(); this.httpget = httpget; } @Override public void run() { try { CloseableHttpResponse response = httpClient.execute(httpget, context); try { HttpEntity entity = response.getEntity(); //EntityUtils.consume(entity); }finally { response.close(); } }catch(ClientProtocolException ex) { // Handle protocol errors }catch(IOException e) { // Handle I/O errors } }} 2.5、连接回收策略经典阻塞I / O模型的主要缺点之一是网络套接字只有在I / O操作中被阻塞时才能对I / O事件作出反应。当连接释放回管理器时，它可以保持活动状态，但它无法监视套接字的状态并对任何I / O事件做出反应。如果连接在服务器端关闭，客户端连接也无法检测到连接状态的变化（也就无法根据连接状态的变化，关闭本地的socket）。 HttpClient为了缓解此问题带来的影响，会在使用某个连接前，监测这个连接是否已经过时，如果服务器端关闭了连接，那么连接就会失效。这种过时检查并不是100%有效，并且会给每个请求增加10到30毫秒额外开销。唯一可行的办法是建立一个监控线程，来专门回收由于长时间不活动而被判定为失效的连接。这个监控线程可以周期性的调用ClientConnectionManager类的closeExpiredConnections()方法来关闭过期的连接，回收连接池中被关闭的连接。它也可以选择性的调用ClientConnectionManager类的closeIdleConnections()方法来关闭一段时间内不活动的连接。 1234567891011121314151617181920212223242526272829303132public class IdleConnectionMonitorThread extends Thread { private final HttpClientConnectionManager connMgr; private volatile boolean shutdown; public IdleConnectionMonitorThread(HttpClientConnectionManager connMgr) { super(); this.connMgr = connMgr; } public void run() { try { while(!shutdown) { synchronized (this) { wait(5000); //关闭过期的连接 connMgr.closeExpiredConnections(); //可选的，关闭闲置时间超过30秒的连接 connMgr.closeIdleConnections(30, TimeUnit.SECONDS); } } }catch(InterruptedException ex) { } } public void shutdown() { shutdown = true; synchronized (this) { notifyAll(); } }} 2.6、连接存活策略Http规范没有规定一个持久连接应该保持多长时间。有些Http服务器使用非标准的Keep-Alive头消息和客户端进行交互，通知服务器端打算保持连接的时间段。如果可用，HttpClient会利用这个头消息。如果服务器返回的响应中没有包含Keep-Alive头消息，HttpClient会认为这个连接可以永远保持。然而，很多服务器都会在不通知客户端的情况下，关闭一定时间内不活动的连接，来节省服务器资源。在某些情况下默认的策略显得太乐观，我们可能需要自定义连接存活策略。 12345678910111213141516171819202122232425262728ConnectionKeepAliveStrategy mystrategy = new ConnectionKeepAliveStrategy() { @Override public long getKeepAliveDuration(HttpResponse response, HttpContext context) { HeaderElementIterator it = new BasicHeaderElementIterator(response.headerIterator(HTTP.CONN_KEEP_ALIVE)); while(it.hasNext()) { HeaderElement he = it.nextElement(); String param = he.getName(); String value = he.getValue(); if(value!=null &amp;&amp; param.equalsIgnoreCase(\"timeout\")) { try { return Long.parseLong(value) * 1000; }catch(NumberFormatException ignore) { } } } HttpHost target = (HttpHost) context.getAttribute(HttpClientContext.HTTP_TARGET_HOST); if(\"www.naught-server.com\".equalsIgnoreCase(target.getHostName())){ return 5 * 1000; }else { return 30 * 1000; } }};CloseableHttpClient client = HttpClients.custom() .setKeepAliveStrategy(mystrategy) .build(); 2.7、连接套接字工厂HTTP连接使用java.net.Socket对象来处理通过线路的数据传输。但是，它们依赖于ConnectionSocketFactory接口来创建，初始化和连接套接字。这使HttpClient的用户能够在运行时提供特定于应用程序的套接字初始化代码。PlainConnectionSocketFactory是创建和初始化普通（未加密）套接字的默认工厂。 创建socket和使用socket连接到目标主机这两个过程是分离的，所以我们可以在连接发生阻塞时，关闭socket连接。 1234567HttpClientContext cleintContext = HttpClientContext.create();PlainConnectionSocketFactory sf = PlainConnectionSocketFactory.getSocketFactory();Socket socket = sf.createSocket(cleintContext);int timout = 1000;HttpHost target = new HttpHost(\"localhost\");InetSocketAddress remoteAddress = new InetSocketAddress(InetAddress.getByAddress(new byte[] {127,0,0,1}), 80);sf.connectSocket(timout, socket, target, remoteAddress, null, cleintContext); 2.7.1.安全SOCKET分层 LayeredConnectionSocketFactory是ConnectionSocketFactory的拓展接口。分层套接字工厂能够在现有的普通套接字上创建分层的套接字。套接字分层主要用于通过代理创建安全套接字。HttpClient附带了SSLSocketFactory实现SSL / TLS分层的功能。请注意，HttpClient不使用任何自定义加密功能。它完全依赖于标准Java加密（JCE）和安全套接字（JSEE）扩展。 2.7.2.与连接管理器集成 自定义的socket工厂类可以和指定的协议（Http、Https）联系起来，用来创建自定义的连接管理器。 1234567891011PlainConnectionSocketFactory plainsf = &lt;...&gt; LayeredConnectionSocketFactory layersf = &lt;...&gt; Registry&lt;ConnectionSocketFactory&gt; r = RegistryBuilder.&lt;ConnectionSocketFactory&gt;create() .register(\"http\", plainsf) .register(\"https\", layersf) .build();HttpClientConnectionManager cm = new PoolingHttpClientConnectionManager(r);HttpClients.custom() .setConnectionManager(cm) .build(); 2.7.3.SSL/TLS定制 HttpClient使用SSLSocketFactory来创建ssl连接。SSLSocketFactory允许用户高度定制。它可以接受javax.net.ssl.SSLContext这个类的实例作为参数，来创建自定义的ssl连接。 12345HttpClientContext clientContext = HttpClientContext.create();KeyStore keystore = KeyStore.getInstance(\"jks\");SSLContext sslContext = SSLContexts.custom() .loadTrustMaterial(keystore, new TrustSelfSignedStrategy()) .build(); 2.7.4.主机名验证 除了在SSL / TLS协议层上执行的信任验证和客户端身份验证之外，一旦建立连接，HttpClient可以选择性地验证目标主机名是否与存储在服务器的X.509证书中的名称匹配。此验证可以为服务器信任提供额外保证。javax.net.ssl.HostnameVerifier接口代表主机名验证的策略。HttpClient附带两个 javax.net.ssl.HostnameVerifier实现。重要提示：不应将主机名验证与SSL信任验证混淆。 DefaultHostnameVerifier：HttpClient使用的默认实现，主机名必须与证书指定的任何替代名称匹配，或者如果没有替代名称，则为证书主题的最具体CN。通配符可以出现在CN和任何主题中。 NoopHostnameVerifier：此主机名验证程序实质上关闭主机名验证。它接受任何SSL会话作为有效并匹配目标主机。 默认情况下，HttpClient使用该DefaultHostnameVerifier 实现。如果需要，可以指定不同的主机名验证器实现。 1234SSLContext sslContext = SSLContexts.createSystemDefault();SSLConnectionSocketFactory sslsf = new SSLConnectionSocketFactory( sslContext, NoopHostnameVerifier.INSTANCE); 从版本4.4开始，HttpClient使用由Mozilla Foundation友好维护的公共后缀列表，以确保SSL证书中的通配符不会被滥用以应用于具有公共顶级域的多个域。HttpClient附带了在发布时检索的列表的副本。该列表的最新版本可在https://publicsuffix.org/list/找到 。建议每天下载一次列表到本地副本。 123PublicSuffixMatcher publicSuffixMatcher = PublicSuffixMatcherLoader.load( PublicSuffixMatcher.class.getResource(\"my-copy-effective_tld_names.dat\"));DefaultHostnameVerifier hostnameVerifier = new DefaultHostnameVerifier(publicSuffixMatcher); 可以使用null禁用对公共服务列表的验证 。 1DefaultHostnameVerifier hostnameVerifier = new DefaultHostnameVerifier(publicSuffixMatcher); 2.8、HttpClient代理配置尽管HttpClient知道复杂的路由方案和代理链，它也支持开箱即用的简单直接或一跳代理连接。 使用代理服务器最简单的方式就是，指定一个默认的proxy参数。 12345HttpHost proxy = new HttpHost(\"someproxy\", 8080);DefaultProxyRoutePlanner routePlanner = new DefaultProxyRoutePlanner(proxy);CloseableHttpClient httpClient = HttpClients.custom() .setRoutePlanner(routePlanner) .build(); 还可以指示HttpClient使用标准JRE代理选择器来获取代理信息： 12345SystemDefaultRoutePlanner routePlanner = new SystemDefaultRoutePlanner( ProxySelector.getDefault());CloseableHttpClient httpClient = HttpClients.custom() .setRoutePlanner(routePlanner) .build(); 或者，可以提供自定义RoutePlanner 实现，以便完全控制HTTP路由计算的过程： 1234567891011HttpRoutePlanner routePlanner = new HttpRoutePlanner() { @Override public HttpRoute determineRoute(HttpHost target, HttpRequest request, HttpContext context) throws HttpException { return new HttpRoute(target, null, new HttpHost(\"someproxy\", 8080), \"https\".equalsIgnoreCase(target.getSchemeName())); }};CloseableHttpClient httpClient = HttpClients.custom() .setRoutePlanner(routePlanner) .build(); 参考：http://hc.apache.org/httpcomponents-client-4.5.x/tutorial/html/connmgmt.html#d5e405","link":"/2018/10/19/java/httpclient/HttpClient%EF%BC%88%E4%BA%8C%EF%BC%89-%20%E8%BF%9E%E6%8E%A5%E7%AE%A1%E7%90%86/"},{"title":"通过HttpClient发送https请求","text":"通过HttpClient发送https请求可能会遇到如下错误： 参考：https://stackoverflow.com/questions/1201048/allowing-java-to-use-an-untrusted-certificate-for-ssl-https-connection https://blog.csdn.net/guicaizhou/article/details/70214065","link":"/2018/11/01/java/httpclient/%E9%80%9A%E8%BF%87HttpClient%E5%8F%91%E9%80%81https%E8%AF%B7%E6%B1%82/"},{"title":"Jackson-注解","text":"@JsonAutoDetect设置属性的自动发现规则。（作用在类上） Jackson默认的属性发现规则，会查找到如下所述的属性: 所有被public修饰的字段（成员变量） 所有被public修饰的getter（即形如“getXxx()”的方法）； 所有被public修饰的setter（即形如“setXxx(value)”的方法），不管可见或不可见。 设置类属性的自动发现规则： 123456789101112131415161718192021//jason: {\"id\":111,\"name\":\"myName\"}@JsonAutoDetect(fieldVisibility = Visibility.NONE, getterVisibility = Visibility.PUBLIC_ONLY, setterVisibility = Visibility.PUBLIC_ONLY)public class Person { protected int id; public String name; public int getId(){ return id; } public void setId(int id){ this.id = id; } protected String getName(){ return name; } protected void setName(String name){ this.name = name; }}//mapper.readValue(\"{\\\"id\\\":111,\\\"name\\\":\\\"myName\\\"}\",Peson.class)//这样只有id可以被检测到，name的值会是null fieldVisibility；字段的可见级别 ，getterVisibility：getter方法检测级别，… ANY:任何级别的字段都可以自动识别。 NONE:所有字段都不可以自动识别 。 NON_PRIVATE:非private修饰的字段可以自动识别。 PROTECTED_AND_PUBLIC:被protected和public修饰的字段可以被自动识别。 PUBLIC_ONLY:只有被public修饰的字段才可以被自动识别。 @JsonIgnore忽略被注解的字段和方法对应的属性（作用在字段或方法上） 不管注解在getters上还是setters上都会忽略对应的属性。 @JsonProperty / @JsonProperty(“firstName”)用来对属性的序列化/反序列化，可以用来避免遗漏属性，同时提供对属性名称重命名。 （作用在字段或方法上） 1234567891011121314151617181920212223//json: {\"id\":111,\"first_name\":\"myName\"}public class Person { @JsonProperty //注意这里必须要有该注解，因为没有提供对应的getId和setId函数，而是其他的getter和setter，防止遗漏该属性 private int id; @JsonProperty(\"firstName\") private String first_name; public int getPersonId(){ return id; } public void setPersonId(int personId){ this.id = personId; } public String getFirstName(){ return first_name; } public void setFirstName(String firstName){ this.first_name = firstName; } } @JsonIgnoreProperties / @JsonIgnoreProperties(“tags”)用来说明有些属性在序列化/反序列化时需要忽略掉。（作用在类上） 可以将它看做是@JsonIgnore的批量操作。它还有一个重要的功能是作用在反序列化时解析字段时过滤一些未知的属性。否则通常情况下解析到我们定义的类不认识的属性便会抛出异常。 可以注明是想要忽略的属性列表如@JsonIgnoreProperties({“name”,”age”,”tags”})， 也可以注明过滤掉未知的属性如@JsonIgnoreProperties(ignoreUnknown=true) @JsonAnySetter在反序列化时用来处理遇到未知的属性的时候调用。（作用在方法上） 我们知道可以通过注解@JsonIgnoreProperties(ignoreUnknown = true)来过滤未知的属性，但是如果需要这些未知的属性该如何是好?那么@JsonAnySetter就可以派上用场了，在类上增加一个Map K/V的setter方法, 然后在这个setter方法加上@JsonAnySetter注解，反序列化时就会把未知的属性保存到map中。 123456789101112131415161718192021222324252627282930313233// json: {\"id\":111,\"name\":\"myName\",\"age\":23}@JsonIgnoreProperties(ignoreUnknown = true)public class Person { private int id; private String name; private Map&lt;String, Object&gt; otherProperties = new HsahMap&lt;&gt;(); public int getId(){ return id; } public void setId(int id){ this.id = id; } public String getName(){ return name; } public void setName(String name){ this.name = name; } public Map&lt;String, Object&gt; getOtherProperties() { return otherProperties; } @JsonAnySetter public void setOther(String name, Object value) { otherProperties.put(name, value); } @JsonAnyGetter public Map&lt;String, Object&gt; any(){ return otherProperties; } } 这样就可以通过peson.getOtherProperties.get(“age”)，获取到被忽略掉的age属性了。 @JsonAnyGetter与@JsonAnySetter对应，在序列化时，将类中的Map K/V属性序列化到json中。 （作用在方法上） 在类上增加一个 @JsonAnyGetter 方法, 该方法直接返回KV map。 @JsonCreator通常用来标注在构造方法或静态工厂方法上，使用该方法来构建实例，默认是使用无参的构造方法。 如果 Pojo 类定义了有参数的构造方法, 但没有提供无参构造方法时, 在反序列化时是会报错，有下面两个办法: 增加一个无参构造方法。 为这个有参数的构造方法, 加上 @JsonCreator 注解, 同时参数需要加上 @JsonProperty 注解. 1234567891011public class Person { private int id; private String name; @JsonCreator public Person(@JsonProperty(\"id\") int id, @JsonProperty(\"name\") String name) { this.id = id; this.name = name; }} 多态类型处理：@JsonTypeInfo用来处理多态类型的序列化及反序列化，（作用于类或接口） 注解属性： use：定义使用哪一种类型识别码，它有下面几个可选值 JsonTypeInfo.Id.CLASS：使用完全限定类名做识别。 JsonTypeInfo.Id.MINIMAL_CLASS：若基类和子类在同一包类，使用类名(忽略包名)作为识别。 JsonTypeInfo.Id.NAME：一个合乎逻辑的指定名称。 JsonTypeInfo.Id.CUSTOM：自定义识别码，由@JsonTypeIdResolver对应。 JsonTypeInfo.Id.NONE：不使用识别码。 include(可选)：指定识别码是如何被包含进去的，它有下面几个可选值： JsonTypeInfo.As.PROPERTY：作为数据的兄弟属性。 JsonTypeInfo.As.EXISTING_PROPERTY：作为POJO中已经存在的属性。 JsonTypeInfo.As.EXTERNAL_PROPERTY：作为扩展属性。 JsonTypeInfo.As.WRAPPER_OBJECT：作为一个包装的对象。 JsonTypeInfo.As.WRAPPER_ARRAY：作为一个包装的数组。 property(可选):制定识别码的属性名称： 此属性只有当use为JsonTypeInfo.Id.CLASS（若不指定property则默认为@class）、JsonTypeInfo.Id.MINIMAL_CLASS(若不指定property则默认为@c)、JsonTypeInfo.Id.NAME(若不指定property默认为@type)，include为JsonTypeInfo.As.PROPERTY、JsonTypeInfo.As.EXISTING_PROPERTY、JsonTypeInfo.As.EXTERNAL_PROPERTY时才有效。 defaultImpl(可选)： 如果类型识别码不存在或者无效，可以使用该属性来制定反序列化时使用的默认类型。 visible(可选)：是否可见 定义了类型标识符的值是否会通过JSON流成为反序列化器的一部分，默认为fale,也就是说,jackson会从JSON内容中处理和删除类型标识符再传递给JsonDeserializer。 @JsonSubTypes用来列出给定类的子类，只有当子类类型无法被检测到时才会使用它，一般是配合@JsonTypeInfo在基类上使用。（作用在类或接口上） @JsonSubTypes的值是一个@JsonSubTypes.Type[]数组，里面枚举了多态类型(value对应类)和类型的标识符值(name对应@JsonTypeInfo中的property标识名称的值，此为可选值，若不制定需由@JsonTypeName在子类上制定) 1234567@JsonTypeInfo(use = JsonTypeInfo.Id.CLASS, include = As.PROPERTY, property = \"@class\")@JsonSubTypes({@Type(value = Lion.class, name = \"lion\"),@Type(value = Elephant.class, name = \"elephant\")})public abstract class Animal { @JsonProperty(\"name\") String name;} 参见：Jackson -Json多态类型 生成的zoo.json如下： 123456789101112131415161718{ \"@class\" : \".Zoo\", \"name\" : \"Samba Wild Park\", \"city\" : \"Paz\", \"animals\" : [ { \"@class\" : \"com.qzf.jackson.model.Lion\", \"name\" : \"Simba\", \"sound\" : \"Roar\", \"type\" : \"carnviorous\", \"endangered\" : true }, { \"@class\" : \"com.qzf.jackson.model.Elephant\", \"name\" : \"Manny\", \"sound\" : \"trumpet\", \"type\" : \"herbivorous\", \"endangered\" : false } ]} @JsonFormat 定义日期类型字段格式。（作用在字段上或getter方法上） 对于日期类型为 Java.util.Calendar,Java.util.GregorianCalendar,Java.sql.Date,Java.util.Date,Java.sql.Timestamp的字段若不指定格式， jackson默认序列化为 long 类型的数据。 jackson有以下方式转换日期格式： 使用@JsonFormat注解。 123456789101112public class Person { @JsonFormat(pattern=\"yyyy-MM-dd HH:mm:ss\",timezone=\"GMT+8\") private Date updateTime； // 或者 @JsonFormat(pattern=\"yyyy-MM-dd HH:mm:ss\",timezone=\"GMT+8\") public Date getUpdateTime() { return updateTime; } public void setUpdateTime(Date updateTime) { this.updateTime = updateTime; }} 调用ObjectMapper的setDateFormat()方法。 123ObjectMapper mapper = new ObjectMapper();SimpleDateFormat outputFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");mapper.setDateFormat(outputFormat); //设置日期格式 可参考：https://www.baeldung.com/jackson-annotations","link":"/2018/12/21/java/json/Jackson-%E6%B3%A8%E8%A7%A3/"},{"title":"Jackson-简介","text":"简介Jackson 是当前用的比较广泛的，用来序列化和反序列化 JSON 的 Java 的开源框架。Jackson 是最流行的 JSON 解析器之一 。 Spring MVC、SpringBoot 的默认 JSON 解析器便是 Jackson。 Jackson 优点很多。 Jackson 所依赖的 jar 包较少 ，简单易用。与其他 Java 的 JSON 的框架 Gson 等相比， Jackson 解析大的 JSON 文件速度比较快；Jackson 运行时占用内存比较低，性能比较好；Jackson 有灵活的 API，可以很容易进行扩展和定制。 Jackson 的核心模块由三部分组成。 jackson-core，核心包，提供基于”流模式”解析的相关 API，它包括 JsonPaser (读取数据)和 JsonGenerator(写入数据)。 Jackson 内部实现正是通过高性能的流模式 API 的 JsonGenerator 和 JsonParser 来生成和解析 JSON。 jackson-annotations，注解包，提供标准注解功能； jackson-databind ，数据绑定包， 提供基于”对象绑定” 解析的相关 API （ ObjectMapper ） 和”树模型” 解析的相关 API （JsonNode）；基于”对象绑定” 解析的 API 和”树模型”解析的 API 依赖基于”流模式”解析的 API。 1、序列化与反序列化–使用示例： 1234567ObjectMapper mapper = new ObjectMapper();Person person = new Person();person.setId(1);person.setName(\"Bob\");mapper.writerWithDefaultPrettyPrinter().writeValue(System.out, person);String json = mapper.writerWithDefaultPrettyPrinter().writeValueAsString(person);//序列化Person deserializedPerson = mapper.readValue(json, Person.class);//反序列化 JacksonFeatures对ObjectMapper，ObjectWriter并ObjectReader进行功能配置，分为两大类：jackson-databind直接影响组件的高级设置；和影响Streaming API行为（JsonParser，JsonGenerator）行为的低级设置。 具体可参考：JacksonFeatures 2、配置信息Feature–使用示例： 1234567mapper.configure(SerializationFeature.INDENT_OUTPUT, true); //美化输出mapper.configure(SerializationFeature.ORDER_MAP_ENTRIES_BY_KEYS, true);//序列化Map时按自然顺序对key排序mapper.configure(SerializationFeature.WRITE_CHAR_ARRAYS_AS_JSON_ARRAYS, true);//序列化char[]时以json数组输出，默认false。mapper.configure(SerializationFeature.WRITE_BIGDECIMAL_AS_PLAIN,false);//序列化BigDecimal时是原始输出还是科学计数方式输出。默认false.mapper.setSerializationInclusion(Include.NON_EMPTY);//在序列化时忽略空的属性mapper.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES);//反序列化时禁用映射器遇到未知属性时导致断开的功能，将忽略bean中不存在的属性。 学习参考：http://www.studytrails.com/java/json/java-jackson-introduction/ https://github.com/FasterXML/jackson-docs","link":"/2018/12/22/java/json/Jackson-%E7%AE%80%E4%BB%8B/"},{"title":"Jackson反序列化处理带泛型","text":"通过Jackson进行反序列化时通常可以使用TypeReference 1234567public public &lt;T&gt; List&lt;T&gt; transJsonArryStrToList(String jsonString, Class&lt;T&gt; beanClass) { ObjectMapper mapper = new ObjectMapper(); mapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); // List&lt;T&gt; student = mapper.readValue(jsonString, new TypeReference&lt;List&lt;T&gt;&gt;(){}); List&lt;Student&gt; student = mapper.readValue(jsonString, new TypeReference&lt;List&lt;Student&gt;&gt;(){});} 其中new TypeReference&lt;List&lt;Student&gt;&gt;()中的List&lt;Student&gt;类型需要明确指定，不能指定为泛型，否则反序列化后List中的对象不是Student，而是LinkedHashMap，接下来再处理list时就会报java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to com.pojo.Student异常。 如果要通过泛型进行反序列化时可以通过如下方式实现 12345public &lt;T&gt; List&lt;T&gt; transJsonArryStrToList(String jsonArryStr, Class&lt;T&gt; beanClass) throws Exception{ ObjectMapper mapper = new ObjectMapper(); List&lt;T&gt; list = mapper.readValue(jsonArryStr, mapper.getTypeFactory().constructParametricType(List.class, beanClass)); return list;} 参考：https://blog.csdn.net/u013466972/article/details/83029854","link":"/2019/01/15/java/json/Jackson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%A4%84%E7%90%86%E5%B8%A6%E6%B3%9B%E5%9E%8B/"},{"title":"JsonObject转为JsonArray","text":"把JsonObject类型的字符串转换为JsonArray类型的字符串 通过Jackson实现 123456789101112131415161718192021222324252627/** * 转换Json字符串为JsonArry字符串 * @param jsonString {\"xx\":\"xx\"} / [{\"xx\":\"xx\"}] * @return [{\"xx\":\"xx\"}] */public static String tranferJsonToJsonArryString(ObjectMapper mapper, String jsonString) { String jsonArray = \"\"; if(StringUtils.isBlank(jsonString)) return jsonArray; JsonFactory factory = mapper.getFactory(); try { JsonParser parser = factory.createParser(jsonString); JsonToken token = parser.nextToken(); if(JsonToken.START_OBJECT.equals(token)) { JsonNode jsonNode = mapper.readTree(jsonString); ArrayNode arrayNode = mapper.createArrayNode(); arrayNode.add(jsonNode); return mapper.writeValueAsString(arrayNode); }else if(JsonToken.START_ARRAY.equals(token)) { return jsonString; } } catch (Exception e) { e.printStackTrace(); } return jsonArray;} 通过Json-lib实现 12345678910111213public static String tranferJsonToJsonArryString(String jsonString) { JSONArray jsonArry = null; Object json = new JSONTokener(jsonString).nextValue(); if(json instanceof JSONObject) { JSONObject jsonObject = JSONObject.fromObject(jsonString); jsonArry = JSONArray.fromObject(jsonObject); }else if (json instanceof JSONArray){ jsonArry = JSONArray.fromObject(jsonString); }else { return \"\"; } return jsonArry.toString(); }","link":"/2018/12/24/java/json/JsonObject%E8%BD%AC%E4%B8%BAJsonArray/"},{"title":"Json-lib","text":"简介json-lib是最开始的也是应用最广泛的json解析工具，json-lib 依赖于很多第三方包， 依赖的jar: commons-lang 2.5 commons-beanutils 1.8.0 commons-collections 3.2.1 commons-logging 1.1.1 ezmorph 1.0.6 对于复杂类型的转换，json-lib对于json转换成bean还有缺陷，比如一个类里面会出现另一个类的list或者map集合，json-lib从json到bean的转换就会出现问题。json-lib在功能和性能上面都已不能满足现在互联网化的需求。 但也是有必要了解的。 描述Json-lib是一个用于转换beans、maps、collections、java arrays、XML成JSON对象以及反之转化成benas和DynaBeans的java库。Json-lib建立在Douglas Crockford的工作基础之上。 使用引入Maven依赖： 123456&lt;dependency&gt; &lt;groupId&gt;net.sf.json-lib&lt;/groupId&gt; &lt;artifactId&gt;json-lib&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;classifier&gt;jdk15&lt;/classifier&gt;&lt;/dependency&gt; JSONObjectJSONObject是一个无序的name/value对集合。它的外部形式是一个由花括号“{}”括起的字符串，在name和value之间使用冒号“:”隔开，在names/values之间用逗号隔开。它的内部的形式是一个由get和opt方法来根据name访问value。及accumulate、put方法来根据name增加或替换value的对象。值value可以是以下类型：Boolean, Double, Integer, JSONArray, JSONObject, Long, String, 或者 JSONNull 对象。 JSONObject类型的构造器可以用于转换外部形式的JSON text成一种可以由get和opt方法访问的内部形式，或者使用element方法和toString方法把值转换成为JSON text。 JSONArrayJSONArray是一个有序的值得序列。它的外部形式是包括在方括号[]内的字符串，由逗号分隔值。内部的形式是一个拥有get和opt方法的对象，这两个方法可以根据索引访问值，element方法可以用来添加和替换值，add()方法，与JSONObject的put()方法类似，在json数组末尾追加元素，也可以在指定位置追加。 JSONObject 与JSONArray 基本方法：fromObject(Object object) ，JSONObject和JSONArray类都有一个fromObject(Object object)的静态方法，可以从参数object中构造json对象或数组 。 ① JSONObject.fromObject(Object object)中，参数可以是String、Map、beans等，不可以是collection、arrays等 ②JSONArray.fromObject(Object object)中，参数可以是String、Map、Colliection、arrays等 get()方法，根据name访问value，如果name存在，则返回对应的值，否则会抛出异常JSONException。 opt()方法，根据name访问value，如果name不存在，可以指定一个默认值而不会抛出异常。 put()方法，向json对象中加入字段和相应值，会覆盖原来的值。 accumulate()方法，向json对象和数组中的某字段追加相应值，形成一个JSONArray对象，不断追加新的Value 。不会覆盖原来的值。 element()方法 ，与put() 类似，向json对象中加入字段和相应值，会覆盖原来的值。可以使用链式存储的方式 12JSONObject json = new JSONObject();json.element(\"1\", 1).element(\"2\", 2); replace(Object Object)，根据key替换原来的值，如果key不存在，不会添加。 isEmpy()，判断JSONObject对象中是否不包含任何name/value对映射 。 isNullObject()，判断JSONObject对象是否是null。 containsKey(Object key)，判断JSONObject中是否包含指定的key。 has(String key), 同containKey方法，判断JSONObject中是否包含指定的key。 containValue(Object value)，判断是否包含指定的value。 equals(Object obj)，判断两个JSONObject对象包含相同的键集合，同时每个键对应的值也相等 。 isArray()，判断是否是JSONArray对象。 遍历：1234567891011121314151617public static void test9() { JSONObject jsonObject = new JSONObject(); jsonObject.element(\"name\", \"zhangsan\").element(\"age\", 12).element(\"sex\", \"男\"); for(Object str : jsonObject.keySet()) { String key = (String)str; System.out.println(key); } Set&lt;Object&gt; entrys = jsonObject.entrySet(); for(Object entry : entrys) { System.out.println(entry); } Collection&lt;Object&gt; col = jsonObject.values(); Iterator&lt;Object&gt; it = col.iterator(); while(it.hasNext()) { System.out.println(it.next()); }} JSONSerializer使用 JSONSerializer 的 toJSON 方法就可以转换任意的 Java Object 为 JSON 对象了，再调用 JSON 对象的 toString 方法可以得到转换后的字符串。 1234567891011121314import net.sf.json.JSONSerializer;public static void test10() { String str = \"[\\\"zhangsan\\\",\\\"lisi\\\"]\"; List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(\"zhangsan\"); list.add(\"lisi\"); JSON json1 = JSONSerializer.toJSON(str); JSON json2 = JSONSerializer.toJSON(list); System.out.println(json1); System.out.println(json2.toString());}//[\"zhangsan\",\"lisi\"]//[\"zhangsan\",\"lisi\"] 筛选Java bean 属性JSONSerializer 提供了一个 toJSON 的重载方法，增加一个参数 JsonConfig，可以通过这个参数对 Json-lib 的缺省方式做自定义的配置。 JSONObject.fromObject()，JSONArray.fromObject()中也可传入JsonConfig进行自定义配置。 12345678910111213141516171819public static void test7() { String json = \"{\\\"data\\\":[{\\\"birthday\\\":\\\"2018-12-14\\\",\\\"certNum\\\":\\\"100101\\\",\\\"id\\\":1,\\\"occuOrient\\\":\\\"车工\\\"}]}\"; JsonConfig jsonConfig = new JsonConfig(); jsonConfig.setJsonPropertyFilter(new PropertyFilter() { // 定义属性过滤器 @Override public boolean apply(Object source, String name, Object value) { if(value != null &amp;&amp; Number.class.isAssignableFrom(value.getClass())) { return true; // 返回 true, 表示这个属性将被过滤掉 } if(\"birthday\".equals(name) || \"certNum\".equals(name)) { return true; } return false; } }); //JSON json1 = JSONSerializer.toJSON(json,jsonConfig); JSONObject jsonObject = JSONObject.fromObject(json, jsonConfig); // 注册属性过滤器 System.out.println(jsonObject);} 也可使用注解对属性进行筛选，可参考：使用 annotation 筛选 JavaBean 属性 JavaIdentifierTransformer另外可以使用jsonConfig.setJavaIdentifierTransformer(),对Bean属性字符进行处理。 Json-lib定义了一组JavaIdentifierTransformer类型的帮助程序，它们将处理以下情况： JavaIdentifierTransformer.NOOP - 不执行任何转换。 JavaIdentifierTransformer.STRICT - 如果找到非JavaIdentifier字符，将抛出JSONException。 JavaIdentifierTransformer.CAMEL_CASE - 将使用非JavaIdentifier和空格字符作为单词边界，将新单词的第一个字符大写。 JavaIdentifierTransformer.WHITESPACE - 将从输入字符串中修剪所有空格和非JavaIdentifier字符。 JavaIdentifierTransformer.UNDERSCORE - 将所有空格和非JavaIdentifier字符转换为’_’。 或者自定义JavaIdentifierTransformers ，可参考：Java中Json转换Bean对象并忽略大小写 。 参考：http://json-lib.sourceforge.net/usage.html https://www.ibm.com/developerworks/cn/java/j-lo-jsonlib/index.html https://blog.csdn.net/lk142500/article/details/82499387","link":"/2018/12/17/java/json/Json-lib/"},{"title":"SoapUI SSL设置","text":"在SoapUI 中SSL配置keystore和keyStorePassword、trustStore和trustStorePassword。 File–&gt;Preferences–&gt;SSL Setting 然后就可以调用HTTPS协议的WebService。","link":"/2018/10/11/java/webservice/SoapUI%20SSL%E8%AE%BE%E7%BD%AE/"},{"title":"webservice之SAOP","text":"SAOP协议 SOAP（Simple Object Accrss Protocol，简单对象访问协议）是一种简单的基于XML和HTTP的协议，可以使应用程序在分散或分布式的环境中通过HTTP来交换信息。 SOAP是Web Service的通信协议。当用户通过UDDI找到你的WSDL描述文档后，他通过可以SOAP调用你建立的Web服务中的一个或多个操作。SOAP是XML文档形式的调用方法的规范，可以支持不同的底层接口，像HTTP(S)或者SMTP。 SOAP消息基本上是从发送端到接收端的单向传输，常常结合起来执行类似于请求/应答的模式。不需要把SOAP消息绑定到特定的协议，SOAP可以运行在任何其他传输协议（HTTP、SMTP、FTP等）上。另外，SOAP提供了标准的RPC方法来调用Web Service以请求/响应模式运行。 SOAP消息组成 所有的SOAP消息都使用XML编码，一条SOAP消息就是一个普通的XML文档，文档包括下列元素： Envelope（信封）元素，必选，可把此XML文档标识为一条SOAP消息。定义消息的开头和结尾。 Header（报头）元素，可选，包含头部信息（包含了使消息在到达最终目的地之前，能够被路由到一个或多个中间节点的信息）。 Body(主体)元素，必选，包含所有的调用和响应信息。 Fault元素，位于Body内，可选，提供有关处理此消息所发生错误的信息。 Attachment（附件）元素，可选，可通过添加一个或多个附件扩展SOAP消息。 SOAP基本消息结构 1234567891011121314151617181920&lt;?xml version=\"1.0\"?&gt;&lt;soap:Envelopexmlns:soap=\"http://www.w3.org/2001/12/soap-envelope\"soap:encodingStyle=\"http://www.w3.org/2001/12/soap-encoding\"&gt; &lt;soap:Header&gt; ... ...&lt;/soap:Header&gt; &lt;soap:Body&gt; ... ... &lt;soap:Fault&gt; ... ... &lt;/soap:Fault&gt;&lt;/soap:Body&gt; &lt;/soap:Envelope&gt; SOAP Envelope元素 SOAP Envelope 是SOAP消息结构的主要容器，也是SOAP消息的根元素，必须出现在每个SOAP消息中，用于把此XML文档标示为一条SOAP消息。 A、命名空间 在SOAP中，使用XML命名空间将SOAP标示符与应用程序特定的标示符区分开，将SOAP消息的元素的作用域限制在一个特定的领域。如果使用了不同的命名空间，应用程序会发生错误，并抛弃此消息。 SOAP消息必须拥有与命名空间相关联的一个Envelope元素，SOAP消息中所有元素必须由第一个命名空间进行限定。SOAP 1.1规范如下： 123&lt;soap-env:Envelope xmlns:soap-env=\"http://schemas.xmlsoap.org/soap/envelope/\"&gt;&lt;/soap-env:Envelope&gt; SOAP 1.2规范如下： 123&lt;soap:Envelope xmlns:soap=\"http://www.w3.org/2001/12/soap-envelope\"&gt; &lt;/soap:Envelope&gt; B、encodingStyle属性 SOAP的encodingStyle属性用于定义在文档中使用的编码规则，encodingStyle属性可出现在任何SOAP元素中，并会被应用到元素的内容及元素的所有子元素上。SOAP消息没有默认的编码方式。SOAP 1.1规范如下： 1234&lt;soap-env:Envelope xmlns:soap-env=\"http://schemas.xmlsoap.org/soap/envelope/\"Soap-env:encodingStyle =“http://schemas.xmlsoap.org/soap/encoding/”&gt; &lt;/ soap-env:Envelope&gt; SOAP 1.2规范如下： 1234&lt;soap:Envelope xmlns:soap=\"http://www.w3.org/2001/12/soap-envelope\"soap:encodingStyle=\"http://www.w3.org/2001/12/soap-encoding\"&gt;&lt;/soap:Envelope&gt; SOAP Header元素 SOAP Header元素应当作为SOAP Envelope的第一个直接子元素，必须使用有效的命名空间。Header还可以包含0个或多个可选的子元素，子元素称为Header项，所有的Header项都必须是完整修饰的，即必须由一个命名空间URI和局部名组成，不允许没有命名空间修饰的Header项存在。 Header元素用于与消息一起传输附加消息，如身份验证或事务信息。Header元素也可以包含某些属性。SOAP在默认的命名空间中定义了三个属性：actor，mustUnderstand以及encodingStyle。这些被定义在SOAP头部的属性可通知容器如何对SOAP消息进行处理。12345678910111213&lt;SOAP-ENV:Envelope xmlns:SOAP-ENV = \" http://www.w3.org/2001/12/soap-envelope\" SOAP-ENV:encodingStyle = \" http://www.w3.org/2001/12/soap-encoding\"&gt; &lt;SOAP-ENV:Header&gt; &lt;t:Transaction xmlns:t = \"http://www.tutorialspoint.com/transaction/\" SOAP-ENV:mustUnderstand = \"true\"&gt;5 &lt;/t:Transaction&gt; &lt;/SOAP-ENV:Header&gt; ... ...&lt;/SOAP-ENV:Envelope&gt; C、actor属性 SOAP消息可能通过沿消息路径传递一组SOAP中介，从出发地传播到最终目的地。SOAP中介是一种能够接收和转发SOAP消息的应用程序。SOAP actor全局属性可用于指示标头元素的接收者。SOAP actor属性的值是URI。 SOAP的actor属性可被用于将Header元素寻址到一个特定的端点。 1234567891011121314151617&lt;?xml version=\"1.0\"?&gt;&lt;soap:Envelopexmlns:soap=\"http://www.w3.org/2001/12/soap-envelope\"soap:encodingStyle=\"http://www.w3.org/2001/12/soap-encoding\"&gt; &lt;soap:Header&gt;&lt;m:Transxmlns:m=\"http://www.w3school.com.cn/transaction/\"soap:actor=\"http://www.w3school.com.cn/appml/\"&gt;234&lt;/m:Trans&gt;&lt;/soap:Header&gt; ...... &lt;/soap:Envelope&gt; D、mustUnderstand属性 SOAP的mustUnderstand属性可用于标识标题项对于要对其进行处理的接收者来说是强制的还是可选的。 假如向Header元素的某个子元素添加了&quot;mustUnderstand=&quot;1&quot;，则它可指示处理此头部的接收者必须认可此元素。假如此接收者无法认可此元素，则在处理此头部时必须失效。1234567891011121314151617&lt;?xml version=\"1.0\"?&gt;&lt;soap:Envelopexmlns:soap=\"http://www.w3.org/2001/12/soap-envelope\"soap:encodingStyle=\"http://www.w3.org/2001/12/soap-encoding\"&gt; &lt;soap:Header&gt;&lt;m:Transxmlns:m=\"http://www.w3school.com.cn/transaction/\"soap:mustUnderstand=\"1\"&gt;234&lt;/m:Trans&gt;&lt;/soap:Header&gt; ...... &lt;/soap:Envelope&gt; E、SOAP Body元素 SOAP的body是必需元素，包含在SOAP消息中交换的应用程序定义的XML数据。 SOAP消息的Body块可以包含以下任何元素： RPC方法及其参数 目标应用程序（消息接收者）专用数据 报告故障和状态消息的SOAP Fault SOAP Body元素的直接子元素可以是合格的命名空间。SOAP在默认的命名空间中(“http://www.w3.org/2001/12/soap-envelope&quot;)定义了Body元素内部的一个元素。即SOAP的Fault元素，用于指示错误消息。 123456789101112&lt;?xml version=\"1.0\"?&gt;&lt;soap:Envelopexmlns:soap=\"http://www.w3.org/2001/12/soap-envelope\"soap:encodingStyle=\"http://www.w3.org/2001/12/soap-encoding\"&gt; &lt;soap:Body&gt; &lt;m:GetPrice xmlns:m=\"http://www.w3school.com.cn/prices\"&gt; &lt;m:Item&gt;Apples&lt;/m:Item&gt; &lt;/m:GetPrice&gt;&lt;/soap:Body&gt; &lt;/soap:Envelope&gt; 上面的例子请求苹果的价格。m:GetPrice和Item元素是应用程序专用的元素，并不是SOAP标准的一部分。而一个SOAP响应应该类似这样： 123456789101112&lt;?xml version=\"1.0\"?&gt;&lt;soap:Envelopexmlns:soap=\"http://www.w3.org/2001/12/soap-envelope\"soap:encodingStyle=\"http://www.w3.org/2001/12/soap-encoding\"&gt; &lt;soap:Body&gt; &lt;m:GetPriceResponse xmlns:m=\"http://www.w3school.com.cn/prices\"&gt; &lt;m:Price&gt;1.90&lt;/m:Price&gt; &lt;/m:GetPriceResponse&gt;&lt;/soap:Body&gt; &lt;/soap:Envelope&gt; F、SOAP Fault元素 SOAP Fault元素用于在SOAP消息中传输错误及状态信息。如果SOAP消息需要包括SOAP Fault元素，SOAP Fault元素必须作为一个Body项出现，而且至多出现一次。SOAP Fault包括以下子元素：faultcode、faultstring、faultactor、detail。 子元素 描述 用于指示一类错误的文本代码。 解释错误的说明。 引发故障的节点信息。 用于携带特定于应用程序的错误消息的元素。 在下面定义的 faultcode 值必须用于描述错误时的 faultcode 元素中： 元素 错误和描述 SOAP-ENV:VersionMismatch 发现SOAP Envelope元素的无效命名空间。 SOAP-ENV:MustUnderstand Header元素的直接子元素（mustUnderstand属性设置为“1”）未被理解。 SOAP-ENV:Client 消息被不正确地构成，或包含了不正确的信息。 SOAP-ENV:Server 服务器有问题，因此无法处理进行下去。 示例：客户端已请求名为ValidateCreditCard的方法，但该服务不支持此类方法。这表示客户端请求错误，服务器返回以下SOAP响应 - 12345678910111213141516&lt;?xml version = '1.0' encoding = 'UTF-8'?&gt;&lt;SOAP-ENV:Envelope xmlns:SOAP-ENV = \"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:xsi = \"http://www.w3.org/1999/XMLSchema-instance\" xmlns:xsd = \"http://www.w3.org/1999/XMLSchema\"&gt; &lt;SOAP-ENV:Body&gt; &lt;SOAP-ENV:Fault&gt; &lt;faultcode xsi:type = \"xsd:string\"&gt;SOAP-ENV:Client&lt;/faultcode&gt; &lt;faultstring xsi:type = \"xsd:string\"&gt; Failed to locate method (ValidateCreditCard) in class (examplesCreditCard) at /usr/local/ActivePerl-5.6/lib/site_perl/5.6.0/SOAP/Lite.pm line 1555. &lt;/faultstring&gt; &lt;/SOAP-ENV:Fault&gt; &lt;/SOAP-ENV:Body&gt;&lt;/SOAP-ENV:Envelope&gt; G、SOAP附件 按照SOAP1.1规范的规定，SOAP消息可以包含XML格式的主SOAP信封，以及包含ASCII或二进制等任何数据格式的SOAP附件。如果SOAP消息包含附件，那么SOAP消息将是一个MIME编码的消息，包含SOAP内容和一个或多个其他类型的附件。因此SOAP消息实际上分为以下两种类型： 仅包含XML内容的消息 MIME编码的消息，包含初始的XML有效内容以及任何数量的附件。附件可以是任何其他类型的数据。 【MIME：Multi-purpose Internet Mail Extensions多用途Internet邮件扩展，是一组技术规范，其目的是使用不同字符集来传递文本，也可以在计算机之间传递各种各样的多媒体数据】 参考： SOAP 1.2、SOAP 1.1 http://blog.51cto.com/9291927/1914041 https://www.tutorialspoint.com/soap/soap_standards.htm https://juejin.im/post/5aadae4bf265da238a303917#heading-17","link":"/2018/10/16/java/webservice/webservice%E4%B9%8Bsaop%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"webservice框架","text":"webservice框架 1、JWS JWS是Java语言对WebService服务的一种实现，用来开发和发布服务。而从服务本身的角度来看JWS服务是没有语言界限的。但是Java语言为Java开发者提供便捷发布和调用WebService服务的一种途径。 2、Axis2 3、XFire XFire是一个高性能的WebService框架，在Java6之前，它的知名度甚至超过了Apache的Axis2，XFire的优点是开发方便，与现有的Web整合很好，可以融为一体，并且开发也很方便。但是对Java之外的语言，没有提供相关的代码工具。XFire后来被Apache收购了，原因是它太优秀了，收购后，随着Java6 JWS的兴起，开源的WebService引擎已经不再被看好，渐渐的都败落了。 4、CXF 几种框架的总结： a：目前开发Web Service的几个框架，分别为Axis，axis2，Xfire，CXF以及JWS(也就是前面所述的JAX-WS，这是Java6发布所提供的对Web Service服务的一种实现。) b：Axis与XFire已随着技术不断的更替慢慢落幕，都已不再更新。 c：以axis2与cxf所最为常用，目前也只有axis2和cxf官方有更新。 d：从使用场景来说，如果你需要多语言的支持，你应该选择AXIS2。如果你需要把你的实现侧重JAVA并希望和Spring集成，CXF就是更好的选择。 参考：https://www.cnblogs.com/domi22/p/8060330.html","link":"/2018/10/18/java/webservice/webservice%E6%A1%86%E6%9E%B6/"},{"title":"webservice之WSDL","text":"WSDL简介 WSDL（网络服务描述语言，Web Services Description Language）是一门基于XML的语言，用于描述WebService以及如何对它们进行访问。 WSDL将Web服务描述定义为一组服务访问点，客户端可以通过这些服务访问点对包含面向文档信息或面向过程调用的服务进行访问。WSDL首先对访问的操作和访问时使用的请求/响应消息进行抽象描述，然后将其绑定到具体的传输协议和消息格式上以最终定义具体部署的服务访问点。 WSDL是一个用于精确描述Web服务的文档，WSDL文档是一个遵循WSDL XML模式的XML文档。WSDL文档将Web服务定义为服务访问点或端口的集合。在WSDL中，由于服务访问点和消息的抽象定义已从具体的服务部署或数据格式绑定中分离出来，因此可以对抽象定义进行再次使用：消息，指对交换数据的抽象描述；而端口类型，指操作的抽象集合。用于特定端口类型的具体协议和数据格式规范构成了可以再次使用的绑定。将Web访问地址与可再次使用的绑定相关联，可以定义一个端口，而端口的集合则定义为服务。 WSDL元素 WSDL文档通常包含7个重要的元素，即types、import、message、portType、operation、binding、service元素。所有元素嵌套在definitions元素中，definitions是WSDL文档的根元素。 definitions - 它是所有WSDL文档的根元素。它定义Web服务的名称，声明在整个文档的其余部分中使用的多个名称空间，并包含此处描述的所有服务元素。 Types - 数据类型定义的容器，采用XML模式的形式。 Message - 通信消息的数据结构的抽象类型化定义。使用Types所定义的类型来定义整个消息的数据结构。 Operation - 对服务中所支持的操作的抽象描述，一般单个Operation描述了一个访问入口的请求/响应消息对。 PortType - 对于某个访问入口点类型所支持的操作的抽象集合，这些操作可以由一个或多个服务访问点来支持。 Binding - 特定端口类型的具体协议和数据格式规范的绑定。 Port - 定义为协议/数据格式绑定与具体Web访问地址组合的单个服务访问点。 Service- 相关服务访问点的集合。 除了这些主要元素之外，WSDL规范还定义了以下元素 - Documentation − 此元素用于提供可读的文档，可以包含在任何其他WSDL元素中。 Import − 此元素用于导入其他WSDL文档或XML架构。 WSDL文档结构 1234567891011121314151617181920212223&lt;definitions&gt; &lt;types&gt; definition of types........ &lt;/types&gt; &lt;message&gt; definition of a message.... &lt;/message&gt; &lt;portType&gt; &lt;operation&gt; definition of a operation....... &lt;/operation&gt; &lt;/portType&gt; &lt;binding&gt; definition of a binding.... &lt;/binding&gt; &lt;service&gt; definition of a service.... &lt;/service&gt;&lt;/definitions&gt; WSDL文档阅读 WSDL文档的阅读顺序从下往上读。 每个WSDL有且只有一个Service节点。 a、先找Service节点 b、Service节点中找port节点。根据pory中的binding的名称找binding。 c、根据binding节点中的type的名称找portType。 d、PortType中有operation 节点就是服务的方法。 e、operation 中有Input（参数）和output（返回值）。 f、Input（参数）和output（返回值）对应message节点。 g、Message对应element节点。Element节点对应complexType节点描述了参数及返回值的数据类型。 WSDL文档解析 wsdl文档示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;wsdl:definitions targetNamespace=\"http://com.liuxiang.xfireDemo/HelloService\" xmlns:tns=\"http://com.liuxiang.xfireDemo/HelloService\" xmlns:wsdlsoap=\"http://schemas.xmlsoap.org/wsdl/soap/\" xmlns:soap12=\"http://www.w3.org/2003/05/soap-envelope\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:soapenc11=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:soapenc12=\"http://www.w3.org/2003/05/soap-encoding\" xmlns:soap11=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:wsdl=\"http://schemas.xmlsoap.org/wsdl/\"&gt; &lt;wsdl:types&gt; &lt;xs:schema elementFormDefault=\"unqualified\" targetNamespace=\"http://webservice.testenroll.com/\" version=\"1.0\"&gt; &lt;xsd:element name=\"sayHello\"&gt; &lt;xsd:complexType&gt; &lt;xsd:sequence&gt; &lt;xsd:element maxOccurs=\"1\" minOccurs=\"1\" name=\"name\" nillable=\"true\" type=\"xsd:string\" /&gt; &lt;/xsd:sequence&gt; &lt;/xsd:complexType&gt; &lt;/xsd:element&gt; &lt;xsd:element name=\"sayHelloResponse\"&gt; &lt;xsd:complexType&gt; &lt;xsd:sequence&gt; &lt;xsd:element maxOccurs=\"1\" minOccurs=\"1\" name=\"out\" nillable=\"true\" type=\"xsd:string\" /&gt; &lt;/xsd:sequence&gt; &lt;/xsd:complexType&gt; &lt;/xsd:element&gt; &lt;/xsd:schema&gt; &lt;/wsdl:types&gt; &lt;wsdl:message name=\"sayHelloResponse\"&gt; &lt;wsdl:part name=\"parameters\" element=\"tns:sayHelloResponse\" /&gt; &lt;/wsdl:message&gt; &lt;wsdl:message name=\"sayHelloRequest\"&gt; &lt;wsdl:part name=\"parameters\" element=\"tns:sayHello\" /&gt; &lt;/wsdl:message&gt; &lt;wsdl:portType name=\"HelloServicePortType\"&gt; &lt;wsdl:operation name=\"sayHello\"&gt; &lt;wsdl:input name=\"sayHelloRequest\" message=\"tns:sayHelloRequest\" /&gt; &lt;wsdl:output name=\"sayHelloResponse\" message=\"tns:sayHelloResponse\" /&gt; &lt;/wsdl:operation&gt; &lt;/wsdl:portType&gt; &lt;wsdl:binding name=\"HelloServiceHttpBinding\" type=\"tns:HelloServicePortType\"&gt; &lt;wsdlsoap:binding style=\"document\" transport=\"http://schemas.xmlsoap.org/soap/http\" /&gt; &lt;wsdl:operation name=\"sayHello\"&gt; &lt;wsdlsoap:operation soapAction=\"\" /&gt; &lt;wsdl:input name=\"sayHelloRequest\"&gt; &lt;wsdlsoap:body use=\"literal\" /&gt; &lt;/wsdl:input&gt; &lt;wsdl:output name=\"sayHelloResponse\"&gt; &lt;wsdlsoap:body use=\"literal\" /&gt; &lt;/wsdl:output&gt; &lt;/wsdl:operation&gt; &lt;/wsdl:binding&gt; &lt;wsdl:service name=\"HelloService\"&gt; &lt;wsdl:port name=\"HelloServiceHttpPort\" binding=\"tns:HelloServiceHttpBinding\"&gt; &lt;wsdlsoap:address location=\"http://localhost:8080/services/HelloService\" /&gt; &lt;/wsdl:port&gt; &lt;/wsdl:service&gt;&lt;/wsdl:definitions&gt; 服务支持名为sayHello的唯一操作，sayHello操作通过在http上运行SOAP协议来实现的。请求接受一个字符串name，经过处理后返回一个简单的字符串。1、definitions元素 所有的WSDL文档的根元素均是definitions元素。definitions元素封装了整个文档，同时通过其name提供了一个WSDL文档。除了提供一个命名空间外，definitions元素没有其他作用。 2、types元素 WSDL采用了W3C XML模式内置类型作为其基本类型系统。types元素用作一个容器，用于定义XML模式内置类型中没有描述的各种数据类型。当声明消息部分的有效负载时，消息定义使用了在types元素中定义的数据类型和元素。在本文的WSDL文档中的types定义：1234567891011121314151617181920&lt;wsdl:types&gt; &lt;xs:schema elementFormDefault=\"unqualified\" targetNamespace=\"http://webservice.testenroll.com/\" version=\"1.0\"&gt; &lt;xsd:element name=\"sayHello\"&gt; &lt;xsd:complexType&gt; &lt;xsd:sequence&gt; &lt;xsd:element maxOccurs=\"1\" minOccurs=\"1\" name=\"name\" nillable=\"true\" type=\"xsd:string\" /&gt; &lt;/xsd:sequence&gt; &lt;/xsd:complexType&gt; &lt;/xsd:element&gt; &lt;xsd:element name=\"sayHelloResponse\"&gt; &lt;xsd:complexType&gt; &lt;xsd:sequence&gt; &lt;xsd:element maxOccurs=\"1\" minOccurs=\"1\" name=\"out\" nillable=\"true\" type=\"xsd:string\" /&gt; &lt;/xsd:sequence&gt; &lt;/xsd:complexType&gt; &lt;/xsd:element&gt; &lt;/xsd:schema&gt; &lt;/wsdl:types&gt; 数据定义部分定义了两个元素，一个是sayHello，一个是sayHelloResponse： sayHello：定义了一个复杂类型，仅仅包含一个简单的字符串，将来用来描述操作的参入传入部分； sayHelloResponse：定义了一个复杂类型，仅仅包含一个简单的字符串，将来用来描述操作的返回值。3、import元素 import元素使得可以在当前的WSDL文档中使用其他WSDL文档中指定的命名空间中的定义元素。本例中没有使用import元素。通常在用户希望模块化WSDL文档的时候，import功能是非常有效果的。 import的格式如下：1&lt;wsdl:import namespace=\"http://xxx.xxx.xxx/xxx/xxx\" location=\"http://xxx.xxx.xxx/xxx/xxx.wsdl\"/&gt; 必须有namespace属性和location属性： namespace属性：值必须与正导入的WSDL文档中声明的targetNamespace相匹配； location属性：必须指向一个实际的WSDL文档，并且该文档不能为空。4、message元素 message元素描述了Web服务使用消息的有效负载。message元素可以描述输出或者接受消息的有效负载；还可以描述SOAP文件头和错误detail元素的内容。定义message元素的方式取决于使用RPC样式还是文档样式的消息传递。在本文中的message元素的定义，本文档使用了采用文档样式的消息传递：123456&lt;wsdl:message name=\"sayHelloResponse\"&gt; &lt;wsdl:part name=\"parameters\" element=\"tns:sayHelloResponse\" /&gt; &lt;/wsdl:message&gt; &lt;wsdl:message name=\"sayHelloRequest\"&gt; &lt;wsdl:part name=\"parameters\" element=\"tns:sayHello\" /&gt;&lt;/wsdl:message&gt; 消息格式的抽象定义：定义了两个消息sayHelloResponse和sayHelloRequest： sayHelloRequest：sayHello操作的请求消息格式，由一个消息片断组成，名字为parameters,元素是我们前面定义的types中的元素； sayHelloResponse：sayHello操作的响应消息格式，由一个消息片断组成，名字为parameters,元素是我们前面定义的types中的元素； 如果采用RPC样式的消息传递，只需要将文档中的element元素应以修改为type即可。5、portType元素 portType元素定义了Web服务的抽象接口。该接口有点类似Java的接口，都是定义了一个抽象类型和方法，没有定义实现。在WSDL中，portType元素是由binding和service元素来实现的，这两个元素用来说明Web服务实现使用的Internet协议、编码方案以及Internet地址。一个portType中可以定义多个operation，一个operation可以看作是一个方法，本文中WSDL文档的定义 12345678&lt;wsdl:portType name=\"HelloServicePortType\"&gt; &lt;wsdl:operation name=\"sayHello\"&gt; &lt;wsdl:input name=\"sayHelloRequest\" message=\"tns:sayHelloRequest\" /&gt; &lt;wsdl:output name=\"sayHelloResponse\" message=\"tns:sayHelloResponse\" /&gt; &lt;/wsdl:operation&gt;&lt;/wsdl:portType&gt; portType定义了服务的调用模式的类型，包含一个操作sayHello方法，同时包含input和output表明该操作是一个请求／响应模式，请求消息是前面定义的sayHelloRequest，响应消息是前面定义的sayHelloResponse。input表示传递到Web服务的有效负载，output消息表示传递给客户的有效负载。6、binding元素 binding元素将一个抽象portType映射到一组具体协议(SOAO和HTTP)、消息传递样式、编码样式。通常binding元素与协议专有的元素和在一起使用，本文中的例子：1234567891011121314&lt;wsdl:binding name=\"HelloServiceHttpBinding\" type=\"tns:HelloServicePortType\"&gt; &lt;wsdlsoap:binding style=\"document\" transport=\"http://schemas.xmlsoap.org/soap/http\" /&gt; &lt;wsdl:operation name=\"sayHello\"&gt; &lt;wsdlsoap:operation soapAction=\"\" /&gt; &lt;wsdl:input name=\"sayHelloRequest\"&gt; &lt;wsdlsoap:body use=\"literal\" /&gt; &lt;/wsdl:input&gt; &lt;wsdl:output name=\"sayHelloResponse\"&gt; &lt;wsdlsoap:body use=\"literal\" /&gt; &lt;/wsdl:output&gt; &lt;/wsdl:operation&gt;&lt;/wsdl:binding&gt; binding元素将服务访问点的抽象定义与SOAP HTTP绑定，描述如何通过SOAP/HTTP来访问按照前面描述的访问入口点类型部署的访问入口。其中规定了在具体SOAP调用时，应当使用的soapAction是&quot;&quot;。7、service元素和port元素 service元素包含一个或者多个port元素，其中每个port元素表示一个不同的Web服务。port元素将URL赋给一个特定的binding，甚至可以使两个或者多个port元素将不同的URL赋值给相同的binding。文档中的例子：1234567&lt;wsdl:service name=\"HelloService\"&gt; &lt;wsdl:port name=\"HelloServiceHttpPort\" binding=\"tns:HelloServiceHttpBinding\"&gt; &lt;wsdlsoap:address location=\"http://localhost:8080/services/HelloService\" /&gt; &lt;/wsdl:port&gt;&lt;/wsdl:service&gt; 这部分是具体的Web服务的定义，在这个名为HelloService的Web服务中，提供了一个服务访问入口，访问地址是http://localhost:8080/xfire/services/HelloService，使用的消息模式是由前面的binding所定义的。参考：http://blog.51cto.com/9291927/1914044 https://www.tutorialspoint.com/wsdl/wsdl_elements.htm","link":"/2018/10/18/java/webservice/webservice%E4%B9%8Bwsdl%EF%BC%88%E4%B8%89%EF%BC%89/"},{"title":"WebService","text":"webservice简介 SOA 先给出一个概念 SOA，即Service-Oriented Architecture，中文意思是中文面向服务编程，是一种思想，一种方法论，一种分布式的服务架构。 SOA 中的服务是构建在一些列基于开放标准的基础之上的， Web 服务定义了如何在异构系统之间实现通信的标准化方法， 从而就使得 Web 服务可以跨越运行平台和实现语言， 同时也使得 Web 服务成为了实现 SOA 中服务的主要技术。 关于SOA参考其它资料：https://www.cnblogs.com/renzhitian/p/6853289.html WebService简介 Web Service即XML Web Service WebService，是一种可以接收从Internet或者Intranet上的其它系统中传递过来的请求，轻量级的独立的通讯技术。通过SOAP在Web上提供的软件服务，使用WSDL文档进行说明，并通过UDDI进行注册。 WebServices特点 WebServices 提供一个建立分布式应用的平台，使得运行在不同操作系统和不同设备上的软件，或者是用不同的程序语言和不同厂商的软件开发工具开发的软件，所有可能的已开发和部署的软件，能够利用这一平台实现分布式计算的目的。WebServices的思想是：使得应用程序也具有 Web 分布式编程模型的松散耦合性。WebService是一种跨编程语言和跨操作系统平台的远程调用技术。 webservice体系结构 在 Web 服务的体系结构中，涉及到三个角色：Web 服务提供者、Web 服务中介者、 Web 服务请求者。同时还涉及到三类动作，即发布，查找，绑定。 Web 服务提供者： 可以发布 Web 服务，并且对使用自身服务的请求进行响应， Web 服务的拥有者，它会等待其他的服务或者是应用程序访问自己。 Web 服务请求者： 也就是 Web 服务功能的使用者，它通过服务注册中心也就是 Web 服务中介者查找到所需要的服务， 再利用 SOAP 消息向 Web 服务提供者发送请求以获得服务。 Web 服务中介者： 也称为服务代理，用来注册已经发布的 Web 服务提供者，并对其进行分类，同时提供搜索服务， 简单来说的话，Web 服务中介者的作用就是把一个 Web 服务请求者和合适的 Web 服务提供者联系在一起， 充当一个管理者的角色，一般是通过 UDDI 来实现。 发布： 通过发布操作，可以使 Web 服务提供者向 Web 服务中介者注册自己的功能以及访问的接口。 发现（查找）： 使得 Web 服务请求者可以通过 Web 服务中介者来查找到特点的种类的 Web 服务。 绑定： 这里就是实现让服务请求者能够使用服务提供者提供的服务了。 webservice三种基本组件 *SOAP * 即 Simple Object Access Protocol 也就是简单对象访问协议。是一种用于访问 Web 服务的协议。 SOAP 是用于在应用程序之间进行通信的一种通信协议。 SOAP 基于 XML 和 HTTP ，其通过 XML 来实现消息描述，然后再通过 HTTP 实现消息传输。 WebService通过HTTP协议发送请求和接收结果时，发送的请求内容和结果内容都采用XML格式封装，并增加了一些特定的HTTP消息头，以说明 HTTP消息的内容格式，这些特定的HTTP消息头和XML内容格式就是SOAP协议。SOAP提供了标准的RPC方法来调用Web Service。 WSDL 即 Web Services Description Language 也就是 Web 服务描述语言。是基于 XML 的用于描述 Web 服务以及如何访问 Web 服务的语言。 服务提供者通过服务描述将所有用于访问 Web 服务的规范传送给服务请求者， WSDL是一种XML文档，详细定义客户端消息的格式，需要什么样的参数，这样可以避免不必要的错误。 UDDI 即 Universal Description，Discovery and Integration，也就是通用的描述，发现以及整合。 UDDI 是一个跨产业，跨平台的开放性架构，可以帮助 Web 服务提供商在互联网上发布 Web 服务的信息。 UDDI 是一种目录服务，企业可以通过 UDDI 来注册和搜索 Web 服务。 简单来时候话，UDDI 就是一个目录，只不过在这个目录中存放的是一些关于 Web 服务的信息而已。 使用WebService并不是必须使用UDDI，因为用户通过WSDL知道了WebService的地址，可以直接通过WSDL调用WebService。 网络提供的一些免费的webservice服务测试地址,:https://my.oschina.net/CraneHe/blog/183471 https://www.cnblogs.com/garfieldcgf/p/5966317.html 参考：https://www.cnblogs.com/BoyXiao/archive/2010/05/22/1741325.html https://www.tutorialspoint.com/webservices/web_services_components.htm http://blog.51cto.com/9291927/1912758","link":"/2018/10/11/java/webservice/webservice%E7%AE%80%E4%BB%8B%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"通过HttpClient携带pfx和jks证书调用HTTPS协议的WebService","text":"和第三方服务进行对接时，他们提供了一个WebService地址，及两个证书文件（后缀为pfx的keyStoref和后缀为 jks的trustStore），给出的请求示例是通过 axis调用的。其中遇到很多问题，暂且不记。 本文主要是通过HttpClient进行调用。 1、构建HttpClient 连接，并进行SSL设置。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import java.io.File;import java.io.FileInputStream;import java.security.KeyStore;import javax.net.ssl.SSLContext;import org.apache.http.conn.ssl.NoopHostnameVerifier;import org.apache.http.conn.ssl.SSLConnectionSocketFactory;import org.apache.http.conn.ssl.TrustSelfSignedStrategy;import org.apache.http.impl.client.CloseableHttpClient;import org.apache.http.impl.client.HttpClients;import org.apache.http.ssl.SSLContexts;public class HttpClientUtil { private final static String keyStoreFile = \"F:/test/jks/oaut.pfx\"; private final static String keyStorePwd = \"111111\"; private final static String trustStoreFile = \"F:/test/jks/127.0.0.1.jks\"; private final static String trustStorePass = \"11111111\"; public static CloseableHttpClient createCustomSSlClient() throws Exception{ KeyStore keyStore = KeyStore.getInstance(\"pkcs12\"); FileInputStream instream = new FileInputStream(new File(keyStoreFile)); keyStore.load(instream,keyStorePwd.toCharArray()); instream.close(); KeyStore trustStore = KeyStore.getInstance(KeyStore.getDefaultType()); FileInputStream instream1= new FileInputStream(new File(trustStoreFile)); trustStore.load(instream1,trustStorePass.toCharArray()); instream1.close(); SSLContext sslcontext= SSLContexts.custom() .loadKeyMaterial(keyStore,keyStorePwd.toCharArray()) .loadTrustMaterial(trustStore,new TrustSelfSignedStrategy()) .build(); // SSLConnectionSocketFactory sslsf = new SSLConnectionSocketFactory(// sslcontext,// new String[] { \"TLSv1\", \"TLSv1.1\", \"TLSv1.2\" },// null,// SSLConnectionSocketFactory.getDefaultHostnameVerifier()); SSLConnectionSocketFactory sslsf1 = new SSLConnectionSocketFactory( sslcontext, NoopHostnameVerifier.INSTANCE); CloseableHttpClient httpclient = HttpClients.custom() .setSSLSocketFactory(sslsf1) .build(); return httpclient; }} 2、发送soap请求 1234567891011121314151617181920212223242526272829303132333435public String sendRequestSoap(CloseableHttpClient httpclient, String postUrl, String soapXml) { HttpPost httpPost = new HttpPost(postUrl); RequestConfig requestConfig = RequestConfig.custom().setSocketTimeout(30000).setConnectTimeout(30000).build(); httpPost.setConfig(requestConfig); httpPost.setHeader(\"Content-Type\", \"text/xml;charset=UTF-8\"); httpPost.setHeader(\"SOAPAction\", \"\"); StringEntity e = new StringEntity(soapXml, Charset.forName(\"UTF-8\")); httpPost.setEntity(e); ResponseHandler&lt;String&gt; responseHandler = new ResponseHandler&lt;String&gt;() { @Override public String handleResponse(HttpResponse response) throws ClientProtocolException, IOException { StatusLine statusLine = response.getStatusLine(); HttpEntity entity = response.getEntity(); if(statusLine.getStatusCode() &gt;= 300) { throw new HttpResponseException(statusLine.getStatusCode(), statusLine.getReasonPhrase()); } if(entity == null) { throw new ClientProtocolException(\"Response contains no content\"); } return EntityUtils.toString(entity, Consts.UTF_8); } }; try { String responseBody = httpclient.execute(httpPost, responseHandler); return responseBody; }catch(Exception e1) { e1.printStackTrace(); return null; }} 3、main方法 123456public static void main(String[] args) { String soapXml = \"&lt;soapenv:Envelope xmlns:soapenv=\\\"http://schemas.xmlsoap.org/soap/envelope/\\\" xmlns:ns1=\\\"http://www.sksk.com/mobileServices/\\\"&gt;&lt;soapenv:Header/&gt;&lt;soapenv:Body&gt;&lt;ns1:queryDailyFtpPictureReq&gt;&lt;ns1:DevID&gt;%s&lt;/ns1:DevID&gt;&lt;ns1:StartTime&gt;%s&lt;/ns1:StartTime&gt;&lt;ns1:EndTime&gt;%s&lt;/ns1:EndTime&gt;&lt;/ns1:queryDailyFtpPictureReq&gt;&lt;/soapenv:Body&gt;&lt;/soapenv:Envelope&gt;\"; String postUrl = \"https://localhost:9000/cxf/MobileService\"; String str = sendRequestSoap(HttpClientUtil.createCustomSSlClient(), postUrl, String.format(soapXml, new Object[]{\"81160301384\", \"2018-03-20 08:00:00\", \"2018-03-20 12:00:00\"})); System.out.println(str); } 其中soapXml可以通过SoapUI中获得。 其它： 操作过程中遇到一个问题，报主机名验证错误 解决方法：将 12345SSLConnectionSocketFactory sslsf = new SSLConnectionSocketFactory( sslcontext, new String[] { \"TLSv1\", \"TLSv1.1\", \"TLSv1.2\" }, null, SSLConnectionSocketFactory.getDefaultHostnameVerifier()); 修改为： 12SSLConnectionSocketFactory sslsf = new SSLConnectionSocketFactory( sslcontext, NoopHostnameVerifier.INSTANCE); 具体参考: SSL/TLS customization 证书的类型pfx、jks、cer、crt之间的关系及转换（keytool 工具）。 WebService 框架 Axis与CXF。 调用方式cxf与Axis及httpclient，对吗 httpclient怎样用crt的证书请求。 webservice 与soap有什么关系。 Xml的解析 四种方式：DOM4J、SAX、JDOM和DOM 扩展参考链接： 如何生成本地SSL，并开发SSL下的socket Spring Boot和Apache CXF - 如何在2016年使用SOAP Java and SOAP pkix path building failed and unable to find valid certification path to requested target unable to find valid certification path to requested target Configuring JSSE System Properties 调试SSL / TLS连接 Spring Boot SSL [https] Example Client HTTP Transport (including SSL support) 参考：https://blog.csdn.net/wanglha/article/details/49272551 https://segmentfault.com/a/1190000008604160 https://www.cnblogs.com/xusweeter/p/7659762.html https://stackoverflow.com/questions/44493040/apache-httpclient-pfx-file","link":"/2018/10/11/java/webservice/%E9%80%9A%E8%BF%87HttpClient%E6%90%BA%E5%B8%A6pfx%E5%92%8Cjks%E8%AF%81%E4%B9%A6%E8%B0%83%E7%94%A8HTTPS%E5%8D%8F%E8%AE%AE%E7%9A%84WebService%20-%20%E5%89%AF%E6%9C%AC%20-%20%E5%89%AF%E6%9C%AC/"},{"title":"jmeter-websocket","text":"jmeter 下载地址 Jmeter本身不支持websocket协议的，所以需要安装第三方的插件 地址：https://bitbucket.org/pjtr/jmeter-websocket-samplers 把下载后的 JMeterWebSocketSamplers-1.2.jar 放到Jmeter目录的\\lib\\ext\\目录下，重新启动jmeter 。 在sampler中可以看到有六个websocket的采样器。 request-response sampler。 ping-pong sampler。 close connection sampler。 single-read sampler。 single-write sampler。 open connection sampler。 具体的使用还未搞明白。","link":"/2018/08/15/java/websocket/jmeter-websocket/"},{"title":"Springboot集成websocket并使用RabbitMQ做为消息代理","text":"首先RabbitMQ启用rabbitmq_web_stomp插件 RabbitMQ启用rabbitmq_web_stomp插件 1$ rabbitmq-plugins enable rabbitmq_web_stomp 默认端口为：61613 Springboot配置1、pom.xml 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-websocket&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.projectreactor.ipc&lt;/groupId&gt; &lt;artifactId&gt;reactor-netty&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.2.Final&lt;/version&gt; &lt;/dependency&gt; 2、WebSocketMessageBrokerConfigurer配置 配置外部Rabibitmq替代Simple Broker做消息代理 123456789101112131415161718192021222324252627282930313233343536@Configuration@EnableWebSocketMessageBroker //开启使用STOMP协议来传输基于代理（message broker）的消息//这时控制器支持使用@MessageMapping，就像使用@RequestMapping一样public class WebSocketConfig implements WebSocketMessageBrokerConfigurer { private static final Logger logger = LoggerFactory.getLogger(WebSocketConfig.class); @Autowired private SessionCookieHelper sessionCookieHelper; /** * 注册 Stomp的端点 */ @Override public void registerStompEndpoints(StompEndpointRegistry registry) { registry.addEndpoint(\"/portfolio\")// 添加STOMP协议的端点。 .setAllowedOrigins(\"*\")// 添加允许跨域访问 .addInterceptors(new WebSocketSessionHandshakeInterceptor()) //.setHandshakeHandler(new DefaultHandshakeHandler()) .withSockJS();//指定使用SockJS协议 } /* * 配置消息代理(message broker) */ @Override public void configureMessageBroker(MessageBrokerRegistry registry) { registry.setApplicationDestinationPrefixes(\"/app\") //.enableSimpleBroker(\"/topic\", \"/queue\");//使用内置代理 .enableStompBrokerRelay(\"/exchange\",\"/topic\",\"/queue\",\"/amq/queue\")//处理所有消息将消息发送到外部的消息代理 rabbitmq .setRelayHost(\"192.168.1.90\") .setRelayPort(61613) .setVirtualHost(\"/eyeshot\"); //.setUserDestinationBroadcast(destination) //registry.setUserDestinationPrefix(\"/user\");//推送用户前缀 // registry.setPathMatcher(new AntPathMatcher(\".\")); //设置路径分隔符 } 3、设置握手拦截器 只在进行连接的时候进行拦截 123456789101112131415161718192021222324252627282930313233343536373839404142public class WebSocketSessionHandshakeInterceptor extends HttpSessionHandshakeInterceptor { private static final Logger logger = LoggerFactory.getLogger(WebSocketSessionHandshakeInterceptor.class); @Override public boolean beforeHandshake(ServerHttpRequest request, ServerHttpResponse response, WebSocketHandler wsHandler, Map&lt;String, Object&gt; attributes) throws Exception { if (getSession(request) != null) { ServletServerHttpRequest servletRequest = (ServletServerHttpRequest) request; HttpServletRequest httpServletRequest = servletRequest.getServletRequest();httpServletRequest.getUserPrincipal(); List&lt;String&gt; requestCookies = servletRequest.getHeaders().get(\"cookie\"); for (String string : requestCookies) { String[] cookies = string.split(\";\"); for (String cookie : cookies) { String[] item = cookie.split(\"=\"); if(item[0].equals(\"sessionToken\")) { System.out.println(item[1]); attributes.put(\"sessionToken\", item[1]); } } } HttpSession session = httpServletRequest.getSession(false); if (session != null) { attributes.put(\"sessionId\", session.getId()); } attributes.put(\"user\", session.getId()); } super.beforeHandshake(request, response, wsHandler, attributes); return true; } @Override public void afterHandshake(ServerHttpRequest request, ServerHttpResponse response, WebSocketHandler wsHandler, Exception ex) { super.afterHandshake(request, response, wsHandler, ex); } private HttpSession getSession(ServerHttpRequest request) { if (request instanceof ServletServerHttpRequest) { ServletServerHttpRequest serverRequest = (ServletServerHttpRequest) request; return serverRequest.getServletRequest().getSession(); } return null; }} 4、自定义拦截器 可以对客户端的任何消息拦截 123456789101112131415161718192021/** * 注册自定义身份验证拦截器 * 拦截器只需要在CONNECT上进行身份验证并设置用户头Message。Spring将记录并保存经过身份验证的用户，并将其与同一会话中的后续STOMP消息相关联 */ @Override public void configureClientInboundChannel(ChannelRegistration registration) { registration.interceptors(new ChannelInterceptorAdapter() { @Override public Message&lt;?&gt; preSend(Message&lt;?&gt; message, MessageChannel channel) { StompHeaderAccessor accessor = MessageHeaderAccessor.getAccessor(message, StompHeaderAccessor.class); accessor.getSessionAttributes().get(\"sessionToken\"); if (StompCommand.CONNECT.equals(accessor.getCommand())) { String nickName = accessor.getNativeHeader(\"nickName\") != null ? accessor.getNativeHeader(\"nickName\").get(0) : \"游客\"+accessor.getSessionId(); Principal user = new MyPrincipal(nickName) ; // access authentication header(s) accessor.setUser(user); } return message; } }); } 12345678910111213141516171819import java.security.Principal;public class MyPrincipal implements Principal { private String nickName; public MyPrincipal() { } public MyPrincipal(String nickName) { this.nickName = nickName; } @Override public String getName() { return nickName; }} 然后在客户端进行连接时，在headers中把用户的nickName传入,在拦截器中加入认证Principal，使后续对用户的时间进行监听。 1234567891011121314151617181920function connect() { var headers = { sessionId: '111', passcode: 'mypasscode', // additional header 'sessionId': 'my-client-id', 'nickName' : '大虾' }; var socket = new SockJS(\"/eyeshot/portfolio\");//连接SockJS的endpoint名称为\"/portfolio\" stompClient = Stomp.over(socket);//使用STOMP子协议的WebSocket客户端 stompClient.connect(headers, function (frame) {//连接WebSocket服务端 stompClient.subscribe(\"/topic/response1\", function (msg) {//通过stopmClient.subscribe订阅\"/topic/response\"目标发送的消息，这个路径是在控制器的@SendTo中定义的 //console.log(\"ack \" + msg.ack()); var msgDom = document.getElementById(\"msg\"); var html = msgDom.innerHTML; msgDom.innerHTML = html + \"\\n\" + msg.body; }); }); } 5、用户事件监听 对用户的连接，订阅、取消订阅、断开等事件监听。 1234567891011121314151617181920 @EventListenerpublic void onConnectEvent(SessionConnectEvent event) { logger.info(\"Client with username {} Connect\", event.getUser().getName());}@EventListenerpublic void onSubscribeEvent(SessionSubscribeEvent event) { logger.info(\"Client with username {} Subscribe\", event.getUser().getName());}@EventListenerpublic void onUnsubscribeEvent(SessionUnsubscribeEvent event) { logger.info(\"Client with username {} Unsubscribe\", event.getUser().getName());}@EventListenerpublic void onDisconnectEvent(SessionDisconnectEvent event) { //event.getUser() logger.info(\"Client with username {} disconnected\", event.getSessionId());} 6、Controller 123456789101112131415161718192021222324252627282930313233343536@RestControllerpublic class WebSocketController { private static final Logger logger = LoggerFactory.getLogger(WebSocketController.class); @Resource private SimpMessagingTemplate messagingTemplate;// spring实现的一个发送模板类 @Autowired private SimpUserRegistry userRegistry; // 可获取连接用户 @RequestMapping(\"/index\") public String index() { return \"index\"; } @MessageMapping(\"/test\") public void toAppTest(RequestMessage message) { System.out.println(message.getMessage()); this.messagingTemplate.convertAndSend(\"/topic/response1\", message.getMessage()); } // 当浏览器向服务端发送请求时，通过@MessageMapping映射的地址，类似于@RequestMapping @MessageMapping(value = \"/message/test\") // 当服务端有消息时，会对订阅了@SendTo中的路径的浏览器发送消息 @SendTo(value = \"/topic/response1\") public ResponseMessage say(Principal principal, RequestMessage acceptor) { System.out.println(principal.getName() + \" : \" + acceptor.getMessage()); System.out.println(\"连接人数: \" + userRegistry.getUserCount()); return new ResponseMessage(principal.getName() + \" : \" + acceptor.getMessage()); } @RequestMapping(value = \"/greetings\") public void greetings(@RequestParam String message) { System.out.println(message); this.messagingTemplate.convertAndSend(\"/topic/response1\", message); } 123456789101112131415public class RequestMessage { /*** * 请求消息实体 */ private String message; public String getMessage() { return message; } public void setMessage(String message) { this.message = message; }} 7、html页面 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990&lt;!DOCTYPE html&gt;&lt;html xmlns=\"http://www.thymeleaf.org\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"/&gt; &lt;title&gt;websocket&lt;/title&gt;&lt;/head&gt;&lt;body onload=\"disconnect()\"&gt;&lt;body&gt;&lt;div&gt; &lt;button onclick=\"connect()\" id=\"connect\"&gt;连接&lt;/button&gt; &lt;button onclick=\"disconnect()\" id=\"disconnect\"&gt;断开&lt;/button&gt;&lt;/div&gt;&lt;div id=\"inputDiv\"&gt; &lt;input type=\"text\" id=\"name\"/&gt; &lt;button id=\"send\" onclick=\"send()\"&gt;发送&lt;/button&gt; &lt;button id=\"appTest\" onclick=\"appTest()\"&gt;系统消息&lt;/button&gt;&lt;/div&gt;&lt;div id=\"msg\"&gt;&lt;/div&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/sockjs-client@1/dist/sockjs.min.js\"&gt;&lt;/script&gt;&lt;script src=\"./stomp.min.js\"&gt;&lt;/script&gt;&lt;script&gt; var stompClient = null; //设置连接状态控制显示隐藏 function setConnected(connected) { document.getElementById(\"connect\").disabled=connected; document.getElementById(\"disconnect\").disabled=!connected; if(!connected) { document.getElementById(\"inputDiv\").style.display=\"none\"; }else{ document.getElementById(\"inputDiv\").style.display=\"\"; } document.getElementById(\"msg\").innerHTML = \"\"; } function connect() { var headers = { sessionId: '111', passcode: 'mypasscode', // additional header 'sessionId': 'my-client-id', 'nickName' : '大虾' }; var socket = new SockJS(\"/eyeshot/portfolio\");//连接SockJS的endpoint名称为\"/portfolio\" stompClient = Stomp.over(socket);//使用STOMP子协议的WebSocket客户端 stompClient.connect(headers, function (frame) {//连接WebSocket服务端 setConnected(true); stompClient.subscribe(\"/topic/response1\", function (msg) {//通过stopmClient.subscribe订阅\"/topic/response\"目标发送的消息，这个路径是在控制器的@SendTo中定义的 //console.log(\"ack \" + msg.ack()); var msgDom = document.getElementById(\"msg\"); var html = msgDom.innerHTML; msgDom.innerHTML = html + \"\\n\" + msg.body; }); }); } //断开连接 function disconnect() { if(stompClient!=null){ stompClient.disconnect(); } setConnected(false); console.log(\"disconnected!\"); } //发送名称到后台 function send() { var name = document.getElementById(\"name\").value; stompClient.send(\"/app/message/test\", {}, JSON.stringify({//通过stompClient.send向\"/message/test\"目标发送消息，这个在控制器的@MessageMapping中定义的。 'message': name })); } function appTest() { var name = document.getElementById(\"name\").value; stompClient.send(\"/app/test\", {}, JSON.stringify({//通过stompClient.send向\"/message/test\"目标发送消息，这个在控制器的@MessageMapping中定义的。 'message': name })); }&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 关于controller映射路径参考：http://www.rabbitmq.com/stomp.html#d https://juejin.im/post/5ac8d30151882548fe4a6143","link":"/2018/08/15/java/websocket/springboot%E9%9B%86%E6%88%90websocket%E4%BD%BF%E7%94%A8rabbitmq/"},{"title":"stomp","text":"stomp WebSocket协议定义了两种类型的消息，文本和二进制，但它们的内容是未定义的 ,stomp是更高级别的消息传递协议，定义了客户端和服务器协商子协议的机制 - ，在WebSocket之上使用stomp定义每个消息可以发送什么类型的消息，每个消息的格式和内容是什么，等等 。 以下是订阅接收股票报价的客户的示例，服务器可以用计划任务通过 SimpMessagingTemplate向客户端发送消息来周期性地发出报价： 12345SUBSCRIBEid:sub-1destination:/topic/price.stock.*^@ 以下是客户端发送交易请求的示例，服务器可以通过@MessageMapping方法处理该交易请求，之后，在执行之后，向客户端广播交易确认消息和详细信息： 123456SENDdestination:/queue/tradecontent-type:application/jsoncontent-length:44{\"action\":\"BUY\",\"ticker\":\"MMM\",\"shares\",44}^@ 在STOMP规范中故意将目的地(destination)的含义保持不透明。它可以是任何字符串，完全取决于STOMP服务器，以定义它们支持的目标语义和语法。然而，很常见的是，目标是类似路径的字符串，其中&quot;/topic/..&quot;暗示发布 - 订阅（一对多）、&quot;/queue/&quot;暗示点对点（一对一）消息交换。 STOMP服务器可以使用MESSAGE命令向所有订户广播消息。以下是服务器向订阅客户端发送股票报价的示例： 123456MESSAGEmessage-id:nxahklf6-1subscription:sub-1destination:/topic/price.stock.MMM{\"ticker\":\"MMM\",\"price\":129.45}^@ 启用STOMP123456789101112131415161718import org.springframework.web.socket.config.annotation.EnableWebSocketMessageBroker;import org.springframework.web.socket.config.annotation.StompEndpointRegistry;@Configuration@EnableWebSocketMessageBrokerpublic class WebSocketConfig implements WebSocketMessageBrokerConfigurer { @Override public void registerStompEndpoints(StompEndpointRegistry registry) { registry.addEndpoint(\"/portfolio\").withSockJS(); } @Override public void configureMessageBroker(MessageBrokerRegistry config) { config.setApplicationDestinationPrefixes(\"/app\"); config.enableSimpleBroker(\"/topic\", \"/queue\"); }} 1、&quot;/portfolio&quot; 是WebSocket（或SockJS）客户端需要连接到的端点的HTTP URL，以进行WebSocket握手。 2、目标头&quot;/app&quot;开头的STOMP消息将路由到 类中的@MessageMapping方法@Controller,即请求路径的前缀。 3、使用内置的消息代理进行订阅和广播; 将目标标头以“/ topic”或“/ queue”开头的邮件路由到内置的代理。 说明：对于内置的简单代理，“/ topic”和“/ queue”前缀没有任何特殊含义。它们仅仅是区分pub-sub和点对点消息传递的惯例（即许多订阅者与一个消费者）。使用外部代理时，请参考代理的STOMP页面，以了解它支持的STOMP目标和前缀类型,如 rabbitmq参考: http://www.rabbitmq.com/stomp.html#d 如果要从浏览器连接，对于SockJS，您可以使用sockjs-client 。对于STOMP，可以使用了jmesnil / stomp-websocket库（也称为stomp.js），该库功能齐全，已在生产中使用多年，但不再维护。目前， JSteunou / webstomp-client是该库中最活跃的维护和不断发展的后继者，下面的示例代码基于它： 12345var socket = new SockJS(\"/spring-websocket-portfolio/portfolio\");var stompClient = webstomp.over(socket);stompClient.connect({}, function(frame) {} 或者如果通过WebSocket连接（没有SockJS）： 12345var socket = new WebSocket(\"/spring-websocket-portfolio/portfolio\");var stompClient = Stomp.over(socket);stompClient.connect({}, function(frame) {} 消息流 通过@EnableWebSocketMessageBroker 来组装消息工作流 上图中有3个消息通道： &quot;clientInboundChannel&quot; - 用于传递从WebSocket客户端收到的消息。 &quot;clientOutboundChannel&quot; - 用于向WebSocket客户端发送服务器消息。 &quot;brokerChannel&quot; - 用于从服务器端的应用程序代码向消息代理发送消息。 下图显示了配置外部代理（例如RabbitMQ）以管理订阅和广播消息时使用的组件 上图中的主要区别是使用“代理中继”通过TCP将消息传递到外部STOMP代理，以及将消息从代理传递到订阅的客户端。 地址映射的注解使用带注释的@Controller类来处理来自客户端的消息。这些类可以声明@MessageMapping，@SubscribeMapping和@ExceptionHandler 方法 @MessageMapping 注解@MessageMapping可映射到该地址的消息路由到次方法。 方法参数 描述 Message 用于访问完整的消息。 MessageHeaders 用于访问内部的标头Message。 MessageHeaderAccessor, SimpMessageHeaderAccessor, StompHeaderAccessor 用于通过类型化访问器方法访问标头。 @Payload 用于访问消息的有效负载，通过配置转换（例如，从JSON）MessageConverter 。不需要设置此注释，因为如果没有其他参数匹配，则默认采用它。 Payload参数可以使用@javax.validation.Valid或Spring 注释，@Validated 以便自动验证。 @Header 用于访问特定标头值以及使用 org.springframework.core.convert.converter.Converter必要时的类型转换 。 @Headers 用于访问消息中的所有标头。此参数必须可分配给 java.util.Map @DestinationVariable 用于访问从消息目标中提取的模板变量。必要时，值将转换为声明的方法参数类型。 java.security.Principal WebSocket HTTP握手时登录的用户。 当@MessageMapping方法返回一个值时，默认情况下，该值通过已配置的序列化为有效负载MessageConverter，然后作为Message发送到 &quot;brokerChannel&quot;它向订阅者广播的位置。出站消息的目的地与入站消息的目的地相同 。 可以使用@SendTo方法批注来自定义要将有效负载发送到的目标。@SendTo也可以在类级别使用以共享发送消息的默认目标目标。@SendToUser是仅向与消息关联的用户发送消息的变体。有关详细信息，请参阅用户目标 。 作为从@MessageMapping方法返回有效负载的替代方法，您还可以使用SimpMessagingTemplate发送消息，这也是在封面下处理返回值的方式。请参阅发送消息。 @SubscribeMapping@SubscribeMapping类似于@MessageMapping但仅将映射缩小到订阅消息。它支持与@MessageMapping相同的 方法参数。但是对于返回值，默认情况下，消息通过“clientOutboundChannel”直接发送到客户端以响应订阅，而不是通过“brokerChannel”作为对匹配订阅的广播发送给代理。添加@SendTo或 @SendToUser覆盖此行为并发送给代理。 @MessageExceptionHandler可以使用@MessageExceptionHandler方法来处理@MessageMapping方法中的异常 。 @MessageExceptionHandler方法支持灵活的方法签名，并支持与@MessageMapping相同的方法参数类型和返回值。 外部代理参考选择的消息代理 的STOMP文档 ，（例如 RabbitMQ， ActiveMQ等） ，并启用STOMP支持 ，然后在Spring配置中启用StompBrokerRelay中继而不是SimpleBroker。 12345678910111213141516@Configuration@EnableWebSocketMessageBrokerpublic class WebSocketConfig implements WebSocketMessageBrokerConfigurer { @Override public void registerStompEndpoints(StompEndpointRegistry registry) { registry.addEndpoint(\"/portfolio\").withSockJS(); } @Override public void configureMessageBroker(MessageBrokerRegistry registry) { registry.enableStompBrokerRelay(\"/topic\", \"/queue\"); registry.setApplicationDestinationPrefixes(\"/app\"); }} 配置中“STOMP代理中继”,它建立TCP连接 ,将消息转发到外部消息代理来处理消息 ,然后通过其WebSocket会话将从代理接收的所有消息转发给客户端。 说明：需要为项目添加io.projectreactor.ipc:reactor-netty和io.netty:netty-all依赖项以进行TCP连接管理。 路径分隔符@MessageMapping方法 ，默认使用斜杠“/”作为分隔符 ，如果更习惯于消息传递约定，则可以切换到使用点“.” 作为分隔符。 12345678910111213@Configuration@EnableWebSocketMessageBrokerpublic class WebSocketConfig implements WebSocketMessageBrokerConfigurer { // ... @Override public void configureMessageBroker(MessageBrokerRegistry registry) { registry.setPathMatcher(new AntPathMatcher(\".\")); registry.enableStompBrokerRelay(\"/queue\", \"/topic\"); registry.setApplicationDestinationPrefixes(\"/app\"); }} 之后，控制器可以使用点“。” 作为@MessageMapping方法中的分隔符： 123456789@Controller@MessageMapping(\"foo\")public class FooController { @MessageMapping(\"bar.{baz}\") public void handleBaz(@DestinationVariable String baz) { // ... }} 客户端现在可以向其发送消息&quot;/app/foo.bar.baz123&quot;。 身份验证无法使用cookie的应用程序可能无法在HTTP协议级别进行身份验证 ，可以在STOMP消息传递协议级别使用标头进行身份验证，而不是使用Cookie。有两个简单的步骤可以做到这一点： 使用STOMP客户端在连接时传递身份验证标头。 使用ChannelInterceptor处理身份验证标头。 下面是注册自定义身份验证拦截器的示例服务器端配置。请注意，拦截器只需要在CONNECT上进行身份验证并设置用户头Message。Spring将记录并保存经过身份验证的用户，并将其与同一会话中的后续STOMP消息相关联： 1234567891011121314151617181920@Configuration@EnableWebSocketMessageBrokerpublic class MyConfig implements WebSocketMessageBrokerConfigurer { @Override public void configureClientInboundChannel(ChannelRegistration registration) { registration.setInterceptors(new ChannelInterceptorAdapter() { @Override public Message&lt;?&gt; preSend(Message&lt;?&gt; message, MessageChannel channel) { StompHeaderAccessor accessor = MessageHeaderAccessor.getAccessor(message, StompHeaderAccessor.class); if (StompCommand.CONNECT.equals(accessor.getCommand())) { Authentication user = ... ; // access authentication header(s) accessor.setUser(user); } return message; } }); }} 消息顺序来自代理的消息将发布到“clientOutboundChannel”，从那里将它们写入WebSocket会话。由于通道由ThreadPoolExecutor消息支持，因此在不同的线程中处理消息，并且客户端接收的结果序列可能与发布的确切顺序不匹配。 可以启用以下标志 1234567891011@Configuration@EnableWebSocketMessageBrokerpublic class MyConfig implements WebSocketMessageBrokerConfigurer { @Override protected void configureMessageBroker(MessageBrokerRegistry registry) { // ... registry.setPreservePublishOrder(true); }} 活动事件几个ApplicationContext事件（如下所列），可以通过实现Spring的ApplicationListener接口来接收。 BrokerAvailabilityEvent - 表示Broker何时可用/不可用。虽然“SimpleBroker”代理在启动时立即可用，并且在应用程序运行时仍然如此，但STOMP“代理中继”可能会丢失与全功能代理的连接，例如，如果代理重新启动。代理中继具有重新连接逻辑，并在它返回时重新建立与代理的“系统”连接，因此只要状态从连接变为断开连接，反之亦然，就会发布此事件。使用该组件的组件SimpMessagingTemplate应订阅此事件，并避免在代理不可用时发送消息。在任何情况下，他们都应该准备好在MessageDeliveryException` 发送消息时进行处理。 SessionConnectEvent - 在收到新的STOMP CONNECT时发布，指示新客户端会话的开始。该事件包含表示连接的消息，包括会话ID，用户信息（如果有）以及客户端可能已发送的任何自定义标头。这对于跟踪客户端会话很有用。订阅此事件的组件可以使用SimpMessageHeaderAccessor或 包装所包含的消息StompMessageHeaderAccessor。 SessionConnectedEvent - SessionConnectEvent在Broker发送STOMP CONNECTED框架以响应CONNECT 之后不久发布的。此时，可以认为STOMP会话已完全建立。 SessionSubscribeEvent - 在收到新的STOMP SUBSCRIBE时发布。 SessionUnsubscribeEvent - 收到新的STOMP UNSUBSCRIBE时发布。 SessionDisconnectEvent - 在STOMP会话结束时发布。DISCONNECT可能已从客户端发送，也可能在WebSocket会话关闭时自动生成。在某些情况下，每个会话可能会多次发布此事件。对于多个断开连接事件，组件应该是幂等的。 拦截器上面的事件提供STOMP连接生命周期的通知，而不是每个客户端消息的通知。应用程序还可以注册ChannelInterceptor来拦截任何消息，以及处理链的任何部分。例如，拦截来自客户端的入站消息： 123456789@Configuration@EnableWebSocketMessageBrokerpublic class WebSocketConfig implements WebSocketMessageBrokerConfigurer { @Override public void configureClientInboundChannel(ChannelRegistration registration) { registration.setInterceptors(new MyChannelInterceptor()); }} 自定义ChannelInterceptor可以使用StompHeaderAccessor或SimpMessageHeaderAccessor 访问有关传递的信息。 12345678910public class MyChannelInterceptor implements ChannelInterceptor { @Override public Message&lt;?&gt; preSend(Message&lt;?&gt; message, MessageChannel channel) { StompHeaderAccessor accessor = StompHeaderAccessor.wrap(message); StompCommand command = accessor.getStompCommand(); // ... return message; }} 还可以实现ExecutorChannelInterceptor，它是ChannelInterceptor在处理消息的线程中具有回调的子接口。虽然ChannelInterceptor对于发送到通道的每个消息调用一次，但是每个消息的 ExecutorChannelInterceptor钩子都MessageHandler 从通道订阅了消息。 参考：https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#websocket","link":"/2018/08/13/java/websocket/stomp/"},{"title":"websocket-stomp向指定用户发送","text":"websocket-stomp向指定用户发送 1、Controller 123456789101112@RequestMapping(value = \"/sendToUser\")public void sendToUser(@RequestParam String userName) { System.out.println(userName); this.messagingTemplate.convertAndSendToUser(userName, \"/queue/position-updates\", \"hello \" + userName);} @MessageMapping(\"/trade\") @SendToUser(\"/queue/position-updates\") public ResponseMessage executeTrade(Principal principal, RequestMessage message) { System.out.println(message.getMessage()); return new ResponseMessage(principal.getName()+\" 订阅成功 \"); } 2、js 123456789101112//单独订阅 function subscribeTrade() { var name = document.getElementById(\"name\").value; stompClient.send(\"/app/trade\", {}, JSON.stringify({//通过stompClient.send向\"/trade\"目标发送消息，这个在控制器的@MessageMapping中定义的。 'message': name })); stompClient.subscribe(\"/user/queue/position-updates\", function (msg) {//通过stopmClient.subscribe订阅\"/queue/position-updates\"目标发送的消息，这个路径是在控制器的@SendToUser中定义的 var msgDom = document.getElementById(\"msg\"); var html = msgDom.innerHTML; msgDom.innerHTML = html + \"\\n\" + msg.body; }); } /app/trade 其中app为websocket应用Destination前缀，trade为在Controller中的@MessageMapping中定义的路径。 Spring的STOMP支持可识别&quot;/user/&quot;为此目的而作为前缀的目标，/user/queue/position-updates，该Destination将由该处理UserDestinationMessageHandler并且转换为用户会话唯一的Destination，例如&quot;/queue/position-updates-user123&quot; 。 在发送侧，可以将消息发送到Destination “/user/{username}/queue/position-updates”，该目的地 将由UserDestinationMessageHandler`翻译成一个或多个Destination，用于与用户每个会话相关联。可以针对特定用户发送消息，而不必知道除其名称和通用目标之外的任何内容 。 Controller中sendToUser方法中，发送模板里的 destination /queue/position-updates 将被UserDestinationMessageHandler处理成”/user/{username}/queue/position-updates”，发送给特定用户 参考：https://docs.spring.io/spring/docs/5.0.7.RELEASE/spring-framework-reference/web.html#websocket-stomp-user-destination","link":"/2018/08/15/java/websocket/websocket-stomp%E5%90%91%E6%8C%87%E5%AE%9A%E7%94%A8%E6%88%B7%E5%8F%91%E9%80%81/"},{"title":"webscoket","text":"WebSocket WebSocket 是一种网络通信协议,它可通过单个TCP连接在客户端和服务器之间建立全双工双向通信通道。它来自HTTP的不同TCP协议，但设计为使用端口80和443通过HTTP工作，并允许重用现有防火墙规则 。 WebSocket交互以HTTP请求开始，该HTTP请求使用HTTP &quot;Upgrade&quot;标头升级 ，切换到WebSocket协议 。 12345678GET /spring-websocket-portfolio/portfolio HTTP/1.1Host: localhost:8080Upgrade: websocketConnection: UpgradeSec-WebSocket-Key: Uc9l9TMkWGbHFD2qnFHltg==Sec-WebSocket-Protocol: v10.stomp, v11.stompSec-WebSocket-Version: 13Origin: http://localhost:8080 WebSocket支持的服务器返回 12345HTTP/1.1 101 Switching ProtocolsUpgrade: websocketConnection: UpgradeSec-WebSocket-Accept: 1qVdfYHU9hPOl4JYYNXF623Gzn0=Sec-WebSocket-Protocol: v10.stomp 成功握手后，HTTP升级请求下的TCP套接字保持打开状态，客户端和服务器都可以继续发送和接收消息。 注意：如果WebSocket服务器在Web服务器（例如nginx）后面运行，您可能需要将其配置为将WebSocket升级请求传递到WebSocket服务器。","link":"/2018/08/13/java/websocket/websocket%E4%B8%80/"},{"title":"Linux命令之awk","text":"同时匹配bash和ubuntu: 1$ awk '/bash/&amp;&amp;/ubuntu/' /etc/passwd 匹配bash或ubuntu： 1$ awk '/bash/||/ubuntu/' /etc/passwd 同时匹配bash和ubuntu并打印用户名及shell： 1$ awk -F ':' '/bash/&amp;&amp;/ubuntu/{print $1\"\\t\"$7}' /etc/passwd # （\"\\t\"制表符） 显示/etc/passwd的账户和账户对应的shell,而账户与shell之间以逗号分割,而且在所有行添加列名name,shell,在最后一行添加”end,end”: 1$ awk -F ':' 'BEGIN {print \"name,shell\"} {print $1\",\"$7} END {print \"end,end\"}' /etc/passwd","link":"/2017/08/31/linux/%E5%91%BD%E4%BB%A4/Linux%E5%91%BD%E4%BB%A4%E4%B9%8Bawk/"},{"title":"Linux命令之sed","text":"简介sed 是一种在线编辑器，它一次处理一行内容。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有改变，除非你使用重定向存储输出。Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。 sed命令格式为： sed [-nefri] ‘command’ 输入文本 选项： 123456789101112 -e ：直接在命令行模式上进行sed动作编辑，此为默认选项。 -n ：只打印模式匹配的行 -f∶ 直接将 sed 的动作写在一个文件内， -f filename 则可以执行 filename 内的sed 动作； -r∶sed 的动作支援的是延伸型正规表示法的语法。(预设是基础正规表示法语法)。 -i∶直接修改读取的文件内容，而不是由屏幕输出。常用命令： a ∶新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)。 i ∶插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)； c ∶取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！ d ∶删除，因为是删除啊，所以 d 后面通常不接任何字符； p ∶列印，亦即将某个选择的资料印出。通常 p 会与参数 sed -n 一起运作。 s ∶取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！ 查找： 同时匹配redis、mongoDB ：sed -n ‘/redis/{/mongoDB/p}’ fileName 同时匹配redis、mongoDB、tomcat : sed -n ‘/redis/{/mongoDB/{/tomcat/p}}’ fileName 匹配redis或mongoDB : sed -n ‘/redis|mongoDB/p’ fileName 匹配redis或mongoDB或tomcat : 12sed -n '/redis\\|mongoDB\\|tomcat/p' fileNamesed -n '/\\(redis\\|mongoDB\\|tomcat\\)/p' fileName 1$ sed -n '1,$d' fileName #显示第一行到最后一行 替换：格式：sed ‘s/要替换的字符串/新的字符串/g’ 文件名 （要替换的字符串可以用正则表达式） 把文档中的redis替换为mongoDB : sed ‘s/redis/mongoDB/g’ fileName 把文档中的http:\\www.bjcscn.com替换为http:\\192.168.1.101:8088 : sed -i ‘s/http:\\/\\/www.bjcscn.com/http:\\/\\/192.168.1.101:8088/g’ fileName 删除1234$ sed '1d' fileName #删除第一行$ sed '$d' fileName #删除最后一行$ sed '1,2d' fileName #删除第一行到第二行$ sed '2,$d' fileName #删除第二行到最后一行 添加1234567$ sed '1a Hello World' fileName #在第一行之后增加Hello World$ sed '1i Hello World' fileName #在第一行之前增加Hello World$ sed '1,4a Hello World' fileName #在第一至四行之后都增加Hello World$ sed '1a Hello World\\nadmin' fileName #在第一之后增加Hello World及admin行(\\n换行)$ sed '/Redis/a mongoDB' fileName #查找到Redis所在行，在其后行添加mongoDB行$ sed 's/^/%/g' fileName #在每一行的前面添加\"%\", ^表示行首$ sed 's/$/---/g' fileName #在每一行的行尾添加\"---\", $表示行尾 待补充。。。","link":"/2017/08/30/linux/%E5%91%BD%E4%BB%A4/Linux%E5%91%BD%E4%BB%A4%E4%B9%8Bsed/"},{"title":"adduser新增用户","text":"adduser新增用户 useradd新增用户比较复杂，可用adduser新增用户。 1234567891011121314151617$ adduser elasticAdding user `elastic' ...Adding new group `elastic' (1000) ...Adding new user `elastic' (1000) with group `elastic' ...Creating home directory `/home/elastic' ...Copying files from `/etc/skel' ...Enter new UNIX password:Retype new UNIX password:passwd: password updated successfullyChanging the user information for elasticEnter the new value, or press ENTER for the default Full Name []: elasticsearch Room Number []: Work Phone []: Home Phone []: Other []:Is the information correct? [Y/n] y","link":"/2018/06/05/linux/%E5%91%BD%E4%BB%A4/adduser%E6%96%B0%E5%A2%9E%E7%94%A8%E6%88%B7/"},{"title":"chattr与lsattr","text":"chattr与lsattr","link":"/2018/06/01/linux/%E5%91%BD%E4%BB%A4/chattr%E4%B8%8Elsattr/"},{"title":"dirname 与 basename","text":"dirname命令用于去除文件名中的非目录部分，然后返回剩下的路径（目录的部分）。截取path中的目录路径返回。 用法： 12$ dirname /opt/share/sysfile/readme.txt /opt/share/sysfile basename命令用于打印目录或者文件的基本名称.截取path中的去目录部分的最后的文件或路径名。 用法： 12$ basename /opt/share/sysfile/readme.txt readme.txt 示例： path dirname basename /usr/local/ /usr local /usr / usr usr . usr / / / . . . .. . .. shell脚本中获取当前目录 123#!/bin/bashbasepath = $(cd `dirname $0`; pwd)echo $bathpath","link":"/2018/05/30/linux/%E5%91%BD%E4%BB%A4/dirname%E4%B8%8Ebasename/"},{"title":"rc.local不执行","text":"在/etc/rc.local写入执行命令或脚本，实现系统开机启动功能 1、查看当前系统启动级别 12root@raspberrypi:~# runlevelN 5 2、进入相应启动级别目录，查看是否有rc.local软连接如果没有就在/etc/init.d/下新建一个rc.local文件vim /etc/init.d/rc.local 12345678910111213141516171819202122232425262728293031323334353637383940414243#! /bin/sh### BEGIN INIT INFO# Provides: rc.local# Required-Start: $all# Required-Stop:# Default-Start: 2 3 4 5# Default-Stop:# Short-Description: Run /etc/rc.local if it exist### END INIT INFOPATH=/sbin:/usr/sbin:/bin:/usr/bin. /lib/init/vars.sh. /lib/lsb/init-functionsdo_start() { if [ -x /etc/rc.local ]; then [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_begin_msg &quot;Running local boot scripts (/etc/rc.local)&quot; /etc/rc.local ES=$? [ &quot;$VERBOSE&quot; != no ] &amp;&amp; log_end_msg $ES return $ES fi}case &quot;$1&quot; in start) do_start ;; restart|reload|force-reload) echo &quot;Error: argument '$1' not supported&quot; &gt;&amp;2 exit 3 ;; stop|status) # No-op exit 0 ;; *) echo &quot;Usage: $0 start|stop&quot; &gt;&amp;2 exit 3 ;;esac 然后设置成开机自启服务 1$ update-rc.d rc.local defaults 之后/etc/rc5.d下就会有rc.local软连接。4、之后在/etc/rc.local文件里添加想要执行的命令 1234567891011121314151617#!/bin/sh -e## rc.local## This script is executed at the end of each multiuser runlevel.# Make sure that the script will &quot;exit 0&quot; on success or any other# value on error.## In order to enable or disable this script just change the execution# bits.## By default this script does nothing./usr/bin/screen -S keepmongo mongod -f /etc/mongodb.conf/usr/bin/screen -S keepngrok /opt/ngrok/ngrok -config=/opt/ngrok/config.yml start ssh mongo redis ssh mongo redis 111ssh 111redis zhpt mongo101exit 0 注意：执行的命令路径都要写成绝对路径。 5、重启验证 参考：https://blog.csdn.net/shm839218753/article/details/80213741","link":"/2018/05/09/linux/%E5%91%BD%E4%BB%A4/rc.local%E4%B8%8D%E6%89%A7%E8%A1%8C/"},{"title":"entr是一个监听文件变更的工具","text":"entr是一个监听文件变更的工具 使用该命令首先要先下载安装 1$ wget http://entrproject.org/code/entr-3.9.tar.gz 安装 123./configuremake testmake install 示例 1$ ls test.txt |entr echo test 监听文件变化然后可以执行任意命令 具体使用参考： http://entrproject.org/ https://bitbucket.org/eradman/entr/","link":"/2018/01/23/linux/%E5%91%BD%E4%BB%A4/entr/"},{"title":"scp远程复制文件","text":"从另一台/opt/back目录下文件复制到本地/root目录下 1$ scp -P 22 -r root@43.224.0.1:/opt/back /root 将本地/opt/back目录下文件复制到另一台/root目录下 1$ scp -P 22 -r /opt/back root@123.152.2.3:/root 免密码传输在需要输入密码的机器上执行 1$ ssh-keygen -t rsa 之后3次回车把产生的id_rsa.pub文件复制到另一台的~/.ssh下，并改名为 authorized_keys，如果该文件已存在，就把id_rsa.pub的内容复制到authorized_keys下。即可。","link":"/2018/05/03/linux/%E5%91%BD%E4%BB%A4/scp/"},{"title":"实时监控网络流量和带宽使用-nethogs","text":"Nethogs 是一个终端下的网络流量监控工具,它显示 每个进程 的带宽占用情况。 安装 1$ apt-get install nethogs 使用： 12$ nethogs eth0 # 监视设备(eth0)的网络带宽$ nethogs eth0 eth1 # 监视设备(eth0、eth1)的网络带宽 设置刷新间隔 (默认500ms) 1$ nethogs -d 5 # 设置刷新频率为5秒 NetHogs交互控制：（使用以下按键操作） m: 按m键，切换单位或显示占用速度；切换顺序是（KB/sec，KB，B，MB） r : 按 r 键，按接收流量排序 s : 按 s 键 ，按发送流量排序 q : 按 q 键退出 更多参数参考：nethogs –help 或 man nethogs 项目地址：https://github.com/raboof/nethogs#readme","link":"/2018/09/20/linux/%E5%91%BD%E4%BB%A4/%E5%AE%9E%E6%97%B6%E7%9B%91%E6%8E%A7%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E5%92%8C%E5%B8%A6%E5%AE%BD%E4%BD%BF%E7%94%A8-nethogs/"},{"title":"流量统计工具-vnstat","text":"vnstat是一个基于控制台的网络流量监视器 ，它会记录指定网卡的每小时，每日和每月网络流量 。 它还自带了 vnstati 命令,通过它可以直接可以输出流量统计图. 安装一、安装vnstat两种方式： （1）在包管理程序中安装（ubuntu） 1$ sudo apt-get install vnstat vnstati （2）编译安装(安装最新稳定版本) 1234$ wget https://humdi.net/vnstat/vnstat-1.18.tar.gz$ tar -zxvf vnstat-1.18.tar.gz$ cd vnstat-1.18$ make &amp;&amp; make install 二、查看网卡 1$ ifcongig -a 三、初始化相应网卡的数据库 1$ vnstat -u -i wnet 四、启动 daemon 进程 1$ sudo /etc/init.d/vnstat start 五、默认开机启动 1$ sudo update-rc.d vnstat enable vnStat基本应用1、按小时统计 1$ vnstat -i wnet -h -i：指定网卡 2、按天统计 1$ vnstat -i wnet -d 3、按周统计 1$ vnstat -i wnet -w 4、按月统计 1$ vnstat -i wnet -m 5、统计消耗流量最多的10天的情况 1$ vnstat -i wnet -t 6、实时流量查看 1$ vnstat -i wnet -l 7、输出到图形：使用 vnstati 命令，更多详细的参数可以请 man vnstati。 1$ vnstati -i wnet -m -o /tmp/month.png 效果 官方主页： http://humdi.net/vnstat 参考：http://www.vpswe.com/vps-jiaocheng/483.html","link":"/2018/09/01/linux/%E5%91%BD%E4%BB%A4/%E6%B5%81%E9%87%8F%E7%BB%9F%E8%AE%A1%E5%B7%A5%E5%85%B7-vnstat/"},{"title":"实时监控网络流量和带宽使用-nload","text":"nload是一个控制台应用程序，可实时监控网络流量和带宽使用情况。它使用两个图表可视化输入和输出流量，并提供其他信息，如传输数据总量和最小/最大网络使用量。 安装 1$ apt-get install nload 使用： 12$ nload$ nload eth0 可以按键盘上的 ← → 或者 Enter/Tab 键切换设备(网卡)。 按 F2 显示选项窗口。 按 F5 将当前设置保存到用户配置文件。 按 F6 从配置文件重新加载设置。 按 q 或者 Ctrl+C 退出 nload。 设置刷新间隔 (默认500ms) 1$ nload -t 1000 更多参数参考：nload –help 或 man nload 项目地址：https://github.com/rolandriegel/nload","link":"/2018/09/18/linux/%E5%91%BD%E4%BB%A4/%E5%AE%9E%E6%97%B6%E7%9B%91%E6%8E%A7%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E5%92%8C%E5%B8%A6%E5%AE%BD%E4%BD%BF%E7%94%A8-nload/"},{"title":"混合命令","text":"分析日志请求状态码 1234$ tail -10000 localhost_access_log.2018-02-09.txt |awk '{print $9}'|sort |uniq -c |sort -nr 3206 200 3 500 1 304 分析连接数 12345678$ netstat -ntal |awk '{print $6}'|sort |uniq -c |sort -nr 5243 ESTABLISHED 47 TIME_WAIT 46 LISTEN 12 CLOSE_WAIT 6 FIN_WAIT2 1 Foreign 1 established) 查看系统的虚拟内存、进程、IO读写、CPU活动信息具体参数可参考：https://www.cnblogs.com/kerrycode/p/6208257.html 12345678$ vmstat -w 2 5 procs ---------------memory-------------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 4652792 1689100 296580 1643004 0 0 10 8 0 0 1 0 99 0 0 0 0 4652792 1689032 296580 1643004 0 0 0 2 680 1289 0 0 100 0 0 0 0 4652792 1689188 296580 1643004 0 0 0 8 740 1385 0 0 100 0 0 0 0 4652792 1689188 296580 1643004 0 0 0 16 679 1304 0 0 100 0 0 0 0 4652792 1688772 296580 1643004 0 0 0 2 691 1310 0 0 100 0 0 查看系统内存使用 12345$ free -m total used free shared buffers cached Mem: 16048 14652 1396 0 289 1604 -/+ buffers/cache: 12757 3290 Swap: 16383 4543 11840","link":"/2018/02/09/linux/%E5%91%BD%E4%BB%A4/%E6%B7%B7%E5%90%88%E5%91%BD%E4%BB%A4/"},{"title":"HTTPS之Let’s Encrypt证书","text":"第一种1、访问certBot 选择相应软件及系统，获取安装帮助（nginx、ubuntu16） 12345$ sudo apt-get update$ sudo apt-get install software-properties-common$ sudo add-apt-repository ppa:certbot/certbot$ sudo apt-get update$ sudo apt-get install python-certbot-nginx 2、 安装好之后, 运行 (注意用–nginx-server-root指定nginx.conf的路径，具体certbot参数参考： certbot参数) 1$ sudo certbot --nginx --nginx-server-root=/usr/local/nginx/conf/ Certbot 会自动注册账户，检测 Nginx 配置文件中的域名，询问你为哪些域名生成证书，是否将 Http 重定向到 Https 等等，最后帮你自动修改 Nginx 配置并重启，这时你的网站已经变成了 Https。 3、 自动更新证书 证书只有三个月的有限期，需要启动一个定时任务，在证书过期时自动更新。 1$ sudo certbot renew --dry-run 4、查看证书状态 12345678$ /usr/sbin/certbot certificatesSaving debug log to /var/log/letsencrypt/letsencrypt.logFound the following certs: Certificate Name: qinzufei.top Domains: qinzufei.top Expiry Date: 2017-11-20 07:58:00+00:00 (VALID: 89 days) Certificate Path: /etc/letsencrypt/live/qinzufei.top/fullchain.pem Private Key Path: /etc/letsencrypt/live/qinzufei.top/privkey.pem 5、验证网站等级 https://www.ssllabs.com/ssltest/analyze.html?d=qinzufei.top 6、 可能遇到的问题 123456789101112131415161718192021222324Which names would you like to activate HTTPS for?-------------------------------------------------------------------------------1: qinzufei.top-------------------------------------------------------------------------------Select the appropriate numbers separated by commas and/or spaces, or leave inputblank to select all options shown (Enter 'c' to cancel): 1Obtaining a new certificatePerforming the following challenges:tls-sni-01 challenge for qinzufei.topWaiting for verification...Cleaning up challengesFailed authorization procedure. qinzufei.top (tls-sni-01): urn:acme:error:connection :: The server could not connect to the client to verify the domain :: Connection refusedIMPORTANT NOTES: - The following errors were reported by the server: Domain: qinzufei.top Type: connection Detail: Connection refused To fix these errors, please make sure that your domain name was entered correctly and the DNS A/AAAA record(s) for that domain contain(s) the right IP address. Additionally, please check that your computer has a publicly routable IP address and that no firewalls are preventing the server from communicating with the client. If you're using the webroot plugin, you should also verify that you are serving files from the webroot path you provided. 是因为没开启443端口。 第二种：1、自动安装 123$ wget https://dl.eff.org/certbot-auto$ chmod a+x certbot-auto$ ./certbot-auto 2、生成证书 12#使用-d追加多个域名$ ./certbot-auto certonly --standalone --email qzf98763@163.com --agree-tos -d qinzufei.top -d www.qinzufei.top 如若出现如下错误 12345678910111213Creating virtual environment...Traceback (most recent call last): File \"/usr/lib/python3/dist-packages/virtualenv.py\", line 2363, in &lt;module&gt; main() File \"/usr/lib/python3/dist-packages/virtualenv.py\", line 719, in main symlink=options.symlink) File \"/usr/lib/python3/dist-packages/virtualenv.py\", line 988, in create_environment download=download, File \"/usr/lib/python3/dist-packages/virtualenv.py\", line 918, in install_wheel call_subprocess(cmd, show_stdout=False, extra_env=env, stdin=SCRIPT) File \"/usr/lib/python3/dist-packages/virtualenv.py\", line 812, in call_subprocess % (cmd_desc, proc.returncode))OSError: Command /root/.local/share/letsencrypt/bin/python2.7 - setuptools pkg_resources pip wheel failed with error code 2 原因是python有多个版本 解决： 123$ apt-get install python-pip$ pip install --upgrade pip$ pip -V 如果还是不行 12$ apt-get purge python-virtualenv python3-virtualenv virtualenv$ pip install virtualenv 3、 查看证书：ls /etc/letsencrypt/live/ 4、在nginx配置证书 1234567listen 443 ssl; # managed by Certbot ssl_certificate /etc/letsencrypt/live/qinzufei.top/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/qinzufei.top/privkey.pem; # managed by Certbot include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbotif ($scheme != \"https\") { return 301 https://$host$request_uri;} # managed by Certbot 5、用nginx -t验证 若报ssl未开启错误时。 就重新编译nginx,并开启ssl模块。 12$ ./configure --prefix=/usr/local/nginx --with-http_ssl_module$ make 6、查看证书的状态： 12345678$ /usr/local/certbot/certbot-auto certificatesSaving debug log to /var/log/letsencrypt/letsencrypt.logFound the following certs: Certificate Name: qinzufei.top Domains: qinzufei.top Expiry Date: 2017-11-20 23:56:00+00:00 (VALID: 89 days) Certificate Path: /etc/letsencrypt/live/qinzufei.top/fullchain.pem Private Key Path: /etc/letsencrypt/live/qinzufei.top/privkey.pem 7、实现定时更新证书 模拟证书更新 1$ /usr/local/certbot/certbot-auto renew --dry-run 问题 12Attempting to renew cert (dsbm.bjuri.com) from /etc/letsencrypt/renewal/dsbm.bjuri.com.conf produced an unexpected error: Problem binding to port 443: Could not bind to IPv4 or IPv6.. Skipping.All renewal attempts failed. The following certs could not be renewed: 解决方法：1、停掉nginx 2、更新证书 3、启动nginx 编写更新脚本 12345678#!/bin/bash# 停止nginxservice nginx stop# 续签# --force-renew 强制更新/usr/local/nginx/certbot/certbot-auto renew --force-renew# 启动nginxservice nginx start 添加到crontab定时任务 crontab -e 1230 2 1 * * /usr/local/nginx/certbot/renew-cert.sh &gt;&gt; /var/log/letsencrypt/le-renew.log#在每个月的1号2点30分自动更新证书，在每个月的1号2点35分重新加载nginx 其它：（验证优化结果）https://www.ssllabs.com/ssltest/analyze.html 1、禁用SSLv3：参考 1ssl_protocols TLSv1 TLSv1.1 TLSv1.2; 2、弱Diffie-Hellman和Logjam攻击;参考使用OpenSSL生成一个新的2048位的Diffie-Hellman组 12$ cd /etc/letsencrypt$ openssl dhparam -out dhparams.pem 2048 nginx中配置添加 1234ssl_ciphers 'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA';ssl_prefer_server_ciphers on;ssl_dhparam /etc/letsencrypt/dhparams.pem; 3、关于session、缓存的 123ssl_session_cache shared:SSL:50m;ssl_session_timeout 1d;ssl_session_tickets on; NGINX开启SSL模块1、查看nginx原有的模块 1$ /usr/local/nginx/sbin/nginx -V 2、切换到nginx源码目录 1$ cd /opt/nginx 3、开启SSL模块 12$ ./configure --prefix=/usr/local/nginx --with-http_ssl_module$ make 这里不要进行make install，否则就是覆盖安装 4、备份原有已安装好的nginx 1$ cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.bak 5、然后将刚刚编译好的nginx覆盖掉原有的nginx（这个时候nginx要停止状态） 1$ cp ./objs/nginx /usr/local/nginx/sbin/ 6、然后验证下 1$ /usr/local/nginx/sbin/nginx -V","link":"/2017/08/22/nginx/https/HTTPS%E4%B9%8BLet%E2%80%99s%20Encrypt%E8%AF%81%E4%B9%A6/"},{"title":"TrustAsia证书","text":"证书申请地址：https://freessl.org/可申请TrustAsia（1年有效期）与 Let’s Encrypt（3个月）免费证书。 云端考试服务的数据是从其它服务在Java程序中通过HttpClient推送过来，因云端考试服务是HTTPS，推送会因为证书问题，推送报错。需要再jdk中添加信任此云端证书。因Let’s Encrypt为3个月需要从新签发，签发后要再次在jdk中添加信任新的云端证书。所以申请1年有效期证书 TrustAsia 1、生成验证文件证书类型选择的RSA（阿里云SLB需）、验证类型选择的File、CSR生成选择的浏览器生成。2、验证文件nginx配置添加 123location /.well-known/pki-validation/{ root /usr/share/nginx/html/www/xxbcpnsp; } 在/usr/share/nginx/html/www/xxbcpnsp下新建/.well-known/pki-validation/fileauth.txt配置完进行效验。之后下载证书。3、安装证书把下载的证书上传到一个目录nginx 配置 123456789101112server { # 监听 ssl 443 端口 listen 443 ssl; server_name example.com; # 开启 ssl ssl on; # 指定 ssl 证书路径 ssl_certificate /path/to/example.com.pem; # 指定私钥文件路径 ssl_certificate_key /path/to/example.com.key;} 4、重新加载nginx配置 1$ service nginx force-reload 参考：https://blog.freessl.org/how-to-install-cert-in-nginx/","link":"/2017/12/08/nginx/https/TrustAsia%E8%AF%81%E4%B9%A6/"},{"title":"Let’s Encrypt申请泛域名证书","text":"由于acme.sh验证只支持 dns 验证, 不支持 http 验证. 所以请使用 dns api 模式dns-api模式参考dns-api 通过acme.sh 从 letsencrypt 生成免费的证书. 以下为 Webroot模式普通单个域名签发安装acme.sh1curl https://get.acme.sh | sh 安装过程进行了以下几步: 1、把 acme.sh 安装到了 home 目录下（~/.acme.sh/）。 2、 自动创建 cronjob, 每天 0:00 点自动检测所有的证书。(目前60天以后会自动更新) 其它安装选项参考：安装选项 生成证书生成证书有多种方式 Webroot模式： 1acme.sh --issue -d zyksdq.com -w /usr/share/nginx/html/kaoshibao/guanli -d www.zyksdq.com 必须zyksdq.com 与www.zyksdq.com 指向相同的web根文件夹，并且nginx做好配置，使其可以请求到该目录。其它模式参考：颁发证书 安装证书生成证书后要把copy 到真正需要用它的地方。默认生成的证书在~/.acme.sh/目录下，不要直接使用此目录下的文件。使用以下方法复制到相应位置 1234acme.sh --installcert -d &lt;domain&gt;.com \\ --key-file /etc/nginx/ssl/&lt;domain&gt;.key \\ --fullchain-file /etc/nginx/ssl/fullchain.cer \\ --reloadcmd &quot;service nginx force-reload&quot; 指定的所有参数都会被自动记录下来, 并在将来证书自动更新以后, 被再次自动调用. 更新 acme.sh1acme.sh --upgrade 具体参考：https://github.com/Neilpang/acme.sh/wiki/%E8%AF%B4%E6%98%8E","link":"/2018/04/08/nginx/https/Let%E2%80%99s%20Encrypt%E6%B3%9B%E5%9F%9F%E5%90%8D%E8%AF%81%E4%B9%A6/"},{"title":"证书文件后缀名区分","text":"平时可能遇到各种后缀名的证书相关文件： PEM、DER、CRT、CER、KEY、CSR、PFX、JKS等。 X.509是一种证书的格式标准，它定义了证书中应该包含哪些信息，并描述了这些信息是如何编码的(即数据格式)，可参考RFC5280，SSL使用的就是这种证书标准。一般由用户公共密钥和用户标识符组成，此外还包括版本号、证书序列号、CA 标识符、签名算法标识、签发者名称、证书有效期等信息。 证书的编码格式1、PEM = 扩展名PEM用于ASCII(Base64)编码的各种X.509 v3 证书。 文件开头由一行”—–BEGIN xxx—–“开始，并以 -----END XXX----- 结尾，中间 Body 内容为 Base64 编码过的数据。 通过如下 OpenSSL 命令可以查看其证书内容： 1$ openssl x509 -in xxx.pem -text -noout 它也可以用来编码存储公钥（RSA PUBLIC KEY）、私钥（RSA PRIVATE KEY）、证书签名请求（CERTIFICATE REQUEST）等数据。 一般 Apache 和 Nginx 服务器应用偏向于使用 PEM 这种编码格式。 2、DER = 扩展名DER用于二进制DER编码的证书（无法直接预览）。 通过如下 OpenSSL 命令查看其证书内容： 1$ openssl x509 -in xxx.der -inform der -text -noout 一般 Java 和 Windows 服务器应用偏向于使用 DER 这种编码格式。 证书编码的转换PEM转为DER ： 1$ openssl x509 -in xxx.pem -outform der -out xxx.der DER转为PEM: 1$ openssl x509 -in xxx.der -inform der -outform pem -out xxx.pem (提示:要转换KEY文件也类似,只不过把x509换成rsa,要转CSR的话,把x509换成req…) 证书的扩展名虽然我们已经知道有PEM和DER这两种编码格式,但文件扩展名并不一定就叫”PEM”或者”DER”,常见的扩展名除了PEM和DER还有以下这些,它们除了编码格式可能不同之外,内容也有差别,但大多数都能相互转换编码格式. CRT = 即 certificate 的缩写，常见于类 UNIX 系统。证书可以是DER编码，也可以是PEM编码。但绝大多数情况下此格式证书都是采用 PEM 编码，扩展名CER和CRT几乎是同义词。 CER = CRT证书的微软型式。也是 certificate 的缩写，常见于 Windows 系统，证书可能是PEM编码，也可能是DER编码。但绝大多数情况下此格式证书都是采用 DER 编码。 KEY = 通常用来存放一个 RSA 公钥或者私钥，它并非 X.509 证书格式PCSK#8。编码可能是PEM,也可能是DER。 查看方式： 12$ openssl rsa -in xxx.key -text -noout # PEM编码格式$ openssl rsa -in xxx.key -text -noout -inform der # DER编码格式 CSR = Certificate Signing Request,即证书签名请求,这个并不是证书,而是向权威证书颁发机构获得签名证书的申请,其核心内容是一个公钥(当然还附带了一些别的信息),在生成这个申请的时候,同时也会生成一个私钥。 PFX/P12 ， PKCS #12，是公钥加密标准（Public Key Cryptography Standards，PKCS）系列的一种。将包含了公钥的 X.509 证书和证书对应的私钥以及其他相关信息进行了打包。可以简单理解：.p12 文件 = X.509 证书+私钥。 对nginx服务器来说,一般CRT和KEY是分开存放在不同文件中的,但Windows的IIS则将它们存在一个PFX文件中,(因此这个文件包含了证书及私钥)这样会不会不安全？应该不会,PFX通常会有一个”提取密码”,你想把里面的东西读取出来的话,它就要求你提供提取密码,PFX使用的是DER编码。 从pfx导出crt和key： 12$ openssl pkcs12 -in xxx.pfx -nocerts -nodes -out xxx.key$ openssl pkcs12 -in xxx.pfx -clcerts -nokeys -out xxx.crt 将crt和key合并出pfx:1$ openssl pkcs12 -export -in xxx.crt -inkey xxx.key -out xxx.pfx JKS - Java Key Storage, 这是Java的专利,跟OpenSSL关系不大,利用Java的一个叫”keytool”的工具,可以将PFX转为JKS,当然了,keytool也能直接生成JKS。它也同时包含证书和私钥。常用于Tomcat。 参考：https://segmentfault.com/a/1190000011709784 https://kangzubin.com/certificate-format/","link":"/2018/10/15/nginx/https/%E8%AF%81%E4%B9%A6%E6%96%87%E4%BB%B6%E5%90%8E%E7%BC%80%E5%90%8D%E5%8C%BA%E5%88%86/"},{"title":"malloc(262144) failed  Cannot allocate memory","text":"malloc(262144) failed (12: Cannot allocate memory) 重庆服务器18-02-09 突然网站无法访问 nginx日志信息(类似) 1232018/02/09 01:47:56 [emerg] 26018#0:*177348 malloc(262144) failed (12: Cannot allocate memory) while reading client request line, client: xx.xx.xx.xx, server: yy.yy.yy.yy:802018/02/09 01:47:56 [emerg] 26018#0: *177350 malloc(262144) failed (12: Cannot allocate memory) while reading client request line, client: xx.xx.xx.x, server: yy.yy.yy.yy:802018/02/09 01:47:56 [emerg] 26018#0: *177351 malloc(262144) failed (12: Cannot allocate memory) while reading client request line, client: xx.xx.xx.xx, server: yy.yy.yy.yy:80 通过free -m 查看内存信息，发现系统内存还宽裕。 修改vim /etc/sysctl.conf 1vm.max_map_count=128000 #增加 然后运行 1$ sysctl -p 参考：http://www.cnblogs.com/jzssuanfa/p/6748531.html","link":"/2018/02/09/nginx/%E5%BE%85%E9%AA%8C%E8%AF%81%E8%A7%A3%E5%86%B3/malloc%20%20Cannot%20allocate%20memory/"},{"title":"nginx配置文件中if多重判断","text":"nginx配置文件中if多重判断 Nginx不支持 and、or、&amp;&amp;、|| 这类语法；且不支持if的多重嵌套。 实现方法一每个域名配置单独的server{}，这样配置比较简明；但缺点是配置文件会写很长，要修改多次。（比较啰嗦）。 实现方法二全部域名配置一个server{}，进行多重判断；这样配置可能稍微复杂一点，但配置文件不会那么啰嗦。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849server{ listen 80; server_name xzjps.bjcscn.com hncszj.bjupi.com; root html/unitrecordO_zjps; index index.html; location = /{ set $flag 0; if ($host = \"hncszj.bjupi.com\"){ set $flag \"${flag}1\"; } if ($query_string !~* ^(.*)userGroup=(.*)$){ set $flag \"${flag}2\"; } if ($flag ~* \"012\"){ rewrite ^/(.*)$ http://hncszj.bjupi.com/?userGroup=41 break; } } # 如果满足条件一并同时也满足条件二,就重定向到http://hncszj.bjupi.com/?userGroup=41 location = /index.html { add_header Cache-Control \"no-cache no-store\"; } location /{ try_files $uri $uri/ /index.html; } location /cpnsp/{ proxy_connect_timeout 3; proxy_send_timeout 300; proxy_read_timeout 300; proxy_pass http://urstrem3; proxy_set_header REMOTE_ADDR $remote_addr; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; }}","link":"/2020/03/29/nginx/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/nginx%E4%B8%ADif%E5%8F%8C%E9%87%8D%E5%88%A4%E6%96%AD/"},{"title":"nginx配置文件中if多重判断","text":"1234upstream teststrem2 { server 127.0.0.1:8300 max_fails=1 fail_timeout=60s; server 127.0.0.1:8301 max_fails=1 fail_timeout=60s; } max_fails 、 fail_timeout 是Nginx的负载均衡检查模块中两个可选参数。用于判断后端节点状态。 Nginx基于连接探测，如果发现后端异常，在单位周期为fail_timeout设置的时间，中达到max_fails次数，这个周期次数内，如果后端同一个节点不可用，那么将把节点标记为不可用，并等待下一个周期（同样时常为fail_timeout）再一次去请求，判断是否连接是否成功。如果成功，将恢复之前的轮询方式，如果不可用将在下一个周期(fail_timeout)再试一次。 在两个节点都可用的情况下，突然有一个节点挂掉，客户端请求过来后哪怕请求到了不可用的节点，此次请求也不会失败，因为Nginx会把此次请求转发到另外一个可用节点，再把结果返回给客户端。当一个节点挂掉，Nginx不知道节点是否恢复的时候，会把客户端的请求同时转发到两个节点，判断节点健康情况。 可用于解决之前刘问的问题，后端服务更新或者出现溢出，服务不可用时，导致前端桌面端卡死的情况。 参考：https://blog.51cto.com/kexiaoke/2316851 参考：https://blog.51cto.com/kexiaoke/2316851","link":"/2020/03/29/nginx/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/nginx%E4%B8%ADmax_fails%E5%92%8Cfail_timeout/"},{"title":"nginx在请求路径中修改字符串","text":"nginx在请求路径后加字符串 需求一：http://192.168.1.113:8080/cpnsp/ws/playhls/4f2ef26002aa4b0b8990e1503abe624a.m3u8，你能跟我转发给：http://192.168.1.113:8080/cpnsp/ws/playhls/4f2ef26002aa4b0b8990e1503abe624a么？就是播放要认后缀名.m3u8，而我们系统没有用后缀。 123456location ~* /playhls/(.*) { set $suffix \".m3u8\"; if ($request_uri !~* /(.*)\\.m3u8$) { rewrite ^/(.*)$ http://$server_name$request_uri$suffix; } } nginx$参数 需求二：把/cpnsp/ws/playhls/4f2ef26002aa4b0b8990e1503abe624a.m3u8 转发到/cpnsp/ws/playhls/4f2ef26002aa4b0b8990e1503abe624a 即前端要用playhls/xxx.m3u8，转到后台是playhls/xxx 123456789location ~* /playhls/(.*) { if ($request_uri ~* (/.*)\\.m3u8$) { set $repath $1; #echo $repath; rewrite ^/(.*)$ $repath break; proxy_pass http://192.168.1.101:8088; # rewrite ^/(.*)$ http://$server_name$repath; }} 1、先用正则(/.*)\\.m3u8$匹配到/cpnsp/ws/playhls/4f2ef26002aa4b0b8990e1503abe624a.m3u8 2、然后把括号中截取到的字符/cpnsp/ws/playhls/4f2ef26002aa4b0b8990e1503abe624a 赋值给变量$repath , $1表示第一个括号内匹配的正则参数。 3、然后用rewrite 修改 $uri。 4、最后proxy_pass按路径/cpnsp/ws/playhls/4f2ef26002aa4b0b8990e1503abe624a转发到 http://192.168.1.101:8088 注意 rewrite 要有个重新匹配 location 的副作用。由于 proxy_pass 的处理阶段比 location 处理更晚，所以这里需要 break 掉，以防止 rewrite 进入下一次 location 匹配而丢失 proxy_pass。","link":"/2020/04/28/nginx/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/nginx%E5%9C%A8%E8%AF%B7%E6%B1%82%E8%B7%AF%E5%BE%84%E4%B8%AD%E4%BF%AE%E6%94%B9%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"title":"梅西","text":"梅西，这个名字 初闻大概是大三那年巴西世界杯，同在宿舍观看世界杯的室友口中第一次听到梅西这个名字，由于此前并未关注过足球，至此，时至俄罗斯世界杯，对梅西的印象也只是踢球比较厉害，别的再无其它，甚至他所代表的国家也是在这次俄罗斯世界杯才得知的。端午假期正值世界杯开赛，有幸观看了阿根廷与冰岛的比赛，最终是1比1平，期间有个点球，是梅西主罚，但最终是被冰岛门将扑出。之后两天便是各种爆料，梅西点球被导演门将扑出的新闻。前两天阿根廷对阵克罗地亚 0：3 惨败，感觉怎么梅西不想传说中的那样。这两天对梅西有了进一步认识，今天又无意得知今天是你的生日，内心产生了一些共鸣。 祝你生日快乐！ 以下转自：https://kuaibao.qq.com/s/FTB2018062400947700 1987年6月24日，阿根廷圣菲胜罗萨里奥市，一个婴孩呱呱坠地。5年后他开始踢球，11年后被诊断患有侏儒症，13年后他用自己的足球天赋换来了治疗疾病的费用。从这一年开始，他的人生和足球彻底捆绑在了一起。然后，31年后的6月24日，2018年俄罗斯，31岁的他带着天之骄子的称号，带着潘帕斯雄鹰的骄傲，再次站在世界杯的舞台上了。里奥-梅西，生日快乐！ 如果我们试着去读懂梅西，就会发现这个总是背对全世界的瘦小男人其实超乎寻常的帅气。 身高170cm，没有发达的肌肉，可每当他瞪着小熊一般的圆眼睛发懵的时候，他微微蹙眉的时候，他咧嘴大笑的时候，却将“萌帅”演绎到了极致。 而剥去“萌帅”的外表，我们看到的则是他安静低调、害羞内敛的性格，是他唯爱与足球不可辜负的忠贞，是他数十年如一日从未崩塌的人设。 【若你喜欢怪人，其实我很美】 5岁开始踢球，11岁被诊断出侏儒症，家里治不起，母队纽维尔老伙计以及一度想要挖角的河床队在得知他的顽疾后都选择了放弃。也许要感谢当年他们的不救之恩，才有了后来的里奥-梅西。 2000年9月，年仅13岁身高只有140cm的梅西去了巴塞罗那青训营拉玛西亚试训。在试训期间，梅西用表现征服了巴萨青年队教练，也为自己赢得了治疗身体的靠山。 风扬起了他的黑发，他不经心地甩过鬓颊。无论是那个右路无限突破，能够复制马拉多纳当年连过五人进球的追风少年，还是转为中锋后疯狂进球的梅球王，耳边越来越嘈杂，他始终安静着。 不同于南美球星的独领风骚，更不像欧洲球星的霸气外露，我从没有见过像梅西这样“存在感极低”的前锋，过人摔倒了居然可以瞬间弹起来，他不擅长表演疼痛，他擅长继续带球。没有狂拽炫酷的进球庆祝动作，每当破门得分时，他只会傻傻的振臂狂奔，虔诚地双手指天。后来这个曾经旁人眼里有些怪异的“病孩子”站在了世界之巅，却仍然行事低调得不像个巨星。 像梅西这样的“怪人”，日本作家中岛敦在《山月记》中如是描述：因为害怕自己并非明珠而不敢刻苦琢磨，又因为有几分相信自己是明珠，而不能与瓦砾碌碌为伍，遂逐渐远离世间，疏避人群，结果在内心不断地用愤懑和羞怒饲育着自己懦弱的自尊心。世上每个人都是驯兽师，而那匹猛兽，就是每人各自的性情。 【你是南国来的孩子，人要爱人要恨的样子】 点球，对每个前锋来说是荣辱兼具的神秘大礼。而对梅西来说，点球留下的几乎全是不堪的回忆。自梅西出道以来，他一共踢了107个点球，踢丢了23次，得分率仅为76%。在国家队中，梅西21次点球踢丢4次。而在欧冠、西甲、国王杯等各条战线他均有点球不进的历史。他甚至在自己30岁时，才玩出了职业生涯第一个“勺子”点球。 2015年十月在北京鸟巢举行的南美超级杯上，梅西点球被巴西门将扑出，导致阿根廷最终落败。2012年欧冠半决赛对阵切尔西，在切尔西被罚下一人的情况下，梅西加时赛点球击中横梁，最终巴萨惨遭托雷斯绝杀。2016年美洲杯决赛，点球大战，梅西面对智利门将没能战胜濒临崩溃的心理防线一脚将球踢飞。 本届世界杯小组赛首轮，梅西左侧打门，一个质量不高的半高球被冰岛门将哈儿多松自信的扑救拒之门外……让人想起张悬那首《南国的孩子》 你是南国来的孩子 有着不能缚的性子 身上披覆了预言而浑然不知 奔跑着忘我的快乐悲伤都放肆 阳光也不愿阻止 球场上的梅西似乎更习惯于风驰电掣的突出重围，或是积极专注的组织进攻，而站上罚球点的梅西，只是一个走下神坛的凡人，所有人都能看到他的彷徨，焦虑，和无助。 五夺金球，四夺金靴，西甲、国王杯、欧冠、奥运会金牌，他在自己的职业生涯中已经做到了极致。如果还有什么遗憾，那便是身上的阿根廷球衣带给他的三个亚军了（2014巴西世界杯亚军、2015智利美洲杯亚军、2016美国美洲杯亚军）。但足球世界若注定要以一座世界杯来封王吗？ 你是南国来的孩子 人要爱人要恨的样子 血里流传着远在古老的故事 手心刻划上帝的仁慈 与未知相似 无论是C罗还是梅西，很多人都习惯在他们落败的时候摆出大评论家的姿态去指摘，但也许要不了几年，我们就快在球迷的口水之中迎来无巨星的足坛。如果无法欣赏，也请别再苛责，至少珍惜这个尚且还有巨星的时代。 【一生一世一双人，一红一蓝一颗魂】 关于梅西有多忠诚，安东内拉和巴塞罗那心里最有数。 有人说梅西最厉害的地方不是年度91球，也不是五座金球奖，而是9岁陪伴在他身边的女孩，30岁依然在。 去年，一向低调的梅西，却终于在爱情上任性了一回。请了足坛的半壁江山，把一场世纪婚礼献给他唯一挚爱的女人安东内拉。尽管婚礼豪华，但梅西执意不收份子钱，要给就捐给慈善机构。梅西的世纪婚礼，不为噱头，只因爱情。结婚那天他说，“我这一生最大的荣誉，是娶到了我喜欢了21年的女孩。” 九岁对她一见钟情，十二岁写了人生第一封情书，十八岁听说她闺蜜车祸身亡便立刻飞回阿根廷陪伴……他会在功成名就的时候打电话给她说，我还是当年那个喜欢踢球的害羞男孩，无论我得到多少荣誉，我还是那个喜欢你的里奥-梅西。对于安东内拉来说，和梅西在一起的这些年同样坎坷，梅西的低谷和巅峰，也是她陪他一起走过。 我爱你，你爱我，那就别管外面几双眼睛几只耳朵，请共我一起，放心探戈。 终老诺坎普？ Sí,quiero.（是的，我愿意。） 去年三十岁的梅西，不仅对安东内拉说，也对巴塞罗那说。 从2000年到如今，梅西送走了巴萨一代又一代的神锋，18年的不离不弃，还将延续。也许真的是性格使然，爱一个人要爱到天荒地老，着一身衫那就这样终老。对爱情，对足球，梅西身上都有一股近乎执拗的倔强。 深山的鹿，不知归处，万般皆苦，只可自渡。他射空过，也失落过，也许天才生来就是孤独，一身才华与满腔抱负也不过是无处安放。光阴荏苒，我们看到左岸身披红蓝衫的梅西站在制高点不断地刷新着荣誉，而右岸那个身披蓝白衫的梅西则总是垂头失意。 淡漠到失去热忱的时候他也许就会觉得自己老了，而某些瞬间，甚至无法描述那个瞬间，我们固执地相信他仍旧是当年那个羞涩的孩子。可当又一次与胜利擦肩的无力感席卷而来，梅西31岁了，我们只能任凭所有的执念无疾而终。或许，这正是我们爱他的原因。 小组赛末轮便是阿根廷的生死战，也许还有一个置之死地而后生的剧本等着我们去开启。他在用背影告诉我们：我不是天生强大，我只是天生要强。我没在慌，我已经是球王。 生日快乐，唯一的里奥-梅西。","link":"/2018/06/24/%E5%85%B6%E5%AE%83/%E6%96%87%E4%BB%B6%E5%A4%B9/%E6%A2%85%E8%A5%BF/"},{"title":"使用systemd控制frp(frpcfrps)开机自启","text":"以frpc为例 1、新建项目的systemd管理文件frpc.service vim /etc/systemd/system/boot_cpnspcms.service 123456789101112[Unit]Description=FRP to bypass NAT NetworkAfter=network.target[Service]Type=simpleExecStart=/opt/frp/frp_0.30.0/frpc -c /opt/frp/frp_0.30.0/frpc.iniStandardOutput=syslogStandardError=inherit[Install]WantedBy=multi-user.target 2、管理 123$ systemctl daemon-reload$ systemctl enable frpc.service$ systemctl start frpc.service","link":"/2019/12/02/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/frp/%E4%BD%BF%E7%94%A8systemd%E6%8E%A7%E5%88%B6frp(frpcfrps)%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF/"},{"title":"内网穿通-frp","text":"一、frp 在服务端（有公网IP的机器）和 客户端（需要穿透的内网环境机器）上下载frp程序 服务端主要使用frps 及 frps.ini 客户端主要使用frpc 及 frpc.ini 二、配置 服务端参考配置 vim frps.ini 123456789101112131415161718192021[common]bind_port = 7000# web服务vhost_http_port = 7070#vhost_https_port = 443subdomain_host = frps.com # 自定义二级域名#frp 的状态及代理统计信息dashboard_port = 7500dashboard_user = admindashboard_pwd = admin#auth tokentoken = 123456#loglog_file = /dbdata/opt/frps/frp_0.21.0_linux_amd64/frps.loglog_level = infolog_max_days = 3 将泛域名 *.frps.com 解析到 frps 所在服务器的 IP 地址。 客户端参考配置 vim frpc.ini 123456789101112131415161718192021222324[common]server_addr = 111.124.41.152server_port = 7000#authenticationtoken = 123456#loglog_file = ./frpc.loglog_level = infolog_max_days = 3# 192.168.1.111 上服务[ssh_111]type = tcplocal_ip = 127.0.0.1local_port = 22remote_port = 11122[web_101]type = httplocal_ip = 192.168.1.101local_port = 80subdomain = fei 三、启动 启动两个frp服务 12$ nohup ./frps -c ./frps.ini &gt; nohup.log 2&gt;&amp;1 &amp; # 服务端$ nohup ./frpc -c ./frpc.ini &gt; nohup.log 2&gt;&amp;1 &amp; #客户端 四、访问： dashboard : http://[server_addr]:7500 访问 dashboard 界面，用户名密码默认为 admin web_101 : http://fei.frps.com:7070 ssh_111: ssh -oPort=11122 root@x.x.x.x 参考：https://github.com/fatedier/frp/blob/master/README_zh.md","link":"/2018/11/13/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/frp/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%9A-frp/"},{"title":"ngrok内网穿通","text":"一、ngrok 服务端 暂不搭建，使用官方或其他人提供的服务端。 1、下载客户端： https://ngrok.com/download http://www.ittun.com 12$ unzip /opt/ngrok.zip$ cd /opt/ngrok 2、定义配置文件 vim ngrok.yml (下面是个示例) 123456789101112131415161718---server_addr: \"ngrok.xiaomiqiu.cn:4443\"trust_host_root_certs: falsetunnels: ssh: remote_port: 51001 proto: tcp: \":22\" web: subdomain: test root: \"html/\" proto: http: \":8080\" web2: hostname: pimwx2 root: \"D:/java/nginx-1.0.11/html\" proto: http: \":80\" 字段说明：参考：https://ngrok.com/docs 每个隧道必须定义 proto和addr。其他属性可用，许多是协议特定的。 server_addr：服务端地址，从网上找，有些服务可能已经停了，可参考：http://ngrok.ciqiuwl.cn/、https://natapp.cn/、http://www.ittun.com。。。（tunnel.phpor.me:4443、tunnel.phpor.me:4443、ittun.com:44433、tunnel.mobi:44433、tunnel.phpor.me:4443) trust_host_root_certs：true 指示ngrok信任计算机上的根证书；false 使用自签名证书。 proto 需要 所有 隧道协议名称，中的一个http，tcp，tls addr 需要 所有 将流量转发到本地端口号或网络地址 inspect 所有 启用http请求检查 auth HTTP HTTP基本认证凭据来强制执行隧道请求 host_header HTTP 将HTTP Host头重写为此值，或preserve将其保持不变 bind_tls HTTP 性结合的HTTPS或HTTP端点或两者true，false或both subdomain HTTP TLS 子域名请求。如果未指定，请使用隧道名称 hostname HTTP TLS 要求的主机名（需要保留名称和DNS CNAME） crt TLS 此路径上的PEM TLS证书在本地转发之前终止TLS流量 key TLS 此路径上的PEM TLS私钥在本地转发之前终止TLS流量 client_cas TLS 此路径上的PEM TLS证书颁发机构将验证传入的TLS客户端连接证书。 remote_addr TCP 绑定给定地址上的远程TCP端口 3、启动 多种方式： 123$ ./ngrok -config=config.yml -subdomain=bjcscn 80$ ngrok start --all$ ngrok start admin ssh 成功后如下： 1234567ITTUN Tunnel Status onlineVersion 1.7/1.7Forwarding http://bjcscn.ngrok.xiaomiqiu.cn -&gt; 127.0.0.1:80Web Interface disabled# Conn 0Avg Conn Time 0.00ms 如启动不成功 查看具体报错行数 1$ ./ngrok list 注意：yaml语法 每行的缩进要一致。 4、后台运行方法 ngrok用&amp;不能后台运行，要使用screen命令或者Supervisor管理。 以下使用screen命令。 安装：apt-get install screen screen -S 任意名（如keepngron 进程名） ./ngrok start ssh mongo redis 最后按快捷键 ctrl+A+D 退出，即可保持ngrok后台运行。 5、服务端： 如需搭建服务端参考：http://blog.csdn.net/u013216667/article/details/50782084 https://github.com/inconshreveable/ngrok/blob/master/docs/SELFHOSTING.md https://hteen.cn/docker/docker-ngrok.html 二、frp 参考：https://github.com/fatedier/frp/blob/master/README_zh.md 三、zerotier https://www.v2ex.com/t/486244#reply14 四、其它服务 如：xtunnel、OpenVPN 、pagekite、…..","link":"/2017/09/29/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/ngrok/ngrok%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%9A/"},{"title":"数据结构于算法一","text":"广义上讲数据结构就是一组数据存储的结构，算法就是操作数据的方式。 数据结构和算法是相辅相成的，数据结构是为算法服务的，算法要作用在特定的数据结构之上。 如数组具有随机访问的特点，二分查找算法需要用数组来存储数据。如果选用了链表的数据结构，就不能用二分查找算法了，因为链表不具有随机访问的特性。 基础常用的 10个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie树； 10个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法 学习数据结构和算法的过程，是非常好的思维训练的过程，所以，千万不要被动地记忆，要多辩证地思考，多问为什么。 学习方法 边学边练，适度刷题。 多问，多思考，多互动。 设立一个切实可行的目标。 知识需要沉淀，不要想试图一下子掌握所有。","link":"/2019/08/29/%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E4%B8%80%E6%96%B9%E6%B3%95/"},{"title":"复杂度分析","text":"时间、空间复杂度分析 大O表示法：T(n) = O( f(n)) T(n)表示代码执行的时间，n代表数据的规模大小，f(n)代表每行代码执行次数的总和，O表示代码的执行时间与f(n)表达式成正比。 大O这种复杂度表示方法只是表示一种变化趋势。通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。 分析时间复杂度 1、只关注循环次数最多的一段代码。 2、加法原则，总复杂度等于量级最大的那段代码的时间复杂度。 3、乘法原则，嵌套代码的复杂度等于嵌套内外代码复杂度的乘积。 常见的多项式时间复杂度 1、O(1) O(1) 是常量级时间复杂度的一种表示方法，代码的执行时间不随n的增大而增长。 2、O(logn)、O(nlogn) 1234i=1;while (i &lt;= n) { i = i * 2;} 变量 i 的值从 1 开始取，每循环一次就乘以 2 。当大于 n 时，循环结束，变量 i 的取值就是一个等比数列。即求解2^x =n，x即代码执行的次数，x=log 2 n，所以时间复杂度就是O(log 2 n)。 在对数阶时间复杂度的表示方法里，可以忽略对数的“底”，统一表示为 O(logn) 。 如果一段代码的时间复杂度是 O(logn) ，循环执行 n 遍，时间复杂度就是 O(nlogn) 了。 O(nlogn) 也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 O(nlogn) 。 3、O(m+n)、O(m*n) 代码的复杂度由两个数据的规模来决定。 常见的复杂度并不多，从低阶到高阶有：O(1)、O(logn)、O(n)、O(nlogn)、O(n^2 ) 最好情况时间复杂度、最坏情况时间复杂度和平均情况时间复杂度。 平均时间复杂度的全称应该叫加权平均时间复杂度或者期望时间复杂度。 均摊时间复杂度，对应的分析方法，摊还分析 均摊时间复杂度就是一种特殊的平均时间复杂度 应用场景，对一组数据结构的连续操作，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，并且这些操作存在着前后连贯的时序关系，这时，就可以将这组操作放在一块分析。看能否将时间复杂度较高的那次操作耗时，均摊到时间复杂度低的操作上，而且，能够运用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。 空间复杂度分析 表示算法的存储空间与数据规模之间的增长关系。 常见的空间复杂度就是O(1)、O(n)、O(n^2 )。","link":"/2019/08/29/%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/"},{"title":"数据结构于算法——数组","text":"数组是一种线性表数据结构，用一组连续的内存空间，来存储一组相同类型的数据。 关键词 1、线性表 线性表即数据排列成像线一样的数据结构，每个线性表上的数据最多只有向前、向后两个方向。数组、链表、队列、栈都是线性表数据结构。 非线性表结构如二叉树、堆、图等，数据间不是简单的前后关系。 2、连续的内存空间和相同的数据类型 正是这两个限制，使数组具有“随机访问”的特性。当然这个特性也使数据的有些操作变得很低效，如插入和删除，为了保证连续性，就需要做大量的数据搬移工作。 链表适合插入和删除操作，时间复杂度为O(1)，数组支持随机访问，根据下标随机访问的时间复杂度为O(1),适合查找操作，排好序的数组用二分查找时间复杂度为O(logn)。 关于数组插入和删除的思路和技巧 如果数组中的数据是有序的，插入一个元素，将要将之后的数据向后搬移。但是，如果数据是没有规律，数组只是被当作一个存储数据的集合，这种情况，在数组的第k个位置插入一个元素，为了避免大规模的数据迁移，可以将第k位数据搬移到数组最后，把新元素插入到第K位上。这样时间复杂度就将为了O(1)，快排中就是这种处理思想。 删除操作也是类似，如果并不一定追求数据的连续性，可以先记录已删除的数据，并不是真正的搬移数据，只是记录数据被删除，当数组没有更多的存储空间时，再触发一次真正的删除操作。这也是JVM的标记清除垃圾回收算法的核心。 注意数组的访问越界问题 ArrayList与数组 ArrayList将数组的操作(如：插入、删除等操作)封装起来了，并且ArrayList支持动态扩容，存储空间不足时，会自动扩容为原来的1.5倍。 ArrayList无法存储基本数据类型，儿装箱和拆箱操作会有一定的性能损耗，如特别关注性能，或者希望使用基本数据类型，就可以选择数组。 事先已知数据大小，并且对数据的操作比较简单，使用不到ArrayList中的操作，可以选用数组。 要表示多维数组时，数组更加直观。如Object[] [] array,用List就像ArrayList array。 12int[][] arr = new int[3][2];//表示arr中有3个一维数组，每个一维数组中有2个元素","link":"/2019/08/30/%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E7%BB%84/"},{"title":"数据结构于算法——链表","text":"缓存淘汰策略 1、先进先出策略 FIFO （ First In ， First Out ） 2、最少使用策略 LFU （ Least Frequently Used ） 3、最近最少使用策略LRU（ Least Recently Used ） 链表 常见的链表结构 单链表、双向链表、循环链表","link":"/2019/09/08/%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/"},{"title":"MongoDB4.0操作pushAll问题.","text":"mongodb4.0中使用$pushAll(),会报错：com.mongodb.MongoWriteException: Unknown modifier: $pushAll mongodb4.0版本中$pushAll()已弃用。改为运算符$push和$each(), $each与$push使用，把数组中的每个元素添加到字段中。(会添加重复项) 1234db.students.update( { name: \"joe\" }, { $push: { scores: { $each: [ 90, 92, 92, 85 ] } } }) $each与$addToSet一起使用，把数组中的每个元素添加到字段中，(不会添加重复项) 1234db.inventory.update( { _id: 2 }, { $addToSet: { tags: { $each: [ \"camera\", \"electronics\", \"accessories\" ] } } } ) 参考：https://docs.mongodb.com/v4.0/reference/operator/update/each/ https://github.com/Automattic/mongoose/issues/5574 https://docs.mongodb.com/v3.0/reference/operator/update/pushAll/","link":"/2018/12/20/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/MongoDB4.0%E6%93%8D%E4%BD%9CpushAll%E9%97%AE%E9%A2%98/"},{"title":"MongoDB可视化管理工具问题","text":"使用NoSQL Manage for MongoDB 工具连接 新的（未创建任何数据库）阿里云MongoDb数据库时一直报错：未将对象引用设置到对象的实例。 网上看到说和 net framework 版本有关系，换了版本也不行。 解决办法： 在上面创建一个数据库，然后用一个新的账号（不要给root权限）去连接，便可以连上。","link":"/2018/12/14/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/MongoDB%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7%E9%97%AE%E9%A2%98/"},{"title":"MongoDb自动备份","text":"1、新建mongoDB备份存放目录： 12mkdir /dbdata/db_backup/mongodb_ali/mongodb_bak_nowmkdir /dbdata/db_backup/mongodb_ali/mongodb_bak_list 2、创建备份脚本说明：删除命令一定要注意vim mongodb_ali_auto_backup.sh 12345678910111213141516171819202122232425262728293031323334#!/bin/bash#backup MongoDB_aliMONGODBDUMP=/path/to/mongodb3.6/bin/mongodump#临时备份目录OUT_DIR=/dbdata/db_backup/mongodb_ali/mongodb_bak_now#备份存放目录TAR_DIR=/dbdata/db_backup/mongodb_ali/mongodb_bak_list#获取当前系统时间DATE=`date +%Y-%m-%d`HOST=dds-bp1a3d180d2abtest1.mongodb.rds.aliyuncs.com:3717USER=rootDATABASE=adminPASSWD=XXXX#保存天数DAY=1TAR_BAK=\"mongod_bak_$DATE.tar.gz\"cd $OUT_DIRrm -rf $OUT_DIR/*mkdir -p $OUT_DIR/$DATE$MONGODBDUMP --host $HOST --authenticationDatabase $DATABASE -u $USER -p $PASSWD -o $OUT_DIR/$DATEtar -zcvf $TAR_DIR/$TAR_BAK $DATE#scp -P 10110 $TAR_DIR/$TAR_BAK root@10.47.96.105:/path/to/db_backup/mongodb_alifind $TAR_DIR/ -mtime +$DAY -deleteecho \"备份完成\"exit 3、添加定时任务vim /etc/crontab 1230 2 * * * /bin/bash /path/to/db_backup/mongodb_ali_auto_backup.sh &gt;&gt; /var/log/mongodb/backlog_ali/$(date +\"\\%Y-\\%m-\\%d\").log 2&gt;&amp;1# 每天2点30分执行 未解决问题：输出日志重定向。单独执行脚本时，日志可以重定向到目标文件。由crontab 定时执行时， 日志文件并没有重定向到目标文件。 18.3.20 已解决 重定向符号由 &amp;&gt; 换成了 &gt;&gt; “/var/log/mongodb/backlog_ali/$(date +”%Y-%m-%d”).log” 2&gt;&amp;1","link":"/2018/03/19/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/MongoDB%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD/"},{"title":"mongodb内存限制","text":"默认情况下，mongodb占用的内存大小为： 1234Starting in MongoDB 3.4, the default WiredTiger internal cache size is the larger of either:50% of (RAM - 1 GB), or256 MB. 即 （总内存 × 50% - 1GB） 和 （256MB） 两者中的较大值。当总内存大于1GB时，为总内存的一半，总内存小于1GB时，为256MB 由于mongodb会占用较大内存，所以生产环境一般会将mongodb单独托管。特殊情况下，比如调试开发环境，或只有一台服务器，则可以限制mongodb的内存。修改配置文件 /etc/mongod.conf, 即添加storage.wiredTiger.engineConfig.cacheSizeGB参数如下： 12345678910111213141516systemLog: destination: file path: \"/ssdb1/mongodb/mongodb4.0.13/logs/mongod.log\" logAppend: truestorage: dbPath: \"/ssdb1/mongodb/mongodb4.0.13/data\" journal: enabled: true wiredTiger: engineConfig: cacheSizeGB: 3processManagement: fork: truenet: bindIp: 0.0.0.0 port: 27017 然后重启mongodb 1$ service mongodb restart 参考：WiredTiger Storage Enginestorage.wiredTiger.engineConfig.cacheSizeGB","link":"/2019/12/03/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/mongodb%E5%86%85%E5%AD%98%E9%99%90%E5%88%B6/"},{"title":"mongodb副本集搭建(一)","text":"副本集是mongodb服务提供冗余和高可用性的方法。 主要成员包括： 主节点（primary ）– 主要接收所有写操作 辅助节点（Secondaries ）– 从主节点复制操作以维护相同的数据集，可以无投票权votes:0，priority: 0。 仲裁节点（Arbiters ）– 仲裁者不保留数据的副本，但可以参与投票。 辅助节点维护主节点数据集的副本。它从主节点的oplog中进行数据的同步。辅助成员中有：优先级为0的副本集成员（不能成为主节点）、隐藏的副本集成员（对客户端程序不可见，不能成为主节点，可以参与投票）、延迟副本集成员（优先级必须是0，是隐藏节点，可参与投票） mongodb副本集搭建 准备3台服务器：192.168.138.2、192.168.138.3、192.168.138.4 1、每台都安装好mongodb。2、编辑配置文件：vim /etc/mongodb.conf 12345678910111213141516# mongodb.confsystemLog: destination: file path: \"/data/mongodb/mongodb4.0.3/logs/mongod.log\" #日志文件存放目录 logAppend: truestorage: dbPath: \"/data/mongodb/mongodb4.0.3/data\" #数据文件存放目录 journal: enabled: trueprocessManagement: fork: true #后台运行net: bindIp: 0.0.0.0 port: 27017replication: replSetName: enroll-rs0 #副本集的名称，用来识别是否属于同一个集群 3、然后依次启动3台数据库：mongod -f /etc/mongodb.conf 4、初始化副本集 登入任意一台机器的MongoDB执行：因为是全新的副本集所以可以任意进入一台执行；要是有一台有数据，则需要在有数据上执行；要多台有数据则不能初始化。 123456789$ mongo$ rs.initiate( { _id : \"enroll-rs0\", members: [ { _id: 0, host: \"192.168.138.2:27017\" }, { _id: 1, host: \"192.168.138.3:27017\" }, { _id: 2, host: \"192.168.138.4:27017\" } ]}) 说明： “_id”:副本集名称。 “members”: 副本集的服务器列表。 “_id”: 服务器的唯一ID “host”: 服务器主机名或IP。 “priority”: 是优先级，默认为1，优先级0为被动节点，不能成为活跃节点。优先级不位0则按照有大到小选出活跃节点。(可选) “arbiterOnly”: 仲裁节点，只参与投票，不接收数据，也不能成为活跃节点。（可选） 5、查看副本集配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364$ rs.conf();{ \"_id\" : \"enroll-rs0\", \"version\" : 1, \"protocolVersion\" : NumberLong(1), \"writeConcernMajorityJournalDefault\" : true, \"members\" : [ { \"_id\" : 0, \"host\" : \"192.168.138.2:27017\", \"arbiterOnly\" : false, \"buildIndexes\" : true, \"hidden\" : false, \"priority\" : 1, \"tags\" : { }, \"slaveDelay\" : NumberLong(0), \"votes\" : 1 }, { \"_id\" : 1, \"host\" : \"192.168.138.3:27017\", \"arbiterOnly\" : false, \"buildIndexes\" : true, \"hidden\" : false, \"priority\" : 1, \"tags\" : { }, \"slaveDelay\" : NumberLong(0), \"votes\" : 1 }, { \"_id\" : 3, \"host\" : \"192.168.138.4:27017\", \"arbiterOnly\" : false, \"buildIndexes\" : true, \"hidden\" : false, \"priority\" : 1, \"tags\" : { }, \"slaveDelay\" : NumberLong(0), \"votes\" : 1 } ], \"settings\" : { \"chainingAllowed\" : true, \"heartbeatIntervalMillis\" : 2000, \"heartbeatTimeoutSecs\" : 10, \"electionTimeoutMillis\" : 10000, \"catchUpTimeoutMillis\" : -1, \"catchUpTakeoverDelayMillis\" : 30000, \"getLastErrorModes\" : { }, \"getLastErrorDefaults\" : { \"w\" : 1, \"wtimeout\" : 0 }, \"replicaSetId\" : ObjectId(\"5bdfa91cc04c5a3e91f5ebdb\") }} 6、查看副本集运行状态 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117$ rs.status(); { \"set\" : \"enroll-rs0\", \"date\" : ISODate(\"2018-11-05T02:21:43.971Z\"), \"myState\" : 2, \"term\" : NumberLong(1), \"syncingTo\" : \"192.168.138.4:27017\", \"syncSourceHost\" : \"192.168.138.4:27017\", \"syncSourceId\" : 3, \"heartbeatIntervalMillis\" : NumberLong(2000), \"optimes\" : { \"lastCommittedOpTime\" : { \"ts\" : Timestamp(1541384492, 1), \"t\" : NumberLong(1) }, \"readConcernMajorityOpTime\" : { \"ts\" : Timestamp(1541384492, 1), \"t\" : NumberLong(1) }, \"appliedOpTime\" : { \"ts\" : Timestamp(1541384492, 1), \"t\" : NumberLong(1) }, \"durableOpTime\" : { \"ts\" : Timestamp(1541384492, 1), \"t\" : NumberLong(1) } }, \"lastStableCheckpointTimestamp\" : Timestamp(1541384489, 3), \"members\" : [ { \"_id\" : 0, \"name\" : \"192.168.138.2:27017\", \"health\" : 1, \"state\" : 1, \"stateStr\" : \"PRIMARY\", \"uptime\" : 25, \"optime\" : { \"ts\" : Timestamp(1541384492, 1), \"t\" : NumberLong(1) }, \"optimeDurable\" : { \"ts\" : Timestamp(1541384492, 1), \"t\" : NumberLong(1) }, \"optimeDate\" : ISODate(\"2018-11-05T02:21:32Z\"), \"optimeDurableDate\" : ISODate(\"2018-11-05T02:21:32Z\"), \"lastHeartbeat\" : ISODate(\"2018-11-05T02:21:43.331Z\"), \"lastHeartbeatRecv\" : ISODate(\"2018-11-05T02:21:43.099Z\"), \"pingMs\" : NumberLong(0), \"lastHeartbeatMessage\" : \"\", \"syncingTo\" : \"\", \"syncSourceHost\" : \"\", \"syncSourceId\" : -1, \"infoMessage\" : \"\", \"electionTime\" : Timestamp(1541384489, 1), \"electionDate\" : ISODate(\"2018-11-05T02:21:29Z\"), \"configVersion\" : 1 }, { \"_id\" : 1, \"name\" : \"192.168.138.3:27017\", \"health\" : 1, \"state\" : 2, \"stateStr\" : \"SECONDARY\", \"uptime\" : 1195, \"optime\" : { \"ts\" : Timestamp(1541384492, 1), \"t\" : NumberLong(1) }, \"optimeDate\" : ISODate(\"2018-11-05T02:21:32Z\"), \"syncingTo\" : \"192.168.138.4:27017\", \"syncSourceHost\" : \"192.168.138.4:27017\", \"syncSourceId\" : 3, \"infoMessage\" : \"\", \"configVersion\" : 1, \"self\" : true, \"lastHeartbeatMessage\" : \"\" }, { \"_id\" : 3, \"name\" : \"192.168.138.4:27017\", \"health\" : 1, \"state\" : 2, \"stateStr\" : \"SECONDARY\", \"uptime\" : 25, \"optime\" : { \"ts\" : Timestamp(1541384492, 1), \"t\" : NumberLong(1) }, \"optimeDurable\" : { \"ts\" : Timestamp(1541384492, 1), \"t\" : NumberLong(1) }, \"optimeDate\" : ISODate(\"2018-11-05T02:21:32Z\"), \"optimeDurableDate\" : ISODate(\"2018-11-05T02:21:32Z\"), \"lastHeartbeat\" : ISODate(\"2018-11-05T02:21:43.331Z\"), \"lastHeartbeatRecv\" : ISODate(\"2018-11-05T02:21:42.756Z\"), \"pingMs\" : NumberLong(0), \"lastHeartbeatMessage\" : \"\", \"syncingTo\" : \"192.168.138.2:27017\", \"syncSourceHost\" : \"192.168.138.2:27017\", \"syncSourceId\" : 0, \"infoMessage\" : \"\", \"configVersion\" : 1 } ], \"ok\" : 1, \"operationTime\" : Timestamp(1541384492, 1), \"$clusterTime\" : { \"clusterTime\" : Timestamp(1541384492, 1), \"signature\" : { \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"), \"keyId\" : NumberLong(0) } }} 至此整个副本集已经搭建成功了。 7、其它常用命令 12345$ rs.isMaster() //查询该节点是否是主节点$ rs.slaveOk() //允许在SECONDARY节点上进行查询操作，默认从节点不具有查询功能$ rs.add(\"ip:port\"); //添加新的节点到该副本集中$ rs.remove(\"ip:port\"); //从副本集中删除节点$ rs.addArb(“ip:port”); //新增仲裁节点 副本集的维护可参考：https://www.cnblogs.com/zhoujinyi/p/3554010.html 参考：https://docs.mongodb.com/manual/tutorial/deploy-replica-set/ https://www.cnblogs.com/out-of-memory/p/6810525.html","link":"/2018/11/05/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/mongodb%E5%89%AF%E6%9C%AC%E9%9B%86%E6%90%AD%E5%BB%BA(%E4%B8%80)/"},{"title":"mongodb副本集搭建(二)开启权限验证","text":"开启权限验证 副本集启用身份验证，需生成keyFile文件： 1、新安装的副本集没有启用身份验证。先添加root用户。 12$ use admin$ db.createUser({user:\"root\",pwd:\"root\",roles:[\"root\"]} 2、生成keyFile文件 在其中一台机器上，生成keyFile文件。 123$ cd /data/mongodb/mongodb4.0.3$ openssl rand -base64 753 &gt; mongodb.keyfile$ chmod 600 mongodb.keyfile 复制到其它2台机器上 12$ scp mongodb.keyfile root@192.168.138.3:/data/mongodb/mongodb4.0.3$ scp mongodb.keyfile root@192.168.138.4:/data/mongodb/mongodb4.0.3 3、修改mongodb.conf 添加如下配置： 123security: authorization: enabled keyFile: /data/mongodb/mongodb4.0.3/mongodb.keyfile 4、然后重启mongodb 参考：https://docs.mongodb.com/manual/administration/configuration/#replication-configuration","link":"/2018/11/05/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/mongodb%E5%89%AF%E6%9C%AC%E9%9B%86%E6%90%AD%E5%BB%BA(%E4%BA%8C)/"},{"title":"mongodb按时间分组统计","text":"mongodb按时间分组统计 关键字：时间段分组、AggregationExpression、$bucket、$bucketAuto 数据： 1234567891011121314151617181920212223242526272829303132333435/* 1 */{ &quot;_id&quot; : &quot;6c2f6089d0df424dbb3dc05a89dd3260_13&quot;, &quot;contentId&quot; : NumberLong(13), &quot;upCnt&quot; : 1, &quot;upTime&quot; : ISODate(&quot;2018-08-07T03:56:51.798Z&quot;), &quot;isLiving&quot; : true, &quot;uid&quot; : &quot;7634aa19f67a44bfaba59e66b9acf7e1&quot;, &quot;_class&quot; : &quot;com.eyeshot.model.EsLiveUp&quot;, &quot;createTime&quot; : &quot;2018-08-07 10:12:00&quot;}/* 2 */{ &quot;_id&quot; : &quot;893e6ee867ba4bc8b58fe3e9046f1520_13&quot;, &quot;contentId&quot; : NumberLong(13), &quot;upCnt&quot; : 1, &quot;upTime&quot; : ISODate(&quot;2018-08-07T04:16:24.848Z&quot;), &quot;isLiving&quot; : true, &quot;uid&quot; : &quot;19d4ec6945c741558fd6321b926bce1e&quot;, &quot;_class&quot; : &quot;com.eyeshot.model.EsLiveUp&quot;, &quot;createTime&quot; : &quot;2018-08-07 10:42:00&quot;}/* 3 */{ &quot;_id&quot; : &quot;73379B9556FDC7FE86E2FCACC8EEC914_13&quot;, &quot;contentId&quot; : NumberLong(13), &quot;upCnt&quot; : 1, &quot;upTime&quot; : ISODate(&quot;2018-08-07T05:46:24.848Z&quot;), &quot;isLiving&quot; : true, &quot;uid&quot; : &quot;49d4ec6945c741558fd6321b926bce5e&quot;, &quot;_class&quot; : &quot;com.eyeshot.model.EsLiveUp&quot;, &quot;createTime&quot; : &quot;2018-08-07 11:12:00&quot;} 如果要统计2018-08-07 0点-14点之间每隔30分钟点赞数据 1234567891011121314151617181920212223db.esLiveUp.aggregate([ {\"$match\":{\"upTime\":{\"$gte\":ISODate(\"2018-08-07T00:00:00.00Z\"),\"$lte\":ISODate(\"2018-08-07T14:00:00.00Z\")}}}, {\"$group\":{ \"_id\":{\"$subtract\":[ { \"$subtract\": [ \"$upTime\", new Date(\"1970-01-01\") ] }, { \"$mod\": [ { \"$subtract\": [ \"$upTime\", new Date(\"1970-01-01\") ] }, 1000 * 60 * 20 //30分钟 ]} ] }, \"total\": {'$sum': '$upCnt'} }}, {\"$project\": { \"_id\": 0, \"total\":1, 'datetime': {'$add': [new Date(0), '$_id']} }}, {\"$sort\": { 'datetime': 1 }}]) 结果： 123{ &quot;total&quot; : 1, &quot;datetime&quot; : ISODate(&quot;2018-08-07T03:40:00Z&quot;) }{ &quot;total&quot; : 1, &quot;datetime&quot; : ISODate(&quot;2018-08-07T04:00:00Z&quot;) }{ &quot;total&quot; : 1, &quot;datetime&quot; : ISODate(&quot;2018-08-07T05:40:00Z&quot;) } 以上参考：https://blog.csdn.net/orangleliu/article/details/79864624 可是在java中未找到对$group有如此复杂的分组。 只了解到project中关于 AggregationExpression 的用法 以下是一段无实际意义的例子。仅记录AggregationExpression的用法。 12345678910ArithmeticOperators.Subtract subtract = ArithmeticOperators.Subtract.valueOf(new AggregationExpression() { @Override public Document toDocument(AggregationOperationContext context) { Document document = new Document(); document.put(\"$subtract\", Arrays.asList(\"$upTime\" ,new Date())); return document; } }).subtract(1);ProjectionOperation project = Aggregation.project().and(subtract).as(\"title\");//.andExpression(\"upTime\").extractMinute().as(\"datetime\"), 完整方法： 12345678910111213141516171819202122232425262728 @RequestMapping(value = \"/getLiveUpStat1/{contentUid}\") @ResponseBody public ResponseData&lt;String&gt; getLiveUpStat1(@PathVariable String contentUid, ) { ResponseData&lt;String&gt; rd = new ResponseData&lt;&gt;(); EsContent content = mongoDao.getByUid(EsContent.class, contentUid, null); ArithmeticOperators.Subtract subtract = ArithmeticOperators.Subtract.valueOf(new AggregationExpression() { @Override public Document toDocument(AggregationOperationContext context) { Document document = new Document(); document.put(\"$subtract\", Arrays.asList(\"$upTime\" ,new Date())); return document; } }).subtract(1); // GroupOperation group = Aggregation.bucket(groupByExpression).group(subtract); MatchOperation match = Aggregation.match(new Criteria().andOperator(Criteria.where(\"contentId\").is(content.getId()).and(\"upTime\").gte(Utils.getDateFromStr(\"2018-08-07 00:00:00\", \"yyyy-MM-dd HH:mm:ss\")).lte(new Date()))); ProjectionOperation project = Aggregation.project().and(subtract).as(\"title\");//.andExpression(\"upTime\").extractMinute().as(\"datetime\"), GroupOperation group = Aggregation.group().count().as(\"count\"); TypedAggregation&lt;EsLiveUp&gt; upAggre = Aggregation.newAggregation(EsLiveUp.class, match, project, group);//[{ \"$match\" : { \"$and\" : [{ \"contentId\" : { \"$numberLong\" : \"13\" }, \"upTime\" : { \"$gte\" : { \"$date\" : 1533571200000 }, \"$lte\" : { \"$date\" : 1533706925605 } } }] } }, { \"$project\" : { \"title\" : { \"$subtract\" : [{ \"$subtract\" : [\"$upTime\", { \"$date\" : 1533706931075 }] }, 1] } } }, { \"$group\" : { \"_id\" : null, \"count\" : { \"$sum\" : 1 } } }] List&lt;EsLiveViewDataDto&gt; upStat = mongoDao.aggregate(upAggre, EsLiveViewDataDto.class); return rd; } 但原需求可通过$bucket、$bucketAuto解决 1234567db.esLiveUp.aggregate([ {\"$bucketAuto\":{ groupBy:\"$createTime\", buckets:3, output:{\"time\":{\"$min\":\"$createTime\"},\"count\":{\"$sum\":1}}}}, {\"$project\":{_id:0,time:1,count:1}} ]) 结果： 123{ &quot;time&quot; : &quot;2018-08-07 10:12:00&quot;, &quot;count&quot; : 1 }{ &quot;time&quot; : &quot;2018-08-07 10:42:00&quot;, &quot;count&quot; : 1 }{ &quot;time&quot; : &quot;2018-08-07 11:12:00&quot;, &quot;count&quot; : 1 } 伪代码： 1234MatchOperation match = Aggregation.match(new Criteria().andOperator(Criteria.where(\"contentId\").is(content.getId())));BucketAutoOperation bucketAuto = Aggregation.bucketAuto(\"upTime\", 20).andOutput(\"upTime\").min().as(\"upTime\").andOutputCount().as(\"count\"); TypedAggregation&lt;EsLiveUp&gt; upAggre = Aggregation.newAggregation(EsLiveUp.class, match, bucketAuto); 参考： https://docs.mongodb.com/manual/meta/aggregation-quick-reference/#aggregation-expressions https://segmentfault.com/q/1010000013755740 https://stackoverflow.com/questions/42840426/mongo-aggregation-using-new-date-as-in-input-to-form-a-aggregationexpression/42856500 https://docs.mongodb.com/manual/reference/operator/aggregation/bucket/index.html https://docs.mongodb.com/manual/reference/operator/aggregation/bucketAuto","link":"/2018/08/08/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/mongodb%E6%8C%89%E6%97%B6%E9%97%B4%E5%88%86%E7%BB%84%E7%BB%9F%E8%AE%A1/"},{"title":"mongodb数据去重","text":"数据：12345{ &quot;_id&quot; : NumberLong(1), &quot;browserId&quot; : NumberLong(3), &quot;sex&quot; : 1, &quot;province&quot; : &quot;广西壮族自治区&quot; }{ &quot;_id&quot; : NumberLong(2), &quot;browserId&quot; : NumberLong(6), &quot;sex&quot; : 1, &quot;province&quot; : &quot;湖南&quot; }{ &quot;_id&quot; : NumberLong(3), &quot;browserId&quot; : NumberLong(5), &quot;sex&quot; : 0,&quot;province&quot; : &quot;湖南&quot; }{ &quot;_id&quot; : NumberLong(4), &quot;browserId&quot; : NumberLong(4) }{ &quot;_id&quot; : NumberLong(5), &quot;browserId&quot; : NumberLong(6), &quot;sex&quot; : 1 , &quot;province&quot; : &quot;湖南&quot; } 按browserId字段去重123456db.coll.aggregate([ {$sort: {id: -1}}, {$group: {_id: &quot;$browserId&quot;, doc: {$first: &quot;$$ROOT&quot;}}}, {$replaceRoot: {newRoot: &quot;$doc&quot;}}, {&quot;$project&quot;:{_id:1,browserId:1,sex:1,province:1}}]); 结果：1234{ &quot;_id&quot; : NumberLong(1), &quot;browserId&quot; : NumberLong(3), &quot;sex&quot; : 1, &quot;province&quot; : &quot;广西壮族自治区&quot; }{ &quot;_id&quot; : NumberLong(3), &quot;browserId&quot; : NumberLong(5), &quot;sex&quot; : 0, &quot;province&quot; : &quot;湖南&quot; }{ &quot;_id&quot; : NumberLong(4), &quot;browserId&quot; : NumberLong(4) }{ &quot;_id&quot; : NumberLong(5), &quot;browserId&quot; : NumberLong(6), &quot;sex&quot; : 1&quot;, province&quot; : &quot;湖南&quot; } 去重后，按性别进行分组统计123456db.coll.aggregate([ {$sort:{_id:-1}}, {&quot;$group&quot;:{_id:&quot;$browserId&quot;,doc:{&quot;$first&quot;:&quot;$$ROOT&quot;}}}, {&quot;$replaceRoot&quot;:{newRoot:&quot;$doc&quot;}}, {&quot;$group&quot;:{_id:&quot;$sex&quot;,count:{&quot;$sum&quot;:1}}}]) 结果：123{ &quot;_id&quot; : null, &quot;count&quot; : 1 }{ &quot;_id&quot; : 0, &quot;count&quot; : 1 }{ &quot;_id&quot; : 1, &quot;count&quot; : 2 } $replaceRoot ：将指定文档提升到顶级并替换所有其他字段。 Mongodb版本3.4以上。 ROOT : 引用当前正在聚合管道阶段处理的根文档，即顶级文档。 参考：https://docs.mongodb.com/manual/reference/operator/aggregation/replaceRoot/index.html https://segmentfault.com/q/1010000010874460","link":"/2018/07/31/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/mongodb%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/"},{"title":"MongoDb解压缩安装","text":"1、新建mongodb工作目录 1$ mkdir /usr/local/mongodb 2、下载安装包从官网下载：下载地址3、解压缩 1234$ tar -zxvf mongodb-linux-x86_64-ubuntu1604-3.6.3.tgz$ mv mongodb-linux-x86_64-ubuntu1604-3.6.3 mongodb3.6.3 #修改下目录名$ mkdir /usr/local/mongodb/mongodb3.6.3/data #创建数据目录$ mkdir /usr/local/mongodb/mongodb3.6.3/logs/ #创建日志目录 4、添加到环境变量vim /etc/profile 123#MONGODBexport MONGODB_HOME=/usr/local/mongodb/mongodb3.6.3export PATH=$MONGODB_HOME/bin:$PATH source /etc/profile5、创建配置文件 在2.6版本后引入了YMAL的配置格式，但仍然是向后兼容的。可参考：mongodn.conf vim /etc/mongodb.conf 12345678910# mongodb.confbind_ip = 0.0.0.0port = 27017logpath=/usr/local/mongodb/mongodb3.6.3/logs/mongodb.loglogappend=truedbpath = /usr/local/mongodb/mongodb3.6.3/datajournal=truefork = true YAML格式： 12345678910111213systemLog: destination: file path: \"/usr/local/mongodb/mongodb-4.0.1/logs/mongodb.log\" logAppend: truestorage: dbPath: \"/usr/local/mongodb/mongodb-4.0.1/data\" journal: enabled: trueprocessManagement: fork: truenet: bindIp: 0.0.0.0 port: 27017 6、启动 1$ mongod -f /etc/mongodb.conf 关于开机自启，见：Keepalived实现mongoDB的高可用","link":"/2018/05/15/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/mongodb%E8%A7%A3%E5%8E%8B%E7%BC%A9%E5%AE%89%E8%A3%85/"},{"title":"mongodb设置开机自启（systemd方式）","text":"环境：Ubuntu18.04 1、在/etc/systemd/system下新建mongodb.service vim /etc/systemd/system/mongodb.service 12345678910111213[Unit]Description=mongodbAfter=network.target remote-fs.target nss-lookup.target[Service]Type=forkingExecStart=/ssdb1/mongodb/mongodb4.0.13/bin/mongod --config /etc/mongodb.confExecReload=/bin/kill -s HUP $MAINPIDExecStop=/ssdb1/mongodb/mongodb4.0.13/bin/mongod --shutdown --config /etc/mongodb.confPrivateTmp=true[Install]WantedBy=multi-user.target 2、设置权限 1$ chmod 754 mongodb.service 3、启动关闭服务，设置开机启动 123456#启动服务 $ systemctl start mongodb.service #关闭服务 $ systemctl stop mongodb.service #开机启动 $ systemctl enable mongodb.service /etc/init.d/mongodb方式见【Keepalived实现mongoDB的高可用】","link":"/2019/11/27/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/mongodb%E8%AE%BE%E7%BD%AE%E8%87%AA%E5%90%AF%E5%8A%A8/"},{"title":"mongodb备忘记录","text":"1、更新数组里面的一组对象的属性 想要对grade是85对应的对象的cnt加一。 原始数据如下： 12345678{ \"_id\" : NumberLong(2), \"grades\": [ {\"grade\": 80, \"cnt\": 8 }, {\"grade\": 85, \"cnt\": 6 }, {\"grade\": 90, \"cnt\": 3 } ]} 更新： 1db.student.update({\"_id\":2,\"grades.grade\":85},{\"$inc\":{\"grades.$.cnt\":1}}) 1无法通过一个update操作更新多个array元素，所以需要写个循环 http://ju.outofmemory.cn/entry/177346","link":"/2019/09/16/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/update/"},{"title":"关于MongoDB","text":"索引1、 创建合适的组合索引，不要依赖于交叉索引（即多个单字段索引）。 2、 组合索引字段顺序：匹配条件在前，范围条件在后。 3、 尽可能使用覆盖索引。 查询字段及返回字段与索引字段相同（注意查询会默认包含_id） 4、 建立索引要在后台运行。 对集合创建索引时，该集合默认不接受其它读写操作。建议使用后台运行选项{background:true} 模式设计1、 不要按照关系型来设计表结构。 MongoDB可以像关系型数据库一样设计表结构，但是它不支持外键，也不支持复杂的Join！ 2、 数据库集合数量不宜太多。 MongoDB表设计不遵从第三范式。MongoDB的数据模型非常接近于对象模型，所以基本上就是按照主要的Domain object的数量来建相应的集合。 3、 不要害怕数据冗余。 MongoDB模式设计不能按照第三范式，很多时候允许数据在多个文档中重复，比如说，在每一个员工的文档中重复他的部门名字，就是一个可以接受的做法。如果部门名字改了，可以执行一个update({},{}, {multi:true}) 的多文档更新来一次性把部门名字更新掉。 4、 适合和不适合冗余的数据类型 如果某个字段的数值经常会变，则不太适合被大量冗余到别的文档或者别的集合里面去；如果是一些不经常变的字段，如客户的姓名，地址，部门等，则可以尽管进行冗余。 5、 对于1：N(一些)的关系使用全部内嵌 对于一对多的关系，如一个人有几个联系方式，一本书有10几个章节，等等，建议使用内嵌方式，把N的数据以数组形式来描述 6、 对于1：NN(很多)的关系使用ID内嵌 有些时候这个一对多的多端数量较大，如：一个部门可能有数千员工，这个时候如果把所有员工信息直接内嵌到部门内肯定不是个好的选择，有可能会超出16MB的文档限制。这个时候可以采用引用ID的方式 如果需要查询部门下员工相关信息，你可以使用$lookup聚合操作符来把员工信息进行关联并返回。 7、 对于1：NNN(很多很多)的关系 应该把多端的数据创建一个集合，并在那个集合的文档里加入对主文档的连接引用。 8、 把二进制大文件和元数据分集合存放 如果你有需要把PDF文件，图片，甚至小视频等二进制文件需要管理，建议使用MongoDB 的GridFS API 或者自己手动分集合来分开管理二进制数据和元数据。 9、 对于经常更新的数据不要放在嵌套数组内 。 程序配置 设定合适的MongoDB连接池大小 Java驱动默认连接池大小是100。对压力较小的应用可适当减少对服务器资源的占用。 正确使用写关注设置 不要实例化多个MongoClient MongoClient是个线程安全的类，自带线程池。通常在一个JVM内不要实例化多个MongoClient实例，避免连接数过多和资源的不必要浪费。 对写操作使用Retry机制 避免使用太长的字段名 使用有规律的命名方式 正确使用更新语句 MongoDB支持和关系型数据库update语句类似的in place update。你只需要在update语句中指定需要更新的字段，而不是整个文档对象。 使用投射 （projection）来减少返回的内容 MongoDB 支持类似于SQL语句里面的select，可以对返回的字段进行过滤。使用Projection可以减少返回的内容，降低网络传输的量和代码中转化成对象所需的时间。 使用TTL来自动删除过期的数据 很多时候我们用MongoDB来存储一些时效性的数据，如7天的监控数据。与其自己写个后台脚本定期清理过期数据，你可以使用TTL索引来让MongoDB自动删除过期数据： 1db.data.ensureIndex({create_time:1}, {expireAfterSeconds: 7*24*3600}} 使用execute命令来实现upsert 有些时候你不知道一条文档数据是否已经在库里存在。这个时候你要么先查询一下，要么就是使用upsert语句。在SpringData下面upsert语句需要你把每个字段的值都在upsert语句中格式化出来。字段多的时候未免有些繁琐。SpringData MongoDB里面的MongoTemplate有个execute方法可以用来实现一个DB调用，也不用繁琐的把所有字段罗列出来的例子。 123456789101112131415public boolean persistEmployee(Employee employee) throws Exception { BasicDBObject dbObject = new BasicDBObject(); mongoTemplate.getConverter().write(employee, dbObject); mongoTemplate.execute(Employee.class, new CollectionCallback&lt;Object&gt;() { public Object doInCollection(DBCollection collection) throws MongoException, DataAccessException { collection.update(new Query(Criteria.where(\"name\").is(employee.getName())).getQueryObject(), dbObject, true, // means upsert - true false // multi update – false ); return null; } }); return true; } 删除SpringData MongoDB下面的_class 字段 SpringData MongoDB默认会在MongoDB文档中添加一个_class字段，里面保存的是fully qualified class name， 如”com.mongodb.examples.Customer”。对于有些小文档来说，这个字段可能会占据不小一部分的存储空间。如果你不希望SpringData 自动加入这个字段， 可以 1）自定义MongoTypeMapper 12345678@Beanpublic MongoTemplate mongoTemplate() throws UnknownHostException {MappingMongoConverter mappingMongoConverter = new MappingMongoConverter(new DefaultDbRefResolver(mongoDbFactory()), newMongoMappingContext());mappingMongoConverter.setTypeMapper(new DefaultMongoTypeMapper(null));return new MongoTemplate(mongoDbFactory(), mappingMongoConverter );} 2） 在使用find语句时，显式地指定类的名字/类型： 1MongoTemplate.find(new Query(), Inventory.class)) 删除SpringData MongoDB下面的_class 字段 删除SpringData MongoDB下面的_class 字段 删除SpringData MongoDB下面的_class 字段 删除SpringData MongoDB下面的_class 字段 删除SpringData MongoDB下面的_class 字段","link":"/2017/09/15/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/%E5%85%B3%E4%BA%8EMongoDB/"},{"title":"修改mongodb副本集中的主机名","text":"修改mongodb副本集中的主机名 mongodb开启副本集初始化后默认为&quot;host&quot; : &quot;主机名:27017&quot; 如下： 配置复制集的名称： mongod –replSet myDevReplSet 123456789101112131415161718192021222324252627282930313233343536373839404142&gt; rs.initiate(){ \"info2\" : \"no configuration specified. Using a default configuration for the set\", \"me\" : \"ubuntu:27017\", \"ok\" : 1}myDevReplSet:OTHER&gt; rs.conf(){ \"_id\" : \"myDevReplSet\", \"version\" : 1, \"protocolVersion\" : NumberLong(1), \"members\" : [ { \"_id\" : 0, \"host\" : \"ubuntu:27017\", \"arbiterOnly\" : false, \"buildIndexes\" : true, \"hidden\" : false, \"priority\" : 1, \"tags\" : { }, \"slaveDelay\" : NumberLong(0), \"votes\" : 1 } ], \"settings\" : { \"chainingAllowed\" : true, \"heartbeatIntervalMillis\" : 2000, \"heartbeatTimeoutSecs\" : 10, \"electionTimeoutMillis\" : 10000, \"catchUpTimeoutMillis\" : 2000, \"getLastErrorModes\" : { }, \"getLastErrorDefaults\" : { \"w\" : 1, \"wtimeout\" : 0 }, \"replicaSetId\" : ObjectId(\"5b35a8568dccf16c7734a30b\") }} 如果局域网中有两台相同主机名机器就会需要修改副本集名称 1、停止副本集中所有成员（本例该副本集只有一个成员） 2、启动mongodb服务，但不使用 --replSet 参数 3、对每个副本集成员执行下列操作（本例该副本集只有一个成员） ​ a、连接到mongodb的shell ​ 1$ mongo ​ b、手动编辑副本集配置。副本集配置是数据库中system.replset 集合中唯一的文档local。使用新主机名和副本集所有成员的正确端口编辑副本集配置。考虑以下命令序列来更改三个成员集中的主机名： 1234567891011use localcfg = db.system.replset.findOne( { &quot;_id&quot;: &quot;rs&quot; } )cfg.members[0].host = &quot;mongodb0.example.net:27017&quot;cfg.members[1].host = &quot;mongodb1.example.net:27017&quot;cfg.members[2].host = &quot;mongodb2.example.net:27017&quot;db.system.replset.update( { &quot;_id&quot;: &quot;rs&quot; } , cfg ) ​ c、停止mongod成员服务 4、所有成员配置完成后，使用--replSet选项启动服务 5、验证 123456789101112131415161718192021222324252627282930313233343536myDevReplSet:PRIMARY&gt; rs.conf();{ \"_id\" : \"myDevReplSet\", \"version\" : 1, \"protocolVersion\" : NumberLong(1), \"members\" : [ { \"_id\" : 0, \"host\" : \"192.168.1.18:27017\", \"arbiterOnly\" : false, \"buildIndexes\" : true, \"hidden\" : false, \"priority\" : 1, \"tags\" : { }, \"slaveDelay\" : NumberLong(0), \"votes\" : 1 } ], \"settings\" : { \"chainingAllowed\" : true, \"heartbeatIntervalMillis\" : 2000, \"heartbeatTimeoutSecs\" : 10, \"electionTimeoutMillis\" : 10000, \"catchUpTimeoutMillis\" : 2000, \"getLastErrorModes\" : { }, \"getLastErrorDefaults\" : { \"w\" : 1, \"wtimeout\" : 0 }, \"replicaSetId\" : ObjectId(\"5b35a8568dccf16c7734a30b\") }} 参考：change-hostnames-in-a-replica-set","link":"/2018/06/29/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/%E4%BF%AE%E6%94%B9mongodb%E5%89%AF%E6%9C%AC%E9%9B%86%E4%B8%AD%E7%9A%84%E4%B8%BB%E6%9C%BA%E5%90%8D/"},{"title":"开启用户认证","text":"开启认证修改配置文件/etc/mongodb.conf打开auth注释 1auth = true 添加管理员添加超级管理员账号 12345678$ use admin;$ db.createUser( { user: \"root\", pwd: \"root\", roles: [ \"root\" } ] }) 重启mongoDB1$ service mongodb restart 进行验证登录 1$ mongo --authenticationDatabase admin -u root -p root 或者登陆后验证 12$ use admin;$ db.auth(\"root\", \"root\" ); 查看用户信息12$ use admin;$ db.getUser(\"root\") 添加数据库用户1、为其他数据库添加用户，添加用户前需要切换到该数据库 12345678$ use testdb;$ db.createUser( { user: \"testUser\", pwd: \"password\", roles: [ \"read\",\"readWrite\",\"dbAdmin\",\"dbOwner\",\"userAdmin\" ] }) 对当前库的权限 当前库普通操作角色 权限 说明 read 查询本库的权限 readWrite 增删改查本库的权限 当前库管理员操作角色 权限 说明 dbAdmin 数据库对象的管理操作，但没有数据库的读写权限 userAdmin 在本库下创建用户的权限 dbOwner 本库所有操作的权限 实例级别操作角色 权限 说明 readAnyDatabase 查询本实例所有库的权限 readWriteAnyDatabase 增删改查本例所有库的权限 userAdminAnyDatabase 在本实例所有库下创建用户的权限 dbAdminAnyDatabase 本实例所有库的dbAdmin权限 集群管理员角色 权限 说明 hostManager 管理和监控服务器的权限 clusterMonitor 查询集群和复制集的权限 clusterManager 管理和监控集群和复制集的权限 clusterAdmin 集群所有操作的权限 备份与恢复操作角色 权限 说明 backup mongodump权限 restore mongorestore权限 超级角色 权限 说明 root root权限 2、添加数据备份账号： 12$ use admin;$ db.createUser({user:\"backUser\",pwd:\"password\",roles:[\"backup\",\"restore\"]}); 修改用户密码需要在定义该账号的数据中修改 12$ use admin$ db.changeUserPassword(\"root\", \"SOh3TbYhx8ypJPxmt1oOfL\") #修改root账号密码 参考：https://docs.mongodb.com/manual/tutorial/enable-authentication/https://docs.mongodb.com/manual/core/security-built-in-roles/https://docs.mongodb.com/manual/reference/method/db.createUser/","link":"/2017/12/22/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/%E5%BC%80%E5%90%AF%E7%94%A8%E6%88%B7%E9%AA%8C%E8%AF%81/"},{"title":"慢查询优化1","text":"慢查询优化 在阿里云mongodb控制台，可看到慢日志的统计和明细分析比较方便，或者可以在mongodb shll环境中针对某个数据库查看慢日志记录。 1db.system.profile.find( { millis : { $gt : 120 } } ) 在控制台查得如下慢查询记录 1234567891011db.setStudyRecord.find({\"ownerId\": \"eat_cp_210\", \"courseId\": 488, \"studentId\": 7107, \"studyType\": { \"$gte\": 10, \"$lt\": 20 }, \"isFinished\": false, \"studyResId\": { \"$in\": [ 1344,1345,1347,1348,1349,1350,1351 ] }}) 使用MongoDB explain进行分析 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197db.setStudyRecord.find({\"ownerId\": \"eat_cp_210\", \"courseId\": 488, \"studentId\": 7107, \"studyType\": { \"$gte\": 10, \"$lt\": 20 }, \"isFinished\": false, \"studyResId\": { \"$in\": [1344,1345,1347,1348,1349,1350,1351 ] }}).explain(\"executionStats\");{ \"queryPlanner\" : { \"plannerVersion\" : 1, \"namespace\" : \"aixueyou_eat190428.setStudyRecord\", \"indexFilterSet\" : false, \"parsedQuery\" : { \"$and\" : [ { \"courseId\" : { \"$eq\" : 488 } }, { \"isFinished\" : { \"$eq\" : false } }, { \"ownerId\" : { \"$eq\" : \"eat_cp_210\" } }, { \"studentId\" : { \"$eq\" : 7107 } }, { \"studyType\" : { \"$lt\" : 20 } }, { \"studyType\" : { \"$gte\" : 10 } }, { \"studyResId\" : { \"$in\" : [ 1344, 1345, 1347, 1348, 1349, 1350, 1351 ] } } ] }, \"winningPlan\" : { \"stage\" : \"COLLSCAN\", \"filter\" : { \"$and\" : [ { \"courseId\" : { \"$eq\" : 488 } }, { \"isFinished\" : { \"$eq\" : false } }, { \"ownerId\" : { \"$eq\" : \"eat_cp_210\" } }, { \"studentId\" : { \"$eq\" : 7107 } }, { \"studyType\" : { \"$lt\" : 20 } }, { \"studyType\" : { \"$gte\" : 10 } }, { \"studyResId\" : { \"$in\" : [ 1344, 1345, 1347, 1348, 1349, 1350, 1351 ] } } ] }, \"direction\" : \"forward\" }, \"rejectedPlans\" : [ ] }, \"executionStats\" : { \"executionSuccess\" : true, \"nReturned\" : 0, \"executionTimeMillis\" : 289, \"totalKeysExamined\" : 0, \"totalDocsExamined\" : 286856, \"executionStages\" : { \"stage\" : \"COLLSCAN\", \"filter\" : { \"$and\" : [ { \"courseId\" : { \"$eq\" : 488 } }, { \"isFinished\" : { \"$eq\" : false } }, { \"ownerId\" : { \"$eq\" : \"eat_cp_210\" } }, { \"studentId\" : { \"$eq\" : 7107 } }, { \"studyType\" : { \"$lt\" : 20 } }, { \"studyType\" : { \"$gte\" : 10 } }, { \"studyResId\" : { \"$in\" : [ 1344, 1345, 1347, 1348, 1349, 1350, 1351 ] } } ] }, \"nReturned\" : 0, \"executionTimeMillisEstimate\" : 280, \"works\" : 286858, \"advanced\" : 0, \"needTime\" : 286857, \"needYield\" : 0, \"saveState\" : 2241, \"restoreState\" : 2241, \"isEOF\" : 1, \"invalidates\" : 0, \"direction\" : \"forward\", \"docsExamined\" : 286856 } }, \"ok\" : 1, \"operationTime\" : Timestamp(1585311418, 2), \"$clusterTime\" : { \"clusterTime\" : Timestamp(1585311418, 2), \"signature\" : { \"hash\" : BinData(0,\"vFOb4kXYvePgnFtOu1B8ASuxLi0=\"), \"keyId\" : NumberLong(\"6778070851129442306\") } }} 可以看到是全表扫描，执行时间280ms 建立索引 1$ db.setStudyRecord.createIndex( { ownerId: 1,courseId:1,studentId:1,studyType:1,isFinished:1,studyResId:1}, {background: true} )","link":"/2020/03/27/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/%E6%85%A2%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%961/"},{"title":"mongodb按字符串长度查找数据","text":"根据字符串字段的长度来筛选一些数据，这时候可能会用到正则表达式，也可以用mongodb的$where。 查询职业编码大于等于10的职业。 12345# $where写法:$ db.spOccupation.find({\"$where\":\"this.code.length&gt;=10\"});# 正则表达式写法：$ db.spOccupation.find({\"code\":{\"$regex\":/^.{10,}$/}}); 其他条件正则：^.{n,m}$ n &lt;= 长度 &lt;= m^.{n}$ 长度 = n 这个长度是字符的长度，比如”正则表达式”长度就是5 正则的性能比$where 的速度快很多","link":"/2020/03/16/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/%E6%8C%89%E5%AD%97%E7%AC%A6%E4%B8%B2%E9%95%BF%E5%BA%A6%E6%9F%A5%E6%89%BE%E6%95%B0%E6%8D%AE/"},{"title":"mongodb更新一个表中字段为另一表中的字段值","text":"更新一个表中字段为另一表中的字段值 1234567891011db.tePendingWork.find({&quot;testPlanId&quot;:{&quot;$exists&quot;:false}}).forEach( function(work){ db.teTestPlanItem.find({_id:work.testPlanItemId}).forEach( function(item){ //db.tePendingWork.update({_id:work._id}) db.tePendingWork.update({_id:work._id},{&quot;$set&quot;:{&quot;testPlanId&quot;:item.testPlanId,&quot;unitId&quot;:item.unitId}}) //printjson(work._id+&quot; testPlanId &quot; +item.testPlanId +&quot; unitId &quot; +item.unitId); //控制台打印 } ); } ) 另一种思想：先查询所有teTestPlanItem然后按_id做key存入map中然后在tePendingWork按照testPlanItemId获取相应的值。 1234567891011121314151617181920function testMap(){ var map = new Map(); db.teTestPlanItem.find().forEach( function(item){ map.put(item._id,item); printjson(&quot; item &quot; + item._id ) } ) //map遍历 //for(var key in map){ // printjson(map[key] ) //} db.tePendingWork.find().forEach( function(work){ printjson(work.testPlanItemId +&quot; &quot; + map.get(work.testPlanItemId)._id) } )}testMap(); //执行testMap函数 引申：Map_Reduce","link":"/2018/04/24/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/%E6%9B%B4%E6%96%B0%E4%B8%80%E4%B8%AA%E8%A1%A8%E4%B8%AD%E5%AD%97%E6%AE%B5%E4%B8%BA%E5%8F%A6%E4%B8%80%E8%A1%A8%E4%B8%AD%E7%9A%84%E5%AD%97%E6%AE%B5%E5%80%BC/"},{"title":"mongoDB监控工具mongostat","text":"mongostat返回反映1秒钟内的操作的值。当mongostat 的值大于1时，mongostat将统计数据平均以反映每秒的平均操作。 mongostat从系统命令行运行，而不是mongoshell。常用命令参数 –host &lt;:port&gt;, -h &lt;:port&gt; 指定连接的主机名 –port 指定端口 –username , -u 指定一个用户名，用来验证使用验证的MongoDB数据库。与–password和 –authenticationDatabase选项一起使用。 –password , -p 指定数据库的密码 –authenticationDatabase 指定用户创建的数据库 –rowcount , -n 控制要输出的行数。与sleeptime参数一起使用来控制mongostat操作的持续时间 。 –jsonmongostat以JSON格式返回输出。 两次mongostat调用之间等待的时间长度，以秒为单位 。默认为1秒。 字段说明mongostat 输出以下字段 inserts每秒插入到数据库中的对象的数量。如果后面跟着星号（如*），则数据是指复制的操作。 query每秒查询操作次数。 delete每秒删除操作的数量。 getmore每秒获得更多（即游标批次）操作的次数。getmore通常发生在结果集比较大的查询时，第一个query返回了部分结果，后续的结果是通过getmore来获取的。 command比如批量插入，只认为是一条命令。每秒命令的数量。如果是slave由管道字符（例如|） 分隔的两个值local|replicated。 flushes对于WiredTiger存储引擎，flushes指的是在每个轮询间隔之间触发的WiredTiger检查点的数量。对于MMAPv1存储引擎，flushes表示每秒fsync操作的数量 。一般都是0，或者1，通过计算两个1之间的间隔时间，可以大致了解多长时间flush一次。 dirty带有脏字节的WiredTiger缓存的百分比 used正在使用的WiredTiger缓存的百分比 mapped以兆字节映射的数据总量。 vsize进程使用的以兆字节为单位的虚拟内存量。 non-mapped不包括所有映射内存的虚拟内存总量。mongostat只有在使用该–all选项启动时才会返回此值 。 res进程使用的驻留内存量（以兆字节为单位）说明：mapped, vsize，res和top看到的相同，mapped, vsize一般不会有大的变动 faults每秒的页面错误次数。 lr必须等待读取锁定采集的百分比。mongostat显示lr|lw 锁定采集是否等待。 lw必须等待写锁定收购的百分比。 lrt平均获取时间（以微秒为单位）等待读取锁定采集。 mongostat显示lrt|lwt锁定采集是否等待。 lwt平均获取时间，以微秒为单位，等待写入锁定采集。 idx miss索引访问尝试的百分比，要求页面错误加载btree节点。这是一个抽样值。 qr等待从MongoDB实例读取数据的客户端队列的长度。 qw等待从MongoDB实例写入数据的客户端队列的长度。 ar执行读取操作的活动客户端的数量。 aw执行写入操作的活动客户端的数量。 netInMongoDB实例收到的网络流量（以字节为单位）。这包括来自mongostat它自己的流量。 netOutMongoDB实例发送的网络流量（以字节为单位）。这包括来自mongostat它自己的流量。 conn打开的连接总数。 set副本集的名称 repl成员的复制状态。 value Type M master SEC secondary REC recovering UNK unknown SLV slave RTR mongos process (“router”) ARB arbiter（仲裁）","link":"/2017/12/22/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7mongostat/"},{"title":"mongodb备忘记录","text":"1、更新数组里面的一组对象的属性 想要对grade是85对应的对象的cnt加一。 原始数据如下： 12345678{ \"_id\" : NumberLong(2), \"grades\": [ {\"grade\": 80, \"cnt\": 8 }, {\"grade\": 85, \"cnt\": 6 }, {\"grade\": 90, \"cnt\": 3 } ]} 更新： 1db.student.update({\"_id\":2,\"grades.grade\":85},{\"$inc\":{\"grades.$.cnt\":1}}) 2、更新集合文档中的多个字段或数组属性值 原始数据 (数据主要为实验需要所构造) 123456789101112131415161718192021222324252627{ \"_id\" : NumberLong(1), \"age\" : 20, \"day\" : 20, \"spotSeatCnts\" : { \"101\" : { \"1\" : 30, \"2\" : 30 }, \"102\" : { \"3\" : 30, \"4\" : 30 } }, \"roomIntentSpots\" : { \"101\" : [ { \"testSpotId\" : 1, \"testSpotTitle\" : \"北京大学\", \"cnt\" : 34.0 }, { \"testSpotId\" : 2, \"testSpotTitle\" : \"清华大学\", \"cnt\" : 33.0 } ], \"102\" : { } }, \"descn\" : { \"grades\" : [ { \"grade\" : 80, \"cnt\" : 30 }, { \"grade\" : 85, \"cnt\" : 31 } ] }, \"grades\" : [ { \"grade\" : 90, \"mean\" : 75, \"std\" : 6 }, { \"grade\" : 87, \"mean\" : 90, \"std\" : 3 }, { \"grade\" : 85, \"mean\" : 85, \"std\" : 4 } ]} 对age和day字段同时做加一操作 12db.neTestPlan.update({\"_id\":1},{\"$inc\":{\"age\":1,\"day\":1}}) #可以db.neTestPlan.update({\"_id\":1},{\"$inc\":{\"age\":1},\"$inc\":{\"day\":1}}) #不可以，只有day+1 同理，下面的操作 12db.neTestPlan.update({\"_id\":1},{\"$inc\":{\"spotSeatCnts.101.1\":1,\"spotSeatCnts.101.2\":1,\"spotSeatCnts.102.3\":1}}) #可以db.neTestPlan.update({\"_id\":1},{\"$inc\":{\"spotSeatCnts.101.1\":1},\"$inc\":{\"spotSeatCnts.102.3\":1}}) #不可以，只会更新spotSeatCnts.102.3+1 总结：对集合文档中的字段或字段中的Map对象，同操作类型($inc、$set等)更新两个及以上字段，都是上面的操作原理。 更新数组中的多个元素，3.6版本之前没发现有好的办法，像这篇文章无法通过一个update操作更新多个array元素，所以需要写个循环 。3.6新增了arrayFilters可以过滤数组中的元素，进而对数组中多个元素更新。详细可参考官方文档：db.collection.update 12345db.neTestPlan.update({\"_id\":100}, {\"$inc\":{\"roomIntentSpots.101.$[elem].cnt\":1}}, {\"arrayFilters\":[{\"elem.testSpotId\":{\"$in\":[1,2]}}]}) #可以db.neTestPlan.update({\"_id\":100}, {\"$inc\":{\"descn.grades.$[elem].cnt\":1}}, {\"arrayFilters\":[{\"elem.grade\":{\"$in\":[80,85]}}]}) #可以db.neTestPlan.findAndModify({query:{\"_id\":100},new:true,update:{\"$inc\":{\"roomIntentSpots.101.$[elem].cnt\":1}},arrayFilters:[{\"elem.testSpotId\":{\"$in\":[1,2]}}]}) #可以 关于update、updateOne、updateMany、save、findAndModify的区别可参考有坑勿踩（三）——关于数据更新","link":"/2019/09/16/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/%E7%89%B9%E6%AE%8A%E6%93%8D%E4%BD%9C/"},{"title":"mongoDB索引管理","text":"索引是特殊的数据结构，以简单的遍历形式存储集合数据集的一小部分。索引存储特定字段或字段集合的值，按字段的值排序。索引条目的排序支持高效的相等匹配和基于范围的查询操作。另外，MongoDB可以使用索引中的排序来返回排序结果。 索引创建自3.0.0版以来不推荐使用db.collection.ensureIndex（键，选项）创建索引 mongoDB索引类型单字段索引MongoDB默认创建的_id索引也是这种类型。 1db.collection.createIndexes(&quot;age&quot;:1) {age: 1} 代表升序索引，也可以通过{age: -1}来指定降序索引，对于单字段索引，升序/降序效果是一样的。 复合索引针对多个字段联合创建索引，先按第一个字段排序，第一个字段相同的文档按第二个字段排序，依次类推。 1db.collection.createIndex( {age: 1, name: 1} ) 复合索引也能匹配复合索引前缀的查询，如按age进行的查询，也能通过该索引来加速。若如果按name查询，则无法使用该复合索引。 多key索引 （Multikey Index）MongoDB使用多键索引来索引存储在数组中的内容。如果索引一个包含数组值的字段，MongoDB将为数组的每个元素创建单独的索引条目。这些多键索引允许查询通过匹配数组的元素来选择包含数组的文档。如果索引字段包含数组值，MongoDB将自动确定是否创建多键索引; 不需要明确指定多键类型。对数组字段建立索引 1db.collection.createIndex( { ratings: 1 } ) 对象的数组字段上创建多键索引 1db.collection.createIndex( { &quot;stock.size&quot;: 1, &quot;stock.quantity&quot;: 1 } ) 地理空间索引为了支持地理空间坐标数据的高效查询，MongoDB提供了两个特殊索引：返回结果时使用平面几何的 2d indexes和使用球面几何返回结果的2dsphere indexes。 创建2dsphere索引 1db.collection.createIndex( { &lt;location field&gt; : &quot;2dsphere&quot; } ) 文本索引MongoDB提供了文本索引来支持字符串内容的文本搜索查询。text索引可以包含任何字段，其值是字符串或字符串元素的数组。 1db.collection.createIndex( { comments: &quot;text&quot; } ) 该字段+”text”在索引文档中指定字符串文字. 索引属性唯一索引 (unique index)保证索引对应的字段不会出现相同的值，比如_id索引就是唯一索引。 12db.collection.createIndex( { &quot;user_id&quot;: 1 }, { unique: true } )db.collection.createIndex( { age: 1, name: 1}, { unique: true } ) 部分索引 (partial index)只针对符合某个特定条件的文档建立索引，（仅索引符合指定过滤器表达式的集合中的文档。）需要用partialFilterExpression指定。 1234db.collection.createIndex( { name: 1 }, { partialFilterExpression: { age: { $gt: 5 } } }) 稀疏索引(sparse index)只针对存在索引字段的文档建立索引。用sparse：true指定为稀疏索引。 1db.collection.createIndex( { score: 1 } , { sparse: true } ) TTL索引TTL索引，MongoDB可以在一段时间后自动从集合中移除文档。用expireAfterSeconds 指定过期时间。 1db.collection.createIndex( { &quot;createdAt&quot;: 1 }, { expireAfterSeconds: 3600 } ) 其它：如在已有较多数据的集合上创建索引，可能会花较长时间，可以用background选项，进行后台创建。 1$ db.collection.createIndex( { name: 1}, {background: true} ) 删除索引 删除集合上的指定索引。12db.collection.dropIndex(&quot;name_age&quot;) //name_age为索引名称db.collection.dropIndex({age:1,name:1}) 删除集合上所有索引。1db.collection.dropIndexes() #查看索引 查看该集合上所有索引1db.collection.getIndexes()","link":"/2017/12/28/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/%E7%B4%A2%E5%BC%95%E7%AE%A1%E7%90%86/"},{"title":"mongodb聚合统计一","text":"mongodb聚合统计写了忘，忘了写，遂做记录，以备查看。 数据信息如下： 要求：按机构Id，分组统计各机构的职业数和职业等级个数。 注意：职业等级（testLevels）字段是一个数组，需要统计出数组中包含的元素个数，即下面中project中的&quot;occuLevelCnt&quot; : { &quot;$size&quot; : [&quot;$testLevels&quot;] }语句，应该通过$unwind也可以实现。 mongodb聚合 1234567891011121314151617181920212223242526272829303132[{ $match: { unitId: { &quot;$in&quot;: [1,2,3] } }}, { $project: { occupationId: 1, occupationTitle: 1, unitId: 1, occuLevelCnt: { $size: &quot;$testLevels&quot; } }}, { $group: { _id: &quot;$unitId&quot;, occupationCnt: { $sum: 1 }, occuLevelCnt: { $sum: &quot;$occuLevelCnt&quot; } }}, { $project: { unitId: &quot;$_id&quot;, occupationCnt: 1, occuLevelCnt: 1 }}] 结果： Java中 1234567TypedAggregation&lt;IrTestRange&gt; occuAggregation = Aggregation.newAggregation(IrTestRange.class, Aggregation.match(Criteria.where(\"unitId\").in(testUnitIds)), Aggregation.project(\"unitId\",\"occupationId\").and(\"testLevels\").size().as(\"occuLevelCnt\"), Aggregation.group(\"unitId\").count().as(\"occupationCnt\").sum(\"occuLevelCnt\").as(\"occuLevelCnt\"), Aggregation.project(\"occupationCnt\", \"occuLevelCnt\").and(Aggregation.previousOperation()).as(\"unitId\"));List&lt;OmTestUnitOccuStatDto&gt; testUnitOccuStat = mongoDao.aggregate(occuAggregation, OmTestUnitOccuStatDto.class);rd.getData().put(\"testUnitOccuStat\", testUnitOccuStat);","link":"/2019/09/14/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/%E8%81%9A%E5%90%881/"},{"title":"PowerDesigner生成数据字典","text":"PowerDesigner连接mysql数据库，生成数据字典。 软件版本 1.打开PowerDesigner，选择菜单：File —&gt; Reverse Engineer —&gt; Database… 2.生成数据字典报告 点击PDM模型项目–&gt;New–&gt;Report 选择Table–&gt;List of Table Columns (先把table加到右边，然后将其他无用的删掉，只留下Table Card 和List of table columns)，可根据实际情况选择。 双击设置表头的名字: 在选定的条目上右键，选择Selection把你数据字典需要的数据勾上 选择Layout,设置显示格式 生成数据字典报告。 生成的示例如下：","link":"/2018/10/12/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/PowerDesigner%E7%94%9F%E6%88%90%E6%95%B0%E6%8D%AE%E5%AD%97%E5%85%B8/"},{"title":"mysql服务安装","text":"系统环境 Ubuntu 16.04 MySQL 版本：5.7 安装方式：apt存储库 安装1、更新APT存储库包信息 1$ sudo apt-get update 2、安装MySQL服务 1$ sudo apt-get install mysql-server 这样将安装MySQL服务器的包，以及客户端和数据库公共文件的包。 在安装过程中，会提示输入mysql中root用户的密码。 3、测试是否安装成功 1$ netstat –tap | grep mysql 4、查看版本 12$ mysql --versionmysql Ver 14.14 Distrib 5.7.24, for Linux (x86_64) using EditLine wrapper 5、设置数据库编码为utf-8 (1) 查看数据库当前编码：SHOW VARIABLES LIKE &apos;character%&apos;; (2) 修改： (5.7版本，默认路径下) : vim /etc/mysql/mysql.conf.d/mysqld.cnf 在[mysqld] 中添加 character_set_server=utf8 (5.7之前版本，默认路径下) ：vim /etc/mysql/my.cnf [mysqld] character_set_server=utf8 [mysql] default-character-set = utf8 [client] default-character-set = utf8 12345678910111213141516171819 (3) 重启MySQL服务 service mysql restart (4) 查看数据库编码 ![](https://ww1.sinaimg.cn/large/007iUjdily1fyap5qekdxj30eu07gwel.jpg)安装完成！#### 管理1、查看mysql服务状态```shell$ sudo service mysql status 2、启动MySQL服务 1$ sudo service mysql start 3、停止MySQL服务 1$ sudo service mysql stop 4、重启MySQL服务器 1$ sudo service mysql restart 基本使用1、登录mysql：mysql –u root –p 2、退出mysql：quit;/exit; 3、查看当前数据库：show databases; 4、创建数据库test：create database test; 5、显示当前数据库中的表：show tables; 6、建表： 12345create table student( -&gt; id int not null primary key, -&gt; name char(8), -&gt; age char(8),-&gt; birthday date ); 7、显示表结构： desc 表名; 8、插入： 12$ insert into test set col_name=expression, col_name=expression, ... $ insert into test (col1,col2) VALUES(15,col1*2); 9、更新： 1$ UPDATE test SET price='20',type=0 WHERE id=2; 10、删除数据库test：drop database test; 11、删除表：drop table 表名; 12、删除数据：delete from Myclass where id = 1; 13、数据库授权用户 12$ create database xxdb;$ grant all privileges on xxdb.* to xxuser@'%' identified by '123456'; 14、备份除information_schema|performance_schema|mysql外所有数据库 1$ mysql -e \"show databases;\" -u root -ppasswd |grep -Ev \"Database|information_schema|performance_schema|mysql|test\" |xargs mysqldump -u root -ppasswd --databases &gt; /ssddata/db_backup/mysql/2017-04-11/mysql_dump.sql 15、备份单个数据库 1$ mysqldump -u root -p ssdb50 &gt; /opt/ssdb60.sql 16、导入 1$ source /opt/ssdb60 参考：https://dev.mysql.com/doc/mysql-apt-repo-quick-guide/en/","link":"/2018/12/18/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/mysql%E6%9C%8D%E5%8A%A1%E5%AE%89%E8%A3%85/"},{"title":"sqlplus安装","text":"1、在oracel官网下载Instantclient-Basic-linux.x64-19.3.0.0.0dbru.zip 、 Instantclient-sqlplus-linux.x64-19.3.0.0.0dbru.zip 到同一个路径下（/opt/oracle/） 2、解压两个压缩包 12$ unzip Instantclient-Basic-linux.x64-19.3.0.0.0dbru.zip$ unzip Instantclient-sqlplus-linux.x64-19.3.0.0.0dbru.zip 3、安装操作系统libaio1软件包 1$ apt-get install libaio1 4、在oracle解压目录下能看到 instantclient_19_3找到sqlplus 运行。 5、执行sqlplus命令可能出现以下错误 12$ /opt/oracle/instantclient_19_3/sqlplus./sqlplus: error while loading shared libraries: libsqlplus.so: cannot open shared object file: No such file or directory 6、设置环境变量：vim /etc/profile 在文件最后添加 123export LD_LIBRARY_PATH=/opt/oracle/instantclient_19_3/:$LD_LIBRARY_PATHexport PATH=/opt/oracle/instantclient_19_3:$PATHexport NLS_LANG=\"american_america.zhs16gbk\" 最后更新环境变量使其生效 source /etc/profile 7、登录数据库 1234567891011121314$ sqlplus SQL*Plus: Release 19.0.0.0.0 - Production on Wed Oct 23 16:12:24 2019Version 19.3.0.0.0Copyright (c) 1982, 2019, Oracle. All rights reserved.Enter user-name: userName/passwd@ip:port/serviceName #输入链接地址Connected to:Oracle Database 11g Enterprise Edition Release 11.2.0.4.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing optionsSQL&gt; 参考：Linux x86-64（64位）的即时客户端安装 SQLplus安装（windows版本） Oracle服务安装后sqlplus命令提示错误 SQLPLUS下出现显示问号的问题","link":"/2019/10/23/%E6%95%B0%E6%8D%AE%E5%BA%93/oracle/sqlplus%E5%AE%89%E8%A3%85/"},{"title":"StringRedisTemplate与RedisTemplate的数据操作","text":"StringRedisTemplate继承自RedisTemplate。 两者数据是不共通的，也就是说StringRedisTemplate只能管理StringRedisTemplate里面的数据，RedisTemplate只能管理RedisTemplate中的数据。 其实他们两者之间的区别主要在于他们使用的序列化类: RedisTemplate使用的是JdkSerializationRedisSerializer 存入数据会将数据先序列化成字节数组然后在存入Redis数据库。 StringRedisTemplate使用的是StringRedisSerializer。 使用时注意事项 当redis数据库里面本来存的是字符串数据或者要存取的数据就是字符串类型数据的时候，那么就使用StringRedisTemplate即可。 如果数据是复杂的对象类型，而取出的时候又不想做任何的数据转换，直接从Redis里面取出一个对象，那么使用RedisTemplate是更好的选择。 RedisTemplate使用时常见问题 redisTemplate 中存取数据都是字节数组。当redis中存入的数据是可读形式而非字节数组时，使用redisTemplate取值的时候会无法获取导出数据，获得的值为null。可以使用 StringRedisTemplate 试试。 常用操作","link":"/2019/10/25/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/StringRedisTemplate%E4%B8%8ERedisTemplate%E7%9A%84%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C/"},{"title":"redis的安装、开机自启","text":"两种安装redis的方式：编译安装或apt安装 编译安装1、下载编译安装 12345678$ cd /opt/redis #创建并进入redis准备目录$ wget http://download.redis.io/releases/redis-4.0.1.tar.gz$ tar -zxvf redis-4.0.1.tar.gz # 解压$ cd redis-4.0.1 #进入解压目录$ make #编译,编译完成后会在src目录下生成Redis服务端程序redis-server和客户端程序redis-cli$ make install #安装$ mkdir /etc/redis #创建redis配置目录$ cp /opt/redis/redis-4.0.1/redis.conf /etc/redis/ #拷贝配置文件 编辑配置文件（暂默认）修改端口、配置数据库保存目录、其它 2、启动： 12$ redis-server /etc/redis/redis.conf # 通过指定配置文件启动$ redis-server &amp; # 以后台程序方式运行 3、登录 12$ redis-cli$ redis-cli -h 127.0.0.1 4、关闭服务 1$ redis-cli shutdown 设置REDIS开机启动1、修改/etc/redis/redis.conf 12daemonize yes #打开后台运行选项logfile \"/var/log/redis/redis.log\" #设置日志文件路径 2、编写脚本 vim /etc/init.d/redis 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#!/bin/sh# chkconfig: 2345 10 90# description: Start and Stop redis### BEGIN INIT INFO# Provides: OSSEC HIDS# Required-Start: $network $remote_fs $syslog $time# Required-Stop:# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: OSSEC HIDS### END INIT INFOPATH=/usr/local/binREDISPORT=6379EXEC=/usr/local/bin/redis-serverREDIS_CLI=/usr/local/bin/redis-cliPIDFILE=/var/run/redis.pidCONF=\"/etc/redis/redis.conf\"case \"$1\" in start) if [ -f $PIDFILE ] then echo \"$PIDFILE exists, process is already running or crashed.\" else echo \"Starting Redis server...\" $EXEC $CONF fi if [ \"$?\"=\"0\" ] then echo \"Redis is running...\" fi ;; stop) if [ ! -f $PIDFILE ] then echo \"$PIDFILE exists, process is not running.\" else PID=$(cat $PIDFILE) echo \"Stopping...\" $REDIS_CLI -p $REDISPORT SHUTDOWN while [ -x $PIDFILE ] do echo \"Waiting for Redis to shutdown...\" sleep 1 done echo \"Redis stopped\" fi ;; restart|force-reload) ${0} stop ${0} start ;; *) echo \"Usage: /etc/init.d/redis {start|stop|restart|fore-reload}\" exit 1esac 3、添加脚本执行权限 1$ sudo chmod +x /etc/init.d/redis 4、注册为服务： 1$ sudo update-rc.d redis defaults 5、 使用脚本管理服务 1234$ service redis start #开启redis$ service redis stop #停止redis$ service redis restart #重启redis$ service redis status #查看服务状态 apt安装12345$ sudo apt-get update #升级软件管理模块$ sudo apt-get install redis-server #安装Redis服务$ redis-server #启动 Redis$ ps -ef | grep redis #查看 redis进程$ netstat -an|grep 6379 #redis的默认端口号6379 可连网状态下一般选择apt进行安装，比较方便。","link":"/2017/08/03/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E7%9A%84%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E3%80%81%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF/"},{"title":"redis集群部署","text":"redis集群部署 redis集群至少需要6个节点（3主3从），也就需要6个实例，因资源有限，只有3个实例，所以在每台上创建2个节点。 1、下载编译安装完redis。 2、创建集群节点文件夹 12$ mkdir -p /etc/redis/redis-cluster/6379$ mkdir -p /etc/redis/redis-cluster/6380 3、拷贝配置文件到相应节点目录 12$ cp /data/redis/redis-4.0.1/redis.conf /etc/redis/redis-cluster/6379$ cp /data/redis/redis-4.0.1/redis.conf /etc/redis/redis-cluster/6380 4、修改配置文件 123456789bind 192.168.138.3port 6379 dir /etc/redis/redis-cluster/6380/logfile \"/var/log/redis/redis_6379.log\"daemonize yes # 后台运行cluster-enabled yes #启用集群cluster-config-file /etc/redis/redis-cluster/6379/nodes_6379.conf # 节点配置文件的路径，集群在启动时自动创建cluster-node-timeout 15000appendonly yes 注意修改每个主机上的相应节点的bind、port。 5、启动每个主机上的2个节点 12$ redis-server /etc/redis/redis-cluster/6379/redis.conf$ redis-server /etc/redis/redis-cluster/6380/redis.conf 6、创建集群 使用上面这些实例来创建集群 1$ redis-cli --cluster create 192.168.138.2:6379 192.168.138.2:6380 192.168.138.3:6379 192.168.138.3:6380 192.168.138.4:6379 192.168.138.4:6380 --cluster-replicas 1 这个命令用于创建一个新的集群, 选项–replicas 1 表示我们希望为集群中的每个主节点创建一个从节点。 之后跟着的其他参数则是这个集群实例的地址列表,3个master3个slave redis-trib 会打印出一份预想中的配置给你看， 如果你觉得没问题的话， 就可以输入 yes ， redis-cli 就会将这份配置应用到集群当中,让各个节点开始互相通讯,最后可以得到如下信息： 1[OK] All 16384 slots covered. 这表示集群中的 16384 个槽都有至少一个主节点在处理， 集群运作正常。 注意：redis5.0可以使用redis-cli来创建集群，不在需要使用ruby语言的redis-trib.rb来创建了。 7、查看节点状态信息 123$ redis-cli -c -h 192.168.138.3 -p 6379&gt; cluster info&gt; cluster nodes 其它： redis哨兵模式 参考 哨兵模式可以监控、故障转移、配置提供者和通知，实现了redis的高可用。 redis集群模式 主要用来做水平扩容，扩大储存容量，解决容灾问题。Redis 集群会把数据储存在不同的节点上，实现负载均衡，流量分发。redis集群模式我认为也就具有高可用性。 参考：http://www.redis.cn/topics/cluster-tutorial.html","link":"/2018/11/06/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"},{"title":"ubuntu Server终端中文菱形乱码","text":"ubuntu Server 安装过程中选择的中文，安装完成后，系统默认的语言将会是中文zh_CN.UTF-8。 但在终端下无法正常的显示默认中文编码zh_CN.UTF-8。 解决方法： 第一种、*使用putty、securteCRT等虚拟终端软件 * 直接修改虚拟终端界面配置项目中的字体编码为UTF-8即可 。但在实际终端下，仍然无法正常显示 汉字。 第二种、把系统转成英文的 修改/etc/default/locale 文件,将内容改为： 12LANG=”en_US.UTF-8″LANGUAGE=”en_US:en” 再运行： 1$ sudo locale-gen -en_US:en 然后重启，会提示是否将文件夹改成英文的，此时选择“Update…”即可 。 第三种、安装zhcon软件包 1$ sudo apt-get install zhcon","link":"/2018/08/23/%E6%9C%8D%E5%8A%A1%E5%99%A8/ubuntu/ubuntuServer%E7%BB%88%E7%AB%AF%E4%B8%AD%E6%96%87%E8%8F%B1%E5%BD%A2%E4%B9%B1%E7%A0%81/"},{"title":"redis设置密码登录","text":"修改配置文件vim /etc/redis.confrequirepass foobared去掉注释，foobared改为自己的密码， 1requirepass 123456 保存，重启服务 1$ service redis-server restart 测试链接 1234567$ redis-cli127.0.0.1:6379&gt; keys *(error) NOAUTH Authentication required.127.0.0.1:6379&gt; auth 123456OK127.0.0.1:6379&gt; keys * 1) \"ts_ea_6206\" 或者连接时验证 1$ redis-cli -a 123456","link":"/2017/12/22/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/%E8%AE%BE%E7%BD%AE%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95/"},{"title":"ubuntu下ssr安装","text":"Shadowsocks 与 Shadowsocksr 区别： SS是原版，SSR是原版基础上衍生出来的第三方版本，兼容原版协议，比原版多了一些伪装功能（协议和混淆）。 SSR 主要特点是增加了一些人性化功能，比如服务器连接统计、连接管理、协议转换、多重代理等。 1、下载ssr客户端 1$ git clone https://github.com/ssrbackup/shadowsocksr 然后运行： 1$ bash ~/shadowsocksr/initcfg.sh 2、配置ss文件在下载的文件中，找到 ssr 配置文件 config.json，修改以下几个参数（具体的服务器，密码，端口从SS帐号提供商那里获取） 123456\"server\": \"0.0.0.0\", //服务器 ip 地址\"server_port\":8388, //端口\"password\":\"password\", //密码 \"protocol\":\"origin\", //协议插件 \"obfs\":\"http_simple\", //混淆插件 \"method\":\"aes-256-cfb\", //加密方式 3、运行ssr 1$ nohup python ~/shadowsocksr/shadowsocks/local.py -c ~/shadowsocksr/config.json &gt;nohup.log 2&gt;&amp;1 &amp; 看输出日志是否启动正常。 可能出现缺少libsodium的问题： 123456789101112131415161718192021IPv6 supportTraceback (most recent call last): File \"server.py\", line 215, in &lt;module&gt; main() File \"server.py\", line 38, in main config = shell.get_config(False) File \"/opt/shadowsocksr/shadowsocks/../shadowsocks/shell.py\", line 299, in get_config check_config(config, is_local) File \"/opt/shadowsocksr/shadowsocks/../shadowsocks/shell.py\", line 129, in check_config encrypt.try_cipher(config['password'], config['method']) File \"/opt/shadowsocksr/shadowsocks/../shadowsocks/encrypt.py\", line 46, in try_cipher Encryptor(key, method) File \"/opt/shadowsocksr/shadowsocks/../shadowsocks/encrypt.py\", line 90, in __init__ random_string(self._method_info[1])) File \"/opt/shadowsocksr/shadowsocks/../shadowsocks/encrypt.py\", line 119, in get_cipher return m[2](method, key, iv, op) File \"/opt/shadowsocksr/shadowsocks/../shadowsocks/crypto/sodium.py\", line 71, in __init__ load_libsodium() File \"/opt/shadowsocksr/shadowsocks/../shadowsocks/crypto/sodium.py\", line 42, in load_libsodium raise Exception('libsodium not found')Exception: libsodium not found 解决： 12345$ apt-get install build-essential$ wget https://github.com/jedisct1/libsodium/releases/download/1.0.10/libsodium-1.0.10.tar.gz$ tar -zxvf libsodium-1.0.10.tar.gz &amp;&amp; cd libsodium-1.0.10$ ./configure &amp;&amp; make -j2 &amp;&amp; make installldconfig 具体可以参考Linux 安装 libsodium 组件 安装 启动正常后，检查端口，默认监听端口1080 1234$ lsof -i:1080COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEpython 10448 root 3u IPv4 1030403 0t0 TCP localhost:socks (LISTEN)python 10448 root 4u IPv4 1030404 0t0 UDP localhost:socks 4、转换HTTP代理Shadowsocks默认是用Socks5协议的，对于Terminal的get,wget等走http协议的地方是无能为力的，所以需要转换成http代理，加强通用性，这里使用的转换方法是基于Polipo的。 12$ sudo apt-get install polipo # 安装Polipo$ sudo vim /etc/polipo/config # 修改配置文件 修改配置文件 123456789101112131415logSyslog = falselogFile = \"/var/log/polipo/polipo.log\"socksParentProxy = \"127.0.0.1:1080\"socksProxyType = socks5chunkHighMark = 50331648objectHighMark = 16384serverMaxSlots = 64serverSlots = 16serverSlots1 = 32proxyAddress = \"0.0.0.0\"proxyPort = 8123 重启Polipo: 1$ /etc/init.d/polipo restart 验证代理是否正常工作： 12$ export http_proxy=\"http://127.0.0.1:8123/\"$ curl www.google.com 如果正常，就会返回抓取到的Google网页内容。此时，终端里面可以访问外网了。 另外，在浏览器中输入http://127.0.0.1:8123/便可以进入到Polipo的使用说明和配置界面。 其它问题 参考：https://www.jianshu.com/p/a0f3268bfa33","link":"/2018/09/29/%E6%9C%8D%E5%8A%A1%E5%99%A8/ubuntu/ubuntu%E4%B8%8Bssr%E5%AE%89%E8%A3%85/"},{"title":"终端登录超时设置","text":"修改/ect/profile 1export TMOUT=120 说明：TMOUT以秒计算，120为两分钟后退出。 使设置生效 1source /etc/profile","link":"/2017/12/22/%E6%9C%8D%E5%8A%A1%E5%99%A8/ubuntu/%E7%BB%88%E7%AB%AF%E7%99%BB%E5%BD%95%E8%B6%85%E6%97%B6%E8%AE%BE%E7%BD%AE/"},{"title":"nginx搭建RTMP流媒体服务器","text":"1、下载nginx-rtmp-modulenginx-rtmp-module的github地址：https://github.com/arut/nginx-rtmp-module 1$ git clone https://github.com/arut/nginx-rtmp-module.git 2、编译nginx(已安装则重新编译)可参考nginx安装、HTTPS之Let’s Encrypt证书的nginx开启SSL模块 123$ ./configure --prefix=/usr/local/nginx --add-module=../nginx-rtmp-module --with-http_ssl_module $ make$ make install # 已安装不要执行此句，否则将覆盖安装 点播视频服务器完成上述nginx服务部署后，就可以开启视频点播服务了。在nginx.conf中天剑RTMP配置 1234567891011121314151617181920212223242526272829303132333435363738worker_processes 1;events { worker_connections 1024;}rtmp { #rtmp服务 server { listen 1935; #服务端口 chunk_size 4096; #数据传输块的大小 application vod { play /opt/video; #视频存放位置 } }}http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 80; server_name localhost; location / { root html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } 在/opt/video目录下放一个视频文件。 12root@ubuntu:/opt/video# lstest.mp4 然后在VLC中打开文件串流，填上点播的节目地址 rtmp://192.168.1.23/vod/test.mp4，就可以播放了。 直播视频服务器添加直播服务器的配置。一共添加两个位置。第一处就是给RTMP服务添加一个application 名字可以任意起，也可以起多个名字，由于是直播就叫做它live吧，如果打算弄多个频道的直播就可以live_cctv1、live_cctv2名字任意。第二处就是添加两个location字段。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455worker_processes 1;events { worker_connections 1024;}rtmp { server { listen 1935; chunk_size 4096; application vod { play /opt; } application live { #直播 频道 live on; } }}http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 80; server_name localhost; location / { root html; index index.html index.htm; } location /stat { #直播location配置 rtmp_stat all; rtmp_stat_stylesheet stat.xsl; } location /stat.xsl { #直播location配置 root /opt/nginx/nginx-rtmp-module; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } }} 添加完后，重启nginx服务。打开浏览器 http://192.168.1.23/stat如图：说明配置生效了。使用推流工具OBS或者liteAv向 rtmp://192.168.1.23/live/test 进行推流就可以使用VLC播放：rtmp://192.168.1.23/live/test在浏览器中查看推流情况 http://192.168.1.23/stat 。 直播视频实时回看视频服务器的配置把正在直播的视频录制在本地，就可以回看之前的视频了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071worker_processes 1;events { worker_connections 1024;}rtmp { server { listen 1935; chunk_size 4096; application vod { play /opt; } application live { live on; hls on; # 这个参数把直播服务器改造成实时回放服务器 wait_key on; # 使视频流以关键帧开始 hls_path /opt/hls; #切片视频文件存放位置 hls_fragment 10s; #每个视频切片的时长 hls_playlist_length 60s; #总共可以回看的事件，这里设置的是1分钟 hls_continuous on; # 连续模式 hls_cleanup on; #对多余的切片进行删除 hls_nested on; #嵌套模式 } }}http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 80; server_name localhost; location / { root html; index index.html index.htm; } location /stat { rtmp_stat all; rtmp_stat_stylesheet stat.xsl; } location /stat.xsl { root /opt/nginx/nginx-rtmp-module; } location /live { #视频回看配置 types { appplication/vnd.apple.mpegurl m3u8; video/mp2t ts; } alias /opt/hls; expires -1; add_header Cache-Control no-cache; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } }} 配置完后，重启nginx服务，这次向nginx推流的直播视频，会向服务器/opt/hls目录写切片视频文件 12root@ubuntu:/opt/hls/# ls0.ts 1.ts 2.ts 3.ts index.m3u8 播放视频 http://192.168.1.23/live/index.m3u8 其它1、hls多码率存储用户设备的尺寸、分辨率、网络环境、带宽不同，因而需要针对不同的网络环境采用不同的码率。 七牛多码率播放hls_playlist_length参数 参考：http://blog.csdn.net/kingroc/article/details/50839994 2、直播权限控制权限控制notify参数 3、获取观看用户数量用户数量 rtmp参数：https://github.com/arut/nginx-rtmp-module/wiki/Directiveshttp://blog.csdn.net/liwf616/article/details/77886991 4、一份较完整配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120user root;worker_processes 1;events { worker_connections 1024;}rtmp { #rtmp服务 server { listen 1935; #服务端口 chunk_size 4096; #数据传输块的大小 application vod { ##播放/opt下视频 rtmp://192.168.1.23/vod/cq2014.mp4 play /opt; #视频存放位置(flv/mp4..) } application live { #直播 频道 ##向此推流进行切片保存 rtmp://192.168.1.23/live/XXX live on; hls on; # 这个参数把直播服务器改造成实时回放服务器 wait_key on; # 使视频流以关键帧开始 hls_path /opt/hls; #切片视频文件存放位置 hls_fragment 10s; #每个视频切片的时长 hls_playlist_length 1h; #总共可以回看的事件，这里设置的是1分钟 hls_continuous on; # 连续模式-HLS序列从上次停止的位置开始 hls_cleanup on; #对多余的切片进行删除 与hls_playlist_length有关 hls_nested on; #嵌套模式-为每个流创建一个子目录 # hls_base_url http://192.168.1.23/; # hls_fragment_naming system; #设置片段命名模式-根据系统时间 # hls_type event; #在event模式下确保播放列表长度足够整个事件 ts不删除 # hls_keys on; #启用HLS加密 # hls_key_path /tmp/keys; #设置保存自动生成的HLS密钥的目录 # hls_key_url http://192.168.1.23/keys/; #设置HLS密钥文件条目的URL # hls_fragments_per_key 10; #设置用同一个密钥加密的HLS分段的数量 } application mytv { ##向此推流 flv格式保存 rtmp://192.168.1.23/live/XXX live on; record all; record_path /opt/video; #指定录制的flv文件的记录路径 record_suffix _recorded.flv; #设置记录文件后缀 # record_unique on; #将当前时间戳添加到录制文件中 record_max_size 10M; #设置最大记录文件大小 # allow publish 192.168.1.101; #允许从指定地址发布 # deny play all; #拒绝所有地址播放 # allow play all; } application big { # 接受rtmp推流，使用ffmpeg降低分辨率为32x32 发布到small应用程序 live on; exec /usr/local/nginx/sbin/ffmpeg -re -i rtmp://192.168.1.23/$app/$name -vcodec flv -acodec copy -s 32x32 -f flv rtmp://192.168.1.23/small/${name}; } application small { live on; } application notify { live on; publish_notify on; on_publish http://baidu.com/on_publish.html; } } log_format new $remote_addr [$time_local] $command &quot;$app&quot; &quot;$name&quot; &quot;$args&quot; - $bytes_received $bytes_sent &quot;$pageurl&quot; &quot;$flashver&quot; ($session_readable_time); access_log logs/rtmp_access.log new; access_log logs/rtmp_access.log; # access_log off;}http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 80; server_name localhost; location / { #video.js插件播放m3u8 首页 root html/hls; index index.html index.htm; } location /stat { #统计配置 http://192.168.1.23/stat rtmp_stat all; rtmp_stat_stylesheet stat.xsl; } location /stat.xsl { #统计配置 root /opt/nginx/nginx-rtmp-module; } location /live { #视频回看配置 与application的live对应 vlc网络串流播放 http://192.168.1.23/live/XXX/index.m3u8 types { appplication/vnd.apple.mpegurl m3u8; video/mp2t ts; } alias /opt/hls; expires -1; add_header Cache-Control no-cache; } location /test { #video.js插件播放m3u8 与application的live对应 http://192.168.1.23/test/index.m3u8 root /opt/hls; } location /keys { #启用HLS加密后 密钥请求地址 root /tmp; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } }} 开源流媒体服务器系统 SRS:http://www.ossrs.net/srs.release/releases/","link":"/2018/03/07/%E6%B5%81%E5%AA%92%E4%BD%93/nginx/nginx%E6%90%AD%E5%BB%BARTMP%E6%B5%81%E5%AA%92%E4%BD%93%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"title":"SRS分发RTMP流及HLS流","text":"SRS支持HLS/RTMP两种成熟而且广泛应用的流媒体分发方式。 RTMP指Adobe的RTMP(Realtime Message Protocol)，广泛应用于低延时直播，也是编码器和服务器对接的实际标准协议，在PC（Flash）上有最佳观看体验和最佳稳定性。 实时性高，实时性在3秒之内。 稳定性高。 支持加密。。。。 HLS指Apple的HLS(Http Live Streaming)，本身就是Live（直播）的，不过Vod（点播）也能支持。HLS是Apple平台的标准流媒体协议，和RTMP在PC上一样支持得天衣无缝，点播以HLS为主。 跨平台，能跨PC/Android/IOS。 实时性差，延迟在10秒以上。 性能高。。。。HLS和RTMP两种分发方式，就可以支持所有的终端。 1、RTMP直播 (1)编写SRS配置文件 vim conf/rtmp.conf 12345# conf/rtmp.conf listen 1935; max_connections 1000; vhost __defaultVhost__ { } (2)启动SRS 1$ ./objs/srs -c conf/rtmp.conf (3)使用推流工具推流 使用FFMPEG命令推流： 123456for((;;)); do \\ ./objs/ffmpeg/bin/ffmpeg -re -i ./doc/source.200kbps.768x320.flv \\ -vcodec copy -acodec copy \\ -f flv -y rtmp://192.168.1.36/live/livestream; \\ sleep 1; \\ done (4)观看RTMP流 RTMP流地址为：rtmp://192.168.1.36/live/livestream 使用VLC观看或使用在线SRS播放器播放：srs-player2、底延时配置 参考：LowLatency (1)编辑配置文件 vim conf/realtime.conf 123456789101112listen 1935;max_connections 1000;vhost __defaultVhost__ { gop_cache off; queue_length 10; min_latency on; mr { enabled off; } mw_latency 100; tcp_nodelay on;} (2)启动SRS 1./objs/srs -c conf/realtime.conf (3)使用推流工具推流 使用FFMPEG命令推流： 123456for((;;)); do \\ ./objs/ffmpeg/bin/ffmpeg -re -i ./doc/source.200kbps.768x320.flv \\ -vcodec copy -acodec copy \\ -f flv -y rtmp://192.168.1.36/live/livestream; \\ sleep 1; \\ done (4)观看RTMP流 RTMP流地址为：rtmp://192.168.1.36/live/livestream 注意：不要使用VLC观看，VLC的延迟会很大。3、分发hls流 参考：HLS配置 (1)启动分发hls（m3u8/ts）的nginx 1./objs/nginx/sbin/nginx nginx启动后可以访问:nginx (2)编写SRS配置文件 vim conf/hls.conf 1234567891011121314listen 1935;max_connections 1000;daemon off;srs_log_tank console;vhost __defaultVhost__ { hls { enabled on; hls_fragment 10; hls_window 60; hls_path ./objs/nginx/html; hls_m3u8_file [app]/[stream].m3u8; hls_ts_file [app]/[stream]-[seq].ts; }} 备注：hls_path必须存在，srs只会自动创建${hls_path}下的app的目录。 参数含义： enabled：是否开启HLS。 hls_fragment：秒，指定ts切片的最小长度。 hls_window：保留的ts文件的时长，超过总时长后，丢弃第一个m3u8中的第一个切片，直到ts的总时长在这个配置项范围之内。 hls_path：HLS的m3u8和ts文件保存的路径。m3u8和ts文件都保存在这个目录中。 hls_m3u8_file: HLS的m3u8文件名，包含可替换的[vhost],[app]和[stream]变量. hls_ts_file：HLS的ts文件名，包含可替换的一系列变量，参考变量 hls_entry_prefix: ts的base url。如：http://your-server。 hls_cleanup：是否删除过期的ts切片，不在hls_window中就是过期。 hls_dispose: HLS清理的过期时间（秒）。 hls_wait_keyframe: 是否按top切片，即等待到关键帧后开始切片。 hls_nb_notify: 从notify服务器读取数据的长度。 on_hls: 当切片生成时，回调这个url，使用POST回调。用来和自己的系统集成，譬如实现切片移动等。 on_hls_notify: 当切片生成时，回调这个url，使用GET回调。 (3)启动SRS 1./objs/srs -c conf/hls.conf (4)使用推流工具推流 使用FFMPEG命令推流： 123456for((;;)); do \\ ./objs/ffmpeg/bin/ffmpeg -re -i ./doc/source.200kbps.768x320.flv \\ -vcodec copy -acodec copy \\ -f flv -y rtmp://192.168.1.36/live/livestream; \\ sleep 1; \\ done 注意：HLS需要RTMP流的编码为h.264+aac/mp3，若不符合这个要求则需要转码。否则会自动禁用HLS。参考：HLS转码、 HLS+Transcode 5、观看RTMP流 RTMP流地址为：rtmp://192.168.1.36/live/livestream 可以使用VLC观看或者使用在线SRS播放器播放srs_player 6、观看HLS流 HLS流地址为： http://192.168.1.36/live/livestream.m3u8 可以使用VLC观看或者使用在线SRS播放器播放jwplayer 其它：RTMP与HLS的优势及应用场景参考：SRS_HLSSRS_RTMPSRS_RTMP PK HLS","link":"/2018/03/21/%E6%B5%81%E5%AA%92%E4%BD%93/srs/SRS%E5%88%86%E5%8F%91RTMP%E6%B5%81%E5%8F%8AHLS%E6%B5%81/"},{"title":"SRS流媒体服务器","text":"前言SRS支持HLS/RTMP两种成熟而且广泛应用的流媒体分发方式。 一、编译安装1、源码下载 1$ git clone https://git.oschina.net/winlinvip/srs.oschina.git 2、切换分支 稳定度 2.0release/1.0release &gt;&gt; develop. (1) 查看当前分支 12$ cd /opt/srs.oschina$ git branch (2) 改变到2.0分支 1$ git pull &amp;&amp; git checkout 2.0release3、编译安装编译参数含义参考：配置参数说明 12$ cd trunk/$ ./configure --prefix=/usr/local/srs --with-ssl --with-hls --with-hds --with-dvr --with-nginx --with-http-callback --with-http-server --with-stream-caster --with-http-api --with-ffmpeg --with-transcode --with-ingest --with-stat --with-librtmp --with-research --with-utest 4、第三方应用启动 123$ sudo ./objs/nginx/sbin/nginx # to start the nginx http server for hls$ ./objs/ffmpeg/bin/ffmpeg # is used for live stream transcoding$ python ./research/api-server/server.py 8085 # to start the api-server 5、SRS启动 (1) 直接启动 1$ cd srs/trunk &amp;&amp; ./etc/init.d/srs start (2) 添加为系统服务 * 将trunk/etc/init.d/srs 文件中 ROOT=”./“改为实际安装目录(默认/usr/local/srs)。 * 链接安装目录的init.d/srs到/etc/init.d/srs 1$ sudo ln -sf /usr/local/srs/etc/init.d/srs /etc/init.d/srs ​ * 添加到系统服务. 12$ sudo update-rc.d srs defaults # ubuntu$ sudo /sbin/chkconfig --add srs # centos 1启动：$ /etc/init.d/srs start 6、SRS-API安装SRS的API即api-server，SRS可以调用api-server提供的http接口，需要打开–with-http-callback支持。SRS使用python(cherrypy)编写的server.py，也直接运行脚本。API服务器主要提供http调用服务，提供demo运行的页面，播放器和编码器视频会议等DEMO。启动后可以通过http://192.168.1.36:8085地址观看。 (1)安装api 1$ make install-api (2)启动api： 12$ /usr/local/srs/etc/init.d/srs-api start` 即可以观看demo的页面。推流需要自己手动推流。 (3)注册为系统服务 12$ sudo ln -sf /usr/local/srs/etc/init.d/srs-api /etc/init.d/srs-api$ sudo update-rc.d srs-api defaults 其它1、编译过程可能出现的问题 12sudo: python: command not foundssr build CherryPy-3.2.4 failed, ret=1 解决： 12345$ cp 3rdparty/CherryPy-3.2.4.zip ./objs/$ cd objs/$ rm -r CherryPy-3.2.4$ unzip CherryPy-3.2.4.zip$ rm CherryPy-3.2.4.zip 之后继续编译安装。2、srs-api启动时问题 12345$ python ./research/api-server/server.py 8085 File &quot;server.py&quot;, line 44 print &quot;[%s][trace] %s&quot;%(date, msg) ^ SyntaxError: invalid syntax 解决：python版本问题 安装Python2.7版本 1$ apt-get install python 3、cherrypy安装问题 12345$ python ./research/api-server/server.py 8085Traceback (most recent call last): File &quot;server.py&quot;, line 39, in &lt;module&gt; import os, json, time, datetime, cherrypy, threading, urllib2ImportError: No module named cherrypy 解决：安装CherryPy(官网) 12$ python ./objs/CherryPy-3.2.4setup.py install$ python -c &quot;import cherrypy&quot; # 验证","link":"/2018/03/20/%E6%B5%81%E5%AA%92%E4%BD%93/srs/SRS%E6%B5%81%E5%AA%92%E4%BD%93%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"title":"svn服务安装与使用","text":"svn服务端客户端安装 ubuntu ：apt-get install subvision 创建版本库：svnadmin crate /path/repos删除版本库：rm -rvf /path/repos svn版本库的配置及权限分组配置文件位于/path/repos/conf/目录下 authz – 配置用户组以及用户组权限 passwd – 配置用户名和密码 svnsere.conf – 配置默认权限、权限配置文件及密码配置文件 启动svn版本库：svnserve -d -r /path/repos/ 默认端口号：3690 –listen-port 指定端口号停止版本库：killall svnservesvn版本库检出 ：svn checkout svn://192.168.0.130 -r 2 检出版本2 –username 用户名 –password 密码 svn服务自启动一种方式(/etc/rc.local) vim /etc/rc.local 1$ svnserve -d -r /path/repos/ 另一种方式(/etc/init.d/) checkout与export区别 checkout-检出 export-导出-checkout检出的工作副本中含.svn文件夹-版本控制中有一种文件状态：无版本控制 checkout =&gt; .svn + 项目文件 export =&gt; 项目文件（无版本控制状态） svn 客户端命令 svn add -添加到版本控制 svn add * –force svn commit - 提交修改到服务端（创建一个新版本号） svn commit -m “注释” index.html svn update - 更新工作副本 svn update * svn delete - 从版本库中删除文件或目录 svn diff - 版本差异比较 svn diff index.html svn mkdir - 创建目录并添加到版本控制 svn cat - 不检出工作副本之间查看指定文件 svn cat svn://192.168.0.130/index.html工作副本还原 svn revert [–recursive][filename|*] svn 处理冲突 svn resolve index.html 或者直接编辑index.html文件 svn resolved inde.html svn 解锁与锁定 svn lock - 锁定文件，防止其他成员对文件进行提交 svn unlock - 解锁文件 svn list - 列出当前目录下处于版本控制的所有文件 svn ls -v –recursive svn status -列出工作副本中的文件（夹）的状态 状态： ？ - 无版本控制 D - 已被标记从版本库中删除 M - 已被编辑过 A - 已被标记增加到版本控制中 R - 文件被替换 C - 文件存在冲突 ！- 文件缺失 svn log - 查看提交日志（来自svn commit的-m 参数） svn info - 工作副本及文件（夹）的详细信息 多个版本库解决方案 一、 多个端口号： 版本库可以创建在任意位置 端口号容易混淆 二、一个端口号： 版本库必须创建在同一目录下 无需分配端口号 svn cp 工作副本–&gt;工作副本 工作副本–&gt;版本库（不可跨库） 版本库 –&gt;工作副本（允许跨库） 版本库 –&gt;版本库（不可跨库） 主干版本 trunk分支版本 branch发布版本的备份 tag hooks 钩子当执行某些特定操作时触发执行预先设定好的任务。钩子的实质是shell脚本。数据先从本地传输到服务器，再从服务器复制到版本库。所以有3个时间点： 传输之前（start）；传输之后复制之前（pre）；复制之后（post）。钩子非常强大，github架设在svn之上也是通过钩子实现的。 版本库的迁移 方式一：1、killall svnserve 2、把/path/repos/压缩成repos.zip 3、复制repos.zip到新服务器并解压。 4、在新服务器上运行repos版本库。 方式二： 1、killall svnserve 2、svnadmin dump /path/repos -r 1:100 &gt; /temp/repos.repo //（-r 版本号：版本号） 3、svnadmin load /path/newrepos/ &lt; /temp/repos.repo 4、把配置文件复制到新版本库中。 5、把旧的版本库删除。 7、启动新版本库服务。svn版本库的重定向svn switch –relocate svn://192.168.0.130/repos svn://192.168.x.xx/newrepos","link":"/2018/04/02/%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/SVN/svn/"},{"title":"SRS-HTTP-FLV点播FLV流","text":"SRS支持将RTMP流转封装为HTTP flv流，即在publish发布RTMP流时，在SRS的http模块中挂载一个对应的http地址（根据配置），用户在访问这个http flv文件时，从rtmp流转封装为flv分发给用户。所有的HTTP FLV流都是一个HTTP FLV地址，譬如：http://192.168.1.36:8080/live/livestream.flv但是，流的形式却至少有三种：1、FLV文件，放一个文件到nginx目录，可以访问下载在播放器播放，这是HTTP FLV文件，也就是渐进式下载流。所谓渐进式下载，也就是用户观看时无法从未下载的地方开始看。2、FLV伪流。一般说的HTTP FLV，如，一个120分钟的电影，作为渐进式流播放时，用户需要从60分钟开始看，如何支持呢？因为nginx是当做文件下载的，无法直接跳转到第60分钟（nginx也不知道60分钟对应的字节偏移是多少呀）。后来有人就支持这种跳着播放，通过指定时间服务器从指定的位置开始给流，这种支持flv?start=，（nginx的flv模块）。就是http flv的伪流，本质上还是点播流。3、FLV直播流。有RTMP的所有特征，譬如集群、低延迟、热备、GOP cache，而且有HTTP的优势，譬如302、穿墙、通用。 1、HTTP FLV直播流分发 HTTP FLV (1)编写SRS配置文件 vim conf/http.flv.live.conf 123456789101112131415# conf/http.flv.live.conflisten 1935;max_connections 1000;http_server { enabled on; listen 8080; dir ./objs/nginx/html;}vhost __defaultVhost__ { http_remux { enabled on; mount [vhost]/[app]/[stream].flv; hstrs on; }} (2)启动SRS 1./objs/srs -c conf/http.flv.live.conf (3)用推流工具进行推流 使用FFMPEG命令推流： 123456for((;;)); do \\ ./objs/ffmpeg/bin/ffmpeg -re -i ./doc/source.200kbps.768x320.flv \\ -vcodec copy -acodec copy \\ -f flv -y rtmp://192.168.1.36/live/livestream; \\ sleep 1; \\ done (4)观看RTMP流 RTMP流地址为：rtmp://192.168.1.170/live/livestream (5)观看FLV流 HTTP FLV流地址为： http://192.168.1.170:8080/live/livestream.flv 注意：在nginx/html/live/下并未保存livestream.flv文件。2、点播FLV流 VOD FLVsrs不支持点播，只支持直播，点播建议用http分发点播FLV流的主要流程是： 服务器录制直播为FLV文件，或者上传FLV点播文件资源，到SRS的HTTP根目录：objs/nginx/html HTTP服务器必须要支持flv的start=offset，譬如nginx的flv模块，或者SRS的实验性HTTP服务器。 使用research/librtmp/objs/srs_flv_injecter将FLV的时间和对于的offset（文件偏移量）写入FLV的metadata。 播放器请求FLV文件，譬如：http://192.168.1.170:8080/sample.flv 用户点击进度条进行SEEK，譬如SEEK到300秒。 播放器根据inject的时间和offset对应关系找出准确的关键帧的offset。譬如：300秒偏移是6638860 根据offset发起新请求：http://192.168.1.170:8080/sample.flv?start=6638860 3、DVR 参考 SRS支持将RTMP流录制成flv文件。 配置说明 1234567891011listen 1935;max_connections 1000;vhost __defaultVhost__ { dvr { enabled on; dvr_path ./objs/nginx/html/[app]/[stream]/[2006]/[01]/[02]/[15].[04].[05].[999].flv; dvr_plan segment; dvr_duration 30; dvr_wait_keyframe on; }} dvr_plan 决定什么时候关闭flv文件，打开新的flv文件 session：按照session来关闭flv文件，即编码器停止推流时关闭flv，整个session录制为一个flv。. segment：按照时间分段录制，flv文件时长配置为dvr_duration和dvr_wait_keyframe。 time_jitter: 时间戳抖动算法。full使用完全的时间戳矫正；zero只是保证从0开始；off不矫正时间戳。 dvr_path: 录制的路径。4、HTTP回调 HTTPCallback事件： on_connect 当客户端连接到指定的vhost和app时。 on_close 当客户端关闭连接，或者SRS主动关闭连接时。 on_publish 当客户端发布流时，譬如flash/FMLE方式推流到服务器。 on_unpublish 当客户端停止发布流时。 on_play 当客户端开始播放流时。 on_stop 当客户端停止播放时。备注：停止播放可能不会关闭连接，还能再继续播放。 on_dvr 当DVR录制关闭一个flv文件时。说明： 事件：发生该事件时，即回调指定的HTTP地址。 HTTP地址：可以支持多个，以空格分隔，SRS会依次回调这些接口。 数据：SRS将数据POST到HTTP接口。 返回值：SRS要求HTTP服务器返回HTTP200并且response内容为整数错误码（0表示成功），其他错误码会断开客户端连接。","link":"/2018/03/20/%E6%B5%81%E5%AA%92%E4%BD%93/srs/SRS%E7%82%B9%E6%92%ADFLV%E6%B5%81/"},{"title":"svn服务安装与使用","text":"1、svn服务安装 1$ apt-get install subversion 2、创建版本库 12$ mkdir /usr/local/svn$ svnadmin create /usr/local/svn/repos 3、查看版本库生成文件 123$ cd /usr/local/svn/repos$ lsconf db format hooks locks README.txt conf文件夹下是存放主配置文件和用户、权限位置，db文件夹是存放svn转储后的数据。 123$ cd conf$ lsauthz hooks-env.tmpl passwd svnserve.conf authz文件是设置用户权限，passwd文件是存储用户及密码，svnserve.conf是主配置文件。4、配置版本库 (1) vim svnserve.conf 12345[general]anon-access = none #匿名访问权限，默认read，none为不允许访问auth-access = write #认证用户权限 password-db = passwd #用户信息存放文件，默认在版本库/conf下面，也可以绝对路径指定文件位置authz-db = authz 注意：每行前面一定不要有空格。 (2) vim passwd #格式是用户名=密码，采用明文密码 1234[users]xiaoming = 123zhangsan = 123lisi = 123 (3)vim authz 1234567[groups]manage = xiaomingdevelop = zhangsan,lisi[repos:/] ##以根目录起始的repos版本库manager组为读写权限@manage = rw[repos:/project] ##develop对repos版本库下media目录为读写权限@develop = rw5、启动svn服务 1$ svnserve -d -r /usr/local/svn -d表示以守护进程模式启动，-r表示代码仓库的根目录.查看是否启动成功,监听3690端口 12$ netstat -tanp |grep svnservetcp 0 0 0.0.0.0:3690 0.0.0.0:* LISTEN 3032/svnserve 6、关闭svn服务 1pkill svnserve","link":"/2018/03/30/%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/SVN/svn%E6%9C%8D%E5%8A%A1%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"title":"GitHub提交时忽略不必要上传的文件","text":"新建.gitignore文件，写入要忽略的内容 123456789.gitignore .settings/ //忽略idea目录下的所有文件.project //忽略项目根目录下的 .project 文件target/*.zip //忽略所有.zip结尾的文件doc/*.txt //忽略 doc/notes.txt,但不包括 doc/server/arch.txt!test.txt //不忽略 test.txt 文件 注:如果要忽略的文件已被git管理,需要先移除,命令如下: 1git rm -r target/ //-r为递归 然后git commit 最后.gitignore中的忽略，就会起作用","link":"/2019/12/21/%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/git/GitHub%E6%8F%90%E4%BA%A4%E6%97%B6%E5%BF%BD%E7%95%A5%E4%B8%8D%E5%BF%85%E8%A6%81%E4%B8%8A%E4%BC%A0%E7%9A%84%E6%96%87%E4%BB%B6/"},{"title":"git服务器的初步简单部署","text":"git服务器的初步简单部署 环境：git服务器Ubuntu，开发机器Windows 7。 1、安装git 1$ apt-get install git 2.创建git用户及权限 12$ adduser -m git$ passwd git 添加git用户后会在/home下生成git目录，我们并不希望这个用户通过ssh连接到服务器上面去，所以，我们要禁止这个用户使用ssh连接上去进行操作。我们通过编辑/etc/passwd权限文件来处理。 12#git:x:1001:1001:,,,:/home/git:/bin/bashgit:x:1001:1001:,,,:/home/git:/usr/bin/git-shell 3、在开发机器上生成公钥 首先下载安装git 在本机生成密钥： 1234567891011121314151617181920212223admin@admin-PC MINGW64 ~$ ssh-keygen.exeGenerating public/private rsa key pair.Enter file in which to save the key (/c/Users/admin/.ssh/id_rsa):Created directory '/c/Users/admin/.ssh'.Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /c/Users/admin/.ssh/id_rsa.Your public key has been saved in /c/Users/admin/.ssh/id_rsa.pub.The key fingerprint is:SHA256:49440Ss8DHEeufZG9U7sQWhe+zUOkkCvyEMjReHdwcg admin@admin-PCThe key's randomart image is:+---[RSA 2048]----+| .oo o. || ...E... || ...o.. . || ..o+. .+ o || ++S+o+.= . || .==ooo..*..|| =o+ ..+ooo|| .*o+ o..|| o=. |+----[SHA256]-----+ 把C:\\Users\\admin.ssh下的id_rsa.pub发送到git服务器上 4、在服务器配置公钥 1234$ cd /home/git/$ mkdir .ssh$ cd .ssh$ vi authorized_keys 把开发机器上的id_rsa.pub文件内容添加保存到authorized_keys文件。 5、初始化一个git仓库 12345678$ su gitgit@ubuntu:~$ mkdir /home/git/repositoriesgit@ubuntu:~$ chown git:git /home/git/repositories/git@ubuntu:~$ chmod 755 /home/git/repositories/git@ubuntu:~$ cd repositories/git@ubuntu:~/repositories$ mkdir helloworld.gitgit@ubuntu:~/repositories$ cd helloworld.git/git@ubuntu:~/repositories/helloworld.git$ git --bare init 6、在本地克隆test仓库 1$ git clone git@192.168.1.32:/home/git/repositories/helloworld.git 7、多用户与权限管理 如果团队人数较少，把每个人的公钥收集起来放到服务器的/home/git/.ssh/authorized_keys文件里就是可行的。如果团队人数较多，就比较麻烦了，这时，可以用Gitosis来管理公钥。","link":"/2017/08/23/%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/git/git%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%88%9D%E6%AD%A5%E7%AE%80%E5%8D%95%E9%83%A8%E7%BD%B2-%E4%B8%80/"},{"title":"git服务器的权限控制","text":"权限控制 git的权限控制是采用的gitolite，自身就是一个特殊的git版本库（gitolite-admin），他们的管理与配置都可以通过git的方式，分布式的进行修改，然后通过push的方式提交到服务器，服务器会通过所谓的钩子脚本自动更新权限控制文件。 1、切换到git用户下(git仓库是在git用户下) 1$ su git gitolite本质就是根据你的配置，自动生成authorized_keys文件，所以它要求你的authorized_keys文件必须是空的，或者不存在，所以我们干脆删了它 1$ rm ~/.ssh/authorized_keys gitolite在初始化时需要通过某一用户的公钥文件指定一个超级管理员，gitolite安装成功后，只有这个超级管理员可以更新gitolite以更新各种权限控制（包括对其自身的更新权限控制），所以在初始化时需要指定该超级管理员账户的公钥文件（最好直接将其拷贝到git用户的主文件夹下）（下面的示例程序使用同一服务器上的另一常用管理员用户admin）。 新建admin用户 12$ useradd -m admin$ passwd admin 切换到admin下，生成超级管理员账户的公钥文件 123root@ubuntu:~# su adminadmin@ubuntu:~$ ssh-keygenadmin@ubuntu:~$ sudo cp .ssh/id_rsa.pub /home/git/id_rsa.pub 2、安装gitolite 123456admin@ubuntu:/home/git$ su gitgit@ubuntu:~$ cd ~git@ubuntu:~$ git clone git://github.com/sitaramc/gitolitegit@ubuntu:~$ mkdir -p $HOME/bin #为gitolite的二进制文件生成创建目录git@ubuntu:~$ gitolite/install -to $HOME/bin/ # 编译生成安装文件git@ubuntu:~$ $HOME/bin/gitolite setup -pk id_rsa.pub # 安装并初始化，指定id_rsa.pub公钥文件对应的用户为超级管理员 gitolite安装后本身是一个特殊的git版本库——gitolite-admin，分布式的进行修改，然后通过push的方式提交，其会通过钩子脚本执行权限更新。gitolite自动生成了两个版本库：gitolite-admin.git和testing.git，其中的gitol-admin.git就是那个权限控制的版本库。 接下来我们要做的，就是回到你刚刚指定的超级管理员账户的电脑跟账户下，clone出gitolite-admin这个特殊的git版本库（当前情况下，只有该超级管理员账户可以clone并更新gitolite-admin这个版本库），然后根据自己的需要对其进行配置（如添加更多的管理员账户、添加新的版本库并为不同的用户指定权限） 3、权限设置 123root@ubuntu:~# su adminadmin@ubuntu:/root$ cd ~admin@ubuntu:~$ git clone git@192.168.1.32:gitolite-admin.git 如果上面的步骤都成功了的话，应该可以查看到有一个gitolite-admin的文件夹，文件夹下有两个目录conf、keydir。clone默认路径是/home/git/repositories，权限控制是只有当前的超级管理员用户可以访问gitolite-admin和testing两个版本库，你之前测试创建的版本库也已经无法访问，如果你尝试再次clone之前创建的测试版本库，就会提示没有权限。要继续访问之前创建的项目，需要将这个项目添加到gitolite的权限控制内。下面演示一下为当前的超级管理员用户指定之前创建的helloworld测试版本库的读写权限（可读可写），以此演示gitolite指定权限的一般流程：1、将需要指定权限的用户的ssh公钥文件，存放在gitolite-admin版本库的keydir目录下（如果提交的都是id_rsa.pub，可以将其重命名为该用户的id或者名称，同时也推荐这样重命名，以明示哪个公钥文件是哪个用户的），因为我们初始化时，gitolite已经将该超级管理员的公钥文件自动拷进去了，所以省略此步骤。2、编辑conf目录下的gitolite.conf文件，添加helloworld版本库管理组，为超级管理员指定读写权限（RW+，具体的权限定义，参考gitolite官方文档） 1234567repo gitolite-adminRW+ = id_rsarepo testing RW+ = @allrepo helloworld RW+ = id_rsa 3、commit到本地 1git commit -am ‘add the helloworld repo and add RW+ to id_rsa’ 提交时，首先要用名称 12git config –global user.email “you@example.com”git config –global user.name “Your Name” 4、push到git仓库 1git push push成功，当前超级管理员用户应该就可以成功clone helloworld版本库，并进行添加、删除、修改与push等操作了。 参考： http://blog.csdn.net/xsl1990/article/details/25486211 https://github.com/sitaramc/gitolite","link":"/2017/08/28/%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/git/git%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6-%E4%BA%8C/"},{"title":"git服务器的用户管理","text":"1、添加用户 要添加新用户alice，bob和carol，首先获取他们的公钥，并将它们分别添加到管理员“gitolite-admin/keydir”作为alice.pub，bob.pub和carol.pub。(以用户名进行命名。) 要添加一个新的仓库repo:foo,并给予上述这些用户不同级别的访问权限编辑 vim conf/gitolite.conf 1234repo foo RW+ = alice RW = bob R = carol 完成这些更改后，执行以下操作： 1234git add confgit add keydirgit commit -m \"added foo, gave access to alice, bob, carol\"git push push完之后，gitolite将添加新的用户到 ~/.ssh/authorized_keys服务器上，以及创建一个名为foo的空的repo。 2、访问规则 1234567repo foo RW+ = alice - master = bob - refs/tags/v[0-9] = bob RW = bob RW refs/tags/v[0-9] = carol R = dave alice可以对任何分支或标签做任何事情, 创建，推送，删除,撤回，覆盖等。 bob 可以创建或推送名称不以“master”开头的分支，并创建名称不以“v”+数字开头的任何标签。 carol可以创建名称以“v”+数字开头的标签。 dave仅可以克隆。 3、组 方便群组用户管理，下面是创建了两个组 1234567@staff = alice bob carol@interns = ashokrepo secret RW = @staffrepo foss RW+ = @staff RW = @interns 组列表累积。以下两行与上面的@staff的早期定义具有相同的效果： 12@staff = alice bob@staff = carol 可以在其它组中使用组名 1@all-devs = @staff @interns 帮助用户 1、用户可以通过 git clone git@host:reponame的形式克隆仓库。 2、用户可以通过 ssh git@host info 查看可访问的仓库及权限。 3、用户可以通过 ssh git@host help获取帮助。","link":"/2017/08/28/%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/git/git%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86-%E4%B8%89/"},{"title":"红烧肉做法","text":"1、猪肉切块。 2、在锅中加入冷水，把猪肉倒入锅中，把水煮沸，捞取浮沫，之后把肉盛出。 3、在炒瓢中倒入油，加入蒜掰等调料，然后把肉倒入，开始翻炒。 4、翻炒大约5分钟，肉有一丝焦黄后，把肉盛出。 5、在炒瓢中加入油，然后加入白糖，待糖化后，把肉倒入。翻炒。 6、肉上色后，加入酱油。盐。 7、加入两碗水，大火煮沸。 8、煮沸后转中小火，煮50分钟。 9、水快干时，转大火，收汁。","link":"/2018/06/17/%E7%94%9F%E6%B4%BB/%E5%81%9A%E8%8F%9C/%E7%BA%A2%E7%83%A7%E8%82%89/"},{"title":"我不是药神","text":"起初决定去卖仿制药也是为了赚钱，因为家庭，因为生活，面对如此巨大的需求市场，自然赚的金盆钵满，但是这始终是违法的，最终选择了解散，他们心中是失望的，是无奈的，是绝望的。但是他们没有理由去让他去为此冒险。只得听天由命，慢慢等死。面对如此高昂的费用，面对被拖垮的家庭，不得不选择自杀。得知他的死讯，和看着大家的期待，这次又决定去冒险去卖仿制药，并且按进口价出售，不为盈利，大家又看到了生的希望。可是面对警察的严加追查，最终被锁定，为了不让他被抓，他开车带警察飞奔，最终出了车祸，他是如此的伤心，面对他的追问，“他有什么罪”，他也是万分的无奈和自责，最后辞去了警察职务。印度仿制药厂面对原药厂的起诉，也不得不关停了药厂，仿制药虽说没有绝产，但价格也番了数番。但他仍然决定按之前价格出售，自己去垫付剩余的差价。最终还是被警察抓到。大家心中都清楚他没有什么罪，法大于情？最后被判了5年，送去监狱的路上，大家都摘下口罩，目送离开，最终得到了减刑，提前出来。结局列出了现实中的一些政策纪事。这也是一个真是的故事：https://www.v2ex.com/t/468603 研制药厂需要研发新药，制定了高昂的价格，病人需要活命，去买仿制药，两者都没有问题，但这两者是对立矛盾的。所以最终只能是由国家出面去协调解决。 慢性粒细胞性白血病 1956年彼得在费城发现了是因为22号染色体比正常的要短。被称为费城染色体。 1973年珍妮特发现了染色体之所以会变短是因为发生了染色体交换。即9号染色体和22号染色体，由于某些原因，9号染色体下面会断出来一截，22号染色体下面也会断出一截，然后他们就交换了，交换后9号染色体的一部分接到了22号染色体上，22号染色体的一部分接到了9号染色体上，这样就造成了22号染色体变得比正常的要短。 1983年美国国立癌症研究所发现9号染色体上有一个叫ABL的基因和22号染色体上的BCR基因，发生了融合，形成了ABL-BCR融合基因，这种融合基因，就是产生这种恶性肿瘤的原因。 格列卫 由诺华公司生产，它是一种小分子靶向药物，他是专门抑制这种基因产生的。 十年存活率可以由50%提高到90%左右。 研制出的药物是有专利期的，过了专利保护期，别的药厂就可以进行仿制。 仿制药 仿制的药需要满足2个等效性，一、药学等效性，即要的剂量，给药方式，活性成分等因素必须相同。二、生物等效性，即吸收速度相同。 赋形剂可以不同，即填充药物，像硫酸钙、乳糖。 印度可以生成仿制药是因为印度许多穷人吃不起药，所以1970年印度修改了自己的专利法，允许强仿，即药物上市后，允许药厂对其进行仿制，而不受专利权的限制，所以一款药物在美国上市后三个月之后印度就能出来仿制药。","link":"/2018/07/15/%E7%94%9F%E6%B4%BB/%E6%9D%82%E6%96%87/%E6%88%91%E4%B8%8D%E6%98%AF%E8%8D%AF%E7%A5%9E/"},{"title":"说话","text":"为了履行之前的承诺，就要去执行 庆余年，三集看完其实没有明白这个名字的含义，只是陈道明饰演的皇帝好像叫庆帝，还有开头现代那段张若昀说的红楼梦那段好像有些关联，但是没太注意。 饰演童年时代的范闲那个小孩，初看时相貌平平淡淡，并没有产生喜欢的念头，后面他和费老师学解剖和下毒那段还是很机灵搞怪的，便又很讨人喜欢，不论在现实中还是在电视中古灵精怪的小孩很明显要比老实乖巧的要招人喜欢。古灵精怪的小孩脑洞灵活，不怕出丑，敢于试错，即使错了，也可以轻松自如的化解。老实乖巧的小孩脑筋也可能转动很快，但是不善于去表现出来，影响力不大，自然就不如古灵精怪的机会多，讨人喜欢。 离别是最令人伤心的吧，幼时范闲与若若青梅竹马，一起玩耍，若若被送往京城，和范闲离别，两个人或许自此便很难相见了，对两个幼小的心灵都是不小的打击。但是命运并不能自己掌控，只能听受安排，即便再过悲伤，也只能用时间来治愈。第二次离别是范闲与费老师，费老师不是一个死板的人，在教他学习的这段时间，两个人相处都是非常开心的，他教授了他成长，他给了他快乐，能遇见彼此，都是各自的幸运。第三次是范闲与奶奶的离别，长大了自然要飞出港湾，奶奶与他的关系并不是那种如胶似漆的疼爱，他们之间隔着一层薄纱，但是心里都是都是爱着对方，离别时，奶奶在屋里听见那声少爷，心里是有多激动，满脸都是惊喜，范闲亲了奶奶额头，在当时是不敬的，虽说奶奶嘴上说成何体统，但心里一定是乐开了花。我从来都不会去表达自己的爱，一切都隐与心底，在外面表现得又是那么冰冷，丝毫没有人情味，是不好意思，也是不会去表达，只得与外人关系越来越疏远，李绗那次和父母里面拥抱的画面对我就很震撼，完全没有料到，因为我从来都没有过如此举动，只有表现出来才能真切感受到彼此的温暖吧。","link":"/2019/11/30/%E7%94%9F%E6%B4%BB/%E6%9D%82%E6%96%87/191130/"},{"title":"梅西","text":"梅西，这个名字 初闻大概是大三那年巴西世界杯，同在宿舍观看世界杯的室友口中第一次听到梅西这个名字，由于此前并未关注过足球，至此，时至俄罗斯世界杯，对梅西的印象也只是踢球比较厉害，别的再无其它，甚至他所代表的国家也是在这次俄罗斯世界杯才得知的。端午假期正值世界杯开赛，有幸观看了阿根廷与冰岛的比赛，最终是1比1平，期间有个点球，是梅西主罚，但最终是被冰岛门将扑出。之后两天便是各种爆料，梅西点球被导演门将扑出的新闻。前两天阿根廷对阵克罗地亚 0：3 惨败，感觉怎么梅西不想传说中的那样。这两天对梅西有了进一步认识，今天又无意得知今天是你的生日，内心产生了一些共鸣。 祝你生日快乐！ 以下转自：https://kuaibao.qq.com/s/FTB2018062400947700 1987年6月24日，阿根廷圣菲胜罗萨里奥市，一个婴孩呱呱坠地。5年后他开始踢球，11年后被诊断患有侏儒症，13年后他用自己的足球天赋换来了治疗疾病的费用。从这一年开始，他的人生和足球彻底捆绑在了一起。然后，31年后的6月24日，2018年俄罗斯，31岁的他带着天之骄子的称号，带着潘帕斯雄鹰的骄傲，再次站在世界杯的舞台上了。里奥-梅西，生日快乐！ 如果我们试着去读懂梅西，就会发现这个总是背对全世界的瘦小男人其实超乎寻常的帅气。 身高170cm，没有发达的肌肉，可每当他瞪着小熊一般的圆眼睛发懵的时候，他微微蹙眉的时候，他咧嘴大笑的时候，却将“萌帅”演绎到了极致。 而剥去“萌帅”的外表，我们看到的则是他安静低调、害羞内敛的性格，是他唯爱与足球不可辜负的忠贞，是他数十年如一日从未崩塌的人设。 【若你喜欢怪人，其实我很美】 5岁开始踢球，11岁被诊断出侏儒症，家里治不起，母队纽维尔老伙计以及一度想要挖角的河床队在得知他的顽疾后都选择了放弃。也许要感谢当年他们的不救之恩，才有了后来的里奥-梅西。 2000年9月，年仅13岁身高只有140cm的梅西去了巴塞罗那青训营拉玛西亚试训。在试训期间，梅西用表现征服了巴萨青年队教练，也为自己赢得了治疗身体的靠山。 风扬起了他的黑发，他不经心地甩过鬓颊。无论是那个右路无限突破，能够复制马拉多纳当年连过五人进球的追风少年，还是转为中锋后疯狂进球的梅球王，耳边越来越嘈杂，他始终安静着。 不同于南美球星的独领风骚，更不像欧洲球星的霸气外露，我从没有见过像梅西这样“存在感极低”的前锋，过人摔倒了居然可以瞬间弹起来，他不擅长表演疼痛，他擅长继续带球。没有狂拽炫酷的进球庆祝动作，每当破门得分时，他只会傻傻的振臂狂奔，虔诚地双手指天。后来这个曾经旁人眼里有些怪异的“病孩子”站在了世界之巅，却仍然行事低调得不像个巨星。 像梅西这样的“怪人”，日本作家中岛敦在《山月记》中如是描述：因为害怕自己并非明珠而不敢刻苦琢磨，又因为有几分相信自己是明珠，而不能与瓦砾碌碌为伍，遂逐渐远离世间，疏避人群，结果在内心不断地用愤懑和羞怒饲育着自己懦弱的自尊心。世上每个人都是驯兽师，而那匹猛兽，就是每人各自的性情。 【你是南国来的孩子，人要爱人要恨的样子】 点球，对每个前锋来说是荣辱兼具的神秘大礼。而对梅西来说，点球留下的几乎全是不堪的回忆。自梅西出道以来，他一共踢了107个点球，踢丢了23次，得分率仅为76%。在国家队中，梅西21次点球踢丢4次。而在欧冠、西甲、国王杯等各条战线他均有点球不进的历史。他甚至在自己30岁时，才玩出了职业生涯第一个“勺子”点球。 2015年十月在北京鸟巢举行的南美超级杯上，梅西点球被巴西门将扑出，导致阿根廷最终落败。2012年欧冠半决赛对阵切尔西，在切尔西被罚下一人的情况下，梅西加时赛点球击中横梁，最终巴萨惨遭托雷斯绝杀。2016年美洲杯决赛，点球大战，梅西面对智利门将没能战胜濒临崩溃的心理防线一脚将球踢飞。 本届世界杯小组赛首轮，梅西左侧打门，一个质量不高的半高球被冰岛门将哈儿多松自信的扑救拒之门外……让人想起张悬那首《南国的孩子》 你是南国来的孩子 有着不能缚的性子 身上披覆了预言而浑然不知 奔跑着忘我的快乐悲伤都放肆 阳光也不愿阻止 球场上的梅西似乎更习惯于风驰电掣的突出重围，或是积极专注的组织进攻，而站上罚球点的梅西，只是一个走下神坛的凡人，所有人都能看到他的彷徨，焦虑，和无助。 五夺金球，四夺金靴，西甲、国王杯、欧冠、奥运会金牌，他在自己的职业生涯中已经做到了极致。如果还有什么遗憾，那便是身上的阿根廷球衣带给他的三个亚军了（2014巴西世界杯亚军、2015智利美洲杯亚军、2016美国美洲杯亚军）。但足球世界若注定要以一座世界杯来封王吗？ 你是南国来的孩子 人要爱人要恨的样子 血里流传着远在古老的故事 手心刻划上帝的仁慈 与未知相似 无论是C罗还是梅西，很多人都习惯在他们落败的时候摆出大评论家的姿态去指摘，但也许要不了几年，我们就快在球迷的口水之中迎来无巨星的足坛。如果无法欣赏，也请别再苛责，至少珍惜这个尚且还有巨星的时代。 【一生一世一双人，一红一蓝一颗魂】 关于梅西有多忠诚，安东内拉和巴塞罗那心里最有数。 有人说梅西最厉害的地方不是年度91球，也不是五座金球奖，而是9岁陪伴在他身边的女孩，30岁依然在。 去年，一向低调的梅西，却终于在爱情上任性了一回。请了足坛的半壁江山，把一场世纪婚礼献给他唯一挚爱的女人安东内拉。尽管婚礼豪华，但梅西执意不收份子钱，要给就捐给慈善机构。梅西的世纪婚礼，不为噱头，只因爱情。结婚那天他说，“我这一生最大的荣誉，是娶到了我喜欢了21年的女孩。” 九岁对她一见钟情，十二岁写了人生第一封情书，十八岁听说她闺蜜车祸身亡便立刻飞回阿根廷陪伴……他会在功成名就的时候打电话给她说，我还是当年那个喜欢踢球的害羞男孩，无论我得到多少荣誉，我还是那个喜欢你的里奥-梅西。对于安东内拉来说，和梅西在一起的这些年同样坎坷，梅西的低谷和巅峰，也是她陪他一起走过。 我爱你，你爱我，那就别管外面几双眼睛几只耳朵，请共我一起，放心探戈。 终老诺坎普？ Sí,quiero.（是的，我愿意。） 去年三十岁的梅西，不仅对安东内拉说，也对巴塞罗那说。 从2000年到如今，梅西送走了巴萨一代又一代的神锋，18年的不离不弃，还将延续。也许真的是性格使然，爱一个人要爱到天荒地老，着一身衫那就这样终老。对爱情，对足球，梅西身上都有一股近乎执拗的倔强。 深山的鹿，不知归处，万般皆苦，只可自渡。他射空过，也失落过，也许天才生来就是孤独，一身才华与满腔抱负也不过是无处安放。光阴荏苒，我们看到左岸身披红蓝衫的梅西站在制高点不断地刷新着荣誉，而右岸那个身披蓝白衫的梅西则总是垂头失意。 淡漠到失去热忱的时候他也许就会觉得自己老了，而某些瞬间，甚至无法描述那个瞬间，我们固执地相信他仍旧是当年那个羞涩的孩子。可当又一次与胜利擦肩的无力感席卷而来，梅西31岁了，我们只能任凭所有的执念无疾而终。或许，这正是我们爱他的原因。 小组赛末轮便是阿根廷的生死战，也许还有一个置之死地而后生的剧本等着我们去开启。他在用背影告诉我们：我不是天生强大，我只是天生要强。我没在慌，我已经是球王。 生日快乐，唯一的里奥-梅西。","link":"/2018/06/24/%E7%94%9F%E6%B4%BB/%E6%9D%82%E6%96%87/%E6%A2%85%E8%A5%BF/"},{"title":"说话","text":"看到你很独立，我心里最真实的想法就是很心疼。有时候刺猬比兔子，更渴望拥抱。 在这个世界上，让人不能自拔的，除了牙齿，就是爱情。 – https://tieba.baidu.com/p/5587556159","link":"/2018/07/14/%E7%94%9F%E6%B4%BB/%E6%9D%82%E6%96%87/%E8%AF%B4%E8%AF%9D/"},{"title":"蛙泳最后一堂课","text":"首先是很高兴总算是赶在了年前学习了游泳，因为之前从六月份就打算学的，当时和招生的老师沟通一下，她也不怎么上心，时常问了之后也没有回复，还有当时也快到了暑假，看她们课程安排主要是针对学生，都是十天一个周期，时间也排不开，最终也就搁置了，到了十月中旬发现她们在招生，就与她们又沟通了下，排课时间是每周末下午，感觉挺合适，就报名了，十一月第二周开始上的课。 ​ 今天是学习蛙泳的最后一节课，之前的节奏感觉都还好，从上一节，教练把浮带的气基本放完了，再游的时候，总是浮不起来，首先是腿开始下沉，慢慢整个人都开始下沉，手臂划水换气的时候，要很费劲才呼到一口空气，游两下，就呼不到空气了，只好憋住，赶紧向池边游。教练总跟说我蹬腿的时候要用力，按照教练说的稍微好些，但还是感觉总浮不起来，尤其是划完手换气的时候，整个人都下沉好深，然后用劲蹬腿，虽然会浮起来，下一次换气的时候，就又有沉了下去，来来回回，游不了几个回合就不行了，下午一直游到了五点，也还是没能找到感觉。只能等有时间再去练习了。 ​ 回来后看到两篇文章，蛙泳时，为什么换气后身体立马下沉到池底？ 和 初学蛙泳，身体往下沉浮不起来，怎么办？ 回想下之前的练习，可能原因，一是蹬夹水动作不到位 ，二是划手换气 不标准，三是缺乏整体的协调性 ，四是下沉的恐惧心里，有时间多看下别人的分享的经验和视频，有时间再去练习练习。","link":"/2018/12/15/%E7%94%9F%E6%B4%BB/%E6%B8%B8%E6%B3%B3/%E8%9B%99%E6%B3%B3%E6%9C%80%E5%90%8E%E4%B8%80%E5%A0%82%E8%AF%BE/"},{"title":"Spring-boot单元测试 简单使用","text":"一、引入单元测试 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&lt;/dependency&gt; 二、测试类示例 1、对Service测试2、对Controller测试 get请求 post请求123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181package com.baseinfo;import java.util.List;import org.junit.Before;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.http.MediaType;import org.springframework.mock.web.MockHttpServletRequest;import org.springframework.mock.web.MockHttpServletResponse;import org.springframework.mock.web.MockHttpSession;import org.springframework.test.context.junit4.SpringRunner;import org.springframework.test.web.servlet.MockMvc;import org.springframework.test.web.servlet.request.MockMvcRequestBuilders;import org.springframework.test.web.servlet.result.MockMvcResultHandlers;import org.springframework.test.web.servlet.result.MockMvcResultMatchers;import org.springframework.test.web.servlet.setup.MockMvcBuilders;import org.springframework.web.context.WebApplicationContext;import org.topcloud.modules.mongodb.dao.MongoDao;import org.topcloud.modules.sessioncookie.SessionCookieHelper;import org.topcloud.password.encoding.Md5PasswordEncoder;import com.cpnsp.api.ApiApplication;import com.cpnsp.model.SpUnit;import com.cpnsp.model.SpUser;import com.cpnsp.service.SpDataService;import com.testenroll.model.TeExaminee;@RunWith(SpringRunner.class)@SpringBootTest(classes = ApiApplication.class)public class BaseTest { @Autowired private WebApplicationContext wac; @Autowired private MockHttpServletRequest request; @Autowired private MockHttpServletResponse response; @Autowired private MockHttpSession session; @Autowired private SessionCookieHelper sessionCookieHelper; @Autowired private MongoDao mongoDao; @Autowired private SpDataService spDataService; private MockMvc mockMvc; @Before public void setup() { // this.mockMvc = MockMvcBuilders.standaloneSetup(new SpUnitController()).build(); mockMvc = MockMvcBuilders.webAppContextSetup(wac).build(); //初始化mockMvc对象 session = new MockHttpSession(); SpUser user = new SpUser(); user = mongoDao.findOneBy(SpUser.class, &quot;loginName&quot;, null, &quot;admin&quot;); // session.setAttribute(&quot;user&quot;, user); sessionCookieHelper.writeCookie(&quot;spu&quot;, user.getId().toString(), 60 * 60 * 24, request, response); } @Test public void findOneTest() { SpUser user = mongoDao.get(SpUser.class, 1); System.out.println(user.getLoginName()); } /** * service测试 */ @Test public void serviceTest() { List&lt;SpUnit&gt; units = spDataService.getUnitTreeData(&quot;1,&quot;); System.out.println(units.size()); } /** * 重置密码 */ @Test public void resetPasswd() { Md5PasswordEncoder passwordEncoder = new Md5PasswordEncoder(); String uid = &quot;60a70fa0aac64fbcb143fab5c6194df5&quot;; SpUser user = new SpUser(); user.setUid(uid); System.out.println(passwordEncoder.encodePassword(&quot;123456&quot;, user.getSalt())); TeExaminee examinee = new TeExaminee(); examinee.setUid(&quot;b854ab1cda634d0885b6275a4f8fafa7&quot;); System.out.println(passwordEncoder.encodePassword(&quot;123456&quot;, examinee.getSalt())); } /** * 登录接口测试 */ @Test public void httpLoginTest() { try { mockMvc.perform(MockMvcRequestBuilders.get(&quot;/admin/login/admin/123456&quot;, &quot;1&quot;)) .andExpect(MockMvcResultMatchers.status().isOk()) .andDo(MockMvcResultHandlers.print()) .andReturn(); } catch (Exception e) { e.printStackTrace(); } } /** * get方法请求测试 */ @Test public void httpGetTest() { try { mockMvc.perform(MockMvcRequestBuilders.get(&quot;/ws/canEnroll/{unitCode}&quot;, &quot;1&quot;)) .andExpect(MockMvcResultMatchers.status().isOk()) .andDo(MockMvcResultHandlers.print()) .andReturn(); } catch (Exception e) { e.printStackTrace(); } } /** * get方法带cookie请求测试 */ @Test public void httpGet_CookieTest() { try { mockMvc.perform(MockMvcRequestBuilders.get(&quot;/admin/getUnit/{unitUid}&quot;, &quot;8fd7979617cc40998c2ca3fa74dae7ab&quot;) .cookie(response.getCookies())) .andExpect(MockMvcResultMatchers.status().isOk()) .andDo(MockMvcResultHandlers.print()) .andReturn(); } catch (Exception e) { e.printStackTrace(); } } /** * post方法请求测试 * 接受参数为@RequestParam */ @Test public void httpPost_ParamTest() { try { // MockMvcRequestBuilders构建GET请求 String result = mockMvc.perform(MockMvcRequestBuilders.post(&quot;/ws/modifyPasswd&quot;) .cookie(response.getCookies()) .contentType(MediaType.APPLICATION_JSON_UTF8)// 请求编码和数据格式为json和UTF8 .param(&quot;oldPasswd&quot;, &quot;12345&quot;).param(&quot;newPasswd&quot;, &quot;123456&quot;))// 请求的参数，为json的格式 .andExpect(MockMvcResultMatchers.status().isOk()) // 期望的返回值 或者返回状态码 .andReturn().getResponse().getContentAsString(); // 返回请求的字符串信息 System.out.println(result); } catch (Exception e) { e.printStackTrace(); } } /** * post方法请求测试 * 接受参数为@RequestBody */ @Test public void httpPost_BodyTest() { try { String content = &quot;{\\&quot;code\\&quot;:\\&quot;111111\\&quot;,\\&quot;linkman\\&quot;:\\&quot;张三\\&quot;}&quot;; // MockMvcRequestBuilders构建GET请求 String result = mockMvc.perform(MockMvcRequestBuilders.post(&quot;/admin/saveUnit&quot;) .cookie(response.getCookies()) .contentType(MediaType.APPLICATION_JSON_UTF8)// 请求编码和数据格式为json和UTF8 .content(content))// 请求的参数，为json的格式 .andExpect(MockMvcResultMatchers.status().isOk())// 期望的返回值 或者返回状态码 .andReturn().getResponse().getContentAsString();// 返回请求的字符串信息 System.out.println(result); } catch (Exception e) { e.printStackTrace(); } }} 此篇只是简单对service、Controller测试，涉及对session、cookie的拦截的方法。其它具体 断言、事务、回滚暂未设涉及。待日后补充。","link":"/2018/05/17/java/Spring-Boot/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/Spring-boot%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/"},{"title":"操作字节数组ByteArrayInputStream与ByteArrayOutputStream","text":"内存操作流： 操作字节数组ByteArrayInputStream、ByteArrayOutputStream 操作字符流数组CharArrayReader、CharArrayWite 操作字符串StringReader、StringWriter ByteArrayInputStream、ByteArrayOutputStream用于操作字节数组的流对象。 ByteArrayInputStream:在构造的时候，需要接收数据源。而且数据源是一个字节数组。 ByteArrayOutputStream:在构造的时候，不用定义数据目的。因为该对象中已经封装了可变长度的字节数组。这就是数据目的地。 因为这两个流对象都操作数据，并没有使用系统资源。所以，不用进行close关闭。 在流操作规律讲解时：源设备： - 键盘 System.in, 硬盘 FileStream，内存 ArrayStream目的设备： - 控制台 System.out ，硬盘 FileStream，内存 ArrayStream 用流的读写思想来操作数组。 12345678910111213141516171819202122232425262728293031323334353637383940414243import java.io.*;class ByteArrayStream{ public static void main(String[] args) throws IOException{ //byteArrayOutputStream_1(); byteArrayInputStream_1(); } public static void byteArrayInputStream_1() throws IOException{ byte[] buf = &quot;ABCD\\n123&quot;.getBytes(); ByteArrayInputStream bais = new ByteArrayInputStream(buf); BufferedReader br = new BufferedReader(new InputStreamReader(bais));//转换为字符流 String str = null; while((str = br.readLine())!=null) { System.out.println(str); } br.close(); } public static void byteArrayOutputStream_1() throws IOException{ ByteArrayOutputStream baos = new ByteArrayOutputStream(); baos.write(&quot;abc&quot;.getBytes()); baos.writeTo(new FileOutputStream(&quot;F:\\\\logs\\\\baos.txt&quot;)); baos.reset(); System.out.println(baos.toString()); } public static void byteArray_1() throws IOException{ ByteArrayInputStream bis = new ByteArrayInputStream(&quot;ABCDEF&quot;.getBytes()); //数据目的 ByteArrayOutputStream bos = new ByteArrayOutputStream(); int by = 0; while((by = bis.read())!=-1){ bos.write(by); } System.out.println(bos.size()); System.out.println(bos.toString()); //bos.writeTo(new FileOutputStream(&quot;a.txt&quot;)); }}","link":"/2018/05/12/java/exercise/IO/ByteArrayStream/"},{"title":"操作基本数据类型DataInputStream与DataOutputStream","text":"DataInputStream、DataOutputStream可用于操作基本数据类型的流对象。 DataInputStream： 构造方法： DataInputStream(InputStream in) - int read(byte[] b) - int read(byte[] b, int off, int len) - int skipBytes(int n) //从输入流中跳过 n字节的数据 - boolean readBoolean() //读取一个输入字节 - byte readByte() //读取并返回一个输入字节。 - int readUnsignedByte() //读取一个输入字节，将其扩展到类型 int ，并返回结果，因此在 0到 255 。 - int readUnsignedShort() //读取两个输入字节，并返回 0到 65535的 int值。 - short readShort() //读取两个输入字节并返回一个 short值。 - char readChar() //读取两个输入字节并返回一个 char值。 - int readInt() //读取四个输入字节并返回一个 int值。 - long readLong() //读取八个输入字节并返回一个 long值。 - float readFloat() //读取四个输入字节并返回一个 float值。 - double readDouble() //读取八个输入字节并返回一个 double值。 - String readUTF() //读取已使用 修改版 UTF-8格式编码的字符串。DataOutputStream 将原始Java数据类型写入输出流。 然后应用程序可以使用数据输入流来读取数据。 构造方法： DataOutputStream(OutputStream out) 常用方法： void flush() 刷新此数据输出流。 void write(int b)将指定的字节b的低8位 写入底层输出流。 void write(byte[] b, int off,int len) void writeBoolean(boolean v)将布尔值以1字节，写入底层输出流。 void writeByte(int v)将byte以1字节，写入底层输出流。 void writeShort(int v)将short以2字节，写入底层输出流。 void writeChar(int v)将char以2字节，写入底层输出流。 void writeInt(int v)将int以4字节，写入底层输出流。 void writeLong(long v)将long以8字节，写入底层输出流。 void writeFloat(float v)将float以4字节，写入底层输出流。 void writeDouble(double v)将double以4字节，写入底层输出流。 void writeBytes(String s)将字符串作为字节序列写入基础输出流。 void writeChars(String s)将字符串作为一系列字符写入底层输出流。 void writeUTF(String str)使用修改版UTF-8编码将字符串写入基础输出流。 int size()返回计数器的当前值written ，到目前为止写入此数据输出流的字节数。 12345678910111213141516171819202122232425262728293031323334353637383940414243import java.io.*;class DataStreamDemo{ public static void main(String[] args)throws IOException{ //writeData(); //readData(); //writeUTFDemo(); //readUTFDemo(); writeUTF2(); } public static void writeUTF2()throws IOException{ OutputStreamWriter osw = new OutputStreamWriter(new FileOutputStream(&quot;utf.txt&quot;),&quot;utf-8&quot;); osw.write(&quot;你好&quot;); osw.close(); } public static void readUTFDemo()throws IOException{ DataInputStream dis = new DataInputStream(new FileInputStream(&quot;utfdata.txt&quot;)); String s = dis.readUTF(); System.out.println(s); dis.close(); } public static void writeUTFDemo()throws IOException{ DataOutputStream dos = new DataOutputStream(new FileOutputStream(&quot;utfdata.txt&quot;)); dos.writeUTF(&quot;你好&quot;); dos.close(); } public static void readData()throws IOException{ DataInputStream dis = new DataInputStream(new FileInputStream(&quot;dos.txt&quot;)); int num = dis.readInt(); boolean b = dis.readBoolean(); double d =dis.readDouble(); System.out.println(&quot;num=&quot;+num); System.out.println(&quot;b=&quot;+b); System.out.println(&quot;d=&quot;+d); dis.close(); } public static void writeData()throws IOException{ DataOutputStream dos = new DataOutputStream(new FileOutputStream(&quot;dos.txt&quot;)); dos.writeInt(23); dos.writeBoolean(true); dos.writeDouble(45.65); dos.close(); }}","link":"/2018/05/12/java/exercise/IO/DataStreamDemo/"},{"title":"编码与解码","text":"编码：字符串变成字节数组。 解码：字节数组变成字符串。 String–&gt;byte[]; str.getBytes(); str.getBytes(charsetName); byte[]–&gt;String; new String(byte[]); new String(byte[],charsetName) 12345678910111213141516import java.util.*;class EncodeDemo{ public static void main(String[] args) throws Exception{ String s = &quot;你好&quot;; byte[] b1 = s.getBytes(&quot;GBK&quot;); System.out.println(Arrays.toString(b1)); String s1 = new String(b1,&quot;ISO8859-1&quot;); System.out.println(s1); //对s1进行iso8859-1编码。 byte[] b2 = s1.getBytes(&quot;ISO8859-1&quot;); System.out.println(Arrays.toString(b2)); String s2 = new String(b2,&quot;GBK&quot;); System.out.println(s2); }}","link":"/2018/05/12/java/exercise/IO/EncodeDemo/"},{"title":"解码——”联通“","text":"字符串”联通“ 二进制数和UTF-8编码表规律形同记事本软件解码，查编码表时，会从UTF-8编码表中查，而没有在GBK编码表中查，所以会造成乱码现象。 123456789class EncodeDemo2{ public static void main(String[] args) throws Exception{ String s = &quot;联通&quot;; byte[] by = s.getBytes(&quot;gbk&quot;); for(byte b : by) //System.out.println(b); System.out.println(Integer.toBinaryString(b&amp;255)); }}","link":"/2018/05/12/java/exercise/IO/EncodeDemo2/"},{"title":"编码_转换流InputStreamReader与OutputStreamWriter","text":"转换流 字节流通向字符流的桥梁，可以指定字符编码表。InputStreamReader、OutputStreamWriter 常见的编码表： - ASCII：美国标准信息交换码。 用一个字节的7位可以表示。 - ISO8859-1：拉丁码表。欧洲码表 用一个字节的8位表示。 - GBK2312:中国的中文编码表。 - GBK:中国的中文编码表升级。 用两个字节表示，且每个字节的最高位为1。所以数字就为负数。 - Unicode：国际标准码，融合了多种文字。 所有的文字都用两个字节来表示，java语言使用的就是unicode。 - UTF-8：最多用三个字节来表示一个字符。 … 中文一个文字在GBK码表中由2个字节。 在UTF-8码表中由3个字节。 InputStreamReader：构造方法： InputStreamReader(InputStream in) 创建一个使用默认字符集的InputStreamReader。 InputStreamReader(InputStream in, String charsetName) 创建一个使用指定命名字符集的InputStreamReader。 常用方法： String getEncoding() 返回此流使用的字符编码的名称。 int read() 读一个字符 int read(char[] cbuf, int offset, int length) 将字符读入数组的一部分。 boolean ready() 返回此流是否准备好被读取。 void close() 关闭流。 OutputStreamWriter：构造方法： OutputStreamWriter(OutputStream out) 创建一个使用默认字符集的OutputStreamWriter。 OutputStreamWriter(OutputStream out, String charsetName) 创建一个使用指定命名字符集的OutputStreamWriter。常用方法： String getEncoding() 返回此流使用的字符编码的名称。 void write(int c) 写一个字符 void write(char[] cbuf, int off, int len) 写入字符数组的一部分。 void write(String str, int off, int len) 写一个字符串的一部分。 void flush() 刷新流。 void close() 关闭流，先刷新。1234567891011121314151617181920import java.io.*;class EncodeStream{ public static void main(String[] args) throws IOException{ //writeText(); readText(); } public static void readText() throws IOException{ InputStreamReader isr = new InputStreamReader(new FileInputStream(&quot;utf.txt&quot;),&quot;GBK&quot;); char[] buf = new char[10]; int len = isr.read(buf); String s = new String(buf,0,len); System.out.println(s); } public static void writeText() throws IOException{ OutputStreamWriter osw = new OutputStreamWriter(new FileOutputStream(&quot;utf.txt&quot;),&quot;utf-8&quot;); osw.write(&quot;你好&quot;); osw.close(); }}","link":"/2018/05/12/java/exercise/IO/EncodeStream/"},{"title":"File对象","text":"File类常见方法：1、创建。 - boolean createNewFile();在指定的位置创建文件，如果该文件已经存在，则不创建，返回false。 和输出流不一样，输出流对象一建立就创建文件。如果文件已经存在，会覆盖。 - boolean mkdir();创建文件夹。 - boolean mkdirs();创建多级文件夹。 2、删除。 - boolean delete();删除失败返回false。 - void deleteOnExit();在程序退出时删除指定文件。3、判断。 - boolean exists();文件是否存在。 - boolean isFile();是否是文件。 - boolean isDirectory();是否是目录。 - boolean isAbsolute();是否是绝对路径。4、获取信息。 - getName(); - getPath(); - getParent(); - getAbsolutePath(); - long lastModified(); - long length()File 构造方法： public File(String pathname) 通过将指定的路径名字符串转换为抽象路径名来创建新的File实例。 public File(String parent, String child) 从父路径名字符串和子路径名字符串创建新的File实例。 public File(File parent, String child) 从父抽象路径名和子路径名字符串创建新的File实例。 public File(URI uri) 通过将给定的file: URI转换为抽象路径名来创建新的File实例。方法： String getName() 返回由此抽象路径名表示的文件或目录的名称。 String getParent() 返回此抽象路径名的父路径名字符串. File getParentFile() 返回此抽象路径名的父抽象路径名。 String getPath() 将此抽象路径名转换为路径名字符串。 boolean isAbsolute() 判断这个抽象路径名是否是绝对的。 String getAbsolutePath() 返回此抽象路径名的绝对路径名字符串。 File getAbsoluteFile() 返回此抽象路径名的绝对形式。 String getCanonicalPath() 返回此抽象路径名的规范路径名字符串。 File getCanonicalFile() 返回此抽象路径名的规范形式。 URI toURI() 构造一个表示此抽象路径名的file: URI。 boolean canRead() 判断文件是否可读。 boolean canWrite() 判断文件是否可写。 boolean exists() 测试此抽象路径名表示的文件或目录是否存在。 boolean isDirectory() 测试此抽象路径名表示的文件是否为目录。 boolean isFile() 测试此抽象路径名表示的文件是否为普通文件。 long lastModified() 返回此抽象路径名表示的文件上次修改的时间。 long length() 返回由此抽象路径名表示的文件的长度。 boolean createNewFile() 当且仅当具有该名称的文件尚不存在时，原子地创建一个由该抽象路径名命名的新的空文件。 boolean delete() 删除由此抽象路径名表示的文件或目录。如果此路径名表示目录，则目录必须为空才能删除。 void deleteOnExit() 在虚拟机终止时删除由此抽象路径名表示的文件或目录。 String[] list() 返回一个字符串数组，命名由此抽象路径名表示的目录中的文件和目录。 String[] list(FilenameFilter filter) 返回一个字符串数组，命名由此抽象路径名表示的目录中满足指定过滤器的文件和目录。 File[] listFiles() 返回一个抽象路径名数组，表示由该抽象路径名表示的目录中的文件。 File[] listFiles(FilenameFilter filter) 返回一个抽象路径名数组，表示由此抽象路径名表示的满足指定过滤器的目录中的文件和目录。 File[] listFiles(FileFilter filter) 返回一个抽象路径名数组，表示由此抽象路径名表示的满足指定过滤器的目录中的文件和目录。 boolean mkdir() 创建由此抽象路径名命名的目录。 public boolean mkdirs() 创建由此抽象路径名命名的目录，包括不存在的父目录。 boolean renameTo(File dest) 重命名由此抽象路径名表示的文件。 boolean setLastModified(long time) 设置由此抽象路径名命名的文件或目录的最后修改时间。 boolean setReadOnly() 设置由此抽象路径名命名的文件或目录，以便只允许读取操作。 boolean setWritable(boolean writable, boolean ownerOnly)设置此抽象路径名的所有者或每个人的写入权限。 boolean setWritable(boolean writable) 设置所有者对此抽象路径名的写入权限。 boolean setReadable(boolean readable, boolean ownerOnly) 设置此抽象路径名的所有者或每个人的读取权限。 boolean setReadable(boolean readable) 设置所有者对此抽象路径名的读取权限。 boolean setExecutable(boolean executable, boolean ownerOnly) 设置该抽象路径名的所有者或每个人的执行权限。 boolean setExecutable(boolean executable) 设置所有者的执行权限。 boolean canExecute() 判断文件是否可以执行。 File[] listRoots() 列出可用的文件系统根。 long getTotalSpace() 通过此抽象路径名返回分区的大小。 long getFreeSpace() 返回分区未分配的字节数。 long getUsableSpace() 返回的可用字节数. File createTempFile(String prefix,String suffix, File directory) 在指定的目录中创建一个新的空文件，使用给定的前缀和后缀字符串生成其名称。 File createTempFile(String prefix, String suffix) 在默认临时文件目录中创建一个空文件，使用给定的前缀和后缀生成其名称。 int compareTo(File pathname) 比较两个抽象的路径名字典。 该方法定义的顺序取决于底层系统。 boolean equals(Object obj) 测试此抽象路径名与给定对象的相等性。 int hashCode() 计算此抽象路径名的哈希码。 String toString() 返回此抽象路径名的路径名字符串。 Path toPath() 返回从该抽象路径构造的java.nio.file.Path对象。 12345678910111213141516import java.io.*;class FileDemo{ public static void main (String[] args) throws IOException{ method_1(); } public static void method_1() throws IOException{ File f = new File(&quot;file.txt&quot;); f.deleteOnExit(); System.out.println(&quot;create : &quot; + f.createNewFile()); if(1==1){ throw new RuntimeException(); } System.out.println(&quot;delete : &quot; + f.delete()); }}","link":"/2018/04/30/java/exercise/IO/FileDemo/"},{"title":"File练习-文件过滤","text":"文件过滤FilenameFilter： 实现此接口的类的实例用于过滤文件名。 boolean accept(File dir, String name) 判断指定文件是否应包含在文件列表中。 FileFilter：抽象路径名的过滤器。 boolean accept(File pathname) 判断指定的抽象路径名是否应包含在路径名列表中。 1234567891011121314151617181920212223242526272829303132333435363738394041import java.io.*;class FileDemo2{ public static void main(String[] args){ listDemo3(); } public static void listDemo3(){ File dir = new File(&quot;c:\\\\&quot;); File[] files = dir.listFiles(); for(File file : files){ System.out.println(&quot;name: &quot;+file.getName()+&quot;---length: &quot;+ file.length()); } } //过滤文件名 public static void listDemo2(){ File dir = new File(&quot;d:\\\\test&quot;); String[] arr = dir.list(new FilenameFilter(){ public boolean accept(File dir, String name){ return name.endsWith(&quot;.java&quot;); } }); for(String name :arr){ System.out.println(name); } } public static void listDemo(){ File dir = new File(&quot;c:\\\\&quot;); String[] names = dir.list();//调用list方法的file对象必须是封装了一个目录。该目录还必须存在。 for(String name : names){ System.out.println(name); } } //列出可用的文件系统根。 public static void listRootDemo(){ File[] files = File.listRoots(); for(File file : files){ System.out.println(file); } }}","link":"/2018/04/30/java/exercise/IO/FileDemo2/"},{"title":"File练习-列出目录结构","text":"123456789101112131415161718192021222324import java.io.*;class FileDemo3{ public static void main(String[] args){ showDir(new File(&quot;D:\\\\test&quot;),0); } public static String getLevel(int level){ StringBuilder sb = new StringBuilder(); for(int x= 0;x&lt;level;x++){ sb.append(&quot;|--&quot;); } return sb.toString(); } public static void showDir(File dir,int level){ System.out.println(getLevel(level)+dir); level++; File[] files = dir.listFiles(); for(int i = 0; i&lt;files.length;i++){ if(files[i].isDirectory()) showDir(files[i],level); else System.out.println(getLevel(level)+files[i]); } }}","link":"/2018/04/30/java/exercise/IO/FileDemo3/"},{"title":"File练习-过滤存储","text":"练习 将一个指定文件夹下的java文件的绝对路径，存储到一个文件中。 思路： 1、对指定的目录进行递归。 2、获取递归过程所有的java文件路径。 3、将这些路径存储到集合中。 4、将集合中的数据写入到一个文件中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import java.io.*;import java.util.*;class JavaFileList{ public static void main(String[] args) throws IOException{ File dir = new File(&quot;d:\\\\test&quot;); List&lt;File&gt; files = new ArrayList&lt;File&gt;(); fileToList(dir,files); System.out.println(files.size()); File javaListFile = new File(dir,&quot;javaListFile.txt&quot;); writeToFile(files,javaListFile.toString()); } public static void fileToList(File dir, List&lt;File&gt; list){ File[] files = dir.listFiles(); for(File file : files){ if(file.isDirectory()) fileToList(file,list); else{ if(file.getName().endsWith(&quot;.java&quot;)) list.add(file); } } } public static void writeToFile(List&lt;File&gt; list, String javaListFile) throws IOException{ BufferedWriter buwr = null; try{ buwr = new BufferedWriter(new FileWriter(javaListFile)); for(File file : list){ String path = file.getAbsolutePath(); buwr.write(path); buwr.newLine(); buwr.flush(); } }catch(IOException e){ throw e; }finally{ try{ if(buwr!=null){ buwr.close(); } }catch(IOException e){ System.out.println(&quot;关闭流异常&quot;); } } }}","link":"/2018/04/30/java/exercise/IO/JavaFileList/"},{"title":"LineNumberReader","text":"LineNumberReader: 继承自BufferedReader 可以缓冲字符输入流，并且可以设置和获取行号。 LineNumberReader(Reader in) 使用默认的输入缓冲区大小创建该对象。 LineNumberReader(Reader in, int sz) 使用指定大小的输入缓冲区大小创建该对象。 void setLineNumber(int lineNumber) 设置当前行号。 int getLineNumber() 获取当前行号。 int read() 读一个字符。 int read(char[] cbuf, int off, int len) 将字符读入数组的一部分。 String readLine() 读一行文字。 long skip(long n) 跳过字符 。 void mark(int readAheadLimit) 标记流中的当前位置。 void reset() 将流重新设置为最近的标记。 LineNumberInputStream: 已弃用 1234567891011121314151617181920 import java.io.FileReader; import java.io.IOException; import java.io.LineNumberReader; public class LineNumberReaderDemo { public static void main(String[] args) throws IOException{ lineNumberReader_1(); //InputStream is = LineNumberReaderDemo.class.getResourceAsStream(&quot;urls.txt&quot;); } public static void lineNumberReader_1() throws IOException{ LineNumberReader lnrd = new LineNumberReader(new FileReader(&quot;F:\\\\logs\\\\urls.txt&quot;)); lnrd.setLineNumber(10); String str =null; while((str= lnrd.readLine())!=null) { System.out.println(lnrd.getLineNumber() + &quot;: &quot; + str); } lnrd.close(); }}","link":"/2018/05/24/java/exercise/IO/LineNumberReaderDemo/"},{"title":"对象序列化ObjectInputStream与ObjectOutputStream","text":"对象操作流ObjectOutputStream 序列化流，向输出流中写入序列化的对象。ObjectInputStream 反序列化流，从流中读取对象。 可以操作基本数据类型或实现序列化接口的对象。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778import java.io.*;class ObjectStreamDemo{ public static void main(String[] args) throws Exception{ //readObj(); //writeObj(); //objectOutputStream_1(); objectInputStream_1(); } public static void objectInputStream_1() throws Exception{ FileInputStream fis = new FileInputStream(new File(&quot;F:\\\\logs\\\\oos.log&quot;)); ObjectInputStream ois = new ObjectInputStream(fis); boolean b = ois.readBoolean(); double d = ois.readDouble(); String str = ois.readUTF(); Object obj = ois.readObject(); Student student = (Student)ois.readObject(); System.out.println(b); System.out.println(d); System.out.println(str); System.out.println(obj); System.out.println(student.toString()); ois.close(); fis.close(); } public static void objectOutputStream_1() throws IOException{ FileOutputStream fos = new FileOutputStream(&quot;F:\\\\logs\\\\oos.log&quot;); ObjectOutputStream oos = new ObjectOutputStream(fos); oos.writeBoolean(true); oos.writeDouble(1.23); oos.writeUTF(&quot;中文&quot;); oos.writeObject(new Date()); oos.writeObject(new Student(1, &quot;张三&quot;, 20)); oos.close(); fos.close(); } public static void readObj() throws Exception{ ObjectInputStream ois = new ObjectInputStream(new FileInputStream(&quot;student.object&quot;)); Student s = (Student)ois.readObject(); System.out.println(s); ois.close(); } public static void writeObj() throws IOException{ ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(&quot;student.object&quot;)); oos.writeObject(new Student(2,&quot;zhangsan&quot;,12)); oos.close(); }}class Student implements Serializable{ public static final long serialVersionUID = 42L; private Integer id; private String name; private Integer age; private transient String address; public Student(){ } public Student(Integer id,String name,Integer age){ this.id = id; this.name = name; this.age = age; } Student(String name, int age,String country){ this.name = name; this.age = age; this.country = country; } @Override public String toString() { return &quot;Student [id=&quot; + id + &quot;, name=&quot; + name + &quot;, address=&quot; + address + &quot;]&quot;; }} 如果对象需要被持久化，那么对象所属的类必须要实现Serializable接口。 Serializable接口没有任何的方法，是一个标识接口而已。 对象的反序列化创建对象的时候并不会调用到构造方法。 serialVersionUID 是用于记录class文件的版本信息的，serialVersionUID这个数字是通过一个类的类名、成员、包名、工程名算出的一个数字。 使用ObjectInputStream反序列化的时候，ObjeectInputStream会先读取文件中的serialVersionUID，然后与本地的class文件的serialVersionUID进行对比，如果这两个id不一致，反序列则失败。 如果序列化与反序列化的时候可能会修改类的成员，那么最好一开始就给这个类指定一个serialVersionUID，如果一类已经指定的serialVersionUID，然后在序列化与反序列化的时候，jvm都不会再自己算这个 class的serialVersionUID了。 如果一个对象某个字段不想被序列化到硬盘上，可以使用关键字transient修饰。 如果一个类维护了另外一个类的引用，则另外一个类也需要实现Serializable接口。","link":"/2018/05/01/java/exercise/IO/ObjectStreamDemo/"},{"title":"管道流对象PipedInputStream","text":"管道流对象PipedInputStream、PipedOutputStream可以让多线程通过管道进行线程间的通讯。管道的输入输出是通过一个循环缓冲数组实现，这个数组默认大小1024字节，输入流PipedInputStream从这个缓冲数组中读数据，输出流PipedOutputStream向这个循环数组中写入数据。当这个缓冲数组首次为空的时候，输入流PipedInputStream所在的线程将会堵塞；当这个缓冲数组已满时，输出流PipedOutputStream所在的线程将会堵塞。 不要再单个线程使用这两个对象，因为它可能会使线程死锁。 PipedInputStream：构造方法： PipedInputStream() 创建一个 PipedInputStream 对象。尚未 connected。 PipedInputStream(int pipeSize) 创建一个 PipedInputStream ，尚未 connected ，并使用指定的管道大小作为管道的缓冲区。 PipedInputStream(PipedOutputStream src) 创建一个 PipedInputStream ，使其连接到管道输出流 src 。 PipedInputStream(PipedOutputStream src, int pipeSize) 创建一个 PipedInputStream ，使其连接到管道输出流 src ，并为管道缓冲区使用指定的管道大小。 void connect(PipedOutputStream src) 使此管道输入流连接到管道输出流src 。 如果此对象已连接到其他管道输出流，则抛出IOException 。 void receive(int b) 接收一个字节的数据。 如果没有输入可用，此方法将阻止。 int read() 从这个管道输入流读取数据的下一个字节。 int read(byte[] b, int off, int len) 从这个管道输入流读取len字节的数据到字节数组。 int available() 返回可以从该输入流读取而不阻塞的字节数。 void close() 关闭此管道输入流。 void write(byte[] b, int off, int len) 从指定的字节数组写入len字节。 void flush() 刷新此输出流并强制任何缓冲的输出字节被写出。 void close() 关闭此管道输出流。 PipedOutputStream：构造方法： PipedOutputStream() 创建一个尚未连接到管道输入流的管道输出流。 PipedOutputStream(PipedInputStream snk) 创建连接到指定管道输入流的管道输出流。 void connect(PipedInputStream snk) 将此管道输出流连接到输入流。 void write(int b) 写入指定byte到管道输出流。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import java.io.*;class Read implements Runnable{ private PipedInputStream in; Read(PipedInputStream in){ this.in = in; } public void run(){ try{ byte[] buf = new byte[1024]; System.out.println(&quot;读取前没有数据，就堵塞。&quot;); int len = in.read(buf); System.out.println(&quot;读到数据，堵塞结束。&quot;); String s = new String(buf,0,len); System.out.println(s); in.close(); }catch(IOException e){ throw new RuntimeException(&quot;读取管道流异常！&quot;); } }}class Write implements Runnable{ private PipedOutputStream out; Write(PipedOutputStream out){ this.out = out; } public void run(){ try{ System.out.println(&quot;开始写入数据，等待六秒后。&quot;); Thread.sleep(6000); out.write(&quot;gandaoliushuju ...&quot;.getBytes()); out.close(); }catch(Exception e){ throw new RuntimeException(&quot;输出管道流异常！&quot;); } }}class PipedStreamDemo{ public static void main(String[] args) throws Exception{ PipedInputStream in = new PipedInputStream(); PipedOutputStream out = new PipedOutputStream(); in.connect(out); Read r = new Read(in); Write w = new Write(out); new Thread(r).start(); new Thread(w).start(); }}","link":"/2018/05/01/java/exercise/IO/PipedStreamDemo/"},{"title":"打印流PrintWriter与PrintStream","text":"打印流：该流提供了打印方法，可以将各种数据类型的数据都原样打印。 字节打印流：PrintStream构造函数可以接收的参数类型。1、file对象。File PrintStream(File file) 使用指定的文件创建一个新的打印流。 PrintStream(File file, String csn) 使用指定的文件和字符集创建新的打印流。2、字符串路径。String PrintStream(String fileName) 使用指定的文件名创建PrintStream。 PrintStream(String fileName, String csn) 使用指定的文件名、字符集创建PrintStream。3、字节输出流。OutputStream PrintStream(OutputStream out) 将OutputStream作为PrintStream的输出流，不会自动flush PrintStream(OutputStream out, boolean autoFlush) 将OutputStream作为PrintStream的输出流，指定是否自动flush。 PrintStream(OutputStream out, boolean autoFlush, String encoding) 将OutputStream作为PrintStream的输出流，指定是否自动flush，并指定字符集。 方法： void flush() 刷新流。 void close() 关闭流。 boolean checkError() 刷新流并检查其错误状态。 void setError() 将流的错误状态设置为true 。 void clearError() 清除此流的内部错误状态。 void write(int b) 将指定的字节写入此流。 void write(byte[] buf, int off, int len) 从指定的字节数组写入len字节。 void print(boolean b) 打印布尔值。 void print(char c) 打印一个字符。 void print(int i) 打印一个整数。 void print(long l) 打印一个长整数。 void print(float f) 打印双精度浮点数。 void print(char[] s) 打印字符数组。 void print(String s) 打印字符串。 void print(Object obj) 打印一个对象。 void println() 写入行分隔符进行换行。 void println(boolean x) 打印一个布尔值，然后换行。… PrintStream printf(String format, Object… args) 使用指定的格式字符串和参数将格式化的字符串写入此输出流。 PrintStream format(String format, Object… args) 使用指定的格式字符串和参数将格式化的字符串写入此输出流。 PrintStream append(char c) 将指定的字符附加到此输出流。 字符输出流PrintWriter构造函数可以接收的参数类型。1、file对象。File PrintWriter(File file) 使用指定的文件创建一个新的打印流。 PrintWriter(File file, String csn) 使用指定的文件和字符集创建一个新的PrintWriter。2、字符串路径。String PrintWriter(String fileName) 使用指定的文件名创建PrintWriter。 PrintWriter(String fileName, String csn) 使用指定的文件名和字符集创建一个新的PrintWriter。3、字节输出流。OutputStream PrintWriter(OutputStream out) 将OutputStream作为PrintWriter的输出流，不会自动flush。 PrintWriter(OutputStream out, boolean autoFlush) 将OutputStream作为PrintWriter的输出流，指定是否自动flush。4、字符输出流。Writer PrintWriter(Writer out) PrintWriter(Writer out, boolean autoFlush) 12345678910111213141516171819import java.io.*;class PrintWriterDemo{ public static void main(String[] args) throws IOException{ BufferedReader bufr = new BufferedReader(new InputStreamReader(System.in)); //PrintWriter out = new PrintWriter(System.out,true); PrintWriter out = new PrintWriter(new FileWriter(&quot;a.txt&quot;),true); String line = null; while((line=bufr.readLine())!=null){ if(&quot;over&quot;.equals(line)) break; out.println(line.toUpperCase()); //out.flush(); } out.close(); bufr.close(); }}","link":"/2018/05/01/java/exercise/IO/PrintWriterDemo/"},{"title":"Properties对象","text":"Properties是hashTable的子类也就是说它具备map集合的特点。而且它里面存储的键值对都是字符串。 是集合中和IO技术相结合的集合容器。 该对象的特点：可以用于键值对形势的配置文件。 那么在加载数据时，需要数据有固定的格式：键=值 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import java.io.*;import java.util.*;class PropertiesDemo{ public static void main(String[] args)throws IOException{ loadDemo(); } public static void loadDemo()throws IOException{ FileInputStream fis = new FileInputStream(&quot;info.txt&quot;); Properties prop = new Properties(); prop.load(fis); prop.setProperty(&quot;wangwu&quot;,&quot;34&quot;); FileOutputStream fos = new FileOutputStream(&quot;info.txt&quot;); prop.store(fos,&quot;zhushi&quot;); //System.out.println(prop); prop.list(System.out); fos.close(); fis.close(); } public static void menthod_1()throws IOException{ BufferedReader bufr = new BufferedReader(new FileReader(&quot;info.txt&quot;)); String line = null; Properties prop = new Properties(); while((line=bufr.readLine())!=null){ String[] arry = line.split(&quot;=&quot;); prop.setProperty(arry[0],arry[1]); } System.out.println(prop); bufr.close(); } public static void setAndGet(){ Properties pro = new Properties(); pro.setProperty(&quot;zhangsan&quot;,&quot;12&quot;); pro.setProperty(&quot;lisi&quot;,&quot;56&quot;); System.out.println(pro); String value = pro.getProperty(&quot;lisi&quot;); System.out.println(value); pro.setProperty(&quot;lisi&quot;,&quot;89&quot;); Set&lt;String&gt; names = pro.stringPropertyNames(); for(String s : names){ System.out.println(s+&quot;:&quot;+pro.getProperty(s)); } }}","link":"/2018/04/30/java/exercise/IO/PropertiesDemo/"},{"title":"随机访问流对象RandomAccessFile","text":"RandomAccessFile可以指定文件中任何一个位置去操作一个文件。 该类不是IO体系中的子类。而是直接继承自object。 但是它是IO包中的成员。因为它具备读和写的功能。内部封装了一个数组，而且通过指针对数组的元素进行操作。可以通过getFilePointer获取指针位置。同时可以通过seek改变指针的位置。 该类完成读写的原理就是内部封装了字节输入流和输出流。 通过构造函数可以看出，该类只能操作文件。而且操作文件还有模式：只读r，读写rw等。 如果文件模式为只读 r。不会创建文件，会去读取一个已存在的文件，如果文件不存在，则会出现异常。如果模式为rw，那么要操作的文件不存在，会自动创建，如果存在则不会覆盖。 构造函数： RandomAccessFile(String name, String mode) 创建RandomAccessFile文件流，从中指定名称的文件读取，并指定操作文件模式。 RandomAccessFile(File file, String mode) 创建RandomAccessFile文件流，以File参数指定名文件，并指定操作文件模式。 常用方法： - int read() - int read(byte[] b, int off, int len) - int read(byte[] b) 从该文件读取最多b.length个字节的数据到字节数组。 - void readFully(byte[] b) 从此文件读取b.length字节到字节数组。 - int skipBytes(int n) 跳过n字节的输入。 - void write(int b) 将指定的字节写入此文件。 - void write(byte[] b) 将 b.length字节从指定的字节数组写入此文件。 - void write(byte[] b, int off, int len) - long getFilePointer() 返回此文件中的当前偏移量。 - void seek(long pos) 设置文件指针偏移。 - long length() 返回此文件的长度。 - void setLength(long newLength) 设置此文件的长度。 - void close() 关闭流。 - boolean readBoolean() 从此文件中读取一个boolean ，单个字节。 … - String readLine() 从此文件中读取下一行文本。 - String readUTF() 从该文件读取字符串，以修改版UTF-8格式编码。 - void writeBoolean(boolean v) 将boolean作为一个字节值写入文件。 … - void writeUTF(String str) 以修改版UTF-8格式编码写入文件。 12345678910111213141516171819202122232425262728293031323334import java.io.*;class RandomAccessFileDemo{ public static void main(String[] args) throws IOException{ //writeFile(); readFile(); } public static void readFile() throws IOException{ RandomAccessFile raf = new RandomAccessFile(&quot;ran.txt&quot;,&quot;r&quot;); //调整对象中的指针。 raf.seek(8*1); //跳过指定的字节数 //raf.skipBytes(8); byte[] buf = new byte[4]; raf.read(buf); String name = new String(buf); int age = raf.readInt(); System.out.println(&quot;name:&quot;+name); System.out.println(&quot;age:&quot;+age); } public static void writeFile() throws IOException{ RandomAccessFile raf = new RandomAccessFile(&quot;ran.txt&quot;,&quot;rw&quot;); raf.write(&quot;李四&quot;.getBytes()); raf.writeInt(97); raf.write(&quot;王五&quot;.getBytes()); raf.writeInt(99); raf.close(); }}","link":"/2018/05/01/java/exercise/IO/RandomAccessFileDemo/"},{"title":"合并流SequenceInputStream","text":"SequenceInputStream将多个流对象进行逻辑串联，合并变成一个流对象。 构造方法： SequenceInputStream(Enumeration&lt;? extends InputStream&gt; e) 传入枚举参数Enumeration的输入流，来创建的SequenceInputStream ，枚举产生的输入流将按顺序读取。 SequenceInputStream(InputStream s1, InputStream s2) 传入两个输入流对象，来创建的SequenceInputStream ，这两个参数将按顺序读取。 常用方法： - int read() - int read(byte[] b, int off, int len) - void close() - int available() 示例： 12345678910111213141516171819202122232425262728293031323334353637import java.io.*;import java.util.*;class SequenceDemo{ public static void main(String[] args) throws IOException{ Vector&lt;FileInputStream&gt; v = new Vector&lt;FileInputStream&gt;(); v.add(new FileInputStream(&quot;1.txt&quot;)); v.add(new FileInputStream(&quot;2.txt&quot;)); v.add(new FileInputStream(&quot;3.txt&quot;)); Enumeration&lt;FileInputStream&gt; en = v.elements(); SequenceInputStream sis =new SequenceInputStream(en); FileOutputStream fos = new FileOutputStream(&quot;4.txt&quot;); byte[] buf = new byte[1024]; int len=0; while((len=sis.read(buf))!=-1){ fos.write(buf,0,len); } fos.close(); sis.close(); } public static void sequenceInputStream_1() throws IOException{ List&lt;FileInputStream&gt; list = new ArrayList&lt;&gt;(); list.add(new FileInputStream(&quot;F:\\\\logs\\\\osw.txt&quot;)); list.add(new FileInputStream(&quot;F:\\\\logs\\\\urls.txt&quot;)); FileOutputStream fos = new FileOutputStream(&quot;F:\\\\logs\\\\sis.txt&quot;); Enumeration&lt;FileInputStream&gt; enume = Collections.enumeration(list); SequenceInputStream sis = new SequenceInputStream(enume); BufferedInputStream bis = new BufferedInputStream(sis); byte[] buf = new byte[1024]; int len = 0; while((len= bis.read(buf))!=-1) { fos.write(buf, 0, len); } bis.close(); fos.close(); }}","link":"/2018/05/01/java/exercise/IO/SequenceDemo/"},{"title":"切割、合并文件","text":"示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import java.io.*;import java.util.*;class SplitFile{ public static void main(String[] args) throws IOException{ //spitFile(); mergFile(); } public static void mergFile() throws IOException{ ArrayList&lt;FileInputStream&gt; list = new ArrayList&lt;FileInputStream&gt;(); for(int i = 1;i&lt;=3;i++){ list.add(new FileInputStream(i+&quot;.part&quot;)); } Iterator&lt;FileInputStream&gt; it = list.iterator(); Enumeration&lt;FileInputStream&gt; en = new Enumeration&lt;FileInputStream&gt;(){ public boolean hasMoreElements(){ return it.hasNext(); } public FileInputStream nextElement(){ return it.next(); } }; SequenceInputStream sis = new SequenceInputStream(en); FileOutputStream fos = new FileOutputStream(&quot;001.jpg&quot;); byte[] buf = new byte[1024]; int len = 0; while((len=sis.read(buf))!=-1){ fos.write(buf,0,len); } sis.close(); fos.close(); } public static void spitFile() throws IOException{ FileInputStream fis = new FileInputStream(&quot;000.jpg&quot;); FileOutputStream fos = null; byte[] buf = new byte[1024*40]; int len = 0; int count = 1; while ((len=fis.read(buf))!=-1){ fos = new FileOutputStream((count++)+&quot;.part&quot;); fos.write(buf,0,len); fos.close(); } fis.close(); }}","link":"/2018/05/01/java/exercise/IO/SplitFile/"},{"title":"IO综合练习","text":"有五个学生，每个学生有三门课的成绩，从键盘输入以上数据（包含姓名，三门课成绩），输入的格式，如：zhangsan，30，40，60计算出总成绩，并把学生的信息和计算出的总分数按高低顺序存放在磁盘文件”stud.txt“中。 1、描述学生对象。2、定义一个可操作学生对象的工具类。 思想：1、通过键盘录入数据，2、因为学生有多个，需要存储，使用到集合。因为要对学生的总分排序。 所以可以使用TreeSet.3、将集合的信息写入到文件中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import java.io.*;import java.util.*;class Student implements Comparable&lt;Student&gt;{ private String name; private int ma,cn,en; private int sum; Student(String name,int ma,int cn,int en){ this.name= name; this.ma = ma; this.cn = cn; this.en = en; this.sum = ma+cn+en; } public String getName(){ return name; } public int getSum(){ return sum; } public int compareTo(Student stu){ int num = new Integer(this.sum).compareTo(new Integer(stu.getSum())); if(num==0) return this.name.compareTo(stu.getName()); return num; } public int hashCode(){ return name.hashCode() + sum*46; } public boolean equals(Object obj){ if(!(obj instanceof Student)){ throw new ClassCastException(&quot;类型转换异常!&quot;); } Student s = (Student)obj; return this.name.equals(s.getName()); } public String toString(){ return &quot;Student[name:&quot;+this.name+&quot; ma:&quot;+this.ma+&quot; cn:&quot;+this.cn+&quot; en:&quot;+this.en+&quot; sum&quot;+this.sum+&quot;]&quot;; }}class StudentTool{ public static Set&lt;Student&gt; getStudents()throws IOException{ return getStudents(null); } public static Set&lt;Student&gt; getStudents(Comparator&lt;Student&gt; compar) throws IOException{ BufferedReader bufr = new BufferedReader(new InputStreamReader(System.in)); Set&lt;Student&gt; stus = null; if(compar==null){ stus = new TreeSet&lt;Student&gt;(); } stus = new TreeSet&lt;Student&gt;(compar); String line = null; while((line = bufr.readLine())!=null){ if(&quot;over&quot;.equals(line)) break; String[] s = line.split(&quot;,&quot;); Student stu = new Student(s[0],Integer.parseInt(s[1]),Integer.parseInt(s[2]),Integer.parseInt(s[3])); stus.add(stu); } bufr.close(); return stus; } public static void writeToFile(Set&lt;Student&gt; students) throws IOException{ BufferedWriter bufw = new BufferedWriter(new FileWriter(&quot;StudentInfo.txt&quot;)); for(Student s : students){ bufw.write(s.toString()+&quot;\\t&quot;); bufw.write(s.getSum()+&quot;&quot;); bufw.newLine(); bufw.flush(); } bufw.close(); }}class StudentInfoTest{ public static void main(String[] args) throws IOException{ Comparator&lt;Student&gt; compar = Collections.reverseOrder(); Set&lt;Student&gt; stus = StudentTool.getStudents(compar); StudentTool.writeToFile(stus); }}","link":"/2018/05/12/java/exercise/IO/StudentInfoTest/"},{"title":"ArrayList","text":"ArrayList 继承自 AbstractList底层的数据结构使用的是数组结构。特点：查询速度很快，但是增删稍慢。线程不同步。 ArrayList其实内部维护了一个一维数组。每次创建 ArrayList 对象，内部的数组引用都会指向一个长度为0的数组常量。初次扩容后，集合容量为10.之后每次扩容都会扩张到原来的 1.5倍。扩容就是新建一个更大的数组对象，然后利用 System.arraycopy() 复制旧数组中的数据。ArrayList 和数组一样，获取数据很快速，但是插入删除会很慢。插入删除操作也是利用 System.arraycopy（）来实现数据的移动的。ArrayList 中 SubList 是 ArrayList 中的一个视图，修改 SubList ，ArrayList 中的数据也会改变。若创建了 SubList 后修改了 ArrayList ，再次调用前面创建的 SubList 的实例，会触发 fail-fast机制的发生。 fail-fast机制 构造方法： ArrayList() 创建一个默认初始容量为10的空列表。 ArrayList(int initialCapacity) 创建具有指定初始容量的空列表。 ArrayList(Collection&lt;? extends E&gt; c) 创建一个包含指定集合的元素的列表。 主要方法： boolean add(E e) 将指定的元素追加到此列表的末尾。 E get(int index) 返回此列表中指定位置的元素。 set(int index, E element) 用指定的元素替换此列表中指定位置的元素。 void add(int index, E element) 将指定的元素插入此列表中的指定位置。后面元素进行后移。 E remove(int index) 删除该列表中指定位置的元素。后面元素进行左移。 int indexOf(Object o) 返回此列表中指定元素的第一次出现的索引，如果此列表不包含元素，则返回-1。 int lastIndexOf(Object o) 返回此列表中指定元素的最后一次出现的索引，如果此列表不包含元素，则返回-1。 void clear() 从此列表中删除所有元素。 boolean addAll(int index, Collection&lt;? extends E&gt; c) 将指定集合中的所有元素插入到此列表中的指定位置。 Iterator iterator() 以正确的顺序返回该列表中的元素的迭代器。 ListIterator listIterator() 返回列表中的列表迭代器。 ListIterator listIterator(int index) 从列表中的指定位置开始，返回列表中的元素的列表迭代器。 List subList(int fromIndex, int toIndex) 返回指定的fromIndex （含）和toIndex之间的列表部分的视图。 void removeRange(int fromIndex, int toIndex) 从此列表中删除所有索引为fromIndex （含）和toIndex之间的元素。 遍历：1、迭代器(Iterator和ListIterator)2、for循环。3、foreach。 12345678910111213141516171819202122232425262728public static void arrayList_1() { ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) { list.add(i); } //Iterator Iterator&lt;Integer&gt; iterator = list.iterator(); while (iterator.hasNext()) { System.out.print(iterator.next()); } //ListIterator ListIterator&lt;Integer&gt; lit = list.listIterator(); while (lit.hasNext()) { System.out.print(lit.next()); } //for for (int i = 0; i &lt; list.size(); i++) { System.out.print(list.get(i)); } //foreach for(Integer i : list) { System.out.print(i); } } 第二种普通for循环遍历效率最高。","link":"/2018/05/30/java/exercise/util/ArrayList/"},{"title":"HashMap","text":"HashMap继承自 AbstractMap&lt;K,V&gt; ，实现了Map接口，底层数据结构是哈希表 。HashMap是数组+链表+红黑树（JDK1.8增加了红黑树部分）实现。 特点：元素是无序的，允许null 值和 null 键，元素（key）不会重复，线程不同步。 构造方法： HashMap() 构造一个空的 HashMap ，默认初始容量（16）和默认负载因子（0.75）。 HashMap(int initialCapacity) 构造一个空的 HashMap ，具有指定的初始容量和默认负载系数（0.75）。 HashMap(int initialCapacity, float loadFactor) 构造一个空的 HashMap, 具有指定的初始容量和负载因子。 public HashMap(Map&lt;? extends K,? extends V&gt; m) 构造一个新的HashMap与指定的相同的映射Map 。 HashMap的实例有两个影响其性能的参数: 初始容量和负载因子。 容量是哈希表中的桶数，初始容量是创建哈希表时的容量。 负载因子是在容量自动增加之前允许哈希表得到满足的度量。 当在哈希表中的条目的数量超过了负载因数和当前容量的乘积，哈希表被重新散列 （即，内部数据结构被重建），使得哈希表具有桶的大约两倍。 主要方法： Iterator iterator() 返回此集合中元素的迭代器。 元素没有特定的顺序。 int size() 返回此Map集合中键值映射的数量。 boolean isEmpty() 判断Map集合是否包含键值映射。 V get(Object key) 返回指定键所映射的值，如果键不存在，返回null。 boolean containsKey(Object key) 判断Map集合中是否包含指定键的映射。 V put(K key, V value) 将指定的值与此映射中的指定键相关联。 如果Map集合中已包含了该键的映射，则替换旧值。 void putAll(Map&lt;? extends K,? extends V&gt; m) 将指定Map集合的所有映射复制到此Map集合中。 V remove(Object key) 从该Map集合中删除指定键的映射（如果存在）。 void clear() 从Map集合中删除所有的映射。 boolean containsValue(Object value) 如果此Map集合中有一个或多个键映射到指定的值，则返回 true 。 Set keySet() 返回此Map集合中包含的键的Set视图。该Set视图支持经由Iterator.remove，Set.remove，removeAll，retainAll和clear操作。 它不支持add或addAll操作。 Collection values() 返回此Map集合中包含的值的Collection视图。该Collection视图支持经由Iterator.remove，Collection.remove，removeAll，retainAll和clear操作。 它不支持add或addAll操作。 Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() 返回此Map集合中包含的映射关系的Set视图。该Set视图支持经由Iterator.remove，Set.remove，removeAll，retainAll和clear操作。 它不支持add或addAll操作。 V getOrDefault(Object key, V defaultValue) 返回指定键所映射的值，或 defaultValue。 V putIfAbsent(K key, V value) 如果指定的键尚未与某个值相关联（或映射到 null ），则将其与给定值相关联并返回 null ，否则返回当前值。 boolean remove(Object key, Object value) 仅当指定的键当前映射到指定的值时删除该条目。 boolean replace(K key, V oldValue, V newValue) 仅当当前映射到指定的值时，才替换指定键的条目。 V replace(K key, V value) 只有当目标映射到某个值时，才能替换指定键的条目。如果没有键的映射， 返回null 。 V computeIfAbsent(K key, Function&lt;? super K,? extends V&gt; mappingFunction) 遍历：1、entrySet2、ketset3、values 123456789101112131415161718192021222324252627282930public static void byEntrySet(HashMap&lt;String, String&gt; map) { Set&lt;Entry&lt;String, String&gt;&gt; entrySet = map.entrySet(); for (Iterator&lt;Entry&lt;String, String&gt;&gt; it = entrySet.iterator(); it.hasNext();) { Entry&lt;String, String&gt; entry = it.next(); String key = entry.getKey(); String value = entry.getValue(); }}public static void byKeySet(HashMap&lt;String, String&gt; map) { Set&lt;String&gt; ketset = map.keySet(); //foreach for (Iterator&lt;String&gt; it = ketset.iterator(); it.hasNext();) { String key = it.next(); String value = map.get(key); } //while Iterator&lt;String&gt; it = ketset.iterator(); while (it.hasNext()) { String key = it.next(); String value = map.get(key); }}public static void byValues(HashMap&lt;String, String&gt; map) { Collection&lt;String&gt; col = map.values(); for (Iterator&lt;String&gt; it = col.iterator(); it.hasNext();) { String value = it.next(); }} HashMap使用key的hashCode()和equals()方法来将值划分到不同的桶里，随着HashMap中元素的数量越来越多，发生碰撞的概率就越来越大，所产生的链表长度就会越来越长 。 当 HashMap 中有大量的key都映射到同一个桶中时，这个桶下有一条长长的链表，这个时候 HashMap 就相当于一个单链表，假如单链表有 n 个元素，遍历的时间复杂度就是 O(n)，完全失去了它的优势。 JDK1.8之前HashMap的实现是 数组+链表，即使哈希函数取得再好，也很难达到元素百分百均匀分布。 JDK 1.8 中引入了红黑树（查找时间复杂度为 O(logn)）优化了这个问题。 HashMap 中关于红黑树的三个关键参数：参考 一个桶的树化阈值 一个树的链表还原阈值 哈希表的最小树形化容量 TREEIFY_THRESHOLD UNTREEIFY_THRESHOLD MIN_TREEIFY_CAPACITY static final int TREEIFY_THRESHOLD = 8; static final int UNTREEIFY_THRESHOLD = 6; static final int MIN_TREEIFY_CAPACITY = 64; 当桶中元素个数超过这个值时需要使用红黑树节点替换链表节点 当扩容时，桶中元素个数小于这个值就会把树形的桶元素 还原（切分）为链表结构 当哈希表中的容量大于这个值时，表中的桶才能进行树形化 否则桶内元素太多时会扩容，而不是树形化 为了避免进行扩容、树形化选择的冲突，这个值不能小于 4 * TREEIFY_THRESHOLD","link":"/2018/06/20/java/exercise/util/HashMap/"},{"title":"HashMap与Hashtable","text":"Hashtable与HashMap的几个不同点： 不同点 HashMap Hashtable 键与值 允许一个key为null和任意个value为null 不允许key和value为null 数据结构 数组+链表+红黑树 数组+链表 继承的类 AbstractMap&lt;K,V&gt; Dictionary&lt;K,V&gt; 是否线程安全 否 是 性能 高 底 默认初始化容量 16 11 扩容方式 原始容量x2 原始容量x2 + 1 底层数组的容量为2的整数次幂 要求一定为2的整数次幂 不要求 确认key在数组中的索引的方法 i = (n - 1) &amp; hash; index = (hash &amp; 0x7FFFFFFF) % tab.length; 遍历方式 Iterator(迭代器) Iterator(迭代器)和Enumeration(枚举) Iterator遍历数组顺序 索引从小到大 索引从大到小 Hashtable已不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。","link":"/2018/06/23/java/exercise/util/HashMap%E4%B8%8EHashtable/"},{"title":"HashSet","text":"HashSet继承自 AbstractSet ，实现了Set接口，底层数据结构是哈希表，实际是基于HashMap来实现的，而且只使用了HashMap的key来实现各种特性 。 特点：元素是无序的，允许元素为null，元素不可以重复，线程不同步。 保证元素惟一性的原理：判断元素的HashCode值是否相同。 如果元素的HashCode值相同，会继续判断equals是否为true。 如果元素的HashCode值不同，不会调用equals。 注意: 对于判断元素是否存在，以及删除等操作，依赖的方法是元素HashCode和equals方法。 对于HashSet中保存的对象，请注意正确重写其equals和hashCode方法，以保证放入的对象的唯一性。 构造方法： HashSet() 构造一个新的空集合; 底层实际会初始化一个空的HashMap实例，并具有默认初始容量16和加载因子0.75。 HashSet(Collection&lt;? extends E&gt; c) 构造一个包含指定集合中的元素的新集合。 底层使用默认加载因子0.75和足以包含指定集合中的元素的初始容量来创建一个HashMap。 HashSet(int initialCapacity, float loadFactor) 构造一个新的空集合; 底层使用指定的初始容量和指定的负载因子创建一个HashMap实例。 HashSet(int initialCapacity) 构造一个新的空集合; 底层使用指定的初始容量和默认负载因子0.75创建一个HashMap实例。 主要方法： Iterator iterator() 返回此集合中元素的迭代器。 元素没有特定的顺序。 int size() 返回此集合中的元素数。 boolean isEmpty() 判断集合是否包含元素。 boolean contains(Object o) 判断此集合是否包含指定的元素 。 boolean add(E e) 将指定的元素添加到此集合（如果尚未存在）。 boolean remove(Object o) 从该集合中删除指定的元素，如果集合包含这个元素，则返回true。 void clear() 删除集合中所有元素。 遍历：1、foreach2、迭代器（Iterator） 1234567891011121314151617181920212223242526272829303132import java.util.HashSet;import java.util.Iterator;public class HashSetDemo { public static void main(String[] args) { HashSet&lt;Integer&gt; set = new HashSet&lt;Integer&gt;(); for (int i = 0; i &lt; 1000000; i++) { set.add(i); } byForeach(set); byIterator(set); } public static void byForeach(HashSet&lt;Integer&gt; set) { long start = System.currentTimeMillis(); for (Integer integer : set) { ; } long end = System.currentTimeMillis(); System.out.println(\"foreach遍历消耗时间为：\" + (end - start) + \"ms\"); } public static void byIterator(HashSet&lt;Integer&gt; set) { long start = System.currentTimeMillis(); for (Iterator&lt;Integer&gt; it = set.iterator(); it.hasNext();) { it.next(); } long end = System.currentTimeMillis(); System.out.println(\"iterator遍历消耗时间为：\" + (end - start) + \"ms\"); }} 输出： 12foreach遍历消耗时间为：23msiterator遍历消耗时间为：17ms","link":"/2018/06/10/java/exercise/util/HashSet/"},{"title":"Hashtable","text":"Hashtable继承自 Dictionary&lt;K,V&gt;，实现了Map接口，底层数据结构是哈希表。 特点：元素是无序的，不允许null 值和null 键，元素（key）不会重复，线程是同步的。 注意: 对于作为键的对象必须实现hashCode方法和equals方法，以保证 key 的唯一性。 如果不需要线程安全的实现，建议使用HashMap代替Hashtable。 构造方法： Hashtable() 构造一个空的Hashtable，默认初始容量（11）和负载因子（0.75）。 Hashtable(int initialCapacity) 构造一个空的Hashtable，具有指定的初始容量和默认负载因子（0.75）。 Hashtable(int initialCapacity, float loadFactor) 构造一个空的Hashtable，具有指定的初始容量和指定的负载因子。 Hashtable(Map&lt;? extends K,? extends V&gt; t) 构造一个与给定Map相同的映射的新Hashtable。 主要方法： int size() 返回此集合中的键的数量。 boolean isEmpty() 判断这个集合中是否有元素。 Enumeration keys() 返回此集合中键的枚举。 Enumeration elements() 返回此集合中值的枚举。 boolean contains(Object value) 判断是否有键映射到哈希表中的指定值。同下containsValue 。 boolean containsValue(Object value) 判断是否有键映射到哈希表中的指定值，同上contains 。 boolean containsKey(Object key) 判断集合中是否包含指定键的映射。 V get(Object key) 返回指定键所映射的值，如果不包含该键的映射，返回null。 V put(K key, V value) 将指定的key映射到此指定的value。 key和value都不能是null 。 V remove(Object key) 从此集合中删除键（及其对应的值）。 void putAll(Map&lt;? extends K,? extends V&gt; t) 将所有从指定Map的映射复制到此Hashtable中。 void clear() 清除集合中所有元素。 Set keySet() 返回此Map集合中包含的键的Set视图。该Set视图支持经由Iterator.remove，Set.remove，removeAll，retainAll和clear操作。 它不支持add或addAll操作。 Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() 返回此Map集合中包含的映射关系的Set视图。该Set视图支持经由Iterator.remove，Set.remove，removeAll，retainAll和clear操作。 它不支持add或addAll操作。 Collection values() 返回此Map集合中包含的值的Collection视图。该Collection视图支持经由Iterator.remove，Collection.remove，removeAll，retainAll和clear操作。 它不支持add或addAll操作。 V getOrDefault(Object key, V defaultValue) 返回指定键所映射的值，或 defaultValue。 boolean remove(Object key, Object value) 仅当指定的键当前映射到指定的值时删除该条目。 boolean replace(K key, V oldValue, V newValue) 仅当当前映射到指定的值时，才替换指定键的条目。 V replace(K key, V value) 只有当目标映射到某个值时，才能替换指定键的条目。如果没有键的映射， 返回null 。 遍历：1、Iterator ​ keySet() ​ entrySet() 2、Enumeration ​ keys() ​ elements() 1234567891011121314151617181920212223242526public static void byKeySet(Hashtable&lt;String, Integer&gt; hashtable) { for(Iterator&lt;String&gt; iterator = hashtable.keySet().iterator();iterator.hasNext();) { String key = iterator.next(); Integer value = hashtable.get(key); }}public static void byEntrySet(Hashtable&lt;String, Integer&gt; hashtable) { Set&lt;Entry&lt;String, Integer&gt;&gt; set = hashtable.entrySet(); for(Iterator&lt;Entry&lt;String, Integer&gt;&gt; iterator = set.iterator();iterator.hasNext();) { Entry&lt;String, Integer&gt; entry = iterator.next(); String key = entry.getKey(); Integer value = entry.getValue(); }}public static void byEnumeration_key(Hashtable&lt;String, Integer&gt; hashtable) { Enumeration&lt;String&gt; enumeration = hashtable.keys(); while (enumeration.hasMoreElements()) { String value = (String) enumeration.nextElement(); }}public static void byEnumeration_value(Hashtable&lt;String, Integer&gt; hashtable) { Enumeration&lt;Integer&gt; enumeration = hashtable.elements(); while (enumeration.hasMoreElements()) { Integer value = (Integer) enumeration.nextElement(); }}","link":"/2018/06/23/java/exercise/util/Hashtable/"},{"title":"LinkedList","text":"LinkedList继承自AbstractSequentialList 底层数据结构是双向链表。 关于链表，链表是一种线性的存储结构，意思是将要存储的数据存在一个存储单元里面，这个存储单元里面除了存放有待存储的数据以外，还存储有其下一个存储单元的地址（有些存储结构还存放其前一个存储单元的地址，如：LinkedList） ，每次查找数据的时候，通过某个存储单元中的下一个存储单元的地址寻找其后面的那个存储单元。 关于双向链表，即链表中任一存储单元都可通过向前或向后寻址的方式获取到其前一个和后一个存储单元。链表的尾节点的后一个存储单元是链表的头节点，链表的头结点的前一个存储单元是链表的尾节点。 LinkedList的基本存储单元 ： 123456private static class Entry&lt;E&gt; { E element; Entry&lt;E&gt; next; Entry&lt;E&gt; previous; ...} 它是LinkedList中的一个内部类 。 特点： 插入和删除操作很快，只需要修改前后指针。 访问速度比较慢。 元素是有序的，允许元素为null，元素可以重复，线程不同步。 构造方法： LinkedList() 构造一个空列表。 LinkedList(Collection&lt;? extends E&gt; c) 构造一个包含指定集合的元素的列表。 主要方法： E getFirst() 返回此列表中的第一个元素，如果列表为空则发生NoSuchElementException 异常。 E getLast() 返回此列表中的最后一个元素，如果列表为空则发生NoSuchElementException 异常。 E removeFirst() 从此列表中删除并返回第一个元素，如果列表为空则发生NoSuchElementException 异常。 E removeLast() 从此列表中删除并返回最后一个元素，如果列表为空则发生NoSuchElementException 异常。 void addFirst(E e) 在该列表开头插入指定的元素。 void addLast(E e) 将指定的元素追加到此列表的末尾。 boolean contains(Object o) 判断此列表是否包含指定的元素，包含则返回true 。 int size() 返回此列表中的元素数。 boolean add(E e) 将指定的元素追加到此列表的末尾。 boolean remove(Object o) 从列表中删除第一个出现的指定的元素，如果存在返回true。 boolean addAll(Collection&lt;? extends E&gt; c) 按照指定集合的迭代器返回的顺序将指定集合中的所有元素追加到此列表的末尾。 boolean addAll(int index, Collection&lt;? extends E&gt; c) 将指定集合中的所有元素从指定的位置开始插入到此列表中，后面元素进行后移。 void clear() 从列表中删除所有元素。 E get(int index) 返回此列表中指定位置的元素。 E set(int index, E element) 用指定的元素替换此列表中指定位置的元素。 void add(int index, E element) 在列表中的指定位置插入指定的元素。后面元素进行后移。 E remove(int index) 删除该列表中指定位置的元素。后面元素进行前移。 int indexOf(Object o) 返回此列表中指定元素的第一次出现的索引，如果此列表不包含元素，则返回-1。 int lastIndexOf(Object o) 返回此列表中指定元素的最后一次出现的索引，如果此列表不包含元素，则返回-1。 E peek() 检索但不删除此列表的第一个元素，如果列表为空则返回null。 E element() 检索但不删除此列表的第一个元素，如果列表为空则发生NoSuchElementException 异常。 E poll() 检索并删除此列表的第一个元素，如果列表为空则返回null。 E remove() 检索并删除此列表的第一个元素，如果列表为空则发生NoSuchElementException 异常。 boolean offer(E e) 将指定的元素添加为此列表的尾部。 JDK1.6新增 boolean offerFirst(E e) 在列表的前面插入指定的元素。 boolean offerLast(E e) 在列表的末尾插入指定的元素。 E peekFirst() 检索但不删除此列表的第一个元素，如果此列表为空，则返回 null 。 E peekLast() 检索但不删除此列表的最后一个元素，如果此列表为空，则返回 null 。 E pollFirst() 检索并删除此列表的第一个元素，如果此列表为空，则返回 null 。 E pollLast() 检索并删除此列表的最后一个元素，如果此列表为空，则返回 null 。 void push(E e) 在该列表的前面插入元素，此方法相当于addFirst(E) 。 E pop() 删除并返回此列表的第一个元素，如果列表为空则发生NoSuchElementException 异常。此方法相当于removeFirst() 。 boolean removeFirstOccurrence(Object o) 删除此列表中从头到尾遍历列表时第一个出现的指定元素。如果列表包含指定的元素，则返回true； 如果列表不包含该元素，则集合不会更改，且返回false。 boolean removeLastOccurrence(Object o) 删除此列表中从头到尾遍历列表时最后一次出现的指定元素。如果列表包含指定的元素，则返回true； 如果列表不包含该元素，则集合不会更改，且返回false。 ListIterator listIterator(int index) 从列表中的指定位置开始，返回此列表中元素的列表迭代器。 Iterator descendingIterator() 以相反的顺序返回此deque中的元素的迭代器。 元素将从最后（尾）到第一（头）的顺序返回。 Object[] toArray() 以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组。 T[] toArray(T[] a) 以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组; 返回的数组的运行时类型是指定数组的运行时类型。 LinkedList实现了Deque接口，而Deque接口定义了在双端队列两端访问元素的方法。提供插入、移除和获取元素的方法。每种方法都存在两种形式：一种形式在操作失败时抛出异常，另一种形式返回一个特殊值（null 或 false，具体取决于操作）。 总结起来如下： 第一个元素（头部） 最后一个元素（尾部） 插入 boolean add(E e) boolean offerFirst(E e) boolean addLast(e) booleanofferLast(e) 抛出异常 返回特殊值 抛出异常 返回特殊值 删除 E removeFirst() E pollFirst() E removeLast() E pollFirst() 查询 E getFirst() E peekFirst() E getLast() E peekLast() 而Deque接口，扩展了Queue接口，LinkedList便可以作为FIFO(先进先出)的队列使用，作为FIFO的队列时 ，下面的方法是等价的： 队列方法 等效方法 boolean add(E e) void addLast(E e) boolean offer(E e) boolean offerLast(E e) boolean remove(Object o) E removeFirst() E poll() E pollFirst() E element() E getFirst() E peek() E peekFirst() Deques也可以用作LIFO（后进先出）堆栈。LinkedList便可以作为LIFO(后进先出)的栈，作为LIFO的栈时，下面的方法是等价的： 栈方法 等效方法 void push(E e) void addFirst(E e) E pop() E removeFirst() E peek() E peekFirst() 遍历：1、for循环(随机访问) 2、foreach 3、迭代器iterator 。 4、pollFirst()遍历 。 5、pollLast()遍历。 6、removeFirst()遍历。 7、removeLast()遍历。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798import java.util.Iterator;import java.util.LinkedList;import java.util.ListIterator;import java.util.NoSuchElementException;public class LinkedListDemo { public static void main(String[] args) { LinkedList&lt;Integer&gt; list = new LinkedList&lt;Integer&gt;(); for(int i = 0;i&lt;100000;i++) { list.add(i); } byFor(list); byForeach(list); byIterator(list); byListIterator(list); byPollFirst(list); byPollLast(list); byRemoveFirst(list); byRemoveLast(list); } public static void byFor(LinkedList&lt;Integer&gt; list) { long start = System.currentTimeMillis(); for (int i = 0; i &lt; list.size(); i++) { list.get(i); } long end = System.currentTimeMillis(); System.out.println(\"for循环遍历消耗时间为：\"+(end - start)+\"ms\"); } public static void byForeach(LinkedList&lt;Integer&gt; list) { long start = System.currentTimeMillis(); for (Integer integer : list) { ; } long end = System.currentTimeMillis(); System.out.println(\"foreach遍历消耗时间为：\"+(end - start)+\"ms\"); } public static void byIterator(LinkedList&lt;Integer&gt; list) { long start = System.currentTimeMillis(); for (Iterator&lt;Integer&gt; it = list.iterator(); it.hasNext();) { it.next(); } long end = System.currentTimeMillis(); System.out.println(\"Iterator遍历消耗时间为：\"+(end - start)+\"ms\"); } public static void byListIterator(LinkedList&lt;Integer&gt; list) { long start = System.currentTimeMillis(); for (ListIterator&lt;Integer&gt; it = list.listIterator(); it.hasNext();) { it.next(); } long end = System.currentTimeMillis(); System.out.println(\"ListIterator遍历消耗时间为：\"+(end - start)+\"ms\"); } public static void byPollFirst(LinkedList&lt;Integer&gt; list) { long start = System.currentTimeMillis(); while (list.pollFirst()!=null) { ; } long end = System.currentTimeMillis(); System.out.println(\"pollFirst遍历消耗时间为：\"+(end - start)+\"ms\"); } public static void byPollLast(LinkedList&lt;Integer&gt; list) { long start = System.currentTimeMillis(); while (list.pollLast()!=null) { ; } long end = System.currentTimeMillis(); System.out.println(\"pollLast遍历消耗时间为：\"+(end - start)+\"ms\"); } public static void byRemoveFirst(LinkedList&lt;Integer&gt; list) { long start = System.currentTimeMillis(); try { while (list.removeFirst()!=null) { ; } } catch (NoSuchElementException e) { } long end = System.currentTimeMillis(); System.out.println(\"removeFirst遍历消耗时间为：\"+(end - start)+\"ms\"); } public static void byRemoveLast(LinkedList&lt;Integer&gt; list) { long start = System.currentTimeMillis(); try { while (list.removeLast()!=null) { ; } } catch (NoSuchElementException e) { } long end = System.currentTimeMillis(); System.out.println(\"removeLast遍历消耗时间为：\"+(end - start)+\"ms\"); }} 输出： 12345678for循环遍历消耗时间为：5754msforeach遍历消耗时间为：13msIterator遍历消耗时间为：12msListIterator遍历消耗时间为：12mspollFirst遍历消耗时间为：7mspollLast遍历消耗时间为：0msremoveFirst遍历消耗时间为：0msremoveLast遍历消耗时间为：0ms 结论: 在遍历LinkedList时，使用removeFist()或removeLast()效率最高。但用它们遍历时，会删除原始数据，集合为空时会抛出NoSuchElementException异常；若单纯只读取，而不删除，LinkedList遍历时建议使用For-each或者迭代器的方式。千万不要通过随机访问去遍历LinkedList！","link":"/2018/06/09/java/exercise/util/LinkedList/"},{"title":"TreeMap","text":"TreeMap继承自 AbstractMap&lt;K,V&gt; ，底层数据结构是红黑树。 特点：元素是有序的，key不允许为null ，value可以为null ，key不会重复，线程不同步。 保证元素惟一性的原理：判断元素的HashCode值是否相同。 如果元素的HashCode值相同，会继续判断equals是否为true。 如果元素的HashCode值不同，不会调用equals。 注意: 对于判断元素是否存在，以及删除等操作，依赖的方法是元素HashCode和equals方法。 对于HashSet中保存的对象，请注意正确重写其equals和hashCode方法，以保证放入的对象的唯一性。 构造方法： TreeMap() 使用其键的自然排序构造一个新的TreeMap。 TreeMap(Comparator&lt;? super K&gt; comparator) 按照指定的比较器排序，构造一个新的TreeMap。 TreeMap(Map&lt;? extends K,? extends V&gt; m) 构造一个包含指定Map相同的映射，根据其键的自然顺序进行排序 。 TreeMap(SortedMap&lt;K,? extends V&gt; m) 构造一个包含m相同映射并使用与指定排序映射相同顺序的TreeMap。 主要方法： int size() 返回此集合中的键值映射的数量。 boolean containsKey(Object key) 判断是否包含指定的key。 boolean containsValue(Object value) 判断是否包含指定的value（一个或多个）。 V get(Object key) 返回指定键所映射的值，如果不包含该键的映射，返回null。 Comparator&lt;? super K&gt; comparator() 返回集合的构造器，如果集合使用的自然排序，返回null。 K firstKey() 返回当前集合中的第一个（最低）键。 K lastKey() 返回当前集合中的最后（最高）键。 void putAll(Map&lt;? extends K,? extends V&gt; map) 将指定map集合的所有映射复制到此集合中。 V put(K key, V value) 将指定的值与此映射中的指定键相关联。 如果集合已包含了该键的映射，则替换旧值。 V remove(Object key) 从TreeMap中删除此键的映射（如果存在）。 void clear() 删除所有的映射。 Map.Entry&lt;K,V&gt; firstEntry() 返回集合中的最小键相关联的键值映射，如果集合为空，返回 null 。 Map.Entry&lt;K,V&gt; lastEntry() 返回集合中的最大键相关联的键值映射，如果集合为空，返回 null 。Map.Entry&lt;K,V&gt; pollFirstEntry() 删除并返回集合中的最小键相关联的键值映射，如果集合为空，则返回 null 。 Map.Entry&lt;K,V&gt; pollLastEntry() 删除并返回集合中的最大键相关联的键值映射，如果集合为空，则返回 null 。 Map.Entry&lt;K,V&gt; lowerEntry(K key) 返回小于指定key的最大key的映射，如果没有这样的key，则返回 null 。 K lowerKey(K key) 返回小于指定key的最大key，如果没有这样的键，则返回 null 。 Map.Entry&lt;K,V&gt; floorEntry(K key) 返回小于或等于指定key的最大key相关联的键值映射，如果没有这样的key，则返回null 。 K floorKey(K key) 返回小于或等于给定key的最大key，如果没有这样的键，则返回 null 。 Map.Entry&lt;K,V&gt; ceilingEntry(K key) 返回大于或等于给定key的最小key相关联的键值映射，如果没有这样的key，则返回 null 。 K ceilingKey(K key) 返回大于或等于给定键的key，如果没有这样的key，则返回 null 。 Map.Entry&lt;K,V&gt; higherEntry(K key) 返回大于指定的key的最小key相关联的键值映射，如果没有这样的键，则 返回null 。 K higherKey(K key) 返回大于给定key的最小key，如果没有这样的key，则返回 null 。 Set keySet() 返回此集合中包含的键的Set视图。该视图支持经由Iterator.remove ， Set.remove ， removeAll ， retainAll和clear操作。 它不支持add或addAll操作。 NavigableSet navigableKeySet() 返回此集合中包含的键的NavigableSet视图。该视图支持经由Iterator.remove ， Set.remove ， removeAll ， retainAll和clear操作。 它不支持add或addAll操作。 NavigableSet descendingKeySet() 返回此集合中包含的键的相反顺序的NavigableSet 。同上。 Collection values() 返回一个Collection包含集合的值。 同上。 Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() 返回此集合中包含的映射的Set视图。 同上。 NavigableMap&lt;K,V&gt; descendingMap() 返回此映射中包含的映射的反向排序视图。 NavigableMap&lt;K,V&gt; subMap(K fromKey, boolean fromInclusive, K toKey, boolean toInclusive) 返回该集合2部分的视图，其关键范围为fromKey至toKey。 NavigableMap&lt;K,V&gt; headMap(K toKey, boolean inclusive) 返回此集合的部分视图，其键值小于（或等于，如果inclusive为true） toKey 。 NavigableMap&lt;K,V&gt; tailMap(K fromKey, boolean inclusive) 返回此集合的部分视图，其键大于（或等于，如果inclusive为true） fromKey 。 SortedMap&lt;K,V&gt; subMap(K fromKey, K toKey) 返回此集合的部分视图，其key范围为fromKey （含），不含toKey。 SortedMap&lt;K,V&gt; headMap(K toKey) 返回此集合的部分视图，其key小于toKey 。 SortedMap&lt;K,V&gt; tailMap(K fromKey) 返回此集合的部分视图，其key大于或等于fromKey 。 boolean replace(K key, V oldValue, V newValue) 仅当当前映射到指定的值时，才能替换指定键的条目。 V replace(K key, V value) 只有当目标key到某个值时，才能替换指定键的条目。 遍历：Iterator entrySet() keySet() values() descendingKeySet() descendingMap() 12345678910111213141516171819202122232425262728293031323334353637public static void byEntrySet(TreeMap&lt;String, Integer&gt; treeMap) { Set&lt;Entry&lt;String, Integer&gt;&gt; set = treeMap.entrySet(); for(Iterator&lt;Entry&lt;String, Integer&gt;&gt; iterator = set.iterator();iterator.hasNext();) { Entry&lt;String, Integer&gt; entry = iterator.next(); String key = entry.getKey(); Integer value = entry.getValue(); } } public static void byKeySet(TreeMap&lt;String, Integer&gt; treeMap) { Set&lt;String&gt; set = treeMap.keySet(); for(Iterator&lt;String&gt; iterator = set.iterator();iterator.hasNext();) { String key = iterator.next(); Integer value = treeMap.get(key); } } public static void byValues(TreeMap&lt;String, Integer&gt; treeMap) { Collection&lt;Integer&gt; collection = treeMap.values(); for (Iterator&lt;Integer&gt; iterator = collection.iterator(); iterator.hasNext();) { Integer value = iterator.next(); } } public static void byDescendingKeySet(TreeMap&lt;String, Integer&gt; treeMap) { NavigableSet&lt;String&gt; set = treeMap.descendingKeySet(); //key的反序。 for (Iterator&lt;String&gt; iterator = set.iterator(); iterator.hasNext();) { String key = iterator.next(); Integer value = treeMap.get(key); } } public static void byDescendingMap(TreeMap&lt;String, Integer&gt; treeMap) { NavigableMap&lt;String, Integer&gt; map = treeMap.descendingMap(); Set&lt;Entry&lt;String, Integer&gt;&gt; set = map.entrySet(); for (Iterator&lt;Entry&lt;String, Integer&gt;&gt; iterator = set.iterator(); iterator.hasNext();) { Entry&lt;String, Integer&gt; entry = iterator.next(); String key = entry.getKey(); Integer value = entry.getValue(); } }","link":"/2018/06/24/java/exercise/util/TreeMap/"},{"title":"TreeSet","text":"TreeSet继承自 AbstractSet ，实现了Set接口，底层数据结构是二叉树，实际是通过TreeMap实现的 ，可以对Set集合中的元素进行排序。 特点：元素是有序的，元素不允许为null，元素不会重复，线程不同步。 保证元素惟一性的原理：compareTo方法 return 0。 TreeSet支持两种排序方式： 一、元素的自然排序：即元素自身实现的Comparable接口，覆盖了compareTo方法，使自身具备了比较性。 123456789101112131415public class Student implements Comparable&lt;Student&gt; { private String name; private Integer age; //get、set... @Override public int compareTo(Student student) { int num = this.age.compareTo(student.getAge()); if (num == 0) { return this.name.compareTo(student.getName()); } return num; }} 二、比较器排序：即定义一个比较器类，实现Comparator接口，覆盖compare方法，将比较器对象作为参数传递给TreeSet集合的构造函数。 12345678910TreeSet&lt;Student&gt; set = new TreeSet&lt;&gt;(new Comparator&lt;Student&gt;() { @Override public int compare(Student s1, Student s2) { int num = s1.getAge().compareTo(s2.getAge()); if (num == 0) { return s1.getName().compareTo(s2.getName()); } return num; } }); 构造函数： TreeSet() 构造一个空的集合，根据其元素的自然排序进行排序。所有元素必须已实现Comparable接口。 TreeSet(Comparator&lt;? super E&gt; comparator) 构造一个空的集合，根据指定的比较器进行排序。 插入到集合中的所有元素由指定的比较器进行相互比较。 TreeSet(Collection&lt;? extends E&gt; c) 构造一个包含指定集合中的元素的新树集，根据其元素的自然排序进行排序 。插入到集合中的所有元素必须实现Comparable接口。 TreeSet(SortedSet s) 构造一个包含相同元素的新树，并使用与指定排序集相同的顺序。 主要方法： Iterator iterator() 以升序返回该集合中的元素的迭代器。 Iterator descendingIterator() 以降序返回该集合中的元素的迭代器。 NavigableSet descendingSet() 返回此集合中包含的元素的反向排序视图。 int size() 返回此集合中的元素数。 boolean isEmpty() 判断集合是否包含元素。 boolean contains(Object o) 判断此集合是否包含指定的元素 。 boolean add(E e) 将指定的元素添加到此集合（如果尚未存在）。 boolean remove(Object o) 从该集合中删除指定的元素，如果集合包含这个元素，则返回true。 void clear() 删除集合中所有元素。 boolean addAll(Collection&lt;? extends E&gt; c) 将指定集合中的所有元素添加到此集合中。 NavigableSet subSet(E fromElement, boolean fromInclusive, E toElement, boolean toInclusive) 返回此集合的部分的视图，其元素的范围从fromElement到toElement 。 NavigableSet headSet(E toElement, boolean inclusive) 返回此集合的部分的视图，其元素小于（或等于，如果inclusive为true） toElement 。 NavigableSet tailSet(E fromElement, boolean inclusive) 返回此集合的部分的视图，其元素大于（或等于，如果inclusive为true） fromElement 。 SortedSet subSet(E fromElement, E toElement) 返回此集合的部分的视图，其元素的范围从fromElement （包含）到toElement (不包含)。 Comparator&lt;? super E&gt; comparator() 返回用于对该集合中的元素进行排序的比较器，如果此集合元素使用自然排序则返回null。 E first() 返回此集合中当前的第一个（最低）元素。 E last() 返回此集合中当前的最后（最高）元素。 E lower(E e) 返回这个集合中最大的元素严格小于给定的元素，如果没有这样的元素，则返回 null 。 E floor(E e) 返回该集合中最大的元素小于或等于给定的元素，如果没有这样的元素，则返回 null 。 E ceiling(E e) 返回此集合中最小元素大于或等于给定元素，如果没有此元素则返回 null 。 E higher(E e) 返回此集中的最小元素严格大于给定元素，如果没有此元素，则返回 null 。 E pollFirst() 检索并删除第一个（最低）元素，如果此集合为空，则返回 null 。 E pollLast() 检索并删除最后一个（最高）元素，如果此集合为空，则返回 null 。 遍历：1、foreach2、迭代器（Iterator） 123456789101112131415161718192021222324252627282930313233343536import java.util.TreeSet;import java.util.Iterator;public class TreeSetDemo { public static void main(String[] args) { TreeSet&lt;Integer&gt; list = new TreeSet&lt;&gt;(); for(int i = 0; i &lt;10000;i++) { list.add(i); } byForeach(list); byIteratorAsc(list); byIteratorDesc(list); } public static void byForeach(TreeSet&lt;Integer&gt; list) { for (Integer integer : list) { ; } } public static void byIteratorAsc(TreeSet&lt;Integer&gt; list) { list.iterator(); for (Iterator&lt;Integer&gt; it = list.iterator(); it.hasNext();) { it.next(); } } public static void byIteratorDesc(TreeSet&lt;Integer&gt; list) { list.iterator(); for (Iterator&lt;Integer&gt; it = list.descendingIterator(); it.hasNext();) { it.next(); } }","link":"/2018/06/19/java/exercise/util/TreeSet/"},{"title":"vector","text":"Vector 继承自 AbstractList 特点:1、Vector 底层是数组数据结构。2、使用默认构造函数创建Vector时，默认容量大小是10。3、当Vector容量不足以容纳全部元素时，Vector的容量会增加。若容量增加系数 &gt;0，则将容量的值增加“容量增加系数”；否则，将容量大小增加一倍。4、Vector 是线程同步的。Vector几乎和ArrayList相等，主要的区别在于Vector是同步的。正因为此，Vector比ArrayList的开销更大。一般Vector就被ArrayList替代了。 构造方法： Vector() 构造一个空的集合，其内部数据数组的大小为 10 ，其标准容量增量为零。 Vector(int initialCapacity) 构造一个具有指定初始容量并且其容量增量等于零的空集合。 Vector(Collection&lt;? extends E&gt; c) 构造一个包含指定集合元素的集合，按照集合的迭代器返回的顺序。 主要方法： void copyInto(Object[] anArray) 将此集合中的元素复制到指定的数组中。 void trimToSize() 修改该向量的容量成为向量的当前大小。 void ensureCapacity(int minCapacity) 如果需要，增加此向量的容量，以确保它可以至少保存指定的最小容量参数元素数。 void setSize(int newSize) 设置此集合的大小。如果新容量小于当前容量，则丢弃索引newSize至当前容量的所有元素。 int capacity() 返回此集合的当前容量。 int size() 返回此集合中的元素数。 boolean isEmpty() 判断此集合是否有元素。 Enumeration elements() 返回此集合元素的枚举。 boolean contains(Object o) 判断此集合是否包含指定的元素。 int indexOf(Object o) 返回此集合中指定元素的第一次出现的索引，如果此集合不包含该元素，则返回-1。 int indexOf(Object o, int index) 返回此集合中从指定的位置处开始向后搜索指定元素的第一次出现的索引，如果未找到该元素，则返回-1。 int lastIndexOf(Object o) 返回此集合中指定元素的最后次出现的索引，如果此集合不包含该元素，则返回-1。 int lastIndexOf(Object o, int index) 返回此集合中从指定的位置开始向前搜索指定元素出现的索引，如果未找到该元素，则返回-1。 E elementAt(int index) 返回指定索引处的元素。 E firstElement() 返回此集合的第一个元素，如果集合为空，则抛出NoSuchElementException 异常。 E lastElement() 返回此集合的最后一个元素，如果集合为空，则抛出NoSuchElementException 异常。 void setElementAt(E obj, int index) 将该集合的指定index的元素设置为指定的对象。 void removeElementAt(int index) 删除指定索引处的元素。 void insertElementAt(E obj, int index) 在指定的index插入指定对象 。 void addElement(E obj) 将指定的元素添加到此集合的末尾。 boolean removeElement(Object obj) 从此集合中删除指定对象的第一次出现的此元素。等同于remove(Object)。 void removeAllElements() 从该集合中删除所有元素，并将其大小设置为零。 Object[] toArray() 以正确的顺序返回一个包含此Vector中所有元素的数组。 T[] toArray(T[] a) 以正确的顺序返回一个包含此Vector中所有元素的数组; 返回的数组的类型是指定数组的类型。 E get(int index) 返回此集合中指定位置的元素。 E set(int index, E element) 用指定的元素替换此集合中指定位置的元素。 boolean add(E e) 将指定的元素追加到此集合的末尾。 boolean remove(Object o) 删除此向量中指定元素的第一个出现的此元素，如果集合中不包含此元素，则不会更改。 void add(int index, E element) 在此集合r中的指定位置插入指定的元素。 E remove(int index) 删除此集合中指定位置的元素。 void clear() 删除集合中所有元素。 boolean containsAll(Collection&lt;?&gt; c) 判断此集合是否包含指定集合中的所有元素。 boolean addAll(Collection&lt;? extends E&gt; c) 将指定集合中的所有元素追加到该集合的末尾。 boolean removeAll(Collection&lt;?&gt; c) 从此集合中删除指定集合中包含的所有元素。 boolean retainAll(Collection&lt;?&gt; c) 仅保留此集合中与指定集合中相同的元素。 boolean addAll(int index, Collection&lt;? extends E&gt; c) 将指定集合中的所有元素插入到此集合中的指定位置。 List subList(int fromIndex, int toIndex )返回此集合中在fromIndex（包括）和toIndex之间的视图。 void removeRange(int fromIndex, int toIndex) 从此集合中删除索引为fromIndex （含）和toIndex之间的所有元素。 Iterator iterator() 返回该列表中的元素的迭代器。 ListIterator listIterator() 返回列表中的列表迭代器。 ListIterator listIterator(int index) 从列表中的指定位置开始，返回列表中的元素（按正确顺序）的列表迭代器。 遍历1、迭代器(Iterator和ListIterator)2、普通for循环3、foreach4、Enumeration遍历（特有的） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import java.util.Enumeration;import java.util.Iterator;import java.util.ListIterator;import java.util.Vector;public class VectorDemo { public static void main(String[] args) { Vector&lt;Integer&gt; list = new Vector&lt;Integer&gt;(); for (int i = 0; i &lt; 1000000; i++) { list.add(i); } byIterator(list); byListIterator(list); byFor(list); byForeach(list); byEnumeration(list); } public static void byIterator(Vector&lt;Integer&gt; list) { long start = System.currentTimeMillis(); for (Iterator&lt;Integer&gt; iterator = list.iterator(); iterator.hasNext();) { iterator.next(); } long end = System.currentTimeMillis(); System.out.println(\"iterator遍历消耗时间为：\" + (end - start) + \"ms\"); } public static void byListIterator(Vector&lt;Integer&gt; list) { long start = System.currentTimeMillis(); for (ListIterator&lt;Integer&gt; iterator = list.listIterator(); iterator.hasNext();) { iterator.next(); } long end = System.currentTimeMillis(); System.out.println(\"listIterator遍历消耗时间为：\" + (end - start) + \"ms\"); } public static void byFor(Vector&lt;Integer&gt; list) { long start = System.currentTimeMillis(); for (int i = 0; i &lt; list.size(); i++) { list.get(i); } long end = System.currentTimeMillis(); System.out.println(\"for循环遍历消耗时间为：\" + (end - start) + \"ms\"); } public static void byForeach(Vector&lt;Integer&gt; list) { long start = System.currentTimeMillis(); for (Integer integer : list) { ; } long end = System.currentTimeMillis(); System.out.println(\"foreach遍历消耗时间为：\" + (end - start) + \"ms\"); } public static void byEnumeration(Vector&lt;Integer&gt; list) { long start = System.currentTimeMillis(); Enumeration&lt;Integer&gt; enumeration = list.elements(); while (enumeration.hasMoreElements()) { enumeration.nextElement(); } long end = System.currentTimeMillis(); System.out.println(\"enumeration遍历消耗时间为：\" + (end - start) + \"ms\"); }} 输出： 12345iterator遍历消耗时间为：38mslistIterator遍历消耗时间为：38msfor循环遍历消耗时间为：34msforeach遍历消耗时间为：42msenumeration遍历消耗时间为：40ms 第二种普通for循环遍历效率最高。","link":"/2018/06/09/java/exercise/util/Vector/"},{"title":"集合框架","text":"Java 集合框架主要结构图 Iterator 接口集合的迭代器，为各种不同的数据结构提供统一的访问机制。主要方法： boolean hasNext() 判断是否存在下一个元素。 E next() 返回迭代中的下一个元素。 void remove() 删除当前指针所指向的元素。1234Iterator li = list.iterator(); while(li.hasNext()){ System.out.println(li.next()); } Java集合框架主要分为两类：Collection、Map Collection |–List:元素是有序的，元素可以重复，因为该集合体系有索引。 |–ArrayList:底层的数据结构使用的是数组结构。特点：查询速度很快，但是增删稍慢。线程不同步。 |–LinkedList:底层使用的链表数据结构。特点：增删速度很快，查询稍慢。 |–Vector:底层是数组数据结构。线程同步。被ArrayList替代了。 |–set:元素是无序的，元素不可以重复。 |–HashSet:底层数据结构是哈希表。 |–TreeSet:底层数据结构是二叉树。 Collection 接口是所有单列集合的共同父接口 主要方法： int size() 返回此集合中的元素数。 boolean isEmpty() 判断集合是否包含元素。 boolean contains(Object o) 如果此集合是否包含指定的元素。 boolean add(E e) 向集合中添加一个元素，成功返回true。 boolean remove(Object o) 从集合中删除指定的元素，成功返回true。 Iterator iterator() 返回此集合中的元素的迭代器。 boolean containsAll(Collection&lt;?&gt; c) 判断此集合是否包含指定集合中的所有元素。 boolean addAll(Collection&lt;? extends E&gt; c) 将指定集合中的所有元素添加到此集合中。 boolean removeAll(Collection&lt;?&gt; c) 删除集合中包含指定集合中的所有元素。 boolean retainAll(Collection&lt;?&gt; c) 保留两集合中共用的元素。如果集合有改变就返回true。 void clear() 清除集合中的所有元素。 Object[] toArray() 返回一个包含此集合中所有元素的数组。 T[] toArray(T[] a) 返回包含此集合中所有元素的数组; 返回的数组的运行时类型是指定数组的运行时类型。 List 接口 继承自Collection有序集合，可以通过索引操作元素。凡是可以操作角标的方法都是该体系特有的方法。特有方法（相对于Collection）： E get(int index) 返回此列表中指定位置的元素。 E set(int index, E element) 用指定的元素替换此集合中指定位置的元素。 void add(int index, E element) 将指定的元素插入此集合中的指定位置。 E remove(int index) 删除该列集合中指定位置的元素，后续元素左移。 int indexOf(Object o) 返回此集合中指定元素的第一次出现的索引，如果此集合不包含该元素，则返回-1。 int lastIndexOf(Object o) 此集合中指定元素的最后一次出现的索引，如果此集合不包含该元素，则返回-1。 ListIterator listIterator() 返回列表中的列表迭代器。 ListIterator listIterator(int index) 从集合中的指定位置开始，返回集合中的元素的集合迭代器。 List subList(int fromIndex, int toIndex) 返回集合中指定的fromIndex （含）和toIndex之间的部分视图。 ListIterator 接口 继承自Iterator List集合特有的迭代器。特点：1、允许向前、向后两个方向遍历 List。2、在遍历时可以进行添加，修改等操作。3、获取迭代器当前游标所在位置。特有方法（相对于ListIterator）： boolean hasPrevious() 判断是否存在前一个元素。 E previous() 返回迭代中的前一个元素。 int nextIndex() 返回游标后边元素的索引位置。 int previousIndex() 返回游标前边元素的索引位置。 void set(E e) 修改当前迭代的元素为e。 void add(E e) 在游标 前面 插入一个元素。 在迭代时，不可以通过集合对象的方法操作集合中的元素。因为会发生ConcurrentModificationException异常。所以在迭代时，只能用迭代器的方法操作元素，可是Iterator方法是有限的，只能对元素进行判断，取出，删除的操作。如果想要其它的操作如添加，修改等，就需要使用其子接口ListIterator。该接口只能通过List集合的listIterator方法获取。","link":"/2018/05/25/java/exercise/util/%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/"},{"title":"ubuntu-18.04-desktop问题","text":"ubuntu-18.04-desktop中遇到的问题（最小化安装 ） 1、休眠后无法唤醒 休眠后，就进不去系统了，目前解决办法是在设置里禁止休眠。 2、ifconfig命令not found 搜索说是ifconfig被抛弃了，被ip命令取代了。 1$ ip address 可缩写为 1$ ip a 可参考：https://www.sunzhongwei.com/ubuntu-1804-ifconfig-command-not-found?from=sidebar_related ​ https://news.ycombinator.com/item?id=17151046 方法二：可安装net-tools ，继续使用ifconfig 1$ apt-get install net-tools 3、ssh连不上 原因是ubuntu18.04默认没有安装ssh服务 。 使用一下命令进行安装： 1$ sudo apt-get install openssh-server 安装完成后,启动ssh服务 1$ sudo /etc/init.d/ssh start 查看ssh进程，若出现sshd，说明启动成功 1$ ps -ef|grep ssh 可参考：https://segmentfault.com/a/1190000015872297","link":"/2018/08/23/%E6%9C%8D%E5%8A%A1%E5%99%A8/ubuntu/18.04/ubuntu-desktop%E4%B8%AD%E9%97%AE%E9%A2%98/"},{"title":"ubuntu 18.04 server中配置静态IP","text":"ubuntu 18.04 server中配置静态IP，新的网络工具netplan的使用方法 最新发布的ubuntu18.04 server，启用了新的网络工具netplan，对于命令行配置网络参数跟之前的版本有比较大的差别，现在介绍如下： 1.其网络配置文件是放在/etc/netplan/50-cloud-init.yaml, 缺省是用dhcp方式， 如下： 123456network: ethernets: enp1s0: addresses: [] dhcp4: true version: 2 如果要配置静态地址，则需要修改此文件的想关内容，见如下的例子： 123456789network: ethernets: enp1s0: addresses: [192.168.1.80/24] dhcp4: false gateway4: 192.168.1.2 nameservers: addresses: [192.168.1.2] version: 2 使其生效： 1$ sudo netplan apply 如果配置有问题会报错，如果没问题，则会新的配置会立即生效。 注意：只是针对ubuntu18.04 Server版，对于18.04 desktop它缺省是使用NetworkManger来进行管理，可使用图形界面进行配置，其网络配置文件是保存在：/etc/NetworkManager/system-connections目录下的，跟Server版区别还是比较大的。 netplan 工具还有其它比较丰富的功能， 详细可参见其的说明文档，man netplan. 参考：http://forum.ubuntu.org.cn/viewtopic.php?t=487463","link":"/2018/08/24/%E6%9C%8D%E5%8A%A1%E5%99%A8/ubuntu/18.04/ubuntu-server%E4%B8%AD%E9%85%8D%E7%BD%AE%E9%9D%99%E6%80%81IP/"},{"title":"升级gcc/g++版本","text":"1、添加ppa源toolchain/test下已经有打包好的gcc，版本有4.x、5.0、6.0等，可以直接使用这个PPA升级gcc。 12sudo add-apt-repository ppa:ubuntu-toolchain-r/test sudo apt-get update 如果提示未安装，还需要先安装它的包 1sudo apt-get install software-properties-common 2、安装版本5+ 1sudo apt-get install gcc-5 g++-5 3、更新链接 12345update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 53 \\--slave /usr/bin/g++ g++ /usr/bin/g++-5 \\--slave /usr/bin/gcc-ar gcc-ar /usr/bin/gcc-ar-5 \\--slave /usr/bin/gcc-nm gcc-nm /usr/bin/gcc-nm-5 \\--slave /usr/bin/gcc-ranlib gcc-ranlib /usr/bin/gcc-ranlib-5 4、检查版本 1234567891011$ gcc --versiongcc (Ubuntu 5.5.0-12ubuntu1~14.04) 5.5.0 20171010Copyright (C) 2015 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.$ g++ --versiong++ (Ubuntu 5.5.0-12ubuntu1~14.04) 5.5.0 20171010Copyright (C) 2015 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. 参考：https://blog.csdn.net/betty13006159467/article/details/78394974","link":"/2018/05/02/%E6%9C%8D%E5%8A%A1%E5%99%A8/ubuntu/%E5%8D%87%E7%BA%A7gcc/g++%E7%89%88%E6%9C%AC/"}],"tags":[{"name":"其它","slug":"其它","link":"/tags/%E5%85%B6%E5%AE%83/"},{"name":"命令","slug":"命令","link":"/tags/%E5%91%BD%E4%BB%A4/"},{"name":"Clonezilla","slug":"Clonezilla","link":"/tags/Clonezilla/"},{"name":"codepush","slug":"codepush","link":"/tags/codepush/"},{"name":"nodejs","slug":"nodejs","link":"/tags/nodejs/"},{"name":"Jenkins","slug":"Jenkins","link":"/tags/Jenkins/"},{"name":"systemd","slug":"systemd","link":"/tags/systemd/"},{"name":"tomcat","slug":"tomcat","link":"/tags/tomcat/"},{"name":"RabbitMq","slug":"RabbitMq","link":"/tags/RabbitMq/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"Elasticsearch","slug":"Elasticsearch","link":"/tags/Elasticsearch/"},{"name":"搜索引擎","slug":"搜索引擎","link":"/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"},{"name":"Spring-boot","slug":"Spring-boot","link":"/tags/Spring-boot/"},{"name":"MongoDB","slug":"MongoDB","link":"/tags/MongoDB/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"反编译","slug":"反编译","link":"/tags/%E5%8F%8D%E7%BC%96%E8%AF%91/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"https","slug":"https","link":"/tags/https/"},{"name":"jasperreports","slug":"jasperreports","link":"/tags/jasperreports/"},{"name":"pdf","slug":"pdf","link":"/tags/pdf/"},{"name":"加密","slug":"加密","link":"/tags/%E5%8A%A0%E5%AF%86/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"rsync","slug":"rsync","link":"/tags/rsync/"},{"name":"同步","slug":"同步","link":"/tags/%E5%90%8C%E6%AD%A5/"},{"name":"sysv-rc-conf","slug":"sysv-rc-conf","link":"/tags/sysv-rc-conf/"},{"name":"ntp","slug":"ntp","link":"/tags/ntp/"},{"name":"selenium","slug":"selenium","link":"/tags/selenium/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"待补充","slug":"待补充","link":"/tags/%E5%BE%85%E8%A1%A5%E5%85%85/"},{"name":"服务器","slug":"服务器","link":"/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"samba","slug":"samba","link":"/tags/samba/"},{"name":"一言","slug":"一言","link":"/tags/%E4%B8%80%E8%A8%80/"},{"name":"工具","slug":"工具","link":"/tags/%E5%B7%A5%E5%85%B7/"},{"name":"cwRsyncServer","slug":"cwRsyncServer","link":"/tags/cwRsyncServer/"},{"name":"inotify","slug":"inotify","link":"/tags/inotify/"},{"name":"工作","slug":"工作","link":"/tags/%E5%B7%A5%E4%BD%9C/"},{"name":"Jmeter","slug":"Jmeter","link":"/tags/Jmeter/"},{"name":"fastdfs","slug":"fastdfs","link":"/tags/fastdfs/"},{"name":"Windows","slug":"Windows","link":"/tags/Windows/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"日志","slug":"日志","link":"/tags/%E6%97%A5%E5%BF%97/"},{"name":"漏洞","slug":"漏洞","link":"/tags/%E6%BC%8F%E6%B4%9E/"},{"name":"服务部署","slug":"服务部署","link":"/tags/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"},{"name":"缓存","slug":"缓存","link":"/tags/%E7%BC%93%E5%AD%98/"},{"name":"OCR","slug":"OCR","link":"/tags/OCR/"},{"name":"爬虫","slug":"爬虫","link":"/tags/%E7%88%AC%E8%99%AB/"},{"name":"总结","slug":"总结","link":"/tags/%E6%80%BB%E7%BB%93/"},{"name":"生活","slug":"生活","link":"/tags/%E7%94%9F%E6%B4%BB/"},{"name":"keepalived","slug":"keepalived","link":"/tags/keepalived/"},{"name":"mongodb","slug":"mongodb","link":"/tags/mongodb/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"java8","slug":"java8","link":"/tags/java8/"},{"name":"spring-boot","slug":"spring-boot","link":"/tags/spring-boot/"},{"name":"HttpClient","slug":"HttpClient","link":"/tags/HttpClient/"},{"name":"json","slug":"json","link":"/tags/json/"},{"name":"SoapUI","slug":"SoapUI","link":"/tags/SoapUI/"},{"name":"webservice","slug":"webservice","link":"/tags/webservice/"},{"name":"jmeter","slug":"jmeter","link":"/tags/jmeter/"},{"name":"webscoket","slug":"webscoket","link":"/tags/webscoket/"},{"name":"linux命令","slug":"linux命令","link":"/tags/linux%E5%91%BD%E4%BB%A4/"},{"name":"rc.local","slug":"rc-local","link":"/tags/rc-local/"},{"name":"scp","slug":"scp","link":"/tags/scp/"},{"name":"HTTPS","slug":"HTTPS","link":"/tags/HTTPS/"},{"name":"nginx配置","slug":"nginx配置","link":"/tags/nginx%E9%85%8D%E7%BD%AE/"},{"name":"共鸣","slug":"共鸣","link":"/tags/%E5%85%B1%E9%B8%A3/"},{"name":"frp","slug":"frp","link":"/tags/frp/"},{"name":"内网穿透","slug":"内网穿透","link":"/tags/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"name":"ngrok","slug":"ngrok","link":"/tags/ngrok/"},{"name":"数据结构于算法","slug":"数据结构于算法","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%BA%8E%E7%AE%97%E6%B3%95/"},{"name":"备份","slug":"备份","link":"/tags/%E5%A4%87%E4%BB%BD/"},{"name":"aggregate","slug":"aggregate","link":"/tags/aggregate/"},{"name":"数据操作","slug":"数据操作","link":"/tags/%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C/"},{"name":"聚合统计","slug":"聚合统计","link":"/tags/%E8%81%9A%E5%90%88%E7%BB%9F%E8%AE%A1/"},{"name":"PowerDesigner","slug":"PowerDesigner","link":"/tags/PowerDesigner/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"oracle","slug":"oracle","link":"/tags/oracle/"},{"name":"ubuntu","slug":"ubuntu","link":"/tags/ubuntu/"},{"name":"HLS","slug":"HLS","link":"/tags/HLS/"},{"name":"RTMP","slug":"RTMP","link":"/tags/RTMP/"},{"name":"SRS","slug":"SRS","link":"/tags/SRS/"},{"name":"svn","slug":"svn","link":"/tags/svn/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"游泳","slug":"游泳","link":"/tags/%E6%B8%B8%E6%B3%B3/"},{"name":"单元测试","slug":"单元测试","link":"/tags/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"},{"name":"21天","slug":"21天","link":"/tags/21%E5%A4%A9/"},{"name":"IO流","slug":"IO流","link":"/tags/IO%E6%B5%81/"},{"name":"20天","slug":"20天","link":"/tags/20%E5%A4%A9/"},{"name":"IO","slug":"IO","link":"/tags/IO/"},{"name":"集合","slug":"集合","link":"/tags/%E9%9B%86%E5%90%88/"}],"categories":[{"name":"其它","slug":"其它","link":"/categories/%E5%85%B6%E5%AE%83/"},{"name":"系统克隆","slug":"系统克隆","link":"/categories/%E7%B3%BB%E7%BB%9F%E5%85%8B%E9%9A%86/"},{"name":"codepush","slug":"codepush","link":"/categories/codepush/"},{"name":"Jenkins","slug":"Jenkins","link":"/categories/Jenkins/"},{"name":"RabbitMq","slug":"RabbitMq","link":"/categories/RabbitMq/"},{"name":"docker","slug":"docker","link":"/categories/docker/"},{"name":"Elasticsearch","slug":"Elasticsearch","link":"/categories/Elasticsearch/"},{"name":"hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"Java基础","slug":"Java基础","link":"/categories/Java%E5%9F%BA%E7%A1%80/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"工作","slug":"工作","link":"/categories/%E5%B7%A5%E4%BD%9C/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"nginx","slug":"nginx","link":"/categories/nginx/"},{"name":"python","slug":"python","link":"/categories/python/"},{"name":"samba","slug":"samba","link":"/categories/samba/"},{"name":"一言","slug":"一言","link":"/categories/%E4%B8%80%E8%A8%80/"},{"name":"工具","slug":"工具","link":"/categories/%E5%B7%A5%E5%85%B7/"},{"name":"同步","slug":"同步","link":"/categories/%E5%90%8C%E6%AD%A5/"},{"name":"服务器","slug":"服务器","link":"/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"http","slug":"http","link":"/categories/http/"},{"name":"OCR","slug":"OCR","link":"/categories/OCR/"},{"name":"爬虫","slug":"爬虫","link":"/categories/%E7%88%AC%E8%99%AB/"},{"name":"生活","slug":"生活","link":"/categories/%E7%94%9F%E6%B4%BB/"},{"name":"keepalived","slug":"keepalived","link":"/categories/keepalived/"},{"name":"Spring-boot","slug":"Spring-boot","link":"/categories/Spring-boot/"},{"name":"webscoket","slug":"webscoket","link":"/categories/webscoket/"},{"name":"HTTPS","slug":"HTTPS","link":"/categories/HTTPS/"},{"name":"杂文","slug":"杂文","link":"/categories/%E6%9D%82%E6%96%87/"},{"name":"内网穿通","slug":"内网穿通","link":"/categories/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%9A/"},{"name":"内网穿透","slug":"内网穿透","link":"/categories/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"name":"数据结构于算法","slug":"数据结构于算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%BA%8E%E7%AE%97%E6%B3%95/"},{"name":"MongoDB","slug":"MongoDB","link":"/categories/MongoDB/"},{"name":"mongodb","slug":"mongodb","link":"/categories/mongodb/"},{"name":"mysql","slug":"mysql","link":"/categories/mysql/"},{"name":"oracle","slug":"oracle","link":"/categories/oracle/"},{"name":"redis","slug":"redis","link":"/categories/redis/"},{"name":"ubuntu","slug":"ubuntu","link":"/categories/ubuntu/"},{"name":"流媒体","slug":"流媒体","link":"/categories/%E6%B5%81%E5%AA%92%E4%BD%93/"},{"name":"svn","slug":"svn","link":"/categories/svn/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"exercise","slug":"exercise","link":"/categories/exercise/"}]}